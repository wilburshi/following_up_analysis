{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1849ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import string\n",
    "import warnings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819c438",
   "metadata": {},
   "source": [
    "# load video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab92aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d analyzed video path\n",
    "camera12_analyzed_path = \"/ysm-gpfs/pi/jadi/VideoTracker_SocialInter/test_video_cooperative_task_3d/20221021_Dodson_Scorch_camera12/\"\n",
    "camera23_analyzed_path = \"/ysm-gpfs/pi/jadi/VideoTracker_SocialInter/test_video_cooperative_task_3d/20221021_Dodson_Scorch_camera23/\"\n",
    "\n",
    "# h5 files for the analyzed videos\n",
    "camera12_h5_file = camera12_analyzed_path + \"20221021_Dodson_Scorch_weikang.h5\"\n",
    "camera23_h5_file = camera23_analyzed_path + \"20221021_Dodson_Scorch_weikang.h5\"\n",
    "\n",
    "# h5 files for save \n",
    "camera12_h5_file_save = camera12_analyzed_path + \"20221021_Dodson_Scorch_weikang.h5\"\n",
    "camera23_h5_file_save = camera23_analyzed_path + \"20221021_Dodson_Scorch_weikang.h5\"\n",
    "\n",
    "# meta pickle data for the analyzed videos\n",
    "camera12_metapickle_file = camera12_analyzed_path + \"20221021_Dodson_Scorch_weikang_meta.pickle\"\n",
    "camera23_metapickle_file = camera23_analyzed_path + \"20221021_Dodson_Scorch_weikang_meta.pickle\"\n",
    "\n",
    "# load data\n",
    "camera12_metapickle_data = pd.read_pickle(camera12_metapickle_file)\n",
    "camera23_metapickle_data = pd.read_pickle(camera23_metapickle_file)\n",
    "\n",
    "camera12_h5_data = pd.read_hdf(camera12_h5_file)\n",
    "camera23_h5_data = pd.read_hdf(camera23_h5_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd88ea1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th colspan=\"21\" halign=\"left\">weikang</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>individuals</th>\n",
       "      <th colspan=\"10\" halign=\"left\">dodson</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">scorch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodyparts</th>\n",
       "      <th colspan=\"3\" halign=\"left\">rightTuft</th>\n",
       "      <th colspan=\"3\" halign=\"left\">whiteBlaze</th>\n",
       "      <th colspan=\"3\" halign=\"left\">leftTuft</th>\n",
       "      <th>rightEye</th>\n",
       "      <th>...</th>\n",
       "      <th>leftTuft</th>\n",
       "      <th colspan=\"3\" halign=\"left\">rightEye</th>\n",
       "      <th colspan=\"3\" halign=\"left\">leftEye</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mouth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coords</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x</th>\n",
       "      <th>...</th>\n",
       "      <th>z</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.696560</td>\n",
       "      <td>-4.018318</td>\n",
       "      <td>14.963746</td>\n",
       "      <td>0.009465</td>\n",
       "      <td>-3.663745</td>\n",
       "      <td>14.099358</td>\n",
       "      <td>0.893506</td>\n",
       "      <td>-3.816093</td>\n",
       "      <td>14.370619</td>\n",
       "      <td>-0.252350</td>\n",
       "      <td>...</td>\n",
       "      <td>15.880178</td>\n",
       "      <td>-13.265951</td>\n",
       "      <td>-4.071291</td>\n",
       "      <td>15.542177</td>\n",
       "      <td>-12.656909</td>\n",
       "      <td>-4.157362</td>\n",
       "      <td>15.548583</td>\n",
       "      <td>-12.884651</td>\n",
       "      <td>-3.525301</td>\n",
       "      <td>15.446373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.647515</td>\n",
       "      <td>-3.981180</td>\n",
       "      <td>14.939265</td>\n",
       "      <td>0.154275</td>\n",
       "      <td>-3.651347</td>\n",
       "      <td>14.042189</td>\n",
       "      <td>0.987550</td>\n",
       "      <td>-3.781943</td>\n",
       "      <td>14.311720</td>\n",
       "      <td>-0.190110</td>\n",
       "      <td>...</td>\n",
       "      <td>15.984202</td>\n",
       "      <td>-13.198664</td>\n",
       "      <td>-4.100332</td>\n",
       "      <td>15.660053</td>\n",
       "      <td>-12.552555</td>\n",
       "      <td>-4.165422</td>\n",
       "      <td>15.571532</td>\n",
       "      <td>-12.799645</td>\n",
       "      <td>-3.521928</td>\n",
       "      <td>15.424392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.531466</td>\n",
       "      <td>-3.906518</td>\n",
       "      <td>14.753322</td>\n",
       "      <td>0.185989</td>\n",
       "      <td>-3.611261</td>\n",
       "      <td>13.910244</td>\n",
       "      <td>1.108637</td>\n",
       "      <td>-3.760516</td>\n",
       "      <td>14.188433</td>\n",
       "      <td>-0.086830</td>\n",
       "      <td>...</td>\n",
       "      <td>15.910983</td>\n",
       "      <td>-13.085751</td>\n",
       "      <td>-4.103259</td>\n",
       "      <td>15.673517</td>\n",
       "      <td>-12.538184</td>\n",
       "      <td>-4.165236</td>\n",
       "      <td>15.632013</td>\n",
       "      <td>-12.696983</td>\n",
       "      <td>-3.535244</td>\n",
       "      <td>15.406340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.475985</td>\n",
       "      <td>-3.897549</td>\n",
       "      <td>14.688633</td>\n",
       "      <td>0.357953</td>\n",
       "      <td>-3.624870</td>\n",
       "      <td>13.913673</td>\n",
       "      <td>1.217632</td>\n",
       "      <td>-3.774356</td>\n",
       "      <td>14.276051</td>\n",
       "      <td>-0.007639</td>\n",
       "      <td>...</td>\n",
       "      <td>15.935396</td>\n",
       "      <td>-13.061450</td>\n",
       "      <td>-4.100812</td>\n",
       "      <td>15.662766</td>\n",
       "      <td>-12.420274</td>\n",
       "      <td>-4.154008</td>\n",
       "      <td>15.635004</td>\n",
       "      <td>-12.673907</td>\n",
       "      <td>-3.573702</td>\n",
       "      <td>15.503886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.407943</td>\n",
       "      <td>-3.843532</td>\n",
       "      <td>14.524401</td>\n",
       "      <td>0.415275</td>\n",
       "      <td>-3.514587</td>\n",
       "      <td>13.818576</td>\n",
       "      <td>1.267234</td>\n",
       "      <td>-3.748719</td>\n",
       "      <td>14.079669</td>\n",
       "      <td>0.104385</td>\n",
       "      <td>...</td>\n",
       "      <td>16.032550</td>\n",
       "      <td>-13.032284</td>\n",
       "      <td>-4.091192</td>\n",
       "      <td>15.677381</td>\n",
       "      <td>-12.366363</td>\n",
       "      <td>-4.161614</td>\n",
       "      <td>15.627819</td>\n",
       "      <td>-12.615909</td>\n",
       "      <td>-3.577841</td>\n",
       "      <td>15.490071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21235</th>\n",
       "      <td>-13.233135</td>\n",
       "      <td>-2.460828</td>\n",
       "      <td>20.247742</td>\n",
       "      <td>-12.135802</td>\n",
       "      <td>-2.448265</td>\n",
       "      <td>20.077989</td>\n",
       "      <td>-11.316481</td>\n",
       "      <td>-2.688163</td>\n",
       "      <td>20.595004</td>\n",
       "      <td>-12.416928</td>\n",
       "      <td>...</td>\n",
       "      <td>13.363206</td>\n",
       "      <td>-0.820131</td>\n",
       "      <td>-4.766105</td>\n",
       "      <td>13.388783</td>\n",
       "      <td>-0.340932</td>\n",
       "      <td>-4.833331</td>\n",
       "      <td>13.079432</td>\n",
       "      <td>-0.637742</td>\n",
       "      <td>-4.231434</td>\n",
       "      <td>12.954199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21236</th>\n",
       "      <td>-13.235138</td>\n",
       "      <td>-2.463566</td>\n",
       "      <td>20.234137</td>\n",
       "      <td>-12.136569</td>\n",
       "      <td>-2.448545</td>\n",
       "      <td>20.074374</td>\n",
       "      <td>-11.317740</td>\n",
       "      <td>-2.691973</td>\n",
       "      <td>20.589399</td>\n",
       "      <td>-12.421200</td>\n",
       "      <td>...</td>\n",
       "      <td>13.365778</td>\n",
       "      <td>-0.818904</td>\n",
       "      <td>-4.762874</td>\n",
       "      <td>13.379453</td>\n",
       "      <td>-0.329168</td>\n",
       "      <td>-4.843523</td>\n",
       "      <td>13.088750</td>\n",
       "      <td>-0.636319</td>\n",
       "      <td>-4.226453</td>\n",
       "      <td>12.943908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21237</th>\n",
       "      <td>-13.225809</td>\n",
       "      <td>-2.471071</td>\n",
       "      <td>20.212991</td>\n",
       "      <td>-12.137196</td>\n",
       "      <td>-2.448717</td>\n",
       "      <td>20.071244</td>\n",
       "      <td>-11.301086</td>\n",
       "      <td>-2.677814</td>\n",
       "      <td>20.550371</td>\n",
       "      <td>-12.419437</td>\n",
       "      <td>...</td>\n",
       "      <td>13.359001</td>\n",
       "      <td>-0.818833</td>\n",
       "      <td>-4.764714</td>\n",
       "      <td>13.378226</td>\n",
       "      <td>-0.326590</td>\n",
       "      <td>-4.841772</td>\n",
       "      <td>13.090184</td>\n",
       "      <td>-0.549640</td>\n",
       "      <td>-4.292379</td>\n",
       "      <td>13.014903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21238</th>\n",
       "      <td>-13.226215</td>\n",
       "      <td>-2.472156</td>\n",
       "      <td>20.210587</td>\n",
       "      <td>-12.137989</td>\n",
       "      <td>-2.448773</td>\n",
       "      <td>20.067408</td>\n",
       "      <td>-11.308278</td>\n",
       "      <td>-2.681913</td>\n",
       "      <td>20.518526</td>\n",
       "      <td>-12.419854</td>\n",
       "      <td>...</td>\n",
       "      <td>13.354898</td>\n",
       "      <td>-0.820103</td>\n",
       "      <td>-4.767100</td>\n",
       "      <td>13.377514</td>\n",
       "      <td>-0.326705</td>\n",
       "      <td>-4.841895</td>\n",
       "      <td>13.090087</td>\n",
       "      <td>-0.550832</td>\n",
       "      <td>-4.296389</td>\n",
       "      <td>13.014305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21239</th>\n",
       "      <td>-13.226929</td>\n",
       "      <td>-2.476274</td>\n",
       "      <td>20.205335</td>\n",
       "      <td>-12.138200</td>\n",
       "      <td>-2.451271</td>\n",
       "      <td>20.067163</td>\n",
       "      <td>-11.309526</td>\n",
       "      <td>-2.681434</td>\n",
       "      <td>20.512998</td>\n",
       "      <td>-12.421625</td>\n",
       "      <td>...</td>\n",
       "      <td>13.352129</td>\n",
       "      <td>-0.820164</td>\n",
       "      <td>-4.772786</td>\n",
       "      <td>13.378347</td>\n",
       "      <td>-0.328718</td>\n",
       "      <td>-4.866852</td>\n",
       "      <td>13.159334</td>\n",
       "      <td>-0.557224</td>\n",
       "      <td>-4.309215</td>\n",
       "      <td>13.022811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21240 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "scorer         weikang                                                       \\\n",
       "individuals     dodson                                                        \n",
       "bodyparts    rightTuft                      whiteBlaze                        \n",
       "coords               x         y          z          x         y          z   \n",
       "0            -0.696560 -4.018318  14.963746   0.009465 -3.663745  14.099358   \n",
       "1            -0.647515 -3.981180  14.939265   0.154275 -3.651347  14.042189   \n",
       "2            -0.531466 -3.906518  14.753322   0.185989 -3.611261  13.910244   \n",
       "3            -0.475985 -3.897549  14.688633   0.357953 -3.624870  13.913673   \n",
       "4            -0.407943 -3.843532  14.524401   0.415275 -3.514587  13.818576   \n",
       "...                ...       ...        ...        ...       ...        ...   \n",
       "21235       -13.233135 -2.460828  20.247742 -12.135802 -2.448265  20.077989   \n",
       "21236       -13.235138 -2.463566  20.234137 -12.136569 -2.448545  20.074374   \n",
       "21237       -13.225809 -2.471071  20.212991 -12.137196 -2.448717  20.071244   \n",
       "21238       -13.226215 -2.472156  20.210587 -12.137989 -2.448773  20.067408   \n",
       "21239       -13.226929 -2.476274  20.205335 -12.138200 -2.451271  20.067163   \n",
       "\n",
       "scorer                                                  ...             \\\n",
       "individuals                                             ...     scorch   \n",
       "bodyparts     leftTuft                        rightEye  ...   leftTuft   \n",
       "coords               x         y          z          x  ...          z   \n",
       "0             0.893506 -3.816093  14.370619  -0.252350  ...  15.880178   \n",
       "1             0.987550 -3.781943  14.311720  -0.190110  ...  15.984202   \n",
       "2             1.108637 -3.760516  14.188433  -0.086830  ...  15.910983   \n",
       "3             1.217632 -3.774356  14.276051  -0.007639  ...  15.935396   \n",
       "4             1.267234 -3.748719  14.079669   0.104385  ...  16.032550   \n",
       "...                ...       ...        ...        ...  ...        ...   \n",
       "21235       -11.316481 -2.688163  20.595004 -12.416928  ...  13.363206   \n",
       "21236       -11.317740 -2.691973  20.589399 -12.421200  ...  13.365778   \n",
       "21237       -11.301086 -2.677814  20.550371 -12.419437  ...  13.359001   \n",
       "21238       -11.308278 -2.681913  20.518526 -12.419854  ...  13.354898   \n",
       "21239       -11.309526 -2.681434  20.512998 -12.421625  ...  13.352129   \n",
       "\n",
       "scorer                                                                       \\\n",
       "individuals                                                                   \n",
       "bodyparts     rightEye                         leftEye                        \n",
       "coords               x         y          z          x         y          z   \n",
       "0           -13.265951 -4.071291  15.542177 -12.656909 -4.157362  15.548583   \n",
       "1           -13.198664 -4.100332  15.660053 -12.552555 -4.165422  15.571532   \n",
       "2           -13.085751 -4.103259  15.673517 -12.538184 -4.165236  15.632013   \n",
       "3           -13.061450 -4.100812  15.662766 -12.420274 -4.154008  15.635004   \n",
       "4           -13.032284 -4.091192  15.677381 -12.366363 -4.161614  15.627819   \n",
       "...                ...       ...        ...        ...       ...        ...   \n",
       "21235        -0.820131 -4.766105  13.388783  -0.340932 -4.833331  13.079432   \n",
       "21236        -0.818904 -4.762874  13.379453  -0.329168 -4.843523  13.088750   \n",
       "21237        -0.818833 -4.764714  13.378226  -0.326590 -4.841772  13.090184   \n",
       "21238        -0.820103 -4.767100  13.377514  -0.326705 -4.841895  13.090087   \n",
       "21239        -0.820164 -4.772786  13.378347  -0.328718 -4.866852  13.159334   \n",
       "\n",
       "scorer                                       \n",
       "individuals                                  \n",
       "bodyparts        mouth                       \n",
       "coords               x         y          z  \n",
       "0           -12.884651 -3.525301  15.446373  \n",
       "1           -12.799645 -3.521928  15.424392  \n",
       "2           -12.696983 -3.535244  15.406340  \n",
       "3           -12.673907 -3.573702  15.503886  \n",
       "4           -12.615909 -3.577841  15.490071  \n",
       "...                ...       ...        ...  \n",
       "21235        -0.637742 -4.231434  12.954199  \n",
       "21236        -0.636319 -4.226453  12.943908  \n",
       "21237        -0.549640 -4.292379  13.014903  \n",
       "21238        -0.550832 -4.296389  13.014305  \n",
       "21239        -0.557224 -4.309215  13.022811  \n",
       "\n",
       "[21240 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera12_h5_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b59b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.97002997002997"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the fps of the analyzed video\n",
    "import cv2\n",
    "video_cam1_file = camera12_analyzed_path + \"20221021_Dodson_Scorch_camera-1.mp4\"\n",
    "cam = cv2.VideoCapture(video_cam1_file)\n",
    "fps1 = cam.get(cv2.CAP_PROP_FPS)\n",
    "video_cam2_file = camera12_analyzed_path + \"20221021_Dodson_Scorch_camera-2.mp4\"\n",
    "cam = cv2.VideoCapture(video_cam2_file)\n",
    "fps2 = cam.get(cv2.CAP_PROP_FPS)\n",
    "fps = fps1\n",
    "fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01a7a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aligned with the audio\n",
    "# get the session start time from \"videosound_bhv_sync.py/.ipynb\"\n",
    "# currently the session_start_time will be manually typed in. It can be updated after a better method is used\n",
    "session_start_time = 27.10 # in second\n",
    "session_start_frame = session_start_time * fps # fps is 30Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0bc3e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaze angle threshold\n",
    "# angle_thres = np.pi/36 # 5 degree\n",
    "angle_thres = np.pi/18 # 10 degree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e00fff",
   "metadata": {},
   "source": [
    "# analyze based on camera 1 and camera 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9276cd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dodson' 'scorch']\n",
      "['rightTuft' 'whiteBlaze' 'leftTuft' 'rightEye' 'leftEye' 'mouth']\n",
      "['x' 'y' 'z']\n"
     ]
    }
   ],
   "source": [
    "# analysis - camera 1 and 2\n",
    "ncols = camera12_h5_data.shape[1]\n",
    "nframes = camera12_h5_data.shape[0]\n",
    "animal_names = []\n",
    "body_parts = []\n",
    "xyz_axis = []\n",
    "\n",
    "for i in np.arange(0,ncols,1):\n",
    "    animal_names.append(camera12_h5_data.columns[i][1])\n",
    "    body_parts.append(camera12_h5_data.columns[i][2])\n",
    "    xyz_axis.append(camera12_h5_data.columns[i][3])\n",
    "  \n",
    "    # fill in the nan data point\n",
    "    data_point = camera12_h5_data.iloc[:,i]\n",
    "    data_point_filled = data_point.interpolate(method='nearest',limit_direction='both')\n",
    "    data_point_filled = data_point_filled.interpolate(method='linear',limit_direction='both')\n",
    "    # smooth the data point   \n",
    "    # data_point_filtered = data_point_filled.rolling(window=5, win_type='gaussian', center=True).mean(std=0.5)\n",
    "    #\n",
    "    # camera12_h5_data.iloc[:,i] = data_point_filled\n",
    "    \n",
    "animal_names_unique = pd.unique(animal_names)\n",
    "print(animal_names_unique)\n",
    "body_parts_unique = pd.unique(body_parts)\n",
    "print(body_parts_unique)\n",
    "xyz_axis_unique = pd.unique(xyz_axis)\n",
    "print(xyz_axis_unique)\n",
    "\n",
    "# camera12_h5_data.to_hdf(camera12_h5_file_save, key = \"camera12_h5_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1025808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the location of each body part\n",
    "body_part_locs = {}\n",
    "for iname in animal_names_unique:\n",
    "    for ibody in body_parts_unique:\n",
    "        ind = np.isin(animal_names,iname) & np.isin(body_parts,ibody)\n",
    "        body_part_locs[(iname,ibody)] = camera12_h5_data.iloc[:,ind]  \n",
    "        \n",
    "        # remove the outlier \n",
    "        for iaxis in np.arange(0,3,1):\n",
    "            # loc_std = np.std(body_part_locs[(iname,ibody)])[iaxis]\n",
    "            # loc_mean = pd.DataFrame.mean(body_part_locs[(iname,ibody)])[iaxis]\n",
    "            # ind = (body_part_locs[(iname,ibody)].iloc[:,iaxis]>loc_mean+3*loc_std) | (body_part_locs[(iname,ibody)].iloc[:,iaxis]<loc_mean-3*loc_std)\n",
    "            # body_part_locs[(iname,ibody)].iloc[:,iaxis][ind] = np.nan\n",
    "            q1 = np.nanquantile(body_part_locs[(iname,ibody)].iloc[:,iaxis],0.25)\n",
    "            q3 = np.nanquantile(body_part_locs[(iname,ibody)].iloc[:,iaxis],0.75)\n",
    "            thres1 = q1 - 1.5*abs(q3-q1)\n",
    "            thres2 = q3 + 1.5*abs(q3-q1)\n",
    "            ind = (body_part_locs[(iname,ibody)].iloc[:,iaxis]>thres2) | (body_part_locs[(iname,ibody)].iloc[:,iaxis]<thres1)\n",
    "            body_part_locs[(iname,ibody)].iloc[:,iaxis][ind] = np.nan\n",
    "            \n",
    "body_part_locs_camera12 = body_part_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ff172",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "eye_direction_camera12 = {}\n",
    "eye_contact_or_not_camera12 = {}\n",
    "look_at_face_or_not_camera12 = {}\n",
    "for iname in animal_names_unique:\n",
    "    eye_dir_frames = []\n",
    "    eye_contact_frames = []\n",
    "    look_at_face_frames = []\n",
    "    for iframe in np.arange(0,nframes,1):\n",
    "        lefteye_loc = body_part_locs[(iname,'leftEye')].iloc[iframe,:].to_numpy()\n",
    "        righteye_loc = body_part_locs[(iname,'rightEye')].iloc[iframe,:].to_numpy()\n",
    "        lefttuft_loc = body_part_locs[(iname,'leftTuft')].iloc[iframe,:].to_numpy()\n",
    "        righttuft_loc = body_part_locs[(iname,'rightTuft')].iloc[iframe,:].to_numpy()\n",
    "        whiblz_loc = body_part_locs[(iname,'whiteBlaze')].iloc[iframe,:].to_numpy()\n",
    "        mouth_loc = body_part_locs[(iname,'mouth')].iloc[iframe,:].to_numpy()\n",
    "        \n",
    "        Vect1 = lefteye_loc - righteye_loc\n",
    "        Vect2 = whiblz_loc - mouth_loc\n",
    "        Vect3 = lefttuft_loc - lefteye_loc\n",
    "        Vect4 = righttuft_loc - righteye_loc\n",
    "        \n",
    "        try:       \n",
    "            Vect1 = Vect1 / scipy.linalg.norm(Vect1)\n",
    "            Vect2 = Vect2 / scipy.linalg.norm(Vect2) \n",
    "        except:\n",
    "            Vect1 = Vect1\n",
    "            Vect2 = Vect2\n",
    "        eyesight_dir = np.cross(Vect1, Vect2)\n",
    "        \n",
    "        if ((np.dot(eyesight_dir, Vect3)>0) | (np.dot(eyesight_dir, Vect4)>0)):\n",
    "            eyesight_dir = -eyesight_dir\n",
    "        \n",
    "        eye_dir_frames.append(eyesight_dir)\n",
    "        \n",
    "        \n",
    "        # examine whether this animal is looking at the other's eyes or face\n",
    "        if (iname == animal_names_unique[0]): \n",
    "            iname_other = animal_names_unique[1]\n",
    "        elif (iname == animal_names_unique[1]): \n",
    "            iname_other = animal_names_unique[0]\n",
    "            \n",
    "        lefteye_loc_other = body_part_locs[(iname_other,'leftEye')].iloc[iframe,:].to_numpy()\n",
    "        righteye_loc_other = body_part_locs[(iname_other,'rightEye')].iloc[iframe,:].to_numpy()\n",
    "        lefttuft_loc_other = body_part_locs[(iname_other,'leftTuft')].iloc[iframe,:].to_numpy()\n",
    "        righttuft_loc_other = body_part_locs[(iname_other,'rightTuft')].iloc[iframe,:].to_numpy()\n",
    "        whiblz_loc_other = body_part_locs[(iname_other,'whiteBlaze')].iloc[iframe,:].to_numpy()\n",
    "        mouth_loc_other = body_part_locs[(iname_other,'mouth')].iloc[iframe,:].to_numpy()\n",
    "        \n",
    "        # where left eye is looking\n",
    "        # vector between body part\n",
    "        vect1_lefteye = lefteye_loc_other - lefteye_loc\n",
    "        vect2_lefteye = righteye_loc_other - lefteye_loc\n",
    "        vect3_lefteye = lefttuft_loc_other - lefteye_loc\n",
    "        vect4_lefteye = righttuft_loc_other - lefteye_loc\n",
    "        vect5_lefteye = whiblz_loc_other - lefteye_loc\n",
    "        vect6_lefteye = mouth_loc_other - lefteye_loc\n",
    "        # angle between body part vector and eyesight direction\n",
    "        angle1_lefteye =  np.sign(np.dot(eyesight_dir,vect1_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect1_lefteye/np.linalg.norm(vect1_lefteye)), -1.0, 1.0))       \n",
    "        angle2_lefteye =  np.sign(np.dot(eyesight_dir,vect2_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect2_lefteye/np.linalg.norm(vect2_lefteye)), -1.0, 1.0))\n",
    "        angle3_lefteye =  np.sign(np.dot(eyesight_dir,vect3_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect3_lefteye/np.linalg.norm(vect3_lefteye)), -1.0, 1.0))\n",
    "        angle4_lefteye =  np.sign(np.dot(eyesight_dir,vect4_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect4_lefteye/np.linalg.norm(vect4_lefteye)), -1.0, 1.0))\n",
    "        angle5_lefteye =  np.sign(np.dot(eyesight_dir,vect5_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect5_lefteye/np.linalg.norm(vect5_lefteye)), -1.0, 1.0))\n",
    "        angle6_lefteye =  np.sign(np.dot(eyesight_dir,vect6_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect6_lefteye/np.linalg.norm(vect6_lefteye)), -1.0, 1.0))\n",
    "        \n",
    "        # where right eye is looking\n",
    "        # vector between body part\n",
    "        vect1_righteye = lefteye_loc_other - righteye_loc\n",
    "        vect2_righteye = righteye_loc_other - righteye_loc\n",
    "        vect3_righteye = lefttuft_loc_other - righteye_loc\n",
    "        vect4_righteye = righttuft_loc_other - righteye_loc\n",
    "        vect5_righteye = whiblz_loc_other - righteye_loc\n",
    "        vect6_righteye = mouth_loc_other - righteye_loc\n",
    "        # angle between body part vector and eyesight direction\n",
    "        angle1_righteye =  np.sign(np.dot(eyesight_dir,vect1_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect1_righteye/np.linalg.norm(vect1_righteye)), -1.0, 1.0))       \n",
    "        angle2_righteye =  np.sign(np.dot(eyesight_dir,vect2_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect2_righteye/np.linalg.norm(vect2_righteye)), -1.0, 1.0))\n",
    "        angle3_righteye =  np.sign(np.dot(eyesight_dir,vect3_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect3_righteye/np.linalg.norm(vect3_righteye)), -1.0, 1.0))\n",
    "        angle4_righteye =  np.sign(np.dot(eyesight_dir,vect4_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect4_righteye/np.linalg.norm(vect4_righteye)), -1.0, 1.0))\n",
    "        angle5_righteye =  np.sign(np.dot(eyesight_dir,vect5_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect5_righteye/np.linalg.norm(vect5_righteye)), -1.0, 1.0))\n",
    "        angle6_righteye =  np.sign(np.dot(eyesight_dir,vect6_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect6_righteye/np.linalg.norm(vect6_righteye)), -1.0, 1.0))\n",
    "        \n",
    "        lefteye_contact_thres = ((angle1_lefteye>0)&(angle1_lefteye<angle_thres))|((angle2_lefteye>0)&(angle2_lefteye<angle_thres))\n",
    "        lefteye_lookface_thres = ((angle3_lefteye>0)&(angle3_lefteye<angle_thres))|((angle4_lefteye>0)&(angle4_lefteye<angle_thres))|((angle5_lefteye>0)&(angle5_lefteye<angle_thres))|((angle6_lefteye>0)&(angle6_lefteye<angle_thres))\n",
    "        righteye_contact_thres = ((angle1_righteye>0)&(angle1_righteye<angle_thres))|((angle2_righteye>0)&(angle2_righteye<angle_thres))\n",
    "        righteye_lookface_thres = ((angle3_righteye>0)&(angle3_righteye<angle_thres))|((angle4_righteye>0)&(angle4_righteye<angle_thres))|((angle5_righteye>0)&(angle5_righteye<angle_thres))|((angle6_righteye>0)&(angle6_righteye<angle_thres))\n",
    "        \n",
    "        eye_contact_frames.append(np.int(lefteye_contact_thres|righteye_contact_thres))\n",
    "        look_at_face_frames.append(np.int(lefteye_contact_thres|righteye_contact_thres|lefteye_lookface_thres|righteye_lookface_thres))\n",
    "        \n",
    "    # save to the summarized data\n",
    "    eye_direction_camera12[(iname)] = eye_dir_frames\n",
    "    eye_contact_or_not_camera12[(iname)] = eye_contact_frames\n",
    "    look_at_face_or_not_camera12[(iname)] = look_at_face_frames\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5764ffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_direction_camera12['time_in_second'] = np.arange(0,np.shape(eye_direction_camera12['dodson'])[0],1)/30 - session_start_time\n",
    "eye_contact_or_not_camera12['time_in_second'] = np.arange(0,np.shape(eye_contact_or_not_camera12['dodson'])[0],1)/30 - session_start_time\n",
    "look_at_face_or_not_camera12['time_in_second'] = np.arange(0,np.shape(look_at_face_or_not_camera12['dodson'])[0],1)/30 - session_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115700d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "np.where(np.array(eye_contact_or_not_camera12['scorch'])==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626cf9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "np.where(np.array(eye_contact_or_not_camera12['dodson'])==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1712422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "with open(camera12_analyzed_path + 'body_part_locs_camera12.pkl', 'wb') as f:\n",
    "    pickle.dump(body_part_locs_camera12, f)\n",
    "with open(camera12_analyzed_path + 'eye_direction_camera12.pkl', 'wb') as f:\n",
    "    pickle.dump(eye_direction_camera12, f)\n",
    "with open(camera12_analyzed_path + 'eye_contact_or_not_camera12.pkl', 'wb') as f:\n",
    "    pickle.dump(eye_contact_or_not_camera12, f)\n",
    "with open(camera12_analyzed_path + 'look_at_face_or_not_camera12.pkl', 'wb') as f:\n",
    "    pickle.dump(look_at_face_or_not_camera12, f)\n",
    "## read\n",
    "# with open(camera12_analyzed_path + 'body_part_locs_camera12.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fffb6d",
   "metadata": {},
   "source": [
    "# analyze based on camera 2 and camera 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99755eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis - camera 2 and 3\n",
    "ncols = camera23_h5_data.shape[1]\n",
    "nframes = camera23_h5_data.shape[0]\n",
    "animal_names = []\n",
    "body_parts = []\n",
    "xyz_axis = []\n",
    "\n",
    "for i in np.arange(0,ncols,1):\n",
    "    animal_names.append(camera23_h5_data.columns[i][1])\n",
    "    body_parts.append(camera23_h5_data.columns[i][2])\n",
    "    xyz_axis.append(camera23_h5_data.columns[i][3])\n",
    "  \n",
    "    # fill in the nan data point\n",
    "    data_point = camera23_h5_data.iloc[:,i]\n",
    "    data_point_filled = data_point.interpolate(method='nearest',limit_direction='both')\n",
    "    data_point_filled = data_point_filled.interpolate(method='linear',limit_direction='both')\n",
    "    # smooth the data point   \n",
    "    # data_point_filtered = data_point_filled.rolling(window=5, win_type='gaussian', center=True).mean(std=0.5)\n",
    "    #\n",
    "    # camera23_h5_data.iloc[:,i] = data_point_filled\n",
    "    \n",
    "animal_names_unique = pd.unique(animal_names)\n",
    "print(animal_names_unique)\n",
    "body_parts_unique = pd.unique(body_parts)\n",
    "print(body_parts_unique)\n",
    "\n",
    "# camera23_h5_data.to_hdf(camera23_h5_file_save, key = \"camera23_h5_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df892d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the location of each body part\n",
    "body_part_locs = {}\n",
    "for iname in animal_names_unique:\n",
    "    for ibody in body_parts_unique:\n",
    "        ind = np.isin(animal_names,iname) & np.isin(body_parts,ibody)\n",
    "        body_part_locs[(iname,ibody)] = camera23_h5_data.iloc[:,ind]    \n",
    "        \n",
    "        # remove the outlier \n",
    "        for iaxis in np.arange(0,3,1):\n",
    "            # loc_std = np.std(body_part_locs[(iname,ibody)])[iaxis]\n",
    "            # loc_mean = pd.DataFrame.mean(body_part_locs[(iname,ibody)])[iaxis]\n",
    "            # ind = (body_part_locs[(iname,ibody)].iloc[:,iaxis]>loc_mean+3*loc_std) | (body_part_locs[(iname,ibody)].iloc[:,iaxis]<loc_mean-3*loc_std)\n",
    "            # body_part_locs[(iname,ibody)].iloc[:,iaxis][ind] = np.nan\n",
    "            q1 = np.nanquantile(body_part_locs[(iname,ibody)].iloc[:,iaxis],0.25)\n",
    "            q3 = np.nanquantile(body_part_locs[(iname,ibody)].iloc[:,iaxis],0.75)\n",
    "            thres1 = q1 - 1.5*abs(q3-q1)\n",
    "            thres2 = q3 + 1.5*abs(q3-q1)\n",
    "            ind = (body_part_locs[(iname,ibody)].iloc[:,iaxis]>thres2) | (body_part_locs[(iname,ibody)].iloc[:,iaxis]<thres1)\n",
    "            body_part_locs[(iname,ibody)].iloc[:,iaxis][ind] = np.nan\n",
    "            \n",
    "body_part_locs_camera23 = body_part_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03097f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "eye_direction_camera23 = {}\n",
    "eye_contact_or_not_camera23 = {}\n",
    "look_at_face_or_not_camera23 = {}\n",
    "for iname in animal_names_unique:\n",
    "    eye_dir_frames = []\n",
    "    eye_contact_frames = []\n",
    "    look_at_face_frames = []\n",
    "    for iframe in np.arange(0,nframes,1):\n",
    "        lefteye_loc = body_part_locs[(iname,'leftEye')].iloc[iframe,:].to_numpy()\n",
    "        righteye_loc = body_part_locs[(iname,'rightEye')].iloc[iframe,:].to_numpy()\n",
    "        lefttuft_loc = body_part_locs[(iname,'leftTuft')].iloc[iframe,:].to_numpy()\n",
    "        righttuft_loc = body_part_locs[(iname,'rightTuft')].iloc[iframe,:].to_numpy()\n",
    "        whiblz_loc = body_part_locs[(iname,'whiteBlaze')].iloc[iframe,:].to_numpy()\n",
    "        mouth_loc = body_part_locs[(iname,'mouth')].iloc[iframe,:].to_numpy()\n",
    "        \n",
    "        Vect1 = lefteye_loc - righteye_loc\n",
    "        Vect2 = whiblz_loc - mouth_loc\n",
    "        Vect3 = lefttuft_loc - lefteye_loc\n",
    "        Vect4 = righttuft_loc - righteye_loc\n",
    "        \n",
    "        try:       \n",
    "            Vect1 = Vect1 / scipy.linalg.norm(Vect1)\n",
    "            Vect2 = Vect2 / scipy.linalg.norm(Vect2) \n",
    "        except:\n",
    "            Vect1 = Vect1\n",
    "            Vect2 = Vect2\n",
    "        eyesight_dir = np.cross(Vect1, Vect2)\n",
    "        \n",
    "        if ((np.dot(eyesight_dir, Vect3)>0) | (np.dot(eyesight_dir, Vect4)>0)):\n",
    "            eyesight_dir = -eyesight_dir\n",
    "        \n",
    "        eye_dir_frames.append(eyesight_dir)\n",
    "        \n",
    "        \n",
    "        # examine whether this animal is looking at the other's eyes or face\n",
    "        if (iname == animal_names_unique[0]): \n",
    "            iname_other = animal_names_unique[1]\n",
    "        elif (iname == animal_names_unique[1]): \n",
    "            iname_other = animal_names_unique[0]\n",
    "            \n",
    "        lefteye_loc_other = body_part_locs[(iname_other,'leftEye')].iloc[iframe,:].to_numpy()\n",
    "        righteye_loc_other = body_part_locs[(iname_other,'rightEye')].iloc[iframe,:].to_numpy()\n",
    "        lefttuft_loc_other = body_part_locs[(iname_other,'leftTuft')].iloc[iframe,:].to_numpy()\n",
    "        righttuft_loc_other = body_part_locs[(iname_other,'rightTuft')].iloc[iframe,:].to_numpy()\n",
    "        whiblz_loc_other = body_part_locs[(iname_other,'whiteBlaze')].iloc[iframe,:].to_numpy()\n",
    "        mouth_loc_other = body_part_locs[(iname_other,'mouth')].iloc[iframe,:].to_numpy()\n",
    "        \n",
    "        # where left eye is looking\n",
    "        # vector between body part\n",
    "        vect1_lefteye = lefteye_loc_other - lefteye_loc\n",
    "        vect2_lefteye = righteye_loc_other - lefteye_loc\n",
    "        vect3_lefteye = lefttuft_loc_other - lefteye_loc\n",
    "        vect4_lefteye = righttuft_loc_other - lefteye_loc\n",
    "        vect5_lefteye = whiblz_loc_other - lefteye_loc\n",
    "        vect6_lefteye = mouth_loc_other - lefteye_loc\n",
    "        # angle between body part vector and eyesight direction\n",
    "        angle1_lefteye =  np.sign(np.dot(eyesight_dir,vect1_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect1_lefteye/np.linalg.norm(vect1_lefteye)), -1.0, 1.0))       \n",
    "        angle2_lefteye =  np.sign(np.dot(eyesight_dir,vect2_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect2_lefteye/np.linalg.norm(vect2_lefteye)), -1.0, 1.0))\n",
    "        angle3_lefteye =  np.sign(np.dot(eyesight_dir,vect3_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect3_lefteye/np.linalg.norm(vect3_lefteye)), -1.0, 1.0))\n",
    "        angle4_lefteye =  np.sign(np.dot(eyesight_dir,vect4_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect4_lefteye/np.linalg.norm(vect4_lefteye)), -1.0, 1.0))\n",
    "        angle5_lefteye =  np.sign(np.dot(eyesight_dir,vect5_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect5_lefteye/np.linalg.norm(vect5_lefteye)), -1.0, 1.0))\n",
    "        angle6_lefteye =  np.sign(np.dot(eyesight_dir,vect6_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect6_lefteye/np.linalg.norm(vect6_lefteye)), -1.0, 1.0))\n",
    "        \n",
    "        # where right eye is looking\n",
    "        # vector between body part\n",
    "        vect1_righteye = lefteye_loc_other - righteye_loc\n",
    "        vect2_righteye = righteye_loc_other - righteye_loc\n",
    "        vect3_righteye = lefttuft_loc_other - righteye_loc\n",
    "        vect4_righteye = righttuft_loc_other - righteye_loc\n",
    "        vect5_righteye = whiblz_loc_other - righteye_loc\n",
    "        vect6_righteye = mouth_loc_other - righteye_loc\n",
    "        # angle between body part vector and eyesight direction\n",
    "        angle1_righteye =  np.sign(np.dot(eyesight_dir,vect1_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect1_righteye/np.linalg.norm(vect1_righteye)), -1.0, 1.0))       \n",
    "        angle2_righteye =  np.sign(np.dot(eyesight_dir,vect2_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect2_righteye/np.linalg.norm(vect2_righteye)), -1.0, 1.0))\n",
    "        angle3_righteye =  np.sign(np.dot(eyesight_dir,vect3_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect3_righteye/np.linalg.norm(vect3_righteye)), -1.0, 1.0))\n",
    "        angle4_righteye =  np.sign(np.dot(eyesight_dir,vect4_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect4_righteye/np.linalg.norm(vect4_righteye)), -1.0, 1.0))\n",
    "        angle5_righteye =  np.sign(np.dot(eyesight_dir,vect5_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect5_righteye/np.linalg.norm(vect5_righteye)), -1.0, 1.0))\n",
    "        angle6_righteye =  np.sign(np.dot(eyesight_dir,vect6_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect6_righteye/np.linalg.norm(vect6_righteye)), -1.0, 1.0))\n",
    "        \n",
    "        lefteye_contact_thres = ((angle1_lefteye>0)&(angle1_lefteye<angle_thres))|((angle2_lefteye>0)&(angle2_lefteye<angle_thres))\n",
    "        lefteye_lookface_thres = ((angle3_lefteye>0)&(angle3_lefteye<angle_thres))|((angle4_lefteye>0)&(angle4_lefteye<angle_thres))|((angle5_lefteye>0)&(angle5_lefteye<angle_thres))|((angle6_lefteye>0)&(angle6_lefteye<angle_thres))\n",
    "        righteye_contact_thres = ((angle1_righteye>0)&(angle1_righteye<angle_thres))|((angle2_righteye>0)&(angle2_righteye<angle_thres))\n",
    "        righteye_lookface_thres = ((angle3_righteye>0)&(angle3_righteye<angle_thres))|((angle4_righteye>0)&(angle4_righteye<angle_thres))|((angle5_righteye>0)&(angle5_righteye<angle_thres))|((angle6_righteye>0)&(angle6_righteye<angle_thres))\n",
    "        \n",
    "        eye_contact_frames.append(np.int(lefteye_contact_thres|righteye_contact_thres))\n",
    "        look_at_face_frames.append(np.int(lefteye_contact_thres|righteye_contact_thres|lefteye_lookface_thres|righteye_lookface_thres))\n",
    "        \n",
    "    # save to the summarized data\n",
    "    eye_direction_camera23[(iname)] = eye_dir_frames\n",
    "    eye_contact_or_not_camera23[(iname)] = eye_contact_frames\n",
    "    look_at_face_or_not_camera23[(iname)] = look_at_face_frames\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f761794",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_direction_camera23['time_in_second'] = np.arange(0,np.shape(eye_direction_camera23['dodson'])[0],1)/30 - session_start_time\n",
    "eye_contact_or_not_camera23['time_in_second'] = np.arange(0,np.shape(eye_contact_or_not_camera23['dodson'])[0],1)/30 - session_start_time\n",
    "look_at_face_or_not_camera23['time_in_second'] = np.arange(0,np.shape(look_at_face_or_not_camera23['dodson'])[0],1)/30 - session_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccefaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "np.where(np.array(eye_contact_or_not_camera23['scorch'])==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9044c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "np.where(np.array(eye_contact_or_not_camera23['dodson'])==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448aabb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "with open(camera23_analyzed_path + 'body_part_locs_camera23.pkl', 'wb') as f:\n",
    "    pickle.dump(body_part_locs_camera23, f)\n",
    "with open(camera23_analyzed_path + 'eye_direction_camera23.pkl', 'wb') as f:\n",
    "    pickle.dump(eye_direction_camera23, f)\n",
    "with open(camera23_analyzed_path + 'eye_contact_or_not_camera23.pkl', 'wb') as f:\n",
    "    pickle.dump(eye_contact_or_not_camera23, f)\n",
    "with open(camera23_analyzed_path + 'look_at_face_or_not_camera23.pkl', 'wb') as f:\n",
    "    pickle.dump(look_at_face_or_not_camera23, f)\n",
    "## read\n",
    "# with open(camera23_analyzed_path + 'body_part_locs_camera23.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf624e3",
   "metadata": {},
   "source": [
    "# examine the relationship between camera pairs\n",
    "## make the 3d space aligned with each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81472895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "try:\n",
    "    ## read\n",
    "    with open(camera23_analyzed_path + 'body_part_locs_camera23.pkl', 'rb') as f:\n",
    "        body_part_locs_camera23 = pickle.load(f) \n",
    "    with open(camera12_analyzed_path + 'body_part_locs_camera12.pkl', 'rb') as f:\n",
    "        body_part_locs_camera12 = pickle.load(f) \n",
    "except:\n",
    "    print(\"did not save data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check \n",
    "xxx = body_part_locs_camera23[('dodson','leftEye')].iloc[:,0]\n",
    "yyy = body_part_locs_camera12[('dodson','leftEye')].iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7312c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = np.min([np.shape(xxx)[0],np.shape(yyy)[0]])\n",
    "xxx = xxx[np.arange(0,min_length,1)]\n",
    "yyy = yyy[np.arange(0,min_length,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ec3ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(xxx,yyy,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ade45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the rotation on all possible pairs\n",
    "RR_sum = {}\n",
    "tt_sum = {}\n",
    "err_sum = {}\n",
    "for iname in animal_names_unique:\n",
    "    for ibody in body_parts_unique:\n",
    "        xxx = body_part_locs_camera23[(iname,ibody)]\n",
    "        yyy = body_part_locs_camera12[(iname,ibody)]\n",
    "        min_lengh = np.min([xxx.shape[0],yyy.shape[0]])\n",
    "        \n",
    "        xxx = xxx.loc[np.arange(0,min_length,1),:]\n",
    "        yyy = yyy.loc[np.arange(0,min_length,1),:]     \n",
    "        \n",
    "        ind_good = (~np.isnan(xxx.iloc[:,0]) & ~np.isnan(xxx.iloc[:,1]) & ~np.isnan(xxx.iloc[:,2])) & (~np.isnan(yyy.iloc[:,0]) & ~np.isnan(yyy.iloc[:,1]) & ~np.isnan(yyy.iloc[:,2])) \n",
    "        xxx_values = pd.DataFrame.transpose(xxx.loc[ind_good,:]).values\n",
    "        yyy_values = pd.DataFrame.transpose(yyy.loc[ind_good,:]).values\n",
    "        \n",
    "        xxx_centroid = np.dot(np.mean(xxx_values,axis = 1).reshape(3,1), np.ones((1,np.shape(xxx_values)[1])))\n",
    "        yyy_centroid = np.dot(np.mean(yyy_values,axis = 1).reshape(3,1), np.ones((1,np.shape(xxx_values)[1])))\n",
    "        HH = np.dot((xxx_values - xxx_centroid), np.transpose(yyy_values - yyy_centroid))\n",
    "        u, s, vh = np.linalg.svd(HH, full_matrices=True)\n",
    "        RR = np.dot(np.transpose(vh),np.transpose(u))\n",
    "        tt= yyy_centroid - np.dot(RR,xxx_centroid)\n",
    "        tt = tt[:,1].reshape(3,1)\n",
    "        \n",
    "        RR_sum[(iname,ibody)] = RR\n",
    "        tt_sum[(iname,ibody)] = tt\n",
    "        err_sum[(iname,ibody)] = np.sum(np.square(yyy_values - (np.dot(RR,xxx_values)+np.dot(tt, np.ones((1,np.shape(xxx_values)[1]))))))\n",
    "\n",
    "RR = RR_sum[min(err_sum, key=err_sum.get)]\n",
    "tt = tt_sum[min(err_sum, key=err_sum.get)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b09481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "xxx_plot = np.transpose(body_part_locs_camera23[('scorch','leftTuft')].loc[np.arange(0,min_length,1),:].values)\n",
    "yyy_plot = np.transpose(body_part_locs_camera12[('scorch','leftTuft')].loc[np.arange(0,min_length,1),:].values)\n",
    "yyy_change = np.dot(RR,xxx_plot)\n",
    "tt_change = np.dot(tt, np.ones((1,np.shape(xxx_plot)[1])))\n",
    "yyy_change = np.dot(RR,xxx_plot) + tt_change\n",
    "plt.plot(xxx_plot[0,:],yyy_plot[0,:],'.')\n",
    "plt.plot(xxx_plot[0,:],yyy_change[0,:],'.')\n",
    "plt.plot(yyy_plot[0,:],yyy_change[0,:],'.')\n",
    "plt.legend(['camera23 and camera12','camera23 and changed camera12','camera12 and changed camera12'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4b328a",
   "metadata": {},
   "source": [
    "## merge the bhv from the two pairs of camera and redo the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a66c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two pairs of cameras\n",
    "body_part_locs_merge = {}\n",
    "for iname in animal_names_unique:\n",
    "    for ibody in body_parts_unique:\n",
    "        RR = RR_sum[(iname,ibody)]\n",
    "        tt = tt_sum[(iname,ibody)]\n",
    "        body_part_x = np.transpose(body_part_locs_camera23[(iname,ibody)].loc[np.arange(0,min_length,1),:])\n",
    "        body_part_project = np.transpose(np.dot(RR,body_part_x) + np.dot(tt, np.ones((1,np.shape(body_part_x)[1]))))\n",
    "        body_part_origin = body_part_locs_camera12[(iname,ibody)].loc[np.arange(0,min_length,1),:].values\n",
    "        body_part_origin[np.sum(np.isnan(body_part_origin),axis=1)>0,:] = body_part_project[np.sum(np.isnan(body_part_origin),axis=1)>0,:]\n",
    "\n",
    "        body_part_locs_merge[(iname,ibody)] = body_part_origin\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9740dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "eye_direction_merge = {}\n",
    "eye_contact_or_not_merge = {}\n",
    "look_at_face_or_not_merge = {}\n",
    "for iname in animal_names_unique:\n",
    "    eye_dir_frames = []\n",
    "    eye_contact_frames = []\n",
    "    look_at_face_frames = []\n",
    "    for iframe in np.arange(0,min_length,1):\n",
    "        lefteye_loc = body_part_locs_merge[(iname,'leftEye')][iframe,:]\n",
    "        righteye_loc = body_part_locs_merge[(iname,'rightEye')][iframe,:]\n",
    "        lefttuft_loc = body_part_locs_merge[(iname,'leftTuft')][iframe,:]\n",
    "        righttuft_loc = body_part_locs_merge[(iname,'rightTuft')][iframe,:]\n",
    "        whiblz_loc = body_part_locs_merge[(iname,'whiteBlaze')][iframe,:]\n",
    "        mouth_loc = body_part_locs_merge[(iname,'mouth')][iframe,:]\n",
    "        \n",
    "        Vect1 = lefteye_loc - righteye_loc\n",
    "        Vect2 = whiblz_loc - mouth_loc\n",
    "        Vect3 = lefttuft_loc - lefteye_loc\n",
    "        Vect4 = righttuft_loc - righteye_loc\n",
    "        \n",
    "        try:       \n",
    "            Vect1 = Vect1 / scipy.linalg.norm(Vect1)\n",
    "            Vect2 = Vect2 / scipy.linalg.norm(Vect2) \n",
    "        except:\n",
    "            Vect1 = Vect1\n",
    "            Vect2 = Vect2\n",
    "        eyesight_dir = np.cross(Vect1, Vect2)\n",
    "        \n",
    "        if ((np.dot(eyesight_dir, Vect3)>0) | (np.dot(eyesight_dir, Vect4)>0)):\n",
    "            eyesight_dir = -eyesight_dir\n",
    "        \n",
    "        eye_dir_frames.append(eyesight_dir)\n",
    "        \n",
    "        \n",
    "        # examine whether this animal is looking at the other's eyes or face\n",
    "        if (iname == animal_names_unique[0]): \n",
    "            iname_other = animal_names_unique[1]\n",
    "        elif (iname == animal_names_unique[1]): \n",
    "            iname_other = animal_names_unique[0]\n",
    "            \n",
    "        lefteye_loc_other = body_part_locs_merge[(iname_other,'leftEye')][iframe,:]\n",
    "        righteye_loc_other = body_part_locs_merge[(iname_other,'rightEye')][iframe,:]\n",
    "        lefttuft_loc_other = body_part_locs_merge[(iname_other,'leftTuft')][iframe,:]\n",
    "        righttuft_loc_other = body_part_locs_merge[(iname_other,'rightTuft')][iframe,:]\n",
    "        whiblz_loc_other = body_part_locs_merge[(iname_other,'whiteBlaze')][iframe,:]\n",
    "        mouth_loc_other = body_part_locs_merge[(iname_other,'mouth')][iframe,:]\n",
    "        \n",
    "        # where left eye is looking\n",
    "        # vector between body part\n",
    "        vect1_lefteye = lefteye_loc_other - lefteye_loc\n",
    "        vect2_lefteye = righteye_loc_other - lefteye_loc\n",
    "        vect3_lefteye = lefttuft_loc_other - lefteye_loc\n",
    "        vect4_lefteye = righttuft_loc_other - lefteye_loc\n",
    "        vect5_lefteye = whiblz_loc_other - lefteye_loc\n",
    "        vect6_lefteye = mouth_loc_other - lefteye_loc\n",
    "        # angle between body part vector and eyesight direction\n",
    "        angle1_lefteye =  np.sign(np.dot(eyesight_dir,vect1_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect1_lefteye/np.linalg.norm(vect1_lefteye)), -1.0, 1.0))       \n",
    "        angle2_lefteye =  np.sign(np.dot(eyesight_dir,vect2_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect2_lefteye/np.linalg.norm(vect2_lefteye)), -1.0, 1.0))\n",
    "        angle3_lefteye =  np.sign(np.dot(eyesight_dir,vect3_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect3_lefteye/np.linalg.norm(vect3_lefteye)), -1.0, 1.0))\n",
    "        angle4_lefteye =  np.sign(np.dot(eyesight_dir,vect4_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect4_lefteye/np.linalg.norm(vect4_lefteye)), -1.0, 1.0))\n",
    "        angle5_lefteye =  np.sign(np.dot(eyesight_dir,vect5_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect5_lefteye/np.linalg.norm(vect5_lefteye)), -1.0, 1.0))\n",
    "        angle6_lefteye =  np.sign(np.dot(eyesight_dir,vect6_lefteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect6_lefteye/np.linalg.norm(vect6_lefteye)), -1.0, 1.0))\n",
    "        \n",
    "        # where right eye is looking\n",
    "        # vector between body part\n",
    "        vect1_righteye = lefteye_loc_other - righteye_loc\n",
    "        vect2_righteye = righteye_loc_other - righteye_loc\n",
    "        vect3_righteye = lefttuft_loc_other - righteye_loc\n",
    "        vect4_righteye = righttuft_loc_other - righteye_loc\n",
    "        vect5_righteye = whiblz_loc_other - righteye_loc\n",
    "        vect6_righteye = mouth_loc_other - righteye_loc\n",
    "        # angle between body part vector and eyesight direction\n",
    "        angle1_righteye =  np.sign(np.dot(eyesight_dir,vect1_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect1_righteye/np.linalg.norm(vect1_righteye)), -1.0, 1.0))       \n",
    "        angle2_righteye =  np.sign(np.dot(eyesight_dir,vect2_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect2_righteye/np.linalg.norm(vect2_righteye)), -1.0, 1.0))\n",
    "        angle3_righteye =  np.sign(np.dot(eyesight_dir,vect3_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect3_righteye/np.linalg.norm(vect3_righteye)), -1.0, 1.0))\n",
    "        angle4_righteye =  np.sign(np.dot(eyesight_dir,vect4_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect4_righteye/np.linalg.norm(vect4_righteye)), -1.0, 1.0))\n",
    "        angle5_righteye =  np.sign(np.dot(eyesight_dir,vect5_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect5_righteye/np.linalg.norm(vect5_righteye)), -1.0, 1.0))\n",
    "        angle6_righteye =  np.sign(np.dot(eyesight_dir,vect6_righteye))*np.arccos(np.clip(np.dot(eyesight_dir/np.linalg.norm(eyesight_dir), vect6_righteye/np.linalg.norm(vect6_righteye)), -1.0, 1.0))\n",
    "        \n",
    "        lefteye_contact_thres = ((angle1_lefteye>0)&(angle1_lefteye<angle_thres))|((angle2_lefteye>0)&(angle2_lefteye<angle_thres))\n",
    "        lefteye_lookface_thres = ((angle3_lefteye>0)&(angle3_lefteye<angle_thres))|((angle4_lefteye>0)&(angle4_lefteye<angle_thres))|((angle5_lefteye>0)&(angle5_lefteye<angle_thres))|((angle6_lefteye>0)&(angle6_lefteye<angle_thres))\n",
    "        righteye_contact_thres = ((angle1_righteye>0)&(angle1_righteye<angle_thres))|((angle2_righteye>0)&(angle2_righteye<angle_thres))\n",
    "        righteye_lookface_thres = ((angle3_righteye>0)&(angle3_righteye<angle_thres))|((angle4_righteye>0)&(angle4_righteye<angle_thres))|((angle5_righteye>0)&(angle5_righteye<angle_thres))|((angle6_righteye>0)&(angle6_righteye<angle_thres))\n",
    "        \n",
    "        eye_contact_frames.append(np.int(lefteye_contact_thres|righteye_contact_thres))\n",
    "        look_at_face_frames.append(np.int(lefteye_contact_thres|righteye_contact_thres|lefteye_lookface_thres|righteye_lookface_thres))\n",
    "        \n",
    "    # save to the summarized data\n",
    "    eye_direction_merge[(iname)] = eye_dir_frames\n",
    "    eye_contact_or_not_merge[(iname)] = eye_contact_frames\n",
    "    look_at_face_or_not_merge[(iname)] = look_at_face_frames\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c308ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_direction_merge['time_in_second'] = np.arange(0,np.shape(eye_direction_merge['dodson'])[0],1)/30 - session_start_time\n",
    "eye_contact_or_not_merge['time_in_second'] = np.arange(0,np.shape(eye_contact_or_not_merge['dodson'])[0],1)/30 - session_start_time\n",
    "look_at_face_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_face_or_not_merge['dodson'])[0],1)/30 - session_start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e977631",
   "metadata": {},
   "source": [
    "## load behavioral results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e93ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load behavioral results\n",
    "try:\n",
    "    bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_from_task_code/20221021_Dodson_Scorch/\"\n",
    "    trial_record_json = bhv_data_path + \"20221021_Scorch_Dodson_TrialRecord_1.json\"\n",
    "    bhv_data_json = bhv_data_path + \"20221021_Scorch_Dodson_bhv_data_1.json\"\n",
    "    session_info_json = bhv_data_path + \"20221021_Scorch_Dodson_session_info_1.json\"\n",
    "    #\n",
    "    trial_record = pd.read_json(trial_record_json)\n",
    "    bhv_data = pd.read_json(bhv_data_json)\n",
    "    session_info = pd.read_json(session_info_json)\n",
    "except:\n",
    "    bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_from_task_code/20221021_Dodson_Scorch/\"\n",
    "    trial_record_json = bhv_data_path + \"20221021_Dodson_Scorch_TrialRecord_1.json\"\n",
    "    bhv_data_json = bhv_data_path + \"20221021_Dodson_Scorch_bhv_data_1.json\"\n",
    "    session_info_json = bhv_data_path + \"20221021_Dodson_Scorch_session_info_1.json\"\n",
    "    #\n",
    "    trial_record = pd.read_json(trial_record_json)\n",
    "    bhv_data = pd.read_json(bhv_data_json)\n",
    "    session_info = pd.read_json(session_info_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4f749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal1 = session_info['lever1_animal'][0].lower()\n",
    "animal2 = session_info['lever2_animal'][0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec12af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the trial_record\n",
    "warnings.filterwarnings('ignore')\n",
    "trial_record_clean = pd.DataFrame(columns=trial_record.columns)\n",
    "for itrial in np.arange(0,np.max(trial_record['trial_number']),1):\n",
    "    # trial_record_clean.loc[itrial] = trial_record[trial_record['trial_number']==itrial+1].iloc[[0]]\n",
    "    trial_record_clean = trial_record_clean.append(trial_record[trial_record['trial_number']==itrial+1].iloc[[0]])\n",
    "trial_record_clean = trial_record_clean.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72cf199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change bhv_data time to the absolute time\n",
    "time_points_new = pd.DataFrame(np.zeros(np.shape(bhv_data)[0]),columns=[\"time_points_new\"])\n",
    "for itrial in np.arange(0,np.max(trial_record_clean['trial_number']),1):\n",
    "    ind = bhv_data[\"trial_number\"]==itrial+1\n",
    "    new_time_itrial = bhv_data[ind][\"time_points\"] + trial_record_clean[\"trial_starttime\"].iloc[itrial]\n",
    "    time_points_new[\"time_points_new\"][ind] = new_time_itrial\n",
    "bhv_data[\"time_points\"] = time_points_new[\"time_points_new\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40407347",
   "metadata": {},
   "source": [
    "## plot behavioral results (with camera pair merged) and eye contact results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fa3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_point_pull1 = bhv_data[\"time_points\"][bhv_data[\"behavior_events\"]==1]\n",
    "time_point_pull2 = bhv_data[\"time_points\"][bhv_data[\"behavior_events\"]==2]\n",
    "ind_lookatotherface1 = np.where(np.array(look_at_face_or_not_merge[animal1])==1)\n",
    "time_point_lookatotherface1 = look_at_face_or_not_merge[\"time_in_second\"][ind_lookatotherface1]\n",
    "ind_lookatotherface2 = np.where(np.array(look_at_face_or_not_merge[animal2])==1)\n",
    "time_point_lookatotherface2 = look_at_face_or_not_merge[\"time_in_second\"][ind_lookatotherface2]\n",
    "\n",
    "ind_eyecontact1 = np.where(np.array(eye_contact_or_not_merge[animal1])==1)\n",
    "time_point_eyecontact1 = eye_contact_or_not_merge[\"time_in_second\"][ind_eyecontact1]\n",
    "ind_eyecontact2 = np.where(np.array(eye_contact_or_not_merge[animal2])==1)\n",
    "time_point_eyecontact2 = eye_contact_or_not_merge[\"time_in_second\"][ind_eyecontact2]\n",
    "\n",
    "# calculate the oneway gaze or mutual gaze\n",
    "animal1_gaze = np.round(np.concatenate((time_point_eyecontact1,time_point_lookatotherface1)),1)\n",
    "animal1_gaze = np.unique(np.sort(animal1_gaze))\n",
    "animal2_gaze = np.round(np.concatenate((time_point_eyecontact2,time_point_lookatotherface2)),1)\n",
    "animal2_gaze = np.unique(np.sort(animal2_gaze))\n",
    "\n",
    "ngaze1 = len(animal1_gaze)\n",
    "ngaze2 = len(animal2_gaze)\n",
    "oneway_gaze1 = []\n",
    "oneway_gaze2 = []\n",
    "mutual_gaze1 = []\n",
    "mutual_gaze2 = []\n",
    "# \n",
    "for igaze1 in np.arange(0, ngaze1, 1):\n",
    "    for igaze2 in np.arange(0,ngaze2,1):\n",
    "        if abs(animal1_gaze[igaze1]-animal2_gaze[igaze2])<1:\n",
    "            mutual_gaze1.append(animal1_gaze[igaze1])\n",
    "            mutual_gaze2.append(animal2_gaze[igaze2])\n",
    "mutual_gaze1 = np.unique(mutual_gaze1)   \n",
    "mutual_gaze2 = np.unique(mutual_gaze2)\n",
    "oneway_gaze1 = animal1_gaze[~np.isin(animal1_gaze,mutual_gaze1)]\n",
    "oneway_gaze2 = animal2_gaze[~np.isin(animal2_gaze,mutual_gaze2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415ee150",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_point_pull1 = np.round(time_point_pull1,2)\n",
    "ind_plot = time_point_pull1 < (720 - session_start_time)\n",
    "plt.plot(time_point_pull1[ind_plot], np.ones(np.shape(time_point_pull1[ind_plot])[0]),'o')\n",
    "plt.plot(oneway_gaze1, np.ones(np.shape(oneway_gaze1)[0])*2,'o')\n",
    "plt.plot(mutual_gaze1, np.ones(np.shape(mutual_gaze1)[0])*3,'o')\n",
    "plt.title(animal1,fontsize = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeeda16",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_point_pull2 = np.round(time_point_pull2,2)\n",
    "ind_plot = time_point_pull2 < (720 - session_start_time)\n",
    "plt.plot(time_point_pull2[ind_plot], np.ones(np.shape(time_point_pull2[ind_plot])[0]),'o')\n",
    "plt.plot(oneway_gaze2, np.ones(np.shape(oneway_gaze2)[0])*2,'o')\n",
    "plt.plot(mutual_gaze2, np.ones(np.shape(mutual_gaze2)[0])*3,'o')\n",
    "plt.title(animal2,fontsize = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mutual_gaze1+session_start_time)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d3b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(25)\n",
    "# plot for animal 1\n",
    "ind_plot = time_point_pull1 < (720 - session_start_time)\n",
    "#for itime in np.arange(0,720,1):\n",
    "#    plt.plot([itime,itime],[0,1],linewidth = 2.0,color=(0.5,0.5,0.5))\n",
    "for itime in time_point_pull1[ind_plot]:\n",
    "    line1, = axs[0].plot([itime,itime],[0,1],linewidth = 2.0,color=(0.0,0.5,0.5),label = 'lever pull')\n",
    "for itime in oneway_gaze1:\n",
    "    line2, = axs[0].plot([itime,itime],[0,1],linewidth = 2.0,color=(0.5,0.0,0.5),label = 'one-way gaze')  \n",
    "try:\n",
    "    for itime in mutual_gaze1:\n",
    "        line3, = axs[0].plot([itime,itime],[0,1],linewidth = 2.0,color=(0.5,0.5,0.0),label = 'mutual gaze')  \n",
    "except:\n",
    "    print(\"no mutual gaze\")\n",
    "axs[0].set_title(animal1,fontsize = 18)\n",
    "axs[0].set_xlim([-10,700])\n",
    "axs[0].set_xlabel(\"\")\n",
    "axs[0].set_xticklabels(\"\")\n",
    "axs[0].set_yticklabels(\"\")\n",
    "try:\n",
    "    axs[0].legend(handles=[line1,line2,line3], fontsize = 13)\n",
    "except:\n",
    "    axs[0].legend(handles=[line1,line2], fontsize = 13)\n",
    "\n",
    "# plot for animal 2\n",
    "ind_plot = time_point_pull2 < (720 - session_start_time)\n",
    "#for itime in np.arange(0,720,1):\n",
    "#    plt.plot([itime,itime],[0,1],linewidth = 2.0,color=(0.5,0.5,0.5))\n",
    "for itime in time_point_pull2[ind_plot]:\n",
    "    line1, = axs[1].plot([itime,itime],[0,1],linewidth = 2.0,color=(0.0,0.5,0.5))\n",
    "for itime in oneway_gaze2:\n",
    "    line2, = axs[1].plot([itime,itime],[0,1],linewidth = 2.0,color=(0.5,0.0,0.5))    \n",
    "try:\n",
    "    for itime in mutual_gaze2:\n",
    "        line3, = axs[1].plot([itime,itime],[0,1],linewidth = 2.0,color=(0.5,0.5,0.0))    \n",
    "except:\n",
    "    print(\"no mutual gaze\")\n",
    "axs[1].set_title(animal2,fontsize = 18)\n",
    "axs[1].set_xlim([-10,700])\n",
    "axs[1].set_xlabel(\"time/s\",fontsize = 19)\n",
    "axs[1].set_yticklabels(\"\")\n",
    "axs[1].tick_params(labelsize = 15)\n",
    "\n",
    "plt.savefig(\"20221021_DS_pattern.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d90226",
   "metadata": {},
   "source": [
    "## train the dynamic bayesian network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b70ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.models import DynamicBayesianNetwork as DBN\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.estimators import HillClimbSearch,BicScore\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d6687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real data\n",
    "total_time = int(720 - session_start_time) * 2\n",
    "# round to 0.5s\n",
    "time_point_pull1_round = round(time_point_pull1 * 2).reset_index(drop = True).astype(int)\n",
    "time_point_pull1_round = time_point_pull1_round[time_point_pull1_round<total_time]\n",
    "time_point_pull2_round  = round(time_point_pull2 * 2).reset_index(drop = True).astype(int)\n",
    "time_point_pull2_round = time_point_pull2_round[time_point_pull2_round<total_time]\n",
    "time_point_onewaygaze1_round = round(pd.Series(oneway_gaze1)*2).reset_index(drop = True).astype(int)\n",
    "time_point_onewaygaze2_round = round(pd.Series(oneway_gaze2)*2).reset_index(drop = True).astype(int)\n",
    "time_point_mutualgaze1_round = round(pd.Series(mutual_gaze1)*2).reset_index(drop = True).astype(int)\n",
    "time_point_mutualgaze2_round = round(pd.Series(mutual_gaze2)*2).reset_index(drop = True).astype(int)\n",
    "time_point_onewaygaze1_round = time_point_onewaygaze1_round[time_point_onewaygaze1_round>0]\n",
    "time_point_onewaygaze2_round = time_point_onewaygaze2_round[time_point_onewaygaze2_round>0]\n",
    "time_point_mutualgaze1_round = time_point_mutualgaze1_round[time_point_mutualgaze1_round>0]\n",
    "time_point_mutualgaze2_round = time_point_mutualgaze2_round[time_point_mutualgaze2_round>0]\n",
    "# t0\n",
    "pull1_t0 = np.zeros((total_time,1))\n",
    "pull1_t0[np.array(time_point_pull1_round)] = 1\n",
    "pull2_t0 = np.zeros((total_time,1))\n",
    "pull2_t0[np.array(time_point_pull2_round)] = 1\n",
    "owgaze1_t0 = np.zeros((total_time,1))\n",
    "owgaze1_t0[np.array(time_point_onewaygaze1_round)] = 1\n",
    "owgaze2_t0 = np.zeros((total_time,1))\n",
    "owgaze2_t0[np.array(time_point_onewaygaze2_round)] = 1\n",
    "mtgaze1_t0 = np.zeros((total_time,1))\n",
    "mtgaze1_t0[np.array(time_point_mutualgaze1_round)] = 1\n",
    "mtgaze2_t0 = np.zeros((total_time,1))\n",
    "mtgaze2_t0[np.array(time_point_mutualgaze2_round)] = 1\n",
    "# t1\n",
    "pull1_t1 = np.zeros((total_time,1))\n",
    "pull1_t1[np.array(time_point_pull1_round)+1] = 1\n",
    "pull2_t1 = np.zeros((total_time,1))\n",
    "pull2_t1[np.array(time_point_pull2_round)+1] = 1\n",
    "owgaze1_t1 = np.zeros((total_time,1))\n",
    "owgaze1_t1[np.array(time_point_onewaygaze1_round)+1] = 1\n",
    "owgaze2_t1 = np.zeros((total_time,1))\n",
    "owgaze2_t1[np.array(time_point_onewaygaze2_round)+1] = 1\n",
    "mtgaze1_t1 = np.zeros((total_time,1))\n",
    "mtgaze1_t1[np.array(time_point_mutualgaze1_round)+1] = 1\n",
    "mtgaze2_t1 = np.zeros((total_time,1))\n",
    "mtgaze2_t1[np.array(time_point_mutualgaze2_round)+1] = 1\n",
    "## create dataframe\n",
    "# data = np.concatenate((pull1_t0,pull2_t0,owgaze1_t0,owgaze2_t0,mtgaze1_t0,mtgaze2_t0,pull1_t1,pull2_t1,owgaze1_t1,owgaze2_t1,mtgaze1_t1,mtgaze2_t1),axis = 1)\n",
    "# colnames = [(\"pull1\",0),(\"pull2\",0),(\"owgaze1\",0),(\"owgaze2\",0),(\"mtgaze1\",0),(\"mtgaze2\",0),(\"pull1\",1),(\"pull2\",1),(\"owgaze1\",1),(\"owgaze2\",1),(\"mtgaze1\",1),(\"mtgaze2\",1)]\n",
    "# df = pd.DataFrame(data, columns=colnames)\n",
    "data = np.concatenate((pull1_t0,pull2_t0,owgaze1_t0,owgaze2_t0,pull1_t1,pull2_t1,owgaze1_t1,owgaze2_t1),axis = 1)\n",
    "colnames = [(\"pull1\",0),(\"pull2\",0),(\"owgaze1\",0),(\"owgaze2\",0),(\"pull1\",1),(\"pull2\",1),(\"owgaze1\",1),(\"owgaze2\",1)]\n",
    "df = pd.DataFrame(data, columns=colnames)\n",
    "\n",
    "## built the model structure\n",
    "# model = DBN(\n",
    "#    [\n",
    "#        ((\"owgaze1\",0), (\"pull1\",1)),\n",
    "#        ((\"owgaze1\",0), (\"mtgaze1\",1)),\n",
    "#        ((\"mtgaze1\",0), (\"pull1\",1)),\n",
    "#        ((\"pull1\",0), (\"owgaze1\",1)),\n",
    "#        ((\"owgaze2\",0), (\"pull2\",1)),\n",
    "#        ((\"owgaze2\",0), (\"mtgaze2\",1)),\n",
    "#        ((\"mtgaze2\",0), (\"pull2\",1)),\n",
    "#        ((\"pull2\",0), (\"owgaze2\",1)),\n",
    "#    ]\n",
    "# )\n",
    "model = DBN(\n",
    "    [\n",
    "        ((\"owgaze1\",0), (\"pull1\",1)),\n",
    "        ((\"pull1\",0), (\"owgaze1\",1)),\n",
    "        ((\"owgaze2\",0), (\"pull2\",1)),\n",
    "        ((\"pull2\",0), (\"owgaze2\",1)),\n",
    "    ]\n",
    ")\n",
    "model.fit(df)\n",
    "#\n",
    "pos=nx.spring_layout(model)\n",
    "nx.draw(model,pos,with_labels = True)\n",
    "labels = nx.get_edge_attributes(model,'weight')\n",
    "nx.draw_networkx_edge_labels(model,pos,edge_labels=labels)\n",
    "\n",
    "model.get_cpds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dacce0",
   "metadata": {},
   "source": [
    "### Methods used by Alec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65169c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_matrix(edges,nevents,eventnames):\n",
    "\n",
    "    output_matrix = np.zeros((nevents,nevents)) \n",
    "    \n",
    "    column = 0\n",
    "    for from_layer in np.arange(0,nevents,1):\n",
    "        row = 0\n",
    "        #Loop through the receiving nodes (the last timeslice of each population)\n",
    "        for to_layer in np.arange(0,nevents,1): \n",
    "            from_pop = eventnames[from_layer]+'_t0'\n",
    "            to_pop = eventnames[to_layer]+'_t1'\n",
    "\n",
    "            if (from_pop, to_pop) in edges:\n",
    "                output_matrix[row,column] = 1\n",
    "            else:\n",
    "                output_matrix[row,column] = 0\n",
    "            row+=1\n",
    "        column+=1\n",
    "                    \n",
    "    return output_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b449238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_dags(binaryDags,nNewBootstraps = 100):\n",
    "    ### Step 1: Create Bootstraps of \"discrete\" DAGs for weighted DAGs\n",
    "    [nTrials,frNodes,toNodes] = binaryDags.shape\n",
    "    \n",
    "    bootstrap_graphs = np.zeros([nNewBootstraps,nTrials,frNodes,toNodes])\n",
    "    for iBootstrap in range(nNewBootstraps):\n",
    "        bootstrap_graphs[iBootstrap,:,:,:] = binaryDags[np.random.randint(nTrials, size=(nTrials)),:,:]\n",
    "\n",
    "    ### Step 2: Get Weighted DAGs\n",
    "    wtd_graphs = np.nanmean(bootstrap_graphs, axis=1)\n",
    "    \n",
    "    return wtd_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b154a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up dataframe\n",
    "data = np.concatenate((pull1_t0,pull2_t0,owgaze1_t0,owgaze2_t0,pull1_t1,pull2_t1,owgaze1_t1,owgaze2_t1),axis = 1)\n",
    "colnames = [\"pull1_t0\",\"pull2_t0\",\"owgaze1_t0\",\"owgaze2_t0\",\"pull1_t1\",\"pull2_t1\",\"owgaze1_t1\",\"owgaze2_t1\"]\n",
    "eventnames = [\"pull1\",\"pull2\",\"owgaze1\",\"owgaze2\"]\n",
    "nevents = np.size(eventnames)\n",
    "bhv_df = pd.DataFrame(data, columns=colnames)\n",
    "\n",
    "# define DBN structures\n",
    "all_pops = list(bhv_df.columns)\n",
    "from_pops = [pop for pop in all_pops if not pop.endswith('t1')]\n",
    "to_pops = [pop for pop in all_pops if pop.endswith('t1')]\n",
    "causal_whitelist = [(from_pop,to_pop) for from_pop in from_pops for to_pop in to_pops]\n",
    "\n",
    "# train the DBN for the edges\n",
    "bhv_hc = HillClimbSearch(bhv_df)\n",
    "best_model = bhv_hc.estimate(max_indegree=None, white_list = causal_whitelist, scoring_method=BicScore(bhv_df))\n",
    "edges = best_model.edges()\n",
    "    \n",
    "nFromNodes = nevents\n",
    "nToNodes = nevents\n",
    "nTrials = 1\n",
    "DAGs = np.zeros((nTrials, nFromNodes, nToNodes))\n",
    "DAGs[0,:,:] = graph_to_matrix(list(edges),nevents,eventnames)\n",
    "\n",
    "edges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9017142",
   "metadata": {},
   "source": [
    "#### methods used by Alec - separate into different \"trials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ceeb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# every 10s (20 0.5s steps) as a \"trial\"\n",
    "# total 720s \"session\" will be 72 \"trials\"\n",
    "ntrials = 72\n",
    "nFromNodes = nevents\n",
    "nToNodes = nevents\n",
    "for itrial in np.arange(0,ntrials,1):\n",
    "    bhv_df_itrial = bhv_df.iloc[itrial*20:(itrial+1)*20]\n",
    "    # define DBN structures\n",
    "    all_pops = list(bhv_df_itrial.columns)\n",
    "    from_pops = [pop for pop in all_pops if not pop.endswith('t1')]\n",
    "    to_pops = [pop for pop in all_pops if pop.endswith('t1')]\n",
    "    causal_whitelist = [(from_pop,to_pop) for from_pop in from_pops for to_pop in to_pops]\n",
    "\n",
    "    # train the DBN for the edges\n",
    "    bhv_hc = HillClimbSearch(bhv_df_itrial)\n",
    "    best_model = bhv_hc.estimate(max_indegree=None, white_list = causal_whitelist, scoring_method=BicScore(bhv_df))\n",
    "    edges_itrial = best_model.edges()\n",
    "    \n",
    "    \n",
    "    DAGs_itrial = np.zeros((ntrials, nFromNodes, nToNodes))\n",
    "    DAGs_itrial[0,:,:] = graph_to_matrix(list(edges_itrial),nevents,eventnames)\n",
    "\n",
    "\n",
    "weighted_graphs = get_weighted_dags(DAGs_itrial,nNewBootstraps = 1)\n",
    "weighted_graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb240293",
   "metadata": {},
   "source": [
    "## plot behavioral results (with camera 12) and eye contact results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_point_pull1 = bhv_data[\"time_points\"][bhv_data[\"behavior_events\"]==1]\n",
    "time_point_pull2 = bhv_data[\"time_points\"][bhv_data[\"behavior_events\"]==2]\n",
    "ind_lookatotherface1 = np.where(np.array(look_at_face_or_not_camera12[animal1])==1)\n",
    "time_point_lookatotherface1 = look_at_face_or_not_camera12[\"time_in_second\"][ind_lookatotherface1]\n",
    "ind_lookatotherface2 = np.where(np.array(look_at_face_or_not_camera12[animal2])==1)\n",
    "time_point_lookatotherface2 = look_at_face_or_not_camera12[\"time_in_second\"][ind_lookatotherface2]\n",
    "\n",
    "ind_eyecontact1 = np.where(np.array(eye_contact_or_not_camera12[animal1])==1)\n",
    "time_point_eyecontact1 = eye_contact_or_not_camera12[\"time_in_second\"][ind_eyecontact1]\n",
    "ind_eyecontact2 = np.where(np.array(eye_contact_or_not_camera12[animal2])==1)\n",
    "time_point_eyecontact2 = eye_contact_or_not_camera12[\"time_in_second\"][ind_eyecontact2]\n",
    "\n",
    "# calculate the oneway gaze or mutual gaze\n",
    "animal1_gaze = np.round(np.concatenate((time_point_eyecontact1,time_point_lookatotherface1)),1)\n",
    "animal1_gaze = np.unique(np.sort(animal1_gaze))\n",
    "animal2_gaze = np.round(np.concatenate((time_point_eyecontact2,time_point_lookatotherface2)),1)\n",
    "animal2_gaze = np.unique(np.sort(animal2_gaze))\n",
    "\n",
    "ngaze1 = len(animal1_gaze)\n",
    "ngaze2 = len(animal2_gaze)\n",
    "oneway_gaze1 = []\n",
    "oneway_gaze2 = []\n",
    "mutual_gaze1 = []\n",
    "mutual_gaze2 = []\n",
    "# \n",
    "for igaze1 in np.arange(0, ngaze1, 1):\n",
    "    for igaze2 in np.arange(0,ngaze2,1):\n",
    "        if abs(animal1_gaze[igaze1]-animal2_gaze[igaze2])<1:\n",
    "            mutual_gaze1.append(animal1_gaze[igaze1])\n",
    "            mutual_gaze2.append(animal2_gaze[igaze2])\n",
    "mutual_gaze1 = np.unique(mutual_gaze1)   \n",
    "mutual_gaze2 = np.unique(mutual_gaze2)\n",
    "oneway_gaze1 = animal1_gaze[~np.isin(animal1_gaze,mutual_gaze1)]\n",
    "oneway_gaze2 = animal2_gaze[~np.isin(animal2_gaze,mutual_gaze2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f26e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_point_pull1 = np.round(time_point_pull1,2)\n",
    "ind_plot = time_point_pull1 < (720 - session_start_time)\n",
    "plt.plot(time_point_pull1[ind_plot], np.ones(np.shape(time_point_pull1[ind_plot])[0]),'o')\n",
    "plt.plot(oneway_gaze1, np.ones(np.shape(oneway_gaze1)[0])*2,'o')\n",
    "plt.plot(mutual_gaze1, np.ones(np.shape(mutual_gaze1)[0])*3,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f7841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(time_point_eyecontact1+session_start_time)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c31c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_point_pull2 = np.round(time_point_pull2,2)\n",
    "ind_plot = time_point_pull2 < (720 - session_start_time)\n",
    "plt.plot(time_point_pull2[ind_plot], np.ones(np.shape(time_point_pull2[ind_plot])[0]),'o')\n",
    "plt.plot(oneway_gaze2, np.ones(np.shape(oneway_gaze2)[0])*2,'o')\n",
    "plt.plot(mutual_gaze2, np.ones(np.shape(mutual_gaze2)[0])*3,'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c15b557",
   "metadata": {},
   "source": [
    "## plot behavioral results (with camera 23) and eye contact results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "deccfe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_point_pull1 = bhv_data[\"time_points\"][bhv_data[\"behavior_events\"]==1]\n",
    "time_point_pull2 = bhv_data[\"time_points\"][bhv_data[\"behavior_events\"]==2]\n",
    "ind_lookatotherface1 = np.where(np.array(look_at_face_or_not_camera23[animal1])==1)\n",
    "time_point_lookatotherface1 = look_at_face_or_not_camera23[\"time_in_second\"][ind_lookatotherface1]\n",
    "ind_lookatotherface2 = np.where(np.array(look_at_face_or_not_camera23[animal2])==1)\n",
    "time_point_lookatotherface2 = look_at_face_or_not_camera23[\"time_in_second\"][ind_lookatotherface2]\n",
    "\n",
    "ind_eyecontact1 = np.where(np.array(eye_contact_or_not_camera23[animal1])==1)\n",
    "time_point_eyecontact1 = eye_contact_or_not_camera23[\"time_in_second\"][ind_eyecontact1]\n",
    "ind_eyecontact2 = np.where(np.array(eye_contact_or_not_camera23[animal2])==1)\n",
    "time_point_eyecontact2 = eye_contact_or_not_camera23[\"time_in_second\"][ind_eyecontact2]\n",
    "\n",
    "# calculate the oneway gaze or mutual gaze\n",
    "animal1_gaze = np.round(np.concatenate((time_point_eyecontact1,time_point_lookatotherface1)),1)\n",
    "animal1_gaze = np.unique(np.sort(animal1_gaze))\n",
    "animal2_gaze = np.round(np.concatenate((time_point_eyecontact2,time_point_lookatotherface2)),1)\n",
    "animal2_gaze = np.unique(np.sort(animal2_gaze))\n",
    "\n",
    "ngaze1 = len(animal1_gaze)\n",
    "ngaze2 = len(animal2_gaze)\n",
    "oneway_gaze1 = []\n",
    "oneway_gaze2 = []\n",
    "mutual_gaze1 = []\n",
    "mutual_gaze2 = []\n",
    "# \n",
    "for igaze1 in np.arange(0, ngaze1, 1):\n",
    "    for igaze2 in np.arange(0,ngaze2,1):\n",
    "        if abs(animal1_gaze[igaze1]-animal2_gaze[igaze2])<1:\n",
    "            mutual_gaze1.append(animal1_gaze[igaze1])\n",
    "            mutual_gaze2.append(animal2_gaze[igaze2])\n",
    "mutual_gaze1 = np.unique(mutual_gaze1)   \n",
    "mutual_gaze2 = np.unique(mutual_gaze2)\n",
    "oneway_gaze1 = animal1_gaze[~np.isin(animal1_gaze,mutual_gaze1)]\n",
    "oneway_gaze2 = animal2_gaze[~np.isin(animal2_gaze,mutual_gaze2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b781a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b0f4170a3d0>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_point_pull1 = np.round(time_point_pull1,2)\n",
    "ind_plot = time_point_pull1 < (720 - session_start_time)\n",
    "plt.plot(time_point_pull1[ind_plot], np.ones(np.shape(time_point_pull1[ind_plot])[0]),'o')\n",
    "plt.plot(oneway_gaze1, np.ones(np.shape(oneway_gaze1)[0])*2,'o')\n",
    "plt.plot(mutual_gaze1, np.ones(np.shape(mutual_gaze1)[0])*3,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b945f65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b0f414b0f70>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_point_pull2 = np.round(time_point_pull2,2)\n",
    "ind_plot = time_point_pull2 < (720 - session_start_time)\n",
    "plt.plot(time_point_pull2[ind_plot], np.ones(np.shape(time_point_pull2[ind_plot])[0]),'o')\n",
    "plt.plot(oneway_gaze2, np.ones(np.shape(oneway_gaze2)[0])*2,'o')\n",
    "plt.plot(mutual_gaze2, np.ones(np.shape(mutual_gaze2)[0])*3,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf3db5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60811dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
