{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca6246b",
   "metadata": {},
   "source": [
    "### This script does basic bhv quantifications\n",
    "#### this script runs DLC and quantifies the gazes\n",
    "#### this script focuses on the summarizing results pooling all four animals (two dyads); it can only be run after the \"BasicBhvAna_singlecam_wholebodylabels_allsessions_basicEvents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd279dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import string\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.models import DynamicBayesianNetwork as DBN\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.estimators import HillClimbSearch,BicScore\n",
    "from pgmpy.base import DAG\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee0ed4",
   "metadata": {},
   "source": [
    "### function - get body part location for each pair of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.body_part_locs_eachpair import body_part_locs_eachpair\n",
    "from ana_functions.body_part_locs_singlecam import body_part_locs_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ae6f98",
   "metadata": {},
   "source": [
    "### function - align the two cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b03438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_align import camera_align       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494356c2",
   "metadata": {},
   "source": [
    "### function - merge the two pairs of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_merge import camera_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc7f6a",
   "metadata": {},
   "source": [
    "### function - find social gaze time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f6ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.find_socialgaze_timepoint import find_socialgaze_timepoint\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam import find_socialgaze_timepoint_singlecam\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam_wholebody import find_socialgaze_timepoint_singlecam_wholebody"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7e75b",
   "metadata": {},
   "source": [
    "### function - define time point of behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_timepoint import bhv_events_timepoint\n",
    "from ana_functions.bhv_events_timepoint_singlecam import bhv_events_timepoint_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4ab8c",
   "metadata": {},
   "source": [
    "### function - plot behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ba678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.plot_bhv_events import plot_bhv_events\n",
    "from ana_functions.plot_bhv_events_levertube import plot_bhv_events_levertube\n",
    "from ana_functions.draw_self_loop import draw_self_loop\n",
    "import matplotlib.patches as mpatches \n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c724b",
   "metadata": {},
   "source": [
    "### function - plot inter-pull interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.plot_interpull_interval import plot_interpull_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d535a6",
   "metadata": {},
   "source": [
    "### function - make demo videos with skeleton and inportant vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4de83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.tracking_video_singlecam_demo import tracking_video_singlecam_demo\n",
    "from ana_functions.tracking_video_singlecam_wholebody_demo import tracking_video_singlecam_wholebody_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69920a6a",
   "metadata": {},
   "source": [
    "### function - interval between all behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a804dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_interval import bhv_events_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c0b97",
   "metadata": {},
   "source": [
    "### function - train the dynamic bayesian network - multi time lag (3 lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag\n",
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag_create_df_only\n",
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag_training_only\n",
    "from ana_functions.train_DBN_multiLag import graph_to_matrix\n",
    "from ana_functions.train_DBN_multiLag import get_weighted_dags\n",
    "from ana_functions.train_DBN_multiLag import get_significant_edges\n",
    "from ana_functions.train_DBN_multiLag import threshold_edges\n",
    "from ana_functions.train_DBN_multiLag import Modulation_Index\n",
    "from ana_functions.EfficientTimeShuffling import EfficientShuffle\n",
    "from ana_functions.AicScore import AicScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819c438",
   "metadata": {},
   "source": [
    "## Analyze each session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e84fc",
   "metadata": {},
   "source": [
    "### prepare the basic behavioral data (especially the time stamps for each bhv events)\n",
    "### separate each session based on trial types (different force levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc05cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instead of using gaze angle threshold, use the target rectagon to deside gaze info\n",
    "# ...need to update\n",
    "sqr_thres_tubelever = 75 # draw the square around tube and lever\n",
    "sqr_thres_face = 1.15 # a ratio for defining face boundary\n",
    "sqr_thres_body = 4 # how many times to enlongate the face box boundry to the body\n",
    "\n",
    "\n",
    "# get the fps of the analyzed video\n",
    "fps = 30\n",
    "\n",
    "# frame number of the demo video\n",
    "# nframes = 0.5*30 # second*30fps\n",
    "nframes = 1*30 # second*30fps\n",
    "\n",
    "# re-analyze the video or not\n",
    "reanalyze_video = 0\n",
    "redo_anystep = 0\n",
    "\n",
    "# only analyze the best (five) sessions for each conditions\n",
    "do_bestsession = 1\n",
    "if do_bestsession:\n",
    "    savefile_sufix = '_bestsessions'\n",
    "else:\n",
    "    savefile_sufix = '_allsessions'\n",
    "    \n",
    "\n",
    "# force manipulation type\n",
    "# SR_bothchange: self reward, both forces changed\n",
    "# CO_bothchange: 1s cooperation, both forces changed\n",
    "# CO_A1change: 1s cooperation, animal 1 forces changed\n",
    "# CO_A2change: 1s cooperation, animal 2 forces changed\n",
    "forceManiTypes = ['SR_bothchange','CO_A1change','CO_A2change']\n",
    "nforceManiTypes = np.shape(forceManiTypes)[0]\n",
    "\n",
    "#  \n",
    "animal1_fixedorders = ['koala','dannon']\n",
    "animal2_fixedorders = ['vermelho','kanga']\n",
    "\n",
    "animal1_filenames = [\"Koala\",\"Dannon\"]\n",
    "animal2_filenames = [\"Vermelho\",\"Kanga\"]\n",
    "\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "\n",
    "# video tracking results info\n",
    "animalnames_videotrack = ['dodson','scorch'] # does not really mean dodson and scorch, instead, indicate animal1 and animal2\n",
    "bodypartnames_videotrack = ['rightTuft','whiteBlaze','leftTuft','rightEye','leftEye','mouth']\n",
    "\n",
    "\n",
    "# which camera to analyzed\n",
    "cameraID = 'camera-2'\n",
    "cameraID_short = 'cam2'\n",
    "\n",
    "\n",
    "# location of levers and tubes for camera 2\n",
    "# get this information using DLC animal tracking GUI, the results are stored: \n",
    "# /home/ws523/marmoset_tracking_DLCv2/marmoset_tracking_with_lever_tube-weikang-2023-04-13/labeled-data/\n",
    "considerlevertube = 1\n",
    "considertubeonly = 0\n",
    "# # camera 1\n",
    "# lever_locs_camI = {'dodson':np.array([645,600]),'scorch':np.array([425,435])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1350,630]),'scorch':np.array([555,345])}\n",
    "# # camera 2\n",
    "lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "tube_locs_camI  = {'dodson':np.array([1550,515]),'scorch':np.array([350,515])}\n",
    "# # lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "# # tube_locs_camI  = {'dodson':np.array([1650,490]),'scorch':np.array([250,490])}\n",
    "# # camera 3\n",
    "# lever_locs_camI = {'dodson':np.array([1580,440]),'scorch':np.array([1296,540])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1470,375]),'scorch':np.array([805,475])}\n",
    "\n",
    "\n",
    "# where to save the summarizing data\n",
    "data_saved_folder = '/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/3d_recontruction_analysis_forceManipulation_task_data_saved/'\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for all animals\n",
    "summary_all_results = pd.DataFrame(columns=['date','forceContType','self_animal','partner_animal','subblockID',\n",
    "                                            'self_force','partner_force','trialnum','blocktime',\n",
    "                                            'succ_rate','interpullintv','pull_IPI','pull_IPI_std',\n",
    "                                            'gaze_number','pull_number','lever_holdtime',\n",
    "                                            'lever_holdtime_std','lever_gauge','lever_gauge_std',\n",
    "                                            'ccf_acrossAnimalsPulls','ccf_withinAnimalpullgaze','ccf_acrossAnimalspullgaze'])\n",
    "\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    \n",
    "    animal1_fixedorder = [animal1_fixedorders[ianimalpair]]\n",
    "    animal2_fixedorder = [animal2_fixedorders[ianimalpair]]\n",
    "    \n",
    "    animal1_filename = animal1_filenames[ianimalpair]\n",
    "    animal2_filename = animal2_filenames[ianimalpair]\n",
    "    \n",
    "    # load data for all manipulation types\n",
    "    for iforceManiType in np.arange(0,nforceManiTypes,1):\n",
    "        \n",
    "        forceManiType = forceManiTypes[iforceManiType]\n",
    "        \n",
    "    \n",
    "        # load saved data\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "\n",
    "        with open(data_saved_subfolder+'/animal1_name_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            animal1_name_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/animal2_name_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            animal2_name_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/trialdates_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            trialdates_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/tasktypes_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            tasktypes_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/coopthres_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            coopthres_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/force1_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            force1_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/force2_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            force2_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/subblockID_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            subblockID_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/succ_rate_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            succ_rate_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/succ_rate1_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            succ_rate1_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/succ_rate2_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            succ_rate2_all_dates = pickle.load(f)\n",
    "            \n",
    "        with open(data_saved_subfolder+'/trialnum_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            trialnum_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/blocktime_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            blocktime_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/interpullintv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            interpullintv_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/pull1_IPI_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            pull1_IPI_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/pull1_IPI_std_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            pull1_IPI_std_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/pull2_IPI_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            pull2_IPI_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/pull2_IPI_std_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            pull2_IPI_std_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/owgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            owgaze1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/owgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            owgaze2_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/mtgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            mtgaze1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/mtgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            mtgaze2_num_all_dates = pickle.load(f)     \n",
    "        with open(data_saved_subfolder+'/pull1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            pull1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/pull2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            pull2_num_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/lever1_holdtime_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            lever1_holdtime_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/lever1_holdtime_std_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            lever1_holdtime_std_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/lever2_holdtime_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            lever2_holdtime_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/lever2_holdtime_std_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            lever2_holdtime_std_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/lever1_gauge_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            lever1_gauge_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/lever1_gauge_std_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            lever1_gauge_std_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/lever2_gauge_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            lever2_gauge_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/lever2_gauge_std_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            lever2_gauge_std_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/bhv_intv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            bhv_intv_all_dates = pickle.load(f)\n",
    "        \n",
    "        with open(data_saved_subfolder+'/cross_corr_bhv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            cross_corr_bhv_all_dates = pickle.load(f)\n",
    "\n",
    "        print('all data are loaded:'+animal1_fixedorder[0]+' '+animal2_fixedorder[0]+' '+forceManiType)\n",
    "\n",
    "        # \n",
    "        ndates = np.shape(trialdates_all_dates)[0]\n",
    "        \n",
    "        for idate in np.arange(0,ndates,1):\n",
    "            \n",
    "            if forceManiType == 'SR_bothchange':\n",
    "                animal1_forceContType = 'self_change_SR'\n",
    "                animal2_forceContType = 'self_change_SR'\n",
    "            elif forceManiType == 'CO_A1change':\n",
    "                animal1_forceContType = 'self_change_MC'\n",
    "                animal2_forceContType = 'partner_change_MC'\n",
    "            elif forceManiType == 'CO_A2change':\n",
    "                animal1_forceContType = 'partner_change_MC'\n",
    "                animal2_forceContType = 'self_change_MC'\n",
    "            else:\n",
    "                animal1_forceContType = None\n",
    "                animal2_forceContType = None\n",
    "            \n",
    "            cross_corr_allbhv_tgt = cross_corr_bhv_all_dates[trialdates_all_dates[idate]][str(int(force1_all_dates[idate]))+'&'+str(int(force2_all_dates[idate]))]\n",
    "            \n",
    "            # center at pull1, xcorr of pull2\n",
    "            cross_corr_allbhv_pull1pull2 = cross_corr_allbhv_tgt['pull1']['pull2']\n",
    "            # center at pull1, xcorr of gaze1\n",
    "            cross_corr_allbhv_pull1gaze1 = cross_corr_allbhv_tgt['pull1']['gaze1']\n",
    "            # center at pull1, xcorr of gaze2\n",
    "            cross_corr_allbhv_pull1gaze2 = cross_corr_allbhv_tgt['pull1']['gaze2']\n",
    "            \n",
    "            # center at pull2, xcorr of pull1\n",
    "            cross_corr_allbhv_pull2pull1 = cross_corr_allbhv_tgt['pull2']['pull1']\n",
    "            # center at pull2, xcorr of gaze2\n",
    "            cross_corr_allbhv_pull2gaze2 = cross_corr_allbhv_tgt['pull2']['gaze2']\n",
    "            # center at pull2, xcorr of gaze1\n",
    "            cross_corr_allbhv_pull2gaze1 = cross_corr_allbhv_tgt['pull2']['gaze1']\n",
    "            \n",
    "            # for animal1\n",
    "            summary_all_results = summary_all_results.append({\n",
    "                                                        'date': trialdates_all_dates[idate],\n",
    "                                                        'forceContType':animal1_forceContType,\n",
    "                                                        'self_animal': animal1_fixedorder[0],\n",
    "                                                        'partner_animal': animal2_fixedorder[0],\n",
    "                                                        'subblockID': subblockID_all_dates[idate],\n",
    "                                                        'self_force': force1_all_dates[idate],\n",
    "                                                        'partner_force': force2_all_dates[idate],\n",
    "                                                        'trialnum': trialnum_all_dates[idate],\n",
    "                                                        'blocktime': blocktime_all_dates[idate],\n",
    "                                                        # 'succ_rate': succ_rate_all_dates[idate],\n",
    "                                                        'succ_rate': succ_rate1_all_dates[idate],\n",
    "                                                        'interpullintv': interpullintv_all_dates[idate],\n",
    "                                                        'pull_IPI': pull1_IPI_all_dates[idate],\n",
    "                                                        'pull_IPI_std': pull1_IPI_std_all_dates[idate],\n",
    "                                                        'gaze_number': owgaze1_num_all_dates[idate]+mtgaze1_num_all_dates[idate],\n",
    "                                                        'pull_number': pull1_num_all_dates[idate],\n",
    "                                                        'lever_holdtime': lever1_holdtime_all_dates[idate],\n",
    "                                                        'lever_holdtime_std': lever1_holdtime_std_all_dates[idate],\n",
    "                                                        'lever_gauge': lever1_gauge_all_dates[idate],\n",
    "                                                        'lever_gauge_std': lever1_gauge_std_all_dates[idate],\n",
    "                                                        'ccf_acrossAnimalsPulls':cross_corr_allbhv_pull1pull2,\n",
    "                                                        'ccf_withinAnimalpullgaze':cross_corr_allbhv_pull1gaze1,\n",
    "                                                        'ccf_acrossAnimalspullgaze':cross_corr_allbhv_pull1gaze2,\n",
    "                                                    }, ignore_index=True)\n",
    "            \n",
    "            # for animal2\n",
    "            summary_all_results = summary_all_results.append({\n",
    "                                                        'date': trialdates_all_dates[idate],\n",
    "                                                        'forceContType':animal2_forceContType,\n",
    "                                                        'self_animal': animal2_fixedorder[0],\n",
    "                                                        'partner_animal': animal1_fixedorder[0],\n",
    "                                                        'subblockID': subblockID_all_dates[idate],\n",
    "                                                        'self_force': force2_all_dates[idate],\n",
    "                                                        'partner_force': force1_all_dates[idate],\n",
    "                                                        'trialnum': trialnum_all_dates[idate],\n",
    "                                                        'blocktime': blocktime_all_dates[idate],\n",
    "                                                        # 'succ_rate': succ_rate_all_dates[idate],\n",
    "                                                        'succ_rate': succ_rate2_all_dates[idate],\n",
    "                                                        'interpullintv': interpullintv_all_dates[idate],\n",
    "                                                        'pull_IPI': pull2_IPI_all_dates[idate],\n",
    "                                                        'pull_IPI_std': pull2_IPI_std_all_dates[idate],\n",
    "                                                        'gaze_number': owgaze2_num_all_dates[idate]+mtgaze2_num_all_dates[idate],\n",
    "                                                        'pull_number': pull2_num_all_dates[idate],\n",
    "                                                        'lever_holdtime': lever2_holdtime_all_dates[idate],\n",
    "                                                        'lever_holdtime_std': lever2_holdtime_std_all_dates[idate],\n",
    "                                                        'lever_gauge': lever2_gauge_all_dates[idate],\n",
    "                                                        'lever_gauge_std': lever2_gauge_std_all_dates[idate],\n",
    "                                                        'ccf_acrossAnimalsPulls':cross_corr_allbhv_pull2pull1,\n",
    "                                                        'ccf_withinAnimalpullgaze':cross_corr_allbhv_pull2gaze2,\n",
    "                                                        'ccf_acrossAnimalspullgaze':cross_corr_allbhv_pull2gaze1,\n",
    "                                                    }, ignore_index=True)\n",
    "            \n",
    "# calculating gaze and pull number per second\n",
    "summary_all_results['gazenum_pers'] = summary_all_results['gaze_number']/summary_all_results['blocktime']\n",
    "summary_all_results['pullnum_pers'] = summary_all_results['pull_number']/summary_all_results['blocktime']\n",
    "\n",
    "\n",
    "# remove entries that has too few trial number\n",
    "trialnum_threshold = 4\n",
    "\n",
    "ind_bad = summary_all_results['trialnum']<trialnum_threshold\n",
    "\n",
    "summary_all_results = summary_all_results[~ind_bad].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c375a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for the blockID regressed for each day versions\n",
    "summary_all_results_blockIDregressed = summary_all_results.copy()\n",
    "\n",
    "unique_combinations = summary_all_results[['date', 'self_animal']].drop_duplicates()\n",
    "ncombines = np.shape(unique_combinations)[0]\n",
    "\n",
    "columns_todo = ['trialnum','blocktime','succ_rate','interpullintv',\n",
    "                'pull_IPI','pull_IPI_std','gaze_number','pull_number',\n",
    "                'lever_holdtime','lever_holdtime_std','lever_gauge','lever_gauge_std',\n",
    "                'gazenum_pers','pullnum_pers']\n",
    "ntodos = np.shape(columns_todo)[0]\n",
    "\n",
    "for icombine in np.arange(0,ncombines,1):\n",
    "    \n",
    "    date_tgt = list(unique_combinations['date'])[icombine]\n",
    "    selfanimal_tgt = list(unique_combinations['self_animal'])[icombine]\n",
    "    \n",
    "    # ind_tgt = (summary_all_results_blockIDregressed['date']==date_tgt)&\\\n",
    "    # (summary_all_results_blockIDregressed['self_animal']==selfanimal_tgt)\n",
    "    ind_tgt = (summary_all_results_blockIDregressed['self_animal']==selfanimal_tgt)\n",
    "\n",
    "    xxx = np.array(summary_all_results_blockIDregressed['subblockID'][ind_tgt])\n",
    "    # in case some subblock is removed due to low trial number\n",
    "    # xxx = np.arange(0,np.shape(xxx)[0],1)\n",
    "    \n",
    "    for itodo in np.arange(0,ntodos,1):\n",
    "        column_todo = columns_todo[itodo]\n",
    "\n",
    "        yyy = np.array(summary_all_results_blockIDregressed[column_todo][ind_tgt])\n",
    "        \n",
    "        # regress again subblock ID first\n",
    "        slope, intercept, rr, pp, std_err = st.linregress(xxx, yyy)\n",
    "        # \n",
    "        yyy_res = yyy - (xxx*slope+intercept)\n",
    "\n",
    "        # Update the DataFrame with residuals for the current column\n",
    "        summary_all_results_blockIDregressed.loc[ind_tgt, column_todo] = yyy_res\n",
    "\n",
    "print('create dataframe for the blockID regressed for each day versions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for the delta force versions - first force\n",
    "summary_all_results_deltafirstforce = summary_all_results.copy()\n",
    "summary_all_results_blockIDregressed_deltafirstforce = summary_all_results_blockIDregressed.copy()\n",
    "\n",
    "\n",
    "unique_combinations = summary_all_results[['date', 'self_animal']].drop_duplicates()\n",
    "ncombines = np.shape(unique_combinations)[0]\n",
    "\n",
    "columns_todo = ['self_force','partner_force']\n",
    "ntodos = np.shape(columns_todo)[0]\n",
    "\n",
    "for icombine in np.arange(0,ncombines,1):\n",
    "    \n",
    "    date_tgt = list(unique_combinations['date'])[icombine]\n",
    "    selfanimal_tgt = list(unique_combinations['self_animal'])[icombine]\n",
    "    \n",
    "    # for normal dataset\n",
    "    ind_tgt = (summary_all_results_deltafirstforce['date']==date_tgt)&\\\n",
    "    (summary_all_results_deltafirstforce['self_animal']==selfanimal_tgt)\n",
    "    \n",
    "    for itodo in np.arange(0,ntodos,1):\n",
    "        column_todo = columns_todo[itodo]\n",
    "\n",
    "        yyy = np.array(summary_all_results_deltafirstforce[column_todo][ind_tgt])\n",
    "       \n",
    "        yyy_new = yyy - yyy[0]\n",
    "        \n",
    "        # Update the DataFrame with residuals for the current column\n",
    "        summary_all_results_deltafirstforce.loc[ind_tgt, column_todo] = yyy_new\n",
    "    \n",
    "    # for dataset with subblockID regressed residual\n",
    "    ind_tgt = (summary_all_results_blockIDregressed_deltafirstforce['date']==date_tgt)&\\\n",
    "    (summary_all_results_blockIDregressed_deltafirstforce['self_animal']==selfanimal_tgt)\n",
    "    \n",
    "    for itodo in np.arange(0,ntodos,1):\n",
    "        column_todo = columns_todo[itodo]\n",
    "\n",
    "        yyy = np.array(summary_all_results_blockIDregressed_deltafirstforce[column_todo][ind_tgt])\n",
    "       \n",
    "        yyy_new = yyy - yyy[0]\n",
    "        \n",
    "        # Update the DataFrame with residuals for the current column\n",
    "        summary_all_results_blockIDregressed_deltafirstforce.loc[ind_tgt, column_todo] = yyy_new\n",
    "    \n",
    "    \n",
    "       \n",
    "print('create dataframe for the delta force versions - first force')\n",
    "\n",
    "# summary_all_results_blockIDregressed_deltafirstforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for the delta force versions - previous force\n",
    "summary_all_results_deltapreforce = summary_all_results.copy()\n",
    "summary_all_results_blockIDregressed_deltapreforce = summary_all_results_blockIDregressed.copy()\n",
    "\n",
    "\n",
    "unique_combinations = summary_all_results[['date', 'self_animal']].drop_duplicates()\n",
    "ncombines = np.shape(unique_combinations)[0]\n",
    "\n",
    "columns_todo = ['partner_force','self_force',]\n",
    "ntodos = np.shape(columns_todo)[0]\n",
    "\n",
    "for icombine in np.arange(0,ncombines,1):\n",
    "    \n",
    "    date_tgt = list(unique_combinations['date'])[icombine]\n",
    "    selfanimal_tgt = list(unique_combinations['self_animal'])[icombine]\n",
    "    \n",
    "    # for normal dataset\n",
    "    ind_tgt = (summary_all_results_deltapreforce['date']==date_tgt)&\\\n",
    "    (summary_all_results_deltapreforce['self_animal']==selfanimal_tgt)\n",
    "    \n",
    "    for itodo in np.arange(0,ntodos,1):\n",
    "        column_todo = columns_todo[itodo]\n",
    "\n",
    "        yyy = np.array(summary_all_results_deltapreforce[column_todo][ind_tgt])\n",
    "       \n",
    "        yyy_new = yyy - np.hstack([yyy[0],yyy[0:-1]])\n",
    "        \n",
    "        # Update the DataFrame with residuals for the current column\n",
    "        summary_all_results_deltapreforce.loc[ind_tgt, column_todo] = yyy_new\n",
    "    \n",
    "    # for dataset with subblockID regressed residual\n",
    "    ind_tgt = (summary_all_results_blockIDregressed_deltapreforce['date']==date_tgt)&\\\n",
    "    (summary_all_results_blockIDregressed_deltapreforce['self_animal']==selfanimal_tgt)\n",
    "    \n",
    "    for itodo in np.arange(0,ntodos,1):\n",
    "        column_todo = columns_todo[itodo]\n",
    "\n",
    "        yyy = np.array(summary_all_results_blockIDregressed_deltapreforce[column_todo][ind_tgt])\n",
    "       \n",
    "        yyy_new = yyy - np.hstack([yyy[0],yyy[0:-1]])\n",
    "        \n",
    "        # Update the DataFrame with residuals for the current column\n",
    "        summary_all_results_blockIDregressed_deltapreforce.loc[ind_tgt, column_todo] = yyy_new\n",
    "    \n",
    "    \n",
    "       \n",
    "print('create dataframe for the delta force versions - previous force')\n",
    "\n",
    "# summary_all_results_blockIDregressed_deltafirstforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb8789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for the normalized force each day versions\n",
    "summary_all_results_normforce = summary_all_results.copy()\n",
    "summary_all_results_blockIDregressed_normforce = summary_all_results_blockIDregressed.copy()\n",
    "\n",
    "\n",
    "unique_combinations = summary_all_results[['date', 'self_animal']].drop_duplicates()\n",
    "ncombines = np.shape(unique_combinations)[0]\n",
    "\n",
    "columns_todo = ['self_force','partner_force']\n",
    "ntodos = np.shape(columns_todo)[0]\n",
    "\n",
    "for icombine in np.arange(0,ncombines,1):\n",
    "    \n",
    "    date_tgt = list(unique_combinations['date'])[icombine]\n",
    "    selfanimal_tgt = list(unique_combinations['self_animal'])[icombine]\n",
    "    \n",
    "    # for normal dataset\n",
    "    ind_tgt = (summary_all_results_normforce['date']==date_tgt)&\\\n",
    "    (summary_all_results_normforce['self_animal']==selfanimal_tgt)\n",
    "    \n",
    "    for itodo in np.arange(0,ntodos,1):\n",
    "        column_todo = columns_todo[itodo]\n",
    "\n",
    "        yyy = np.array(summary_all_results_normforce[column_todo][ind_tgt])\n",
    "       \n",
    "        yyy_new = st.zscore(yyy)\n",
    "        \n",
    "        # Update the DataFrame with residuals for the current column\n",
    "        summary_all_results_normforce.loc[ind_tgt, column_todo] = yyy_new\n",
    "    \n",
    "    # for dataset with subblockID regressed residual\n",
    "    ind_tgt = (summary_all_results_blockIDregressed_normforce['date']==date_tgt)&\\\n",
    "    (summary_all_results_blockIDregressed_normforce['self_animal']==selfanimal_tgt)\n",
    "    \n",
    "    for itodo in np.arange(0,ntodos,1):\n",
    "        column_todo = columns_todo[itodo]\n",
    "\n",
    "        yyy = np.array(summary_all_results_blockIDregressed_normforce[column_todo][ind_tgt])\n",
    "       \n",
    "        yyy_new = st.zscore(yyy)\n",
    "        \n",
    "        # Update the DataFrame with residuals for the current column\n",
    "        summary_all_results_blockIDregressed_normforce.loc[ind_tgt, column_todo] = yyy_new\n",
    "    \n",
    "    \n",
    "       \n",
    "print('create dataframe for the normalized force each day versions')\n",
    "\n",
    "# summary_all_results_blockIDregressed_deltafirstforce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4641e944",
   "metadata": {},
   "source": [
    "### plot the summarizing figures with all animals\n",
    "#### different variables plot against self force level or other force level\n",
    "#### separating condition (self sr, other sr, self mc, other mc etc)\n",
    "#### choose the version of the variables - raw, normalized force, or delta force; raw or blockiD regressed residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341efe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypename = '' # 'blockIDregressed_normforce','blockIDregressed_deltafirstforce','blockIDregressed_deltapreforce'\n",
    "# summary_all_tgt = summary_all_results\n",
    "datatypename = 'deltapreforce'\n",
    "summary_all_tgt = summary_all_results_deltapreforce\n",
    "\n",
    "nTrialConds = np.shape(np.unique(summary_all_tgt['forceContType']))[0]\n",
    "\n",
    "xplottype = 'partner_force' # 'self_focce' or 'other_force' or 'subblockID'\n",
    "yplottypes = ['succ_rate','interpullintv','pull_IPI','pullnum_pers','gazenum_pers']\n",
    "nyplottypes = np.shape(yplottypes)[0]\n",
    "\n",
    "# Set up the figure grid\n",
    "fig, axes = plt.subplots(nTrialConds, nyplottypes, \n",
    "                         figsize=(5 * nyplottypes, 4 * nTrialConds), \n",
    "                         sharex=False, sharey=False)\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "# Plotting each unique condition and y-axis type\n",
    "unique_conditions = summary_all_tgt['forceContType'].unique()\n",
    "\n",
    "for i, condition in enumerate(unique_conditions):\n",
    "    # Filter data for the current condition\n",
    "    condition_data = summary_all_tgt[summary_all_tgt['forceContType'] == condition]\n",
    "    \n",
    "    for j, yplot in enumerate(yplottypes):\n",
    "        ax = axes[i, j] if nTrialConds > 1 else axes[j]  # Adjust for single-row cases\n",
    "        \n",
    "        # Drop rows with NaN or inf in the columns of interest\n",
    "        data_cleaned = condition_data[[xplottype, yplot]].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        \n",
    "        # Create a regression plot for each y-axis type within the current condition\n",
    "        seaborn.regplot(data=data_cleaned, x=xplottype, y=yplot, ax=ax, \n",
    "                        scatter_kws={'s': 10}, line_kws={'color': 'blue'})\n",
    "        \n",
    "        try:\n",
    "        # Calculate correlation coefficient and p-value\n",
    "            r_value, p_value = st.pearsonr(data_cleaned[xplottype], data_cleaned[yplot])\n",
    "        except:\n",
    "            r_value = np.nan\n",
    "            p_value = np.nan\n",
    "        \n",
    "        # Add text for the correlation statistics\n",
    "        ax.text(0.05, 0.95, f\"r = {r_value:.2f}\\np = {p_value:.3f}\", \n",
    "                transform=ax.transAxes, fontsize=10, verticalalignment='top', color='blue')\n",
    "        \n",
    "        \n",
    "        # Set titles and labels\n",
    "        ax.set_title(f\"{condition} - {yplot}\")\n",
    "        if i == nTrialConds - 1:\n",
    "            ax.set_xlabel(xplottype)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(yplot)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_BasicBhvAna_singlecam_wholebodylabels_allsessions_basicEvents_allanimal_summary/'+savefile_sufix+'/'+cameraID+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    fig.savefig(figsavefolder+xplottype+\"level_vs_bhvvariables_allanimal_allcondition_versionof_\"+datatypename+\".pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c2222b",
   "metadata": {},
   "source": [
    "### plot the summarizing figures with all animals - plot each animal separately\n",
    "#### different variables plot against self force level or other force level\n",
    "#### separating condition (self sr, other sr, self mc, other mc etc)\n",
    "#### choose the version of the variables - raw, normalized force, or delta force; raw or blockiD regressed residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3959b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypename = '' # 'blockIDregressed_normforce','blockIDregressed_deltafirstforce','blockIDregressed_deltapreforce'\n",
    "# summary_all_tgt = summary_all_results\n",
    "datatypename = 'deltapreforce'\n",
    "summary_all_tgt = summary_all_results_deltapreforce\n",
    "\n",
    "nTrialConds = np.shape(np.unique(summary_all_tgt['forceContType']))[0]\n",
    "\n",
    "xplottype = 'self_force' # 'self_focce' or 'other_force' or 'subblockID'\n",
    "yplottypes = ['succ_rate','interpullintv','pull_IPI','pullnum_pers','gazenum_pers']\n",
    "nyplottypes = np.shape(yplottypes)[0]\n",
    "\n",
    "animalcolors = ['red','blue','purple','darkblue']\n",
    "\n",
    "# Set up the figure grid\n",
    "fig, axes = plt.subplots(nTrialConds, nyplottypes, \n",
    "                         figsize=(5 * nyplottypes, 4 * nTrialConds), \n",
    "                         sharex=False, sharey=False)\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "# Plotting each unique condition and y-axis type\n",
    "unique_conditions = summary_all_tgt['forceContType'].unique()\n",
    "\n",
    "for i, condition in enumerate(unique_conditions):\n",
    "    # Filter data for the current condition\n",
    "    condition_data = summary_all_tgt[summary_all_tgt['forceContType'] == condition]\n",
    "    \n",
    "    selfanimals = np.unique(condition_data['self_animal'])\n",
    "    # selfanimals = ['kanga']\n",
    "    nanimals = np.shape(selfanimals)[0]\n",
    "    \n",
    "    for ianimal in np.arange(0,nanimals,1):\n",
    "        \n",
    "        selfanimal = selfanimals[ianimal]\n",
    "        \n",
    "        condition_data_ianimal = condition_data[condition_data['self_animal']==selfanimal]\n",
    "    \n",
    "        for j, yplot in enumerate(yplottypes):\n",
    "            ax = axes[i, j] if nTrialConds > 1 else axes[j]  # Adjust for single-row cases\n",
    "\n",
    "            # Drop rows with NaN or inf in the columns of interest\n",
    "            data_cleaned = condition_data_ianimal[[xplottype, yplot]].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "            # Create a regression plot for each y-axis type within the current condition\n",
    "            seaborn.regplot(data=data_cleaned, x=xplottype, y=yplot, ax=ax, \n",
    "                            scatter_kws={'s': 10, 'color': animalcolors[ianimal]}, \n",
    "                            line_kws={'color': animalcolors[ianimal]})\n",
    "\n",
    "            try:\n",
    "            # Calculate correlation coefficient and p-value\n",
    "                r_value, p_value = st.pearsonr(data_cleaned[xplottype], data_cleaned[yplot])\n",
    "            except:\n",
    "                r_value = np.nan\n",
    "                p_value = np.nan\n",
    "\n",
    "            # Add text for the correlation statistics\n",
    "            ax.text(0.05, 0.95-0.1*ianimal, selfanimal+':'+f\"r = {r_value:.2f}\\np = {p_value:.3f}\", \n",
    "                    transform=ax.transAxes, fontsize=10, verticalalignment='top', color=animalcolors[ianimal])\n",
    "\n",
    "\n",
    "            # Set titles and labels\n",
    "            ax.set_title(f\"{condition} - {yplot}\")\n",
    "            if i == nTrialConds - 1:\n",
    "                ax.set_xlabel(xplottype)\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(yplot)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_BasicBhvAna_singlecam_wholebodylabels_allsessions_basicEvents_allanimal_summary/'+savefile_sufix+'/'+cameraID+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    fig.savefig(figsavefolder+xplottype+\"level_vs_bhvvariables_separatedanimal_allcondition_versionof_\"+datatypename+\".pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad358e9a",
   "metadata": {},
   "source": [
    "### plot the summarizing figures with all animals - plot each day separately; color coded the animal ID\n",
    "#### different variables plot against self force level or other force level\n",
    "#### separating condition (self sr, other sr, self mc, other mc etc)\n",
    "#### choose the version of the variables - raw, normalized force, or delta force; raw or blockiD regressed residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0321a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypename = '' # 'blockIDregressed_normforce','blockIDregressed_deltafirstforce','blockIDregressed_deltapreforce'\n",
    "# summary_all_tgt = summary_all_results\n",
    "datatypename = 'blockIDregressed'\n",
    "summary_all_tgt = summary_all_results_blockIDregressed\n",
    "\n",
    "nTrialConds = np.shape(np.unique(summary_all_tgt['forceContType']))[0]\n",
    "\n",
    "xplottype = 'self_force' # 'self_focce' or 'other_force' or 'subblockID'\n",
    "yplottypes = ['succ_rate','interpullintv','pull_IPI','pullnum_pers','gazenum_pers']\n",
    "nyplottypes = np.shape(yplottypes)[0]\n",
    "\n",
    "animalcolors = ['red','blue','purple','darkblue']\n",
    "\n",
    "slopes_all_result = pd.DataFrame(columns=['self_animal','date','tasktype','xplottype','yplottype','slope',])\n",
    "\n",
    "# Set up the figure grid\n",
    "fig, axes = plt.subplots(nTrialConds, nyplottypes, \n",
    "                         figsize=(5 * nyplottypes, 4 * nTrialConds), \n",
    "                         sharex=False, sharey=False)\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "# Plotting each unique condition and y-axis type\n",
    "unique_conditions = summary_all_tgt['forceContType'].unique()\n",
    "\n",
    "for i, condition in enumerate(unique_conditions):\n",
    "    # Filter data for the current condition\n",
    "    condition_data = summary_all_tgt[summary_all_tgt['forceContType'] == condition]\n",
    "    \n",
    "    selfanimals = np.unique(condition_data['self_animal'])\n",
    "    nanimals = np.shape(selfanimals)[0]\n",
    "    \n",
    "    for j, yplot in enumerate(yplottypes):\n",
    "        ax = axes[i, j] if nTrialConds > 1 else axes[j]  # Adjust for single-row cases\n",
    "            \n",
    "        # plot for each animal separately\n",
    "        for ianimal in np.arange(0,nanimals,1):\n",
    "\n",
    "            selfanimal = selfanimals[ianimal]\n",
    "\n",
    "            condition_data_ianimal = condition_data[condition_data['self_animal']==selfanimal]\n",
    "\n",
    "            sessiondates = np.unique(condition_data_ianimal['date'])\n",
    "            nsessiondates = np.shape(sessiondates)[0]\n",
    "\n",
    "            for isessdate in np.arange(0,nsessiondates,1):\n",
    "\n",
    "                sessiondate = sessiondates[isessdate]\n",
    "\n",
    "                condition_data_ianimal_idate = condition_data_ianimal[condition_data_ianimal['date']==sessiondate]\n",
    "\n",
    "                # Drop rows with NaN or inf in the columns of interest\n",
    "                data_cleaned = condition_data_ianimal_idate[[xplottype, yplot]].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "                # Create a regression plot for each y-axis type within the current condition\n",
    "                seaborn.regplot(data=data_cleaned, x=xplottype, y=yplot, ax=ax, ci=None,\n",
    "                                scatter_kws={'s':10,'color':'gray'}, \n",
    "                                line_kws={'color': animalcolors[ianimal],'linewidth': 1})\n",
    "\n",
    "                try:\n",
    "                    slope, intercept, r_value, p_value, std_err = st.linregress(data_cleaned[xplottype], data_cleaned[yplot])\n",
    "                except:\n",
    "                    slope = np.nan\n",
    "                slopes_all_result = slopes_all_result.append({'self_animal':selfanimal,\n",
    "                                                              'date':sessiondate,\n",
    "                                                              'tasktype':condition,\n",
    "                                                              'xplottype':xplottype,\n",
    "                                                              'yplottype':yplot,\n",
    "                                                              'slope':slope}, ignore_index=True)\n",
    "            \n",
    "            # run wilcoxcon on the slope\n",
    "            ind_slope_tgt = (slopes_all_result['self_animal']==selfanimal) &\\\n",
    "                            (slopes_all_result['tasktype']==condition) &\\\n",
    "                            (slopes_all_result['xplottype']==xplottype) &\\\n",
    "                            (slopes_all_result['yplottype']==yplot)\n",
    "            slopes_tgt = slopes_all_result[ind_slope_tgt]\n",
    "                            \n",
    "            try:\n",
    "                _,p_value = st.wilcoxon(slopes_tgt['slope'])\n",
    "            except:\n",
    "                p_value = np.nan \n",
    "                \n",
    "            # Add text for the correlation statistics\n",
    "            ax.text(0.05, 0.95-0.1*ianimal, selfanimal+':'+f\"p = {p_value:.3f}\", \n",
    "                    transform=ax.transAxes, fontsize=10, verticalalignment='top', color=animalcolors[ianimal])\n",
    "\n",
    "        \n",
    "        # run wilcoxcon on the slope\n",
    "        ind_slope_tgt = (slopes_all_result['tasktype']==condition) &\\\n",
    "                        (slopes_all_result['xplottype']==xplottype) &\\\n",
    "                        (slopes_all_result['yplottype']==yplot)\n",
    "        slopes_tgt = slopes_all_result[ind_slope_tgt]\n",
    "\n",
    "        try:\n",
    "            _,p_value = st.wilcoxon(slopes_tgt['slope'])\n",
    "        except:\n",
    "            p_value = np.nan \n",
    "         \n",
    "        # Add text for the correlation statistics\n",
    "        ax.text(0.05, 0.95-0.1*nanimals, 'all animals:'+f\"p = {p_value:.3f}\", \n",
    "                transform=ax.transAxes, fontsize=10, verticalalignment='top', color='k')\n",
    "\n",
    "        # Set titles and labels\n",
    "        ax.set_title(f\"{condition} - {yplot}\")\n",
    "        if i == nTrialConds - 1:\n",
    "            ax.set_xlabel(xplottype)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(yplot)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_BasicBhvAna_singlecam_wholebodylabels_allsessions_basicEvents_allanimal_summary/'+savefile_sufix+'/'+cameraID+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    fig.savefig(figsavefolder+xplottype+\"level_vs_bhvvariables_separatedanimal_separatedays_allcondition_versionof_\"+datatypename+\".pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ce3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c463bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc96cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e930c3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ffb05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650bfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
