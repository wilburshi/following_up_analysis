{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca6246b",
   "metadata": {},
   "source": [
    "### In this script, DBN is run on the all the sessions\n",
    "### In this script, DBN is run with 1s time bin, 3 time lag \n",
    "### In this script, the animal tracking is done with only one camera - camera 2 (middle) \n",
    "#### this script focuses on the summarizing results pooling all four animals (two dyads); it can only be run after the \"3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd279dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import string\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.models import DynamicBayesianNetwork as DBN\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.estimators import HillClimbSearch,BicScore\n",
    "from pgmpy.base import DAG\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee0ed4",
   "metadata": {},
   "source": [
    "### function - get body part location for each pair of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.body_part_locs_eachpair import body_part_locs_eachpair\n",
    "from ana_functions.body_part_locs_singlecam import body_part_locs_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ae6f98",
   "metadata": {},
   "source": [
    "### function - align the two cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b03438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_align import camera_align       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494356c2",
   "metadata": {},
   "source": [
    "### function - merge the two pairs of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_merge import camera_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc7f6a",
   "metadata": {},
   "source": [
    "### function - find social gaze time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f6ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.find_socialgaze_timepoint import find_socialgaze_timepoint\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam import find_socialgaze_timepoint_singlecam\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam_wholebody import find_socialgaze_timepoint_singlecam_wholebody"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7e75b",
   "metadata": {},
   "source": [
    "### function - define time point of behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_timepoint import bhv_events_timepoint\n",
    "from ana_functions.bhv_events_timepoint_singlecam import bhv_events_timepoint_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4ab8c",
   "metadata": {},
   "source": [
    "### function - plot behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ba678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.plot_bhv_events import plot_bhv_events\n",
    "from ana_functions.plot_bhv_events_levertube import plot_bhv_events_levertube\n",
    "from ana_functions.draw_self_loop import draw_self_loop\n",
    "import matplotlib.patches as mpatches \n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c724b",
   "metadata": {},
   "source": [
    "### function - plot inter-pull interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.plot_interpull_interval import plot_interpull_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d535a6",
   "metadata": {},
   "source": [
    "### function - make demo videos with skeleton and inportant vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4de83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.tracking_video_singlecam_demo import tracking_video_singlecam_demo\n",
    "from ana_functions.tracking_video_singlecam_wholebody_demo import tracking_video_singlecam_wholebody_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69920a6a",
   "metadata": {},
   "source": [
    "### function - interval between all behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a804dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_interval import bhv_events_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c0b97",
   "metadata": {},
   "source": [
    "### function - train the dynamic bayesian network - multi time lag (3 lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag\n",
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag_create_df_only\n",
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag_training_only\n",
    "from ana_functions.train_DBN_multiLag import graph_to_matrix\n",
    "from ana_functions.train_DBN_multiLag import get_weighted_dags\n",
    "from ana_functions.train_DBN_multiLag import get_significant_edges\n",
    "from ana_functions.train_DBN_multiLag import threshold_edges\n",
    "from ana_functions.train_DBN_multiLag import Modulation_Index\n",
    "from ana_functions.EfficientTimeShuffling import EfficientShuffle\n",
    "from ana_functions.AicScore import AicScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819c438",
   "metadata": {},
   "source": [
    "## Analyze each session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e84fc",
   "metadata": {},
   "source": [
    "### prepare the basic behavioral data (especially the time stamps for each bhv events)\n",
    "### separate each session based on trial types (different force levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc05cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instead of using gaze angle threshold, use the target rectagon to deside gaze info\n",
    "# ...need to update\n",
    "sqr_thres_tubelever = 75 # draw the square around tube and lever\n",
    "sqr_thres_face = 1.15 # a ratio for defining face boundary\n",
    "sqr_thres_body = 4 # how many times to enlongate the face box boundry to the body\n",
    "\n",
    "\n",
    "# get the fps of the analyzed video\n",
    "fps = 30\n",
    "\n",
    "# frame number of the demo video\n",
    "# nframes = 0.5*30 # second*30fps\n",
    "nframes = 1*30 # second*30fps\n",
    "\n",
    "# re-analyze the video or not\n",
    "reanalyze_video = 0\n",
    "redo_anystep = 0\n",
    "\n",
    "# only analyze the best (five) sessions for each conditions\n",
    "do_bestsession = 1\n",
    "if do_bestsession:\n",
    "    savefile_sufix = '_bestsessions'\n",
    "else:\n",
    "    savefile_sufix = '_allsessions'\n",
    "    \n",
    "\n",
    "# force manipulation type\n",
    "# SR_bothchange: self reward, both forces changed\n",
    "# CO_bothchange: 1s cooperation, both forces changed\n",
    "# CO_A1change: 1s cooperation, animal 1 forces changed\n",
    "# CO_A2change: 1s cooperation, animal 2 forces changed\n",
    "forceManiTypes = ['SR_bothchange','CO_A1change','CO_A2change',]\n",
    "nforceManiTypes = np.shape(forceManiTypes)[0]\n",
    "\n",
    "#  \n",
    "animal1_fixedorders = ['koala','dannon']\n",
    "animal2_fixedorders = ['vermelho','kanga']\n",
    "\n",
    "animal1_filenames = [\"Koala\",\"Dannon\"]\n",
    "animal2_filenames = [\"Vermelho\",\"Kanga\"]\n",
    "\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "\n",
    "# video tracking results info\n",
    "animalnames_videotrack = ['dodson','scorch'] # does not really mean dodson and scorch, instead, indicate animal1 and animal2\n",
    "bodypartnames_videotrack = ['rightTuft','whiteBlaze','leftTuft','rightEye','leftEye','mouth']\n",
    "\n",
    "\n",
    "# which camera to analyzed\n",
    "cameraID = 'camera-2'\n",
    "cameraID_short = 'cam2'\n",
    "\n",
    "\n",
    "# location of levers and tubes for camera 2\n",
    "# get this information using DLC animal tracking GUI, the results are stored: \n",
    "# /home/ws523/marmoset_tracking_DLCv2/marmoset_tracking_with_lever_tube-weikang-2023-04-13/labeled-data/\n",
    "considerlevertube = 1\n",
    "considertubeonly = 0\n",
    "# # camera 1\n",
    "# lever_locs_camI = {'dodson':np.array([645,600]),'scorch':np.array([425,435])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1350,630]),'scorch':np.array([555,345])}\n",
    "# # camera 2\n",
    "lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "tube_locs_camI  = {'dodson':np.array([1550,515]),'scorch':np.array([350,515])}\n",
    "# # lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "# # tube_locs_camI  = {'dodson':np.array([1650,490]),'scorch':np.array([250,490])}\n",
    "# # camera 3\n",
    "# lever_locs_camI = {'dodson':np.array([1580,440]),'scorch':np.array([1296,540])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1470,375]),'scorch':np.array([805,475])}\n",
    "\n",
    "\n",
    "# where to save the summarizing data\n",
    "data_saved_folder = '/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/3d_recontruction_analysis_forceManipulation_task_data_saved/'\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for all animals\n",
    "summary_all_results = pd.DataFrame(columns=['date','forceContType','self_animal','partner_animal','subblockID',\n",
    "                                            'self_force','partner_force','trialnum','blocktime',\n",
    "                                            'succ_rate','gaze_number','pull_number',\n",
    "                                            'AcroAnimal_gazeDist_mean','AcroAnimal_gazeDist_shuffle',\n",
    "                                            'SameAnimal_gazeDist_mean','SameAnimal_gazeDist_shuffle',\n",
    "                                            'ccf_acrossAnimalsPulls','ccf_withinAnimalpullgaze','ccf_acrossAnimalspullgaze'\n",
    "                                           ])\n",
    "\n",
    "# load the data for plot\n",
    "mergetempRos = 0\n",
    "doBhvitv_timebin = 0\n",
    "\n",
    "temp_resolu = 1 # temporal resolution - 1s\n",
    "\n",
    "#\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    \n",
    "    animal1_fixedorder = [animal1_fixedorders[ianimalpair]]\n",
    "    animal2_fixedorder = [animal2_fixedorders[ianimalpair]]\n",
    "    \n",
    "    animal1_filename = animal1_filenames[ianimalpair]\n",
    "    animal2_filename = animal2_filenames[ianimalpair]\n",
    "    \n",
    "    # load data for all manipulation types\n",
    "    for iforceManiType in np.arange(0,nforceManiTypes,1):\n",
    "        \n",
    "        forceManiType = forceManiTypes[iforceManiType]\n",
    "        \n",
    "    \n",
    "        # load saved data\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "\n",
    "        with open(data_saved_subfolder+'/animal1_name_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            animal1_name_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/animal2_name_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            animal2_name_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/trialdates_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            trialdates_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/force1_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            force1_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/force2_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            force2_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/subblockID_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            subblockID_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/succ_rate_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            succ_rate_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/trialnum_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            trialnum_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/blocktime_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            blocktime_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/owgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            owgaze1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/owgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            owgaze2_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/mtgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            mtgaze1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/mtgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            mtgaze2_num_all_dates = pickle.load(f)     \n",
    "        with open(data_saved_subfolder+'/pull1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            pull1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/pull2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            pull2_num_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/cross_corr_bhv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            cross_corr_bhv_all_dates = pickle.load(f)\n",
    "            \n",
    "        # load the gaze distribution data\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_allsessions'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "\n",
    "        if not mergetempRos:\n",
    "            if doBhvitv_timebin:\n",
    "                with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_'+str(temp_resolu)+'bhvItvTempReSo.pkl', 'rb') as f:\n",
    "                    DBN_input_data_alltypes =pickle.load(f)\n",
    "                #\n",
    "                with open(data_saved_subfolder+'/SameAnimal_gazeDist_mean_all_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_'+str(temp_resolu)+'bhvItvTempReSo.pkl', 'rb') as f:\n",
    "                    SameAnimal_gazeDist_mean_all=pickle.load(f)\n",
    "                with open(data_saved_subfolder+'/AcroAnimal_gazeDist_mean_all_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_'+str(temp_resolu)+'bhvItvTempReSo.pkl', 'rb') as f:\n",
    "                    AcroAnimal_gazeDist_mean_all=pickle.load(f)\n",
    "                with open(data_saved_subfolder+'/SameAnimal_gazeDist_shuffle_all_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_'+str(temp_resolu)+'bhvItvTempReSo.pkl', 'rb') as f:\n",
    "                    SameAnimal_gazeDist_shuffle_all=pickle.load(f)\n",
    "                with open(data_saved_subfolder+'/AcroAnimal_gazeDist_shuffle_all_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_'+str(temp_resolu)+'bhvItvTempReSo.pkl', 'rb') as f:\n",
    "                    AcroAnimal_gazeDist_shuffle_all=pickle.load(f)\n",
    "            else:\n",
    "                with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "                    DBN_input_data_alltypes=pickle.load(f)\n",
    "                #\n",
    "                with open(data_saved_subfolder+'/SameAnimal_gazeDist_mean_all_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "                    SameAnimal_gazeDist_mean_all=pickle.load(f)\n",
    "                with open(data_saved_subfolder+'/AcroAnimal_gazeDist_mean_all_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "                    AcroAnimal_gazeDist_mean_all=pickle.load(f)\n",
    "                with open(data_saved_subfolder+'/SameAnimal_gazeDist_shuffle_all_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "                    SameAnimal_gazeDist_shuffle_all=pickle.load(f)\n",
    "                with open(data_saved_subfolder+'/AcroAnimal_gazeDist_shuffle_all_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "                    AcroAnimal_gazeDist_shuffle_all=pickle.load(f)\n",
    "        else:\n",
    "            with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "                DBN_input_data_alltypes=pickle.load(f) \n",
    "            #\n",
    "            with open(data_saved_subfolder+'/SameAnimal_gazeDist_mean_all_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "                SameAnimal_gazeDist_mean_all=pickle.load(f)\n",
    "            with open(data_saved_subfolder+'/AcroAnimal_gazeDist_mean_all_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "                AcroAnimal_gazeDist_mean_all=pickle.load(f)\n",
    "            with open(data_saved_subfolder+'/SameAnimal_gazeDist_shuffle_all_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "                SameAnimal_gazeDist_shuffle_all=pickle.load(f)\n",
    "            with open(data_saved_subfolder+'/AcroAnimal_gazeDist_shuffle_all_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "                AcroAnimal_gazeDist_shuffle_all=pickle.load(f)\n",
    "\n",
    "        print('all data are loaded:'+animal1_fixedorder[0]+' '+animal2_fixedorder[0]+' '+forceManiType)\n",
    "\n",
    "        # \n",
    "        ndates = np.shape(trialdates_all_dates)[0]\n",
    "        \n",
    "        for idate in np.arange(0,ndates,1):\n",
    "            \n",
    "            if forceManiType == 'SR_bothchange':\n",
    "                animal1_forceContType = 'self_change_SR'\n",
    "                animal2_forceContType = 'self_change_SR'\n",
    "            elif forceManiType == 'CO_A1change':\n",
    "                animal1_forceContType = 'self_change_MC'\n",
    "                animal2_forceContType = 'partner_change_MC'\n",
    "            elif forceManiType == 'CO_A2change':\n",
    "                animal1_forceContType = 'partner_change_MC'\n",
    "                animal2_forceContType = 'self_change_MC'\n",
    "            else:\n",
    "                animal1_forceContType = None\n",
    "                animal2_forceContType = None\n",
    "             \n",
    "            # cross correlation between bhv variables\n",
    "            cross_corr_allbhv_tgt = cross_corr_bhv_all_dates[trialdates_all_dates[idate]][str(int(force1_all_dates[idate]))+'&'+str(int(force2_all_dates[idate]))]\n",
    "            #\n",
    "            # center at pull1, xcorr of pull2\n",
    "            cross_corr_allbhv_pull1pull2 = cross_corr_allbhv_tgt['pull1']['pull2']\n",
    "            # center at pull1, xcorr of gaze1\n",
    "            cross_corr_allbhv_pull1gaze1 = cross_corr_allbhv_tgt['pull1']['gaze1']\n",
    "            # center at pull1, xcorr of gaze2\n",
    "            cross_corr_allbhv_pull1gaze2 = cross_corr_allbhv_tgt['pull1']['gaze2']\n",
    "            #\n",
    "            # center at pull2, xcorr of pull1\n",
    "            cross_corr_allbhv_pull2pull1 = cross_corr_allbhv_tgt['pull2']['pull1']\n",
    "            # center at pull2, xcorr of gaze2\n",
    "            cross_corr_allbhv_pull2gaze2 = cross_corr_allbhv_tgt['pull2']['gaze2']\n",
    "            # center at pull2, xcorr of gaze1\n",
    "            cross_corr_allbhv_pull2gaze1 = cross_corr_allbhv_tgt['pull2']['gaze1']\n",
    "            \n",
    "            # for animal1\n",
    "            forcecombined = str(int(force1_all_dates[idate]))+'&'+str(int(force2_all_dates[idate]))\n",
    "            \n",
    "            AcroAnimal_gazeDist_mean = AcroAnimal_gazeDist_mean_all[animal1_fixedorder[0]][trialdates_all_dates[idate]][forcecombined]\n",
    "            AcroAnimal_gazeDist_shuffle = AcroAnimal_gazeDist_shuffle_all[animal1_fixedorder[0]][trialdates_all_dates[idate]][forcecombined]\n",
    "            SameAnimal_gazeDist_mean = SameAnimal_gazeDist_mean_all[animal1_fixedorder[0]][trialdates_all_dates[idate]][forcecombined]\n",
    "            SameAnimal_gazeDist_shuffle = SameAnimal_gazeDist_shuffle_all[animal1_fixedorder[0]][trialdates_all_dates[idate]][forcecombined]\n",
    "           \n",
    "            summary_all_results = summary_all_results.append({\n",
    "                                                        'date': trialdates_all_dates[idate],\n",
    "                                                        'forceContType':animal1_forceContType,\n",
    "                                                        'self_animal': animal1_fixedorder[0],\n",
    "                                                        'partner_animal': animal2_fixedorder[0],\n",
    "                                                        'subblockID': subblockID_all_dates[idate],\n",
    "                                                        'self_force': force1_all_dates[idate],\n",
    "                                                        'partner_force': force2_all_dates[idate],\n",
    "                                                        'trialnum': trialnum_all_dates[idate],\n",
    "                                                        'blocktime': blocktime_all_dates[idate],\n",
    "                                                        'succ_rate': succ_rate_all_dates[idate],\n",
    "                                                        'gaze_number': owgaze1_num_all_dates[idate]+mtgaze1_num_all_dates[idate],\n",
    "                                                        'pull_number': pull1_num_all_dates[idate],\n",
    "                                                        'AcroAnimal_gazeDist_mean':AcroAnimal_gazeDist_mean,\n",
    "                                                        'AcroAnimal_gazeDist_shuffle':AcroAnimal_gazeDist_shuffle,\n",
    "                                                        'SameAnimal_gazeDist_mean':SameAnimal_gazeDist_mean,\n",
    "                                                        'SameAnimal_gazeDist_shuffle':SameAnimal_gazeDist_shuffle,  \n",
    "                                                        'ccf_acrossAnimalsPulls':cross_corr_allbhv_pull1pull2,\n",
    "                                                        'ccf_withinAnimalpullgaze':cross_corr_allbhv_pull1gaze1,\n",
    "                                                        'ccf_acrossAnimalspullgaze':cross_corr_allbhv_pull2gaze1,\n",
    "                                                    }, ignore_index=True)\n",
    "            \n",
    "            # for animal2\n",
    "            forcecombined = str(int(force1_all_dates[idate]))+'&'+str(int(force2_all_dates[idate]))\n",
    "            \n",
    "            AcroAnimal_gazeDist_mean = AcroAnimal_gazeDist_mean_all[animal2_fixedorder[0]][trialdates_all_dates[idate]][forcecombined]\n",
    "            AcroAnimal_gazeDist_shuffle = AcroAnimal_gazeDist_shuffle_all[animal2_fixedorder[0]][trialdates_all_dates[idate]][forcecombined]\n",
    "            SameAnimal_gazeDist_mean = SameAnimal_gazeDist_mean_all[animal2_fixedorder[0]][trialdates_all_dates[idate]][forcecombined]\n",
    "            SameAnimal_gazeDist_shuffle = SameAnimal_gazeDist_shuffle_all[animal2_fixedorder[0]][trialdates_all_dates[idate]][forcecombined]\n",
    "           \n",
    "            summary_all_results = summary_all_results.append({\n",
    "                                                        'date': trialdates_all_dates[idate],\n",
    "                                                        'forceContType':animal2_forceContType,\n",
    "                                                        'self_animal': animal2_fixedorder[0],\n",
    "                                                        'partner_animal': animal1_fixedorder[0],\n",
    "                                                        'subblockID': subblockID_all_dates[idate],\n",
    "                                                        'self_force': force2_all_dates[idate],\n",
    "                                                        'partner_force': force1_all_dates[idate],\n",
    "                                                        'trialnum': trialnum_all_dates[idate],\n",
    "                                                        'blocktime': blocktime_all_dates[idate],\n",
    "                                                        'succ_rate': succ_rate_all_dates[idate],\n",
    "                                                        'gaze_number': owgaze2_num_all_dates[idate]+mtgaze2_num_all_dates[idate],\n",
    "                                                        'pull_number': pull2_num_all_dates[idate],\n",
    "                                                        'AcroAnimal_gazeDist_mean':AcroAnimal_gazeDist_mean,\n",
    "                                                        'AcroAnimal_gazeDist_shuffle':AcroAnimal_gazeDist_shuffle,\n",
    "                                                        'SameAnimal_gazeDist_mean':SameAnimal_gazeDist_mean,\n",
    "                                                        'SameAnimal_gazeDist_shuffle':SameAnimal_gazeDist_shuffle,\n",
    "                                                        'ccf_acrossAnimalsPulls':cross_corr_allbhv_pull2pull1,\n",
    "                                                        'ccf_withinAnimalpullgaze':cross_corr_allbhv_pull2gaze2,\n",
    "                                                        'ccf_acrossAnimalspullgaze':cross_corr_allbhv_pull1gaze2,\n",
    "                                                    }, ignore_index=True)\n",
    "\n",
    "\n",
    "# calculating gaze and pull number per second\n",
    "summary_all_results['gazenum_pers'] = summary_all_results['gaze_number']/summary_all_results['blocktime']\n",
    "summary_all_results['pullnum_pers'] = summary_all_results['pull_number']/summary_all_results['blocktime']\n",
    "\n",
    "# remove entries that has too few trial number\n",
    "trialnum_threshold = 5\n",
    "\n",
    "ind_bad = summary_all_results['trialnum']<trialnum_threshold\n",
    "\n",
    "summary_all_results = summary_all_results[~ind_bad].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ede61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for the version that force and success rate and other variables are separated into quantiles\n",
    "summary_all_results_quantile = summary_all_results.copy()\n",
    "\n",
    "unique_combinations = summary_all_results[['date', 'self_animal']].drop_duplicates()\n",
    "ncombines = np.shape(unique_combinations)[0]\n",
    "\n",
    "columns_todo = ['self_force','partner_force','succ_rate','subblockID','gazenum_pers','pullnum_pers']\n",
    "# columns_todo = ['succ_rate','subblockID','gazenum_pers','pullnum_pers']\n",
    "ntodos = np.shape(columns_todo)[0]\n",
    "\n",
    "for icombine in np.arange(0,ncombines,1):\n",
    "    \n",
    "    date_tgt = list(unique_combinations['date'])[icombine]\n",
    "    selfanimal_tgt = list(unique_combinations['self_animal'])[icombine]\n",
    "    \n",
    "    # for normal dataset\n",
    "    ind_tgt = (summary_all_results_quantile['date']==date_tgt)&\\\n",
    "    (summary_all_results_quantile['self_animal']==selfanimal_tgt)\n",
    "    \n",
    "    for itodo in np.arange(0,ntodos,1):\n",
    "        column_todo = columns_todo[itodo]\n",
    "\n",
    "        yyy = np.array(summary_all_results_quantile[column_todo][ind_tgt])\n",
    "        \n",
    "        # only one kind of force\n",
    "        if np.shape(np.unique(yyy))[0] == 1:\n",
    "            yyy_quant = np.ones(np.shape(yyy))*1\n",
    "        # two kinds of force\n",
    "        elif np.shape(np.unique(yyy))[0] == 2:\n",
    "            ranks = st.rankdata(yyy, method='average')  # Average ranks for ties\n",
    "            yyy_quant = (np.ceil(ranks / len(yyy) * 2)-1)*2+1 # separate into three quantiles\n",
    "            # yyy_quant = (np.ceil(ranks / len(yyy) * 2)) # separate into two quantiles         \n",
    "        # more than two kinds of force,\n",
    "        else:\n",
    "            ranks = st.rankdata(yyy, method='average')  # Average ranks for ties\n",
    "            yyy_quant = np.ceil(ranks / len(yyy) * 3) # separate into three quantiles\n",
    "            # yyy_quant = (np.ceil(ranks / len(yyy) * 2)) # separate into two quantiles\n",
    "        \n",
    "        # Update the DataFrame with residuals for the current column\n",
    "        summary_all_results_quantile.loc[ind_tgt, column_todo] = yyy_quant\n",
    "    \n",
    "print('create dataframe for the version that force and other variables is defined into quantiles')\n",
    "# print('create dataframe for the version that variables other than force is defined into quantiles')\n",
    "\n",
    "# summary_all_results_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc52bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for the version that force are refered to the first block and then separated into quantiles\n",
    "if 0: \n",
    "    # summary_all_results_quantile = summary_all_results.copy()\n",
    "\n",
    "    unique_combinations = summary_all_results[['date', 'self_animal']].drop_duplicates()\n",
    "    ncombines = np.shape(unique_combinations)[0]\n",
    "\n",
    "    columns_todo = ['self_force','partner_force',]\n",
    "    ntodos = np.shape(columns_todo)[0]\n",
    "\n",
    "    for icombine in np.arange(0,ncombines,1):\n",
    "\n",
    "        date_tgt = list(unique_combinations['date'])[icombine]\n",
    "        selfanimal_tgt = list(unique_combinations['self_animal'])[icombine]\n",
    "\n",
    "        # for normal dataset\n",
    "        ind_tgt = (summary_all_results_quantile['date']==date_tgt)&\\\n",
    "        (summary_all_results_quantile['self_animal']==selfanimal_tgt)\n",
    "\n",
    "        for itodo in np.arange(0,ntodos,1):\n",
    "            column_todo = columns_todo[itodo]\n",
    "\n",
    "            yyy = np.array(summary_all_results_quantile[column_todo][ind_tgt])\n",
    "\n",
    "            # two steps: \n",
    "            # step 1 - refer to the force of the first block; \n",
    "            # step 2 - two 'quantile': 1 for smaller than and same as first block; 2 for larger than the first block        \n",
    "            yyy_new = yyy - yyy[0]\n",
    "            yyy_quant = np.ones(np.shape(yyy_new))\n",
    "            yyy_quant[yyy_new>=0] = 2\n",
    "\n",
    "            # Update the DataFrame with residuals for the current column\n",
    "            summary_all_results_quantile.loc[ind_tgt, column_todo] = yyy_quant\n",
    "\n",
    "\n",
    "\n",
    "    print('create dataframe for the version that force is defined into quantiles based on the reference to the first block')\n",
    "\n",
    "    # summary_all_results_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for the version that force are separated into quantiles,but based on the refered to the previous block\n",
    "if 0: \n",
    "    # summary_all_results_quantile = summary_all_results.copy()\n",
    "\n",
    "    unique_combinations = summary_all_results[['date', 'self_animal']].drop_duplicates()\n",
    "    ncombines = np.shape(unique_combinations)[0]\n",
    "\n",
    "    columns_todo = ['partner_force','self_force',]\n",
    "    ntodos = np.shape(columns_todo)[0]\n",
    "\n",
    "    for icombine in np.arange(0,ncombines,1):\n",
    "\n",
    "        date_tgt = list(unique_combinations['date'])[icombine]\n",
    "        selfanimal_tgt = list(unique_combinations['self_animal'])[icombine]\n",
    "\n",
    "        # for normal dataset\n",
    "        ind_tgt = (summary_all_results_quantile['date']==date_tgt)&\\\n",
    "        (summary_all_results_quantile['self_animal']==selfanimal_tgt)\n",
    "\n",
    "        for itodo in np.arange(0,ntodos,1):\n",
    "            column_todo = columns_todo[itodo]\n",
    "\n",
    "            yyy = np.array(summary_all_results_quantile[column_todo][ind_tgt])\n",
    "\n",
    "            # two steps: \n",
    "            # step 1 - refer to the force of the first block; \n",
    "            # step 2 - two 'quantile': 1 for smaller than and same as first block; 2 for larger than the first block        \n",
    "            yyy_new = yyy - np.hstack((yyy[0],yyy[0:-1]))\n",
    "            yyy_quant = np.ones(np.shape(yyy_new))\n",
    "            yyy_quant[yyy_new>0] = 2\n",
    "\n",
    "            # Update the DataFrame with residuals for the current column\n",
    "            summary_all_results_quantile.loc[ind_tgt, column_todo] = yyy_quant\n",
    "\n",
    "\n",
    "\n",
    "    print('create dataframe for the version that force is defined into quantiles based on the reference to the previous block')\n",
    "\n",
    "    # summary_all_results_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b487367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for the version that force are separated into quantiles, based on the value cluster\n",
    "if 0: \n",
    "    from sklearn.cluster import KMeans\n",
    "    \n",
    "    # summary_all_results_quantile = summary_all_results.copy()\n",
    "    unique_combinations = summary_all_results[['date', 'self_animal']].drop_duplicates()\n",
    "    ncombines = np.shape(unique_combinations)[0]\n",
    "\n",
    "    columns_todo = ['self_force','partner_force',]\n",
    "    ntodos = np.shape(columns_todo)[0]\n",
    "\n",
    "    for icombine in np.arange(0,ncombines,1):\n",
    "\n",
    "        date_tgt = list(unique_combinations['date'])[icombine]\n",
    "        selfanimal_tgt = list(unique_combinations['self_animal'])[icombine]\n",
    "\n",
    "        # for normal dataset\n",
    "        ind_tgt = (summary_all_results_quantile['date']==date_tgt)&\\\n",
    "        (summary_all_results_quantile['self_animal']==selfanimal_tgt)\n",
    "\n",
    "        for itodo in np.arange(0,ntodos,1):\n",
    "            column_todo = columns_todo[itodo]\n",
    "\n",
    "            yyy = np.array(summary_all_results_quantile[column_todo][ind_tgt])\n",
    "            y_array = np.array(yyy).reshape(-1, 1)\n",
    "            \n",
    "            # Perform k-means clustering with 2 clusters\n",
    "            kmeans = KMeans(n_clusters=2, random_state=42).fit(y_array)         \n",
    "            yyy_quant = kmeans.labels_ + 1\n",
    "\n",
    "            # Update the DataFrame with residuals for the current column\n",
    "            summary_all_results_quantile.loc[ind_tgt, column_todo] = yyy_quant\n",
    "\n",
    "\n",
    "\n",
    "    print('create dataframe for the version that force is defined into quantiles based on the value cluster')\n",
    "\n",
    "    # summary_all_results_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66beee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(summary_all_results_quantile['self_force']==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between variables\n",
    "summary_all_tgt = summary_all_results_quantile\n",
    "\n",
    "ind_tgt = (summary_all_tgt['forceContType']=='self_change_MC') # & (summary_all_tgt['self_animal']=='vermelho')\n",
    "summary_all_tgt = summary_all_tgt[ind_tgt]\n",
    "\n",
    "data1 = np.array(summary_all_tgt['subblockID'])\n",
    "data2 = np.array(summary_all_tgt['succ_rate'])\n",
    "\n",
    "kendall_corr, kendall_p = st.kendalltau(data1, data2)\n",
    "print(f\"Kendall's tau: {kendall_corr}, p-value: {kendall_p}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1212536",
   "metadata": {},
   "source": [
    "### plot the summarizing figures with all animals\n",
    "#### averaged gaze distribution around pull (self pull or other pull)\n",
    "#### separating condition (self sr, other sr, self mc, other mc etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f1a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_all_tgt = summary_all_results_quantile\n",
    "nTrialConds = np.shape(np.unique(summary_all_tgt['forceContType']))[0]\n",
    "\n",
    "# xplottype = 'pullnum_pers' # 'succ_rate', 'subblockID', 'gazenum_pers', 'pullnum_pers'\n",
    "xplottype = 'self_force'  # 'self_force', 'partner_force'\n",
    "nxplotgroups = np.shape(np.unique(summary_all_tgt[xplottype]))[0]\n",
    "xplotgroupcolors = ['red','blue','green','skyblue','purple']\n",
    "\n",
    "yplottypes = ['AcroAnimal_gazeDist','SameAnimal_gazeDist']\n",
    "nyplottypes = np.shape(yplottypes)[0]\n",
    "\n",
    "timebins = np.arange(-5,6,1)\n",
    "\n",
    "# Set up the figure grid\n",
    "fig, axes = plt.subplots(nTrialConds, nyplottypes, \n",
    "                         figsize=(5 * nyplottypes, 4 * nTrialConds), \n",
    "                         sharex=True, sharey=False)\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "# Plotting each unique condition and y-axis type\n",
    "unique_conditions = summary_all_tgt['forceContType'].unique()\n",
    "\n",
    "for i, condition in enumerate(unique_conditions):\n",
    "    # Filter data for the current condition\n",
    "    condition_data = summary_all_tgt[summary_all_tgt['forceContType'] == condition]\n",
    "    \n",
    "    for j, yplot in enumerate(yplottypes):\n",
    "        ax = axes[i, j] if nTrialConds > 1 else axes[j]  # Adjust for single-row cases\n",
    "        \n",
    "        # create dataframe and then do statistic test\n",
    "        condition_data_fortest = pd.concat([pd.DataFrame(condition_data[yplot+'_mean'].\n",
    "                                                     reset_index(drop=True).values.tolist()),\n",
    "                                        condition_data[xplottype].reset_index(drop=True)],axis=1)\n",
    "\n",
    "        anova_results = {}\n",
    "        for col in range(0, np.shape(condition_data_fortest)[1]-1):\n",
    "            # Group the data by `partner_force`\n",
    "            groups = [group[col].values for name, group in condition_data_fortest.groupby(xplottype)]\n",
    "            # Filter out NaNs from each array in groups\n",
    "            groups_cleaned = [g[~np.isnan(g)] for g in groups]\n",
    "\n",
    "            # Run ANOVA on cleaned groups\n",
    "            try:\n",
    "                f_stat, p_value = st.f_oneway(*groups_cleaned)\n",
    "            except:\n",
    "                f_stat = np.nan\n",
    "                p_value = np.nan\n",
    "            # Store results\n",
    "            anova_results[col] = {'F-statistic': f_stat, 'p-value': p_value}\n",
    "        anova_results_df = pd.DataFrame(anova_results).T\n",
    "        # print(anova_results_df)\n",
    "     \n",
    "        # for plot\n",
    "        for ixplotgroup in np.arange(1,nxplotgroups+1,1):\n",
    "            # group based on the force quantile\n",
    "            condition_data_iforcequant = condition_data[condition_data[xplottype]==ixplotgroup]\n",
    "\n",
    "            # real data\n",
    "            data_cleaned = condition_data_iforcequant[yplot+'_mean'].reset_index(drop=True)\n",
    "\n",
    "            data_clean_df = pd.DataFrame(data_cleaned.values.tolist())\n",
    "            xxx_mean = np.nanmean(data_clean_df,axis=0)\n",
    "            xxx_std = np.nanstd(data_clean_df,axis=0)/np.sqrt(np.shape(data_clean_df)[0])\n",
    "            \n",
    "            # shuffled data\n",
    "            data_cleaned_sf = condition_data_iforcequant[yplot+'_shuffle'].reset_index(drop=True)\n",
    "\n",
    "            data_clean_sf_df = pd.DataFrame(data_cleaned_sf.values.tolist())\n",
    "            xxx_mean_sf = np.nanmean(data_clean_sf_df,axis=0)\n",
    "            xxx_std_sf = np.nanstd(data_clean_sf_df,axis=0)/np.sqrt(np.shape(data_clean_sf_df)[0])\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                # real data\n",
    "                seaborn.lineplot(x=timebins, y=xxx_mean, ax=ax,label=xplottype+'level'+str(ixplotgroup),\n",
    "                                 color = xplotgroupcolors[ixplotgroup-1])\n",
    "                ax.fill_between(timebins, xxx_mean - xxx_std, xxx_mean + xxx_std, alpha=0.3,\n",
    "                                color = xplotgroupcolors[ixplotgroup-1])\n",
    "                # shuffled data\n",
    "                seaborn.lineplot(x=timebins, y=xxx_mean_sf, ax=ax,label=xplottype+'level'+str(ixplotgroup)+'shuffled',\n",
    "                                 color = xplotgroupcolors[ixplotgroup-1],linestyle='--')\n",
    "                ax.fill_between(timebins, xxx_mean_sf - xxx_std_sf, xxx_mean_sf + xxx_std_sf, alpha=0.1,\n",
    "                                color = xplotgroupcolors[ixplotgroup-1])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        ax.set_ylim([-0.05,0.55])\n",
    "        ax.plot([0,0],ax.get_ylim(),'k--')\n",
    "        \n",
    "        # Add significance markers outside of group loop\n",
    "        for col, p_value in enumerate(anova_results_df['p-value']):\n",
    "            if p_value < 0.05:  # Significance threshold\n",
    "                # Slight vertical offset for the marker\n",
    "                ax.text(timebins[col], 0.5, '*', ha='center', color='black', fontsize=12)\n",
    "\n",
    "        \n",
    "        # Set titles and labels\n",
    "        ax.set_title(f\"{condition} - {yplot}\")\n",
    "        if i == nTrialConds - 1:\n",
    "            ax.set_xlabel('time (s)')\n",
    "        if j == 0:\n",
    "            ax.set_ylabel('social gaze distribution')\n",
    "\n",
    "            \n",
    "\n",
    "plt.show()\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_allanimal_summary/'+savefile_sufix+'/'+cameraID+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    fig.savefig(figsavefolder+\"gaze_distribution_aligned_with_pulls_groupedas\"+xplottype+\".pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a6643",
   "metadata": {},
   "source": [
    "### plot the summarizing figures with all animals - separate animals\n",
    "#### averaged gaze distribution around pull (self pull or other pull)\n",
    "#### separating condition (self sr, other sr, self mc, other mc etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_all_tgt = summary_all_results_quantile\n",
    "\n",
    "nTrialConds = np.shape(np.unique(summary_all_tgt['forceContType']))[0]\n",
    "\n",
    "selfanimals = np.unique(summary_all_tgt['self_animal'])\n",
    "nanimals = np.shape(selfanimals)[0]\n",
    "\n",
    "# xplottype = 'subblockID'\n",
    "xplottype = 'partner_force'  # 'self_force', 'partner_force'\n",
    "nxplotgroups = np.shape(np.unique(summary_all_tgt[xplottype]))[0]\n",
    "xplotgroupcolors = ['red','blue','green','skyblue','purple']\n",
    "\n",
    "yplottype = 'SameAnimal_gazeDist'\n",
    "\n",
    "timebins = np.arange(-5,6,1)\n",
    "\n",
    "# Set up the figure grid\n",
    "fig, axes = plt.subplots(nTrialConds, nanimals, \n",
    "                         figsize=(5 * nanimals, 4 * nTrialConds), \n",
    "                         sharex=True, sharey=False)\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "# Plotting each unique condition and y-axis type\n",
    "unique_conditions = summary_all_tgt['forceContType'].unique()\n",
    "\n",
    "for i, condition in enumerate(unique_conditions):\n",
    "    # Filter data for the current condition\n",
    "    condition_data = summary_all_tgt[summary_all_tgt['forceContType'] == condition]\n",
    "    \n",
    "    for j, ianimal in enumerate(selfanimals):\n",
    "        ax = axes[i, j] if nTrialConds > 1 else axes[j]  # Adjust for single-row cases\n",
    "        \n",
    "        condition_data_ianimal = condition_data[condition_data['self_animal']==ianimal]\n",
    "\n",
    "        # create dataframe and then do statistic test\n",
    "        condition_data_fortest = pd.concat([pd.DataFrame(condition_data_ianimal[yplottype+'_mean'].\n",
    "                                                     reset_index(drop=True).values.tolist()),\n",
    "                                        condition_data_ianimal[xplottype].reset_index(drop=True)],axis=1)\n",
    "\n",
    "        anova_results = {}\n",
    "        for col in range(0, np.shape(condition_data_fortest)[1]-1):\n",
    "            # Group the data by `partner_force`\n",
    "            groups = [group[col].values for name, group in condition_data_fortest.groupby(xplottype)]\n",
    "            # Filter out NaNs from each array in groups\n",
    "            groups_cleaned = [g[~np.isnan(g)] for g in groups]\n",
    "\n",
    "            # Run ANOVA on cleaned groups\n",
    "            try:\n",
    "                f_stat, p_value = st.f_oneway(*groups_cleaned)\n",
    "            except:\n",
    "                f_stat = np.nan\n",
    "                p_value = np.nan\n",
    "            # Store results\n",
    "            anova_results[col] = {'F-statistic': f_stat, 'p-value': p_value}\n",
    "        anova_results_df = pd.DataFrame(anova_results).T\n",
    "        # print(anova_results_df)\n",
    "        \n",
    "        \n",
    "        # for plot\n",
    "        for ixplotgroup in np.arange(1,nxplotgroups+1,1):\n",
    "            # group based on the force quantile\n",
    "            condition_data_iforcequant_ianimal = condition_data_ianimal[condition_data_ianimal[xplottype]==ixplotgroup]\n",
    " \n",
    "            # real data\n",
    "            data_cleaned = condition_data_iforcequant_ianimal[yplottype+'_mean'].reset_index(drop=True)\n",
    "\n",
    "            data_clean_df = pd.DataFrame(data_cleaned.values.tolist())\n",
    "            xxx_mean = np.nanmean(data_clean_df,axis=0)\n",
    "            xxx_std = np.nanstd(data_clean_df,axis=0)/np.sqrt(np.shape(data_clean_df)[0])\n",
    "            \n",
    "            # shuffled data\n",
    "            data_cleaned_sf = condition_data_iforcequant_ianimal[yplottype+'_shuffle'].reset_index(drop=True)\n",
    "\n",
    "            data_clean_sf_df = pd.DataFrame(data_cleaned_sf.values.tolist())\n",
    "            xxx_mean_sf = np.nanmean(data_clean_sf_df,axis=0)\n",
    "            xxx_std_sf = np.nanstd(data_clean_sf_df,axis=0)/np.sqrt(np.shape(data_clean_sf_df)[0])\n",
    "            \n",
    "            try:\n",
    "                # real data\n",
    "                seaborn.lineplot(x=timebins, y=xxx_mean, ax=ax,label=xplottype+'level'+str(ixplotgroup),\n",
    "                                 color = xplotgroupcolors[ixplotgroup-1])\n",
    "                ax.fill_between(timebins, xxx_mean - xxx_std, xxx_mean + xxx_std, alpha=0.3,\n",
    "                                color = xplotgroupcolors[ixplotgroup-1])\n",
    "                # shuffled data\n",
    "                seaborn.lineplot(x=timebins, y=xxx_mean_sf, ax=ax,label=xplottype+'level'+str(ixplotgroup)+'shuffled',\n",
    "                                 color = xplotgroupcolors[ixplotgroup-1],linestyle='--')\n",
    "                ax.fill_between(timebins, xxx_mean_sf - xxx_std_sf, xxx_mean_sf + xxx_std_sf, alpha=0.1,\n",
    "                                color = xplotgroupcolors[ixplotgroup-1])\n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        ax.set_ylim([-0.05,0.55])\n",
    "        ax.plot([0,0],ax.get_ylim(),'k--')\n",
    "        \n",
    "        # Add significance markers outside of group loop\n",
    "        for col, p_value in enumerate(anova_results_df['p-value']):\n",
    "            if p_value < 0.05:  # Significance threshold\n",
    "                # Slight vertical offset for the marker\n",
    "                ax.text(timebins[col], 0.5, '*', ha='center', color='black', fontsize=12)\n",
    "\n",
    "        \n",
    "        # Set titles and labels\n",
    "        ax.set_title(f\"{condition} - {yplottype}; {ianimal}\")\n",
    "        if i == nTrialConds - 1:\n",
    "            ax.set_xlabel('time (s)')\n",
    "        if j == 0:\n",
    "            ax.set_ylabel('social gaze distribution')\n",
    "            \n",
    "\n",
    "plt.show()\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_allanimal_summary/'+savefile_sufix+'/'+cameraID+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    fig.savefig(figsavefolder+\"gaze_distribution_aligned_with_pulls_groupedas\"+xplottype+\"_\"+yplottype+\"_separateanimals.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf12599",
   "metadata": {},
   "source": [
    "### plot the summarizing figures with all animals\n",
    "#### average cross correlation function \n",
    "#### separating condition (self sr, other sr, self mc, other mc etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_all_tgt = summary_all_results_quantile\n",
    "\n",
    "# Plotting each unique condition and y-axis type\n",
    "unique_conditions = summary_all_tgt['forceContType'].unique()\n",
    "# unique_conditions = ['self_change_SR']\n",
    "# \n",
    "nTrialConds = np.shape(unique_conditions)[0]\n",
    "\n",
    "# xplottype = 'subblockID' # 'succ_rate', 'subblockID', 'gazenum_pers', 'pullnum_pers'\n",
    "xplottype = 'self_force'  # 'self_force', 'partner_force'\n",
    "nxplotgroups = np.shape(np.unique(summary_all_tgt[xplottype]))[0]\n",
    "xplotgroupcolors = ['red','blue','green','skyblue','purple']\n",
    "\n",
    "yplottypes = ['ccf_acrossAnimalsPulls','ccf_withinAnimalpullgaze','ccf_acrossAnimalspullgaze']\n",
    "# yplottypes = ['ccf_acrossAnimalsPulls']\n",
    "nyplottypes = np.shape(yplottypes)[0]\n",
    "\n",
    "timebins = np.arange(-4,4.1,0.1)\n",
    "\n",
    "# Set up the figure grid\n",
    "fig, axes = plt.subplots(nTrialConds, nyplottypes, \n",
    "                         figsize=(5 * nyplottypes, 4 * nTrialConds), \n",
    "                         sharex=False, sharey=False)\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "\n",
    "\n",
    "for i, condition in enumerate(unique_conditions):\n",
    "    # Filter data for the current condition\n",
    "    condition_data = summary_all_tgt[summary_all_tgt['forceContType'] == condition]\n",
    "    \n",
    "    for j, yplot in enumerate(yplottypes):\n",
    "        ax = axes[i, j] if nTrialConds > 1 else axes[j]  # Adjust for single-row cases\n",
    "        \n",
    "        # create dataframe and then do statistic test\n",
    "        condition_data_fortest = pd.concat([pd.DataFrame(condition_data[yplot].\n",
    "                                                     reset_index(drop=True).values.tolist()),\n",
    "                                        condition_data[xplottype].reset_index(drop=True)],axis=1)\n",
    "\n",
    "        anova_results = {}\n",
    "        for col in range(0, np.shape(condition_data_fortest)[1]-1):\n",
    "            # Group the data by `partner_force`\n",
    "            groups = [group[col].values for name, group in condition_data_fortest.groupby(xplottype)]\n",
    "            # Filter out NaNs from each array in groups\n",
    "            groups_cleaned = [g[~np.isnan(g)] for g in groups]\n",
    "\n",
    "            # Run ANOVA on cleaned groups\n",
    "            try:\n",
    "                f_stat, p_value = st.f_oneway(*groups_cleaned)\n",
    "            except:\n",
    "                f_stat = np.nan\n",
    "                p_value = np.nan\n",
    "            # Store results\n",
    "            anova_results[col] = {'F-statistic': f_stat, 'p-value': p_value}\n",
    "        anova_results_df = pd.DataFrame(anova_results).T\n",
    "        # print(anova_results_df)\n",
    "     \n",
    "        # for plot\n",
    "        for ixplotgroup in np.arange(1,nxplotgroups+1,1):\n",
    "            # group based on the force quantile\n",
    "            condition_data_iforcequant = condition_data[condition_data[xplottype]==ixplotgroup]\n",
    "\n",
    "            # real data\n",
    "            data_cleaned = condition_data_iforcequant[yplot].reset_index(drop=True)\n",
    "\n",
    "            data_clean_df = pd.DataFrame(data_cleaned.values.tolist())\n",
    "            xxx_mean = np.nanmean(data_clean_df,axis=0)\n",
    "            xxx_std = np.nanstd(data_clean_df,axis=0)/np.sqrt(np.shape(data_clean_df)[0])\n",
    "            \n",
    "            # # shuffled data\n",
    "            # data_cleaned_sf = condition_data_iforcequant[yplot+'_shuffle'].reset_index(drop=True)\n",
    "            # \n",
    "            # data_clean_sf_df = pd.DataFrame(data_cleaned_sf.values.tolist())\n",
    "            # xxx_mean_sf = np.nanmean(data_clean_sf_df,axis=0)\n",
    "            # xxx_std_sf = np.nanstd(data_clean_sf_df,axis=0)/np.sqrt(np.shape(data_clean_sf_df)[0])\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                # real data\n",
    "                seaborn.lineplot(x=timebins, y=xxx_mean, ax=ax,label=xplottype+'level'+str(ixplotgroup),\n",
    "                                 color = xplotgroupcolors[ixplotgroup-1])\n",
    "                ax.fill_between(timebins, xxx_mean - xxx_std, xxx_mean + xxx_std, alpha=0.3,\n",
    "                                color = xplotgroupcolors[ixplotgroup-1])\n",
    "                # # shuffled data\n",
    "                # seaborn.lineplot(x=timebins, y=xxx_mean_sf, ax=ax,label=xplottype+'level'+str(ixplotgroup)+'shuffled',\n",
    "                #                  color = xplotgroupcolors[ixplotgroup-1],linestyle='--')\n",
    "                # ax.fill_between(timebins, xxx_mean_sf - xxx_std_sf, xxx_mean_sf + xxx_std_sf, alpha=0.1,\n",
    "                #                 color = xplotgroupcolors[ixplotgroup-1])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        ax.set_ylim([-0.05,0.25])\n",
    "        ax.plot([0,0],ax.get_ylim(),'k--')\n",
    "        \n",
    "        # Add significance markers outside of group loop\n",
    "        for col, p_value in enumerate(anova_results_df['p-value']):\n",
    "            if p_value < 0.06:  # Significance threshold\n",
    "                # Slight vertical offset for the marker\n",
    "                ax.text(timebins[col], 0.15, '*', ha='center', color='black', fontsize=12)\n",
    "\n",
    "        \n",
    "        # Set titles and labels\n",
    "        ax.set_title(f\"{condition} - {yplot}\")\n",
    "        # if i == nTrialConds - 1:\n",
    "        ax.set_xlabel('time (s)')\n",
    "        # if j == 0:\n",
    "        ax.set_ylabel('cross correlation function')\n",
    "\n",
    "            \n",
    "\n",
    "plt.show()\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_allanimal_summary/'+savefile_sufix+'/'+cameraID+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    fig.savefig(figsavefolder+\"bhv_cross_corelation_groupedas\"+xplottype+\".pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce5e30b",
   "metadata": {},
   "source": [
    "### plot the summarizing figures with all animals - separate animals\n",
    "#### average cross correlation function \n",
    "#### separating condition (self sr, other sr, self mc, other mc etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc98f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_all_tgt = summary_all_results_quantile\n",
    "\n",
    "# Plotting each unique condition and y-axis type\n",
    "unique_conditions = summary_all_tgt['forceContType'].unique()\n",
    "#\n",
    "nTrialConds = np.shape(unique_conditions)[0]\n",
    "\n",
    "selfanimals = np.unique(summary_all_tgt['self_animal'])\n",
    "nanimals = np.shape(selfanimals)[0]\n",
    "\n",
    "# xplottype = 'subblockID'\n",
    "xplottype = 'self_force'  # 'self_force', 'partner_force'\n",
    "nxplotgroups = np.shape(np.unique(summary_all_tgt[xplottype]))[0]\n",
    "xplotgroupcolors = ['red','blue','green','skyblue','purple']\n",
    "\n",
    "yplottype = 'ccf_acrossAnimalsPulls' # 'ccf_acrossAnimalsPulls','ccf_withinAnimalpullgaze','ccf_acrossAnimalspullgaze'\n",
    "\n",
    "timebins = np.arange(-4,4.1,0.1)\n",
    "\n",
    "# Set up the figure grid\n",
    "fig, axes = plt.subplots(nTrialConds, nanimals, \n",
    "                         figsize=(5 * nanimals, 4 * nTrialConds), \n",
    "                         sharex=False, sharey=False)\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "\n",
    "\n",
    "for i, condition in enumerate(unique_conditions):\n",
    "    # Filter data for the current condition\n",
    "    condition_data = summary_all_tgt[summary_all_tgt['forceContType'] == condition]\n",
    "    \n",
    "    for j, ianimal in enumerate(selfanimals):\n",
    "        ax = axes[i, j] if nTrialConds > 1 else axes[j]  # Adjust for single-row cases\n",
    "        \n",
    "        condition_data_ianimal = condition_data[condition_data['self_animal']==ianimal]\n",
    "\n",
    "        # create dataframe and then do statistic test\n",
    "        condition_data_fortest = pd.concat([pd.DataFrame(condition_data_ianimal[yplottype].\n",
    "                                                     reset_index(drop=True).values.tolist()),\n",
    "                                        condition_data_ianimal[xplottype].reset_index(drop=True)],axis=1)\n",
    "\n",
    "        anova_results = {}\n",
    "        for col in range(0, np.shape(condition_data_fortest)[1]-1):\n",
    "            # Group the data by `partner_force`\n",
    "            groups = [group[col].values for name, group in condition_data_fortest.groupby(xplottype)]\n",
    "            # Filter out NaNs from each array in groups\n",
    "            groups_cleaned = [g[~np.isnan(g)] for g in groups]\n",
    "\n",
    "            # Run ANOVA on cleaned groups\n",
    "            try:\n",
    "                f_stat, p_value = st.f_oneway(*groups_cleaned)\n",
    "            except:\n",
    "                f_stat = np.nan\n",
    "                p_value = np.nan\n",
    "            # Store results\n",
    "            anova_results[col] = {'F-statistic': f_stat, 'p-value': p_value}\n",
    "        anova_results_df = pd.DataFrame(anova_results).T\n",
    "        # print(anova_results_df)\n",
    "        \n",
    "        \n",
    "        # for plot\n",
    "        for ixplotgroup in np.arange(1,nxplotgroups+1,1):\n",
    "            # group based on the force quantile\n",
    "            condition_data_iforcequant_ianimal = condition_data_ianimal[condition_data_ianimal[xplottype]==ixplotgroup]\n",
    " \n",
    "            # real data\n",
    "            data_cleaned = condition_data_iforcequant_ianimal[yplottype].reset_index(drop=True)\n",
    "\n",
    "            data_clean_df = pd.DataFrame(data_cleaned.values.tolist())\n",
    "            xxx_mean = np.nanmean(data_clean_df,axis=0)\n",
    "            xxx_std = np.nanstd(data_clean_df,axis=0)/np.sqrt(np.shape(data_clean_df)[0])\n",
    "            \n",
    "            # # shuffled data\n",
    "            # data_cleaned_sf = condition_data_iforcequant_ianimal[yplottype+'_shuffle'].reset_index(drop=True)\n",
    "            # \n",
    "            # data_clean_sf_df = pd.DataFrame(data_cleaned_sf.values.tolist())\n",
    "            # xxx_mean_sf = np.nanmean(data_clean_sf_df,axis=0)\n",
    "            # xxx_std_sf = np.nanstd(data_clean_sf_df,axis=0)/np.sqrt(np.shape(data_clean_sf_df)[0])\n",
    "            \n",
    "            try:\n",
    "                # real data\n",
    "                seaborn.lineplot(x=timebins, y=xxx_mean, ax=ax,label=xplottype+'level'+str(ixplotgroup),\n",
    "                                 color = xplotgroupcolors[ixplotgroup-1])\n",
    "                ax.fill_between(timebins, xxx_mean - xxx_std, xxx_mean + xxx_std, alpha=0.3,\n",
    "                                color = xplotgroupcolors[ixplotgroup-1])\n",
    "                # # shuffled data\n",
    "                # seaborn.lineplot(x=timebins, y=xxx_mean_sf, ax=ax,label=xplottype+'level'+str(ixplotgroup)+'shuffled',\n",
    "                #                  color = xplotgroupcolors[ixplotgroup-1],linestyle='--')\n",
    "                # ax.fill_between(timebins, xxx_mean_sf - xxx_std_sf, xxx_mean_sf + xxx_std_sf, alpha=0.1,\n",
    "                #                 color = xplotgroupcolors[ixplotgroup-1])\n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        ax.set_ylim([-0.05,0.25])\n",
    "        ax.plot([0,0],ax.get_ylim(),'k--')\n",
    "        \n",
    "        # Add significance markers outside of group loop\n",
    "        for col, p_value in enumerate(anova_results_df['p-value']):\n",
    "            if p_value < 0.05:  # Significance threshold\n",
    "                # Slight vertical offset for the marker\n",
    "                ax.text(timebins[col], 0.15, '*', ha='center', color='black', fontsize=12)\n",
    "\n",
    "        \n",
    "        # Set titles and labels\n",
    "        ax.set_title(f\"{condition} - {yplottype}; {ianimal}\")\n",
    "        # if i == nTrialConds - 1:\n",
    "        ax.set_xlabel('time (s)')\n",
    "        # if j == 0:\n",
    "        ax.set_ylabel('cross correlation function')\n",
    "            \n",
    "\n",
    "plt.show()\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_allanimal_summary/'+savefile_sufix+'/'+cameraID+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    fig.savefig(figsavefolder+\"bhv_cross_corelation_groupedas\"+xplottype+\"_\"+yplottype+\"_separateanimals.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006edf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_all_tgt['forceContType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f5ba99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a880ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f35fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18148622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2234d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4dadb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271b0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117a94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2584223d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c634d699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f42ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
