{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca6246b",
   "metadata": {},
   "source": [
    "### In this script, DBN is run on the all the sessions\n",
    "### In this script, DBN is run with 1s time bin, 3 time lag \n",
    "### In this script, the animal tracking is done with only one camera - camera 2 (middle) \n",
    "### This script specifically summarized the DBN related results\n",
    "#### this script focuses on the summarizing results pooling all four animals (two dyads); it can only be run after the \"3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd279dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import string\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.models import DynamicBayesianNetwork as DBN\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.estimators import HillClimbSearch,BicScore\n",
    "from pgmpy.base import DAG\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee0ed4",
   "metadata": {},
   "source": [
    "### function - get body part location for each pair of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.body_part_locs_eachpair import body_part_locs_eachpair\n",
    "from ana_functions.body_part_locs_singlecam import body_part_locs_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ae6f98",
   "metadata": {},
   "source": [
    "### function - align the two cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b03438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_align import camera_align       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494356c2",
   "metadata": {},
   "source": [
    "### function - merge the two pairs of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_merge import camera_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc7f6a",
   "metadata": {},
   "source": [
    "### function - find social gaze time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f6ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.find_socialgaze_timepoint import find_socialgaze_timepoint\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam import find_socialgaze_timepoint_singlecam\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam_wholebody import find_socialgaze_timepoint_singlecam_wholebody"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7e75b",
   "metadata": {},
   "source": [
    "### function - define time point of behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_timepoint import bhv_events_timepoint\n",
    "from ana_functions.bhv_events_timepoint_singlecam import bhv_events_timepoint_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4ab8c",
   "metadata": {},
   "source": [
    "### function - plot behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ba678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.plot_bhv_events import plot_bhv_events\n",
    "from ana_functions.plot_bhv_events_levertube import plot_bhv_events_levertube\n",
    "from ana_functions.draw_self_loop import draw_self_loop\n",
    "import matplotlib.patches as mpatches \n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c724b",
   "metadata": {},
   "source": [
    "### function - plot inter-pull interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.plot_interpull_interval import plot_interpull_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d535a6",
   "metadata": {},
   "source": [
    "### function - make demo videos with skeleton and inportant vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4de83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.tracking_video_singlecam_demo import tracking_video_singlecam_demo\n",
    "from ana_functions.tracking_video_singlecam_wholebody_demo import tracking_video_singlecam_wholebody_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69920a6a",
   "metadata": {},
   "source": [
    "### function - interval between all behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a804dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_interval import bhv_events_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c0b97",
   "metadata": {},
   "source": [
    "### function - train the dynamic bayesian network - multi time lag (3 lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag\n",
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag_create_df_only\n",
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag_training_only\n",
    "from ana_functions.train_DBN_multiLag import graph_to_matrix\n",
    "from ana_functions.train_DBN_multiLag import get_weighted_dags\n",
    "from ana_functions.train_DBN_multiLag import get_significant_edges\n",
    "from ana_functions.train_DBN_multiLag import threshold_edges\n",
    "from ana_functions.train_DBN_multiLag import Modulation_Index\n",
    "from ana_functions.EfficientTimeShuffling import EfficientShuffle\n",
    "from ana_functions.AicScore import AicScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819c438",
   "metadata": {},
   "source": [
    "## Analyze each session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e84fc",
   "metadata": {},
   "source": [
    "### prepare the basic behavioral data (especially the time stamps for each bhv events)\n",
    "### separate each session based on trial types (different force levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc05cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instead of using gaze angle threshold, use the target rectagon to deside gaze info\n",
    "# ...need to update\n",
    "sqr_thres_tubelever = 75 # draw the square around tube and lever\n",
    "sqr_thres_face = 1.15 # a ratio for defining face boundary\n",
    "sqr_thres_body = 4 # how many times to enlongate the face box boundry to the body\n",
    "\n",
    "\n",
    "# get the fps of the analyzed video\n",
    "fps = 30\n",
    "\n",
    "# frame number of the demo video\n",
    "# nframes = 0.5*30 # second*30fps\n",
    "nframes = 1*30 # second*30fps\n",
    "\n",
    "# re-analyze the video or not\n",
    "reanalyze_video = 0\n",
    "redo_anystep = 0\n",
    "\n",
    "# only analyze the best (five) sessions for each conditions\n",
    "do_bestsession = 1\n",
    "if do_bestsession:\n",
    "    savefile_sufix = '_bestsessions'\n",
    "else:\n",
    "    savefile_sufix = '_allsessions'\n",
    "    \n",
    "\n",
    "# force manipulation type\n",
    "# SR_bothchange: self reward, both forces changed\n",
    "# CO_bothchange: 1s cooperation, both forces changed\n",
    "# CO_A1change: 1s cooperation, animal 1 forces changed\n",
    "# CO_A2change: 1s cooperation, animal 2 forces changed\n",
    "forceManiTypes = ['SR_bothchange','CO_A1change','CO_A2change',]\n",
    "nforceManiTypes = np.shape(forceManiTypes)[0]\n",
    "\n",
    "#  \n",
    "animal1_fixedorders = ['koala','dannon']\n",
    "animal2_fixedorders = ['vermelho','kanga']\n",
    "\n",
    "animal1_filenames = [\"Koala\",\"Dannon\"]\n",
    "animal2_filenames = [\"Vermelho\",\"Kanga\"]\n",
    "\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "\n",
    "# video tracking results info\n",
    "animalnames_videotrack = ['dodson','scorch'] # does not really mean dodson and scorch, instead, indicate animal1 and animal2\n",
    "bodypartnames_videotrack = ['rightTuft','whiteBlaze','leftTuft','rightEye','leftEye','mouth']\n",
    "\n",
    "\n",
    "# which camera to analyzed\n",
    "cameraID = 'camera-2'\n",
    "cameraID_short = 'cam2'\n",
    "\n",
    "\n",
    "# location of levers and tubes for camera 2\n",
    "# get this information using DLC animal tracking GUI, the results are stored: \n",
    "# /home/ws523/marmoset_tracking_DLCv2/marmoset_tracking_with_lever_tube-weikang-2023-04-13/labeled-data/\n",
    "considerlevertube = 1\n",
    "considertubeonly = 0\n",
    "# # camera 1\n",
    "# lever_locs_camI = {'dodson':np.array([645,600]),'scorch':np.array([425,435])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1350,630]),'scorch':np.array([555,345])}\n",
    "# # camera 2\n",
    "lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "tube_locs_camI  = {'dodson':np.array([1550,515]),'scorch':np.array([350,515])}\n",
    "# # lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "# # tube_locs_camI  = {'dodson':np.array([1650,490]),'scorch':np.array([250,490])}\n",
    "# # camera 3\n",
    "# lever_locs_camI = {'dodson':np.array([1580,440]),'scorch':np.array([1296,540])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1470,375]),'scorch':np.array([805,475])}\n",
    "\n",
    "\n",
    "# where to save the summarizing data\n",
    "data_saved_folder = '/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/3d_recontruction_analysis_forceManipulation_task_data_saved/'\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e21d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables for looking at specific data set\n",
    "\n",
    "# load the data for plot\n",
    "mergetempRos = 0\n",
    "doBhvitv_timebin = 0\n",
    "\n",
    "moreSampSize = 0\n",
    "minmaxfullSampSize = 1\n",
    "samplingsize_name = 'full_row_number'\n",
    "\n",
    "temp_resolu = 1 # temporal resolution - 1s\n",
    "\n",
    "# DBN weight, define which time lag to look at\n",
    "# make sure the to nodes are the targeted animal\n",
    "doconsiderSigEdge = 0\n",
    "\n",
    "# modulation index between first block and others\n",
    "doMI_firstblock = 0\n",
    "# modulation index between previous block and others\n",
    "doMI_preblock = 1\n",
    "\n",
    "\n",
    "pull_pull_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "pull_pull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "#\n",
    "gaze_gaze_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "gaze_gaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "#\n",
    "within_pullgaze_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "within_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "#\n",
    "across_pullgaze_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "across_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "#\n",
    "within_gazepull_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "within_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "#\n",
    "across_gazepull_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "across_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for all animals\n",
    "summary_all_results = pd.DataFrame(columns=['date','forceContType','self_animal','partner_animal','subblockID',\n",
    "                                            'self_force','partner_force','trialnum','blocktime',\n",
    "                                            'succ_rate','gaze_number','pull_number',\n",
    "                                            'pull_pull_weight','gaze_gaze_weight','within_pullgaze_weight',\n",
    "                                            'across_pullgaze_weight','within_gazepull_weight','across_gazepull_weight',\n",
    "                                           ])\n",
    "\n",
    "\n",
    "#\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    \n",
    "    animal1_fixedorder = [animal1_fixedorders[ianimalpair]]\n",
    "    animal2_fixedorder = [animal2_fixedorders[ianimalpair]]\n",
    "    \n",
    "    animal1_filename = animal1_filenames[ianimalpair]\n",
    "    animal2_filename = animal2_filenames[ianimalpair]\n",
    "    \n",
    "    # load data for all manipulation types\n",
    "    for iforceManiType in np.arange(0,nforceManiTypes,1):\n",
    "        \n",
    "        forceManiType = forceManiTypes[iforceManiType]       \n",
    "    \n",
    "        # load saved data\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "\n",
    "        with open(data_saved_subfolder+'/animal1_name_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            animal1_name_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/animal2_name_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            animal2_name_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/trialdates_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            trialdates_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/force1_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            force1_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/force2_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            force2_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/subblockID_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            subblockID_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/succ_rate_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            succ_rate_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/trialnum_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            trialnum_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/blocktime_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            blocktime_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/owgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            owgaze1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/owgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            owgaze2_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/mtgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            mtgaze1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/mtgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            mtgaze2_num_all_dates = pickle.load(f)     \n",
    "        with open(data_saved_subfolder+'/pull1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            pull1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/pull2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            pull2_num_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/cross_corr_bhv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'.pkl', 'rb') as f:\n",
    "            cross_corr_bhv_all_dates = pickle.load(f)\n",
    "            \n",
    "        # load the DBN related data\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_allsessions'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "\n",
    "        if moreSampSize:\n",
    "            with open(data_saved_subfolder+'/DAGscores_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_moreSampSize.pkl', 'rb') as f:\n",
    "                DAGscores_diffTempRo_diffSampSize = pickle.load(f) \n",
    "            with open(data_saved_subfolder+'/DAGscores_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_moreSampSize.pkl', 'rb') as f:\n",
    "                DAGscores_shuffled_diffTempRo_diffSampSize = pickle.load(f) \n",
    "            with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_moreSampSize.pkl', 'rb') as f:\n",
    "                weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "            with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_moreSampSize.pkl', 'rb') as f:\n",
    "                weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "            with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_moreSampSize.pkl', 'rb') as f:\n",
    "                sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "        if minmaxfullSampSize:\n",
    "            with open(data_saved_subfolder+'/DAGscores_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_minmaxfullSampSize.pkl', 'rb') as f:\n",
    "                DAGscores_diffTempRo_diffSampSize = pickle.load(f) \n",
    "            with open(data_saved_subfolder+'/DAGscores_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_minmaxfullSampSize.pkl', 'rb') as f:\n",
    "                DAGscores_shuffled_diffTempRo_diffSampSize = pickle.load(f) \n",
    "            with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_minmaxfullSampSize.pkl', 'rb') as f:\n",
    "                weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "            with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_minmaxfullSampSize.pkl', 'rb') as f:\n",
    "                weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "            with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+forceManiType+'_minmaxfullSampSize.pkl', 'rb') as f:\n",
    "                sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "        print('all data are loaded:'+animal1_fixedorder[0]+' '+animal2_fixedorder[0]+' '+forceManiType)\n",
    "\n",
    "        # get the force for the first block of each session\n",
    "        #\n",
    "        # Identify unique trial dates and their first occurrence indices\n",
    "        unique_dates, first_indices = np.unique(trialdates_all_dates, return_index=True)\n",
    "        # Filter for first block (subblockID = 0)\n",
    "        first_block_indices = first_indices[subblockID_all_dates[first_indices] == 0]\n",
    "        # force 1\n",
    "        # Map the trial date to the first block's force1 value\n",
    "        first_block_force_map = {trialdates_all_dates[i]: force1_all_dates[i] for i in first_block_indices}\n",
    "        # Create the new array by mapping each trialdate to its first block's force1 value\n",
    "        force1_firstblock_all_dates = np.array([first_block_force_map[date] for date in trialdates_all_dates])\n",
    "        # force 2\n",
    "        # Map the trial date to the first block's force2 value\n",
    "        first_block_force_map = {trialdates_all_dates[i]: force2_all_dates[i] for i in first_block_indices}\n",
    "        # Create the new array by mapping each trialdate to its first block's force2 value\n",
    "        force2_firstblock_all_dates = np.array([first_block_force_map[date] for date in trialdates_all_dates])\n",
    "\n",
    "        # get the force for the previous block of each session\n",
    "        #\n",
    "        # force 1\n",
    "        # Initialize the output array with NaNs (same size as force1_all_dates)\n",
    "        force1_preblock_all_dates = np.full_like(force1_all_dates, np.nan)\n",
    "        # Iterate through the array\n",
    "        for i in range(1, len(force1_all_dates)):\n",
    "            # Check if the current trial date is the same as the previous one\n",
    "            if trialdates_all_dates[i] == trialdates_all_dates[i - 1]:\n",
    "                # Assign the force2 value from the previous block\n",
    "                force1_preblock_all_dates[i] = force1_all_dates[i - 1]\n",
    "            else:\n",
    "                # If it's the first block of a new trial date, use the same value\n",
    "                force1_preblock_all_dates[i] = force1_all_dates[i]\n",
    "        # The first value for the array should match itself (no previous block)\n",
    "        force1_preblock_all_dates[0] = force1_all_dates[0]\n",
    "        # force 2\n",
    "        # Initialize the output array with NaNs (same size as force2_all_dates)\n",
    "        force2_preblock_all_dates = np.full_like(force2_all_dates, np.nan)\n",
    "        # Iterate through the array\n",
    "        for i in range(1, len(force2_all_dates)):\n",
    "            # Check if the current trial date is the same as the previous one\n",
    "            if trialdates_all_dates[i] == trialdates_all_dates[i - 1]:\n",
    "                # Assign the force2 value from the previous block\n",
    "                force2_preblock_all_dates[i] = force2_all_dates[i - 1]\n",
    "            else:\n",
    "                # If it's the first block of a new trial date, use the same value\n",
    "                force2_preblock_all_dates[i] = force2_all_dates[i]\n",
    "        # The first value for the array should match itself (no previous block)\n",
    "        force2_preblock_all_dates[0] = force2_all_dates[0]\n",
    "        \n",
    "        # \n",
    "        ndates = np.shape(trialdates_all_dates)[0]\n",
    "        \n",
    "        for idate in np.arange(0,ndates,1):\n",
    "            \n",
    "            idate_name = trialdates_all_dates[idate]\n",
    "            idate_blockID = subblockID_all_dates[idate]\n",
    "            \n",
    "            forcecombined = str(int(force1_all_dates[idate]))+'&'+str(int(force2_all_dates[idate]))\n",
    "\n",
    "            if forceManiType == 'SR_bothchange':\n",
    "                animal1_forceContType = 'self_change_SR'\n",
    "                animal2_forceContType = 'self_change_SR'\n",
    "            elif forceManiType == 'CO_A1change':\n",
    "                animal1_forceContType = 'self_change_MC'\n",
    "                animal2_forceContType = 'partner_change_MC'\n",
    "            elif forceManiType == 'CO_A2change':\n",
    "                animal1_forceContType = 'partner_change_MC'\n",
    "                animal2_forceContType = 'self_change_MC'\n",
    "            else:\n",
    "                animal1_forceContType = None\n",
    "                animal2_forceContType = None\n",
    "             \n",
    "            # get the dbn matrix\n",
    "            if (~doMI_firstblock==1) & (~doMI_preblock==1):\n",
    "                weighted_graphs = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),samplingsize_name)][idate_name][forcecombined]\n",
    "                weighted_shaffle_graphs = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),samplingsize_name)][idate_name][forcecombined]\n",
    "                sig_edges = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),samplingsize_name)][idate_name][forcecombined]\n",
    "                #\n",
    "                sig_edges[sig_edges==0]=np.nan\n",
    "                \n",
    "            # modulation index comparing the first block\n",
    "            elif doMI_firstblock | doMI_preblock:\n",
    "                \n",
    "                if doMI_firstblock:\n",
    "                    forcecombined_base = str(int(force1_firstblock_all_dates[idate]))+'&'+str(int(force2_firstblock_all_dates[idate]))\n",
    "                elif doMI_preblock:\n",
    "                    forcecombined_base = str(int(force1_preblock_all_dates[idate]))+'&'+str(int(force2_preblock_all_dates[idate]))\n",
    "                \n",
    "                #\n",
    "                weighted_graphs_base = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),samplingsize_name)][idate_name][forcecombined_base]\n",
    "                weighted_shaffle_graphs_base = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),samplingsize_name)][idate_name][forcecombined_base]\n",
    "                sig_edges_base = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),samplingsize_name)][idate_name][forcecombined_base]\n",
    "                \n",
    "                weighted_graphs_tgt = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),samplingsize_name)][idate_name][forcecombined]\n",
    "                weighted_shaffle_graphs_tgt = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),samplingsize_name)][idate_name][forcecombined]\n",
    "                sig_edges_tgt = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),samplingsize_name)][idate_name][forcecombined]\n",
    "                \n",
    "                nMIbootstraps = 100\n",
    "                weighted_graphs, sig_edges = Modulation_Index(weighted_graphs_base, weighted_graphs_tgt,\n",
    "                                                      sig_edges_base, sig_edges_tgt, nMIbootstraps)\n",
    "                #\n",
    "                sig_edges = sig_edges.astype(float)\n",
    "                sig_edges[sig_edges==0]=np.nan\n",
    "                #\n",
    "                # remove the first block\n",
    "                if forcecombined_base == forcecombined:\n",
    "                    firstblock_edges = np.ones(np.shape(sig_edges))*np.nan\n",
    "                    weighted_graphs = weighted_graphs* firstblock_edges\n",
    "            \n",
    "            # \n",
    "            if doconsiderSigEdge:\n",
    "                weighted_graphs = weighted_graphs * sig_edges\n",
    "                weighted_shaffle_graphs = weighted_shaffle_graphs * sig_edges\n",
    "                    \n",
    "                    \n",
    "            # for animal1\n",
    "            summary_all_results = summary_all_results.append({\n",
    "                                                        'date': trialdates_all_dates[idate],\n",
    "                                                        'forceContType':animal1_forceContType,\n",
    "                                                        'self_animal': animal1_fixedorder[0],\n",
    "                                                        'partner_animal': animal2_fixedorder[0],\n",
    "                                                        'subblockID': subblockID_all_dates[idate],\n",
    "                                                        'self_force': force1_all_dates[idate],\n",
    "                                                        'partner_force': force2_all_dates[idate],\n",
    "                                                        'trialnum': trialnum_all_dates[idate],\n",
    "                                                        'blocktime': blocktime_all_dates[idate],\n",
    "                                                        'succ_rate': succ_rate_all_dates[idate],\n",
    "                                                        'gaze_number': owgaze1_num_all_dates[idate]+mtgaze1_num_all_dates[idate],\n",
    "                                                        'pull_number': pull1_num_all_dates[idate],\n",
    "                                                        \n",
    "                                                        'pull_pull_weight':weighted_graphs[:,pull_pull_fromNodes_all[0],pull_pull_toNodes_all[0]].T,\n",
    "                                                        'gaze_gaze_weight':weighted_graphs[:,gaze_gaze_fromNodes_all[0],gaze_gaze_toNodes_all[0]].T,\n",
    "                                                        'within_pullgaze_weight':weighted_graphs[:,within_pullgaze_fromNodes_all[0],within_pullgaze_toNodes_all[0]].T,\n",
    "                                                        'across_pullgaze_weight':weighted_graphs[:,across_pullgaze_fromNodes_all[0],across_pullgaze_toNodes_all[0]].T,\n",
    "                                                        'within_gazepull_weight':weighted_graphs[:,within_gazepull_fromNodes_all[0],within_gazepull_toNodes_all[0]].T,\n",
    "                                                        'across_gazepull_weight':weighted_graphs[:,across_gazepull_fromNodes_all[0],across_gazepull_toNodes_all[0]].T,\n",
    "                                                    }, ignore_index=True)\n",
    "            \n",
    "            # for animal2            \n",
    "            summary_all_results = summary_all_results.append({\n",
    "                                                        'date': trialdates_all_dates[idate],\n",
    "                                                        'forceContType':animal2_forceContType,\n",
    "                                                        'self_animal': animal2_fixedorder[0],\n",
    "                                                        'partner_animal': animal1_fixedorder[0],\n",
    "                                                        'subblockID': subblockID_all_dates[idate],\n",
    "                                                        'self_force': force2_all_dates[idate],\n",
    "                                                        'partner_force': force1_all_dates[idate],\n",
    "                                                        'trialnum': trialnum_all_dates[idate],\n",
    "                                                        'blocktime': blocktime_all_dates[idate],\n",
    "                                                        'succ_rate': succ_rate_all_dates[idate],\n",
    "                                                        'gaze_number': owgaze2_num_all_dates[idate]+mtgaze2_num_all_dates[idate],\n",
    "                                                        'pull_number': pull2_num_all_dates[idate],\n",
    "                \n",
    "                                                        'pull_pull_weight':weighted_graphs[:,pull_pull_fromNodes_all[1],pull_pull_toNodes_all[1]].T,\n",
    "                                                        'gaze_gaze_weight':weighted_graphs[:,gaze_gaze_fromNodes_all[1],gaze_gaze_toNodes_all[1]].T,\n",
    "                                                        'within_pullgaze_weight':weighted_graphs[:,within_pullgaze_fromNodes_all[1],within_pullgaze_toNodes_all[1]].T,\n",
    "                                                        'across_pullgaze_weight':weighted_graphs[:,across_pullgaze_fromNodes_all[1],across_pullgaze_toNodes_all[1]].T,\n",
    "                                                        'within_gazepull_weight':weighted_graphs[:,within_gazepull_fromNodes_all[1],within_gazepull_toNodes_all[1]].T,\n",
    "                                                        'across_gazepull_weight':weighted_graphs[:,across_gazepull_fromNodes_all[1],across_gazepull_toNodes_all[1]].T,\n",
    "                                                        \n",
    "                                                    }, ignore_index=True)\n",
    "\n",
    "\n",
    "# calculating gaze and pull number per second\n",
    "summary_all_results['gazenum_pers'] = summary_all_results['gaze_number']/summary_all_results['blocktime']\n",
    "summary_all_results['pullnum_pers'] = summary_all_results['pull_number']/summary_all_results['blocktime']\n",
    "\n",
    "# remove entries that has too few trial number\n",
    "trialnum_threshold = 5\n",
    "\n",
    "ind_bad = summary_all_results['trialnum']<trialnum_threshold\n",
    "\n",
    "summary_all_results = summary_all_results[~ind_bad].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ede61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for the version that force and success rate and other variables are separated into quantiles\n",
    "summary_all_results_quantile = summary_all_results.copy()\n",
    "\n",
    "unique_combinations = summary_all_results[['date', 'self_animal']].drop_duplicates()\n",
    "ncombines = np.shape(unique_combinations)[0]\n",
    "\n",
    "columns_todo = ['self_force','partner_force','succ_rate','subblockID','gazenum_pers','pullnum_pers']\n",
    "# columns_todo = ['succ_rate','subblockID','gazenum_pers','pullnum_pers']\n",
    "ntodos = np.shape(columns_todo)[0]\n",
    "\n",
    "for icombine in np.arange(0,ncombines,1):\n",
    "    \n",
    "    date_tgt = list(unique_combinations['date'])[icombine]\n",
    "    selfanimal_tgt = list(unique_combinations['self_animal'])[icombine]\n",
    "    \n",
    "    # for normal dataset\n",
    "    ind_tgt = (summary_all_results_quantile['date']==date_tgt)&\\\n",
    "    (summary_all_results_quantile['self_animal']==selfanimal_tgt)\n",
    "    \n",
    "    for itodo in np.arange(0,ntodos,1):\n",
    "        column_todo = columns_todo[itodo]\n",
    "\n",
    "        yyy = np.array(summary_all_results_quantile[column_todo][ind_tgt])\n",
    "        \n",
    "        # only one kind of force\n",
    "        if np.shape(np.unique(yyy))[0] == 1:\n",
    "            yyy_quant = np.ones(np.shape(yyy))*1\n",
    "        # two kinds of force\n",
    "        elif np.shape(np.unique(yyy))[0] == 2:\n",
    "            ranks = st.rankdata(yyy, method='average')  # Average ranks for ties\n",
    "            # yyy_quant = (np.ceil(ranks / len(yyy) * 2)-1)*2+1 # separate into three quantiles\n",
    "            yyy_quant = (np.ceil(ranks / len(yyy) * 2)) # separate into two quantiles         \n",
    "        # more than two kinds of force,\n",
    "        else:\n",
    "            ranks = st.rankdata(yyy, method='average')  # Average ranks for ties\n",
    "            # yyy_quant = np.ceil(ranks / len(yyy) * 3) # separate into three quantiles\n",
    "            yyy_quant = (np.ceil(ranks / len(yyy) * 2)) # separate into two quantiles\n",
    "        \n",
    "        # Update the DataFrame with residuals for the current column\n",
    "        summary_all_results_quantile.loc[ind_tgt, column_todo] = yyy_quant\n",
    "    \n",
    "print('create dataframe for the version that force and other variables is defined into quantiles')\n",
    "# print('create dataframe for the version that variables other than force is defined into quantiles')\n",
    "\n",
    "# summary_all_results_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc52bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for the version that force are refered to the first block and then separated into quantiles\n",
    "if 0: \n",
    "    # summary_all_results_quantile = summary_all_results.copy()\n",
    "\n",
    "    unique_combinations = summary_all_results[['date', 'self_animal']].drop_duplicates()\n",
    "    ncombines = np.shape(unique_combinations)[0]\n",
    "\n",
    "    columns_todo = ['self_force','partner_force',]\n",
    "    ntodos = np.shape(columns_todo)[0]\n",
    "\n",
    "    for icombine in np.arange(0,ncombines,1):\n",
    "\n",
    "        date_tgt = list(unique_combinations['date'])[icombine]\n",
    "        selfanimal_tgt = list(unique_combinations['self_animal'])[icombine]\n",
    "\n",
    "        # for normal dataset\n",
    "        ind_tgt = (summary_all_results_quantile['date']==date_tgt)&\\\n",
    "        (summary_all_results_quantile['self_animal']==selfanimal_tgt)\n",
    "\n",
    "        for itodo in np.arange(0,ntodos,1):\n",
    "            column_todo = columns_todo[itodo]\n",
    "\n",
    "            yyy = np.array(summary_all_results_quantile[column_todo][ind_tgt])\n",
    "\n",
    "            # two steps: \n",
    "            # step 1 - refer to the force of the first block; \n",
    "            # step 2 - two 'quantile': 1 for smaller than and same as first block; 2 for larger than the first block        \n",
    "            yyy_new = yyy - yyy[0]\n",
    "            yyy_quant = np.ones(np.shape(yyy_new))\n",
    "            yyy_quant[yyy_new>=0] = 2\n",
    "\n",
    "            # Update the DataFrame with residuals for the current column\n",
    "            summary_all_results_quantile.loc[ind_tgt, column_todo] = yyy_quant\n",
    "\n",
    "\n",
    "\n",
    "    print('create dataframe for the version that force is defined into quantiles based on the reference to the first block')\n",
    "\n",
    "    # summary_all_results_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for the version that force are separated into quantiles,but based on the refered to the previous block\n",
    "if 0: \n",
    "    # summary_all_results_quantile = summary_all_results.copy()\n",
    "\n",
    "    unique_combinations = summary_all_results[['date', 'self_animal']].drop_duplicates()\n",
    "    ncombines = np.shape(unique_combinations)[0]\n",
    "\n",
    "    columns_todo = ['partner_force','self_force',]\n",
    "    ntodos = np.shape(columns_todo)[0]\n",
    "\n",
    "    for icombine in np.arange(0,ncombines,1):\n",
    "\n",
    "        date_tgt = list(unique_combinations['date'])[icombine]\n",
    "        selfanimal_tgt = list(unique_combinations['self_animal'])[icombine]\n",
    "\n",
    "        # for normal dataset\n",
    "        ind_tgt = (summary_all_results_quantile['date']==date_tgt)&\\\n",
    "        (summary_all_results_quantile['self_animal']==selfanimal_tgt)\n",
    "\n",
    "        for itodo in np.arange(0,ntodos,1):\n",
    "            column_todo = columns_todo[itodo]\n",
    "\n",
    "            yyy = np.array(summary_all_results_quantile[column_todo][ind_tgt])\n",
    "\n",
    "            # two steps: \n",
    "            # step 1 - refer to the force of the first block; \n",
    "            # step 2 - two 'quantile': 1 for smaller than and same as first block; 2 for larger than the first block        \n",
    "            yyy_new = yyy - np.hstack((yyy[0],yyy[0:-1]))\n",
    "            yyy_quant = np.ones(np.shape(yyy_new))\n",
    "            yyy_quant[yyy_new>0] = 2\n",
    "\n",
    "            # Update the DataFrame with residuals for the current column\n",
    "            summary_all_results_quantile.loc[ind_tgt, column_todo] = yyy_quant\n",
    "\n",
    "\n",
    "\n",
    "    print('create dataframe for the version that force is defined into quantiles based on the reference to the previous block')\n",
    "\n",
    "    # summary_all_results_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b487367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for the version that force are separated into quantiles, based on the value cluster\n",
    "if 0: \n",
    "    from sklearn.cluster import KMeans\n",
    "    \n",
    "    # summary_all_results_quantile = summary_all_results.copy()\n",
    "    unique_combinations = summary_all_results[['date', 'self_animal']].drop_duplicates()\n",
    "    ncombines = np.shape(unique_combinations)[0]\n",
    "\n",
    "    columns_todo = ['self_force','partner_force',]\n",
    "    ntodos = np.shape(columns_todo)[0]\n",
    "\n",
    "    for icombine in np.arange(0,ncombines,1):\n",
    "\n",
    "        date_tgt = list(unique_combinations['date'])[icombine]\n",
    "        selfanimal_tgt = list(unique_combinations['self_animal'])[icombine]\n",
    "\n",
    "        # for normal dataset\n",
    "        ind_tgt = (summary_all_results_quantile['date']==date_tgt)&\\\n",
    "        (summary_all_results_quantile['self_animal']==selfanimal_tgt)\n",
    "\n",
    "        for itodo in np.arange(0,ntodos,1):\n",
    "            column_todo = columns_todo[itodo]\n",
    "\n",
    "            yyy = np.array(summary_all_results_quantile[column_todo][ind_tgt])\n",
    "            y_array = np.array(yyy).reshape(-1, 1)\n",
    "            \n",
    "            # Perform k-means clustering with 2 clusters\n",
    "            kmeans = KMeans(n_clusters=2, random_state=42).fit(y_array)         \n",
    "            yyy_quant = kmeans.labels_ + 1\n",
    "\n",
    "            # Update the DataFrame with residuals for the current column\n",
    "            summary_all_results_quantile.loc[ind_tgt, column_todo] = yyy_quant\n",
    "\n",
    "\n",
    "\n",
    "    print('create dataframe for the version that force is defined into quantiles based on the value cluster')\n",
    "\n",
    "    # summary_all_results_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4bae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for the delta force versions - first force\n",
    "summary_all_results_deltafirstforce = summary_all_results.copy()\n",
    "\n",
    "unique_combinations = summary_all_results[['date', 'self_animal']].drop_duplicates()\n",
    "ncombines = np.shape(unique_combinations)[0]\n",
    "\n",
    "columns_todo = ['self_force','partner_force']\n",
    "ntodos = np.shape(columns_todo)[0]\n",
    "\n",
    "for icombine in np.arange(0,ncombines,1):\n",
    "    \n",
    "    date_tgt = list(unique_combinations['date'])[icombine]\n",
    "    selfanimal_tgt = list(unique_combinations['self_animal'])[icombine]\n",
    "    \n",
    "    # for normal dataset\n",
    "    ind_tgt = (summary_all_results_deltafirstforce['date']==date_tgt)&\\\n",
    "    (summary_all_results_deltafirstforce['self_animal']==selfanimal_tgt)\n",
    "    \n",
    "    for itodo in np.arange(0,ntodos,1):\n",
    "        column_todo = columns_todo[itodo]\n",
    "\n",
    "        yyy = np.array(summary_all_results_deltafirstforce[column_todo][ind_tgt])\n",
    "       \n",
    "        yyy_new = yyy - yyy[0]\n",
    "        \n",
    "        # Update the DataFrame with residuals for the current column\n",
    "        summary_all_results_deltafirstforce.loc[ind_tgt, column_todo] = yyy_new\n",
    "       \n",
    "print('create dataframe for the delta force versions - first force')\n",
    "\n",
    "# summary_all_results_blockIDregressed_deltafirstforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7857cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for the delta force versions - previous force\n",
    "summary_all_results_deltapreforce = summary_all_results.copy()\n",
    "\n",
    "unique_combinations = summary_all_results[['date', 'self_animal']].drop_duplicates()\n",
    "ncombines = np.shape(unique_combinations)[0]\n",
    "\n",
    "columns_todo = ['partner_force','self_force',]\n",
    "ntodos = np.shape(columns_todo)[0]\n",
    "\n",
    "for icombine in np.arange(0,ncombines,1):\n",
    "    \n",
    "    date_tgt = list(unique_combinations['date'])[icombine]\n",
    "    selfanimal_tgt = list(unique_combinations['self_animal'])[icombine]\n",
    "    \n",
    "    # for normal dataset\n",
    "    ind_tgt = (summary_all_results_deltapreforce['date']==date_tgt)&\\\n",
    "    (summary_all_results_deltapreforce['self_animal']==selfanimal_tgt)\n",
    "    \n",
    "    for itodo in np.arange(0,ntodos,1):\n",
    "        column_todo = columns_todo[itodo]\n",
    "\n",
    "        yyy = np.array(summary_all_results_deltapreforce[column_todo][ind_tgt])\n",
    "       \n",
    "        yyy_new = yyy - np.hstack([yyy[0],yyy[0:-1]])\n",
    "        \n",
    "        # Update the DataFrame with residuals for the current column\n",
    "        summary_all_results_deltapreforce.loc[ind_tgt, column_todo] = yyy_new\n",
    "    \n",
    "    \n",
    "    \n",
    "       \n",
    "print('create dataframe for the delta force versions - previous force')\n",
    "\n",
    "# summary_all_results_blockIDregressed_deltapreforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66beee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(summary_all_results_quantile['self_force']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between variables\n",
    "# summary_all_tgt = summary_all_results_quantile\n",
    "summary_all_tgt = summary_all_results\n",
    "\n",
    "ind_tgt = (summary_all_tgt['forceContType']=='self_change_MC') # & (summary_all_tgt['self_animal']=='vermelho')\n",
    "summary_all_tgt = summary_all_tgt[ind_tgt]\n",
    "\n",
    "data1 = np.array(summary_all_tgt['subblockID'])\n",
    "data2 = np.array(summary_all_tgt['self_force'])\n",
    "\n",
    "kendall_corr, kendall_p = st.kendalltau(data1, data2)\n",
    "print(f\"Kendall's tau: {kendall_corr}, p-value: {kendall_p}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1212536",
   "metadata": {},
   "source": [
    "## plot the summarizing figures with all animals\n",
    "#### average the DBN weights for different dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd733811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define what time lags to look at \n",
    "timelag_tgt = 0 # 1:1s; 2:2s; 3:3s; 0:1s to 3s merged; 12: 1s to 2s merged\n",
    "timelag_tgt_name = '1to3s_merged' # 1s_timelag, 2s_timelag, 3s_timelag, 1to3s_merged, 1to2s_merged\n",
    "#\n",
    "if timelag_tgt == 1:\n",
    "    timelag_rowID = [2]\n",
    "elif timelag_tgt == 2:\n",
    "    timelag_rowID = [1]\n",
    "elif timelag_tgt == 3:\n",
    "    timelag_rowID = [0]\n",
    "elif timelag_tgt == 0:\n",
    "    timelag_rowID = [0,1,2]\n",
    "elif timelag_tgt == 12:\n",
    "    timelag_rowID = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f1a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypename = 'quantile'\n",
    "# summary_all_tgt = summary_all_results_quantile\n",
    "datatypename = 'deltapreforce'\n",
    "summary_all_tgt = summary_all_results_deltapreforce\n",
    "\n",
    "nTrialConds = np.shape(np.unique(summary_all_tgt['forceContType']))[0]\n",
    "\n",
    "# xplottype = 'succ_rate' # 'succ_rate', 'subblockID', 'gazenum_pers', 'pullnum_pers'\n",
    "xplottype = 'partner_force'  # 'self_force', 'partner_force'\n",
    "yplottypes = ['pull_pull_weight','across_pullgaze_weight','across_gazepull_weight','within_gazepull_weight']\n",
    "nyplottypes = np.shape(yplottypes)[0]\n",
    "\n",
    "# Set up the figure grid\n",
    "fig, axes = plt.subplots(nTrialConds, nyplottypes, \n",
    "                         figsize=(5 * nyplottypes, 4 * nTrialConds), \n",
    "                         sharex=False, sharey=False)\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "# Plotting each unique condition and y-axis type\n",
    "unique_conditions = summary_all_tgt['forceContType'].unique()\n",
    "\n",
    "for i, condition in enumerate(unique_conditions):\n",
    "    # Filter data for the current condition\n",
    "    condition_data = summary_all_tgt[summary_all_tgt['forceContType'] == condition]\n",
    "    \n",
    "    for j, yplot in enumerate(yplottypes):\n",
    "        ax = axes[i, j] if nTrialConds > 1 else axes[j]  # Adjust for single-row cases\n",
    "        \n",
    "        data_cleaned = condition_data[[xplottype, yplot]].reset_index(drop=True)\n",
    "        data_cleaned['mean_weight'] = np.nan\n",
    "        \n",
    "        nrows = np.shape(data_cleaned)[0]\n",
    "        for irow in np.arange(0,nrows,1):    \n",
    "            tgt_weight = data_cleaned[yplot][irow][timelag_rowID].flatten()\n",
    "            data_cleaned['mean_weight'][irow] = np.nanmean(tgt_weight)\n",
    "        #\n",
    "        data_cleaned = data_cleaned[~np.isnan(data_cleaned['mean_weight'])]\n",
    "             \n",
    "        # Create a regression plot for each y-axis type within the current condition\n",
    "        seaborn.regplot(data=data_cleaned, x=xplottype, y='mean_weight', ax=ax, \n",
    "                        scatter_kws={'s': 10}, line_kws={'color': 'blue'})\n",
    "        \n",
    "        try:\n",
    "        # Calculate correlation coefficient and p-value\n",
    "            r_value, p_value = st.pearsonr(data_cleaned[xplottype], data_cleaned['mean_weight'])\n",
    "            # r_value, p_value = st.spearmanr(data_cleaned[xplottype], data_cleaned['mean_weight'])\n",
    "        except:\n",
    "            r_value = np.nan\n",
    "            p_value = np.nan\n",
    "        \n",
    "        # Add text for the correlation statistics\n",
    "        ax.text(0.05, 0.95, f\"r = {r_value:.2f}\\np = {p_value:.3f}\", \n",
    "                transform=ax.transAxes, fontsize=10, verticalalignment='top', color='blue')\n",
    "        \n",
    "        \n",
    "        # Set titles and labels\n",
    "        ax.set_title(f\"{condition} - {yplot}\")\n",
    "        if i == nTrialConds - 1:\n",
    "            ax.set_xlabel(xplottype)\n",
    "        #\n",
    "        ax.set_ylabel('mean weight')\n",
    "        if doMI_firstblock:\n",
    "            ax.set_ylabel('MI with the first block')\n",
    "        if doMI_preblock:\n",
    "            ax.set_ylabel('MI with the previous block')\n",
    "        ax.set_ylim([-1.1,1.1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_allanimal_summary_DBNspecific/'+savefile_sufix+'/'+cameraID+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    fig.savefig(figsavefolder+xplottype+\"level_vs_\"+timelag_tgt_name+\"_DBNweight_allanimal_allcondition_versionof_\"+datatypename+\".pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd0cd0",
   "metadata": {},
   "source": [
    "#### average the DBN weights for different dependencies - plot each animal separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5d5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypename = 'quantile'\n",
    "# summary_all_tgt = summary_all_results_quantile\n",
    "datatypename = 'deltapreforce'\n",
    "summary_all_tgt = summary_all_results_deltapreforce\n",
    "\n",
    "nTrialConds = np.shape(np.unique(summary_all_tgt['forceContType']))[0]\n",
    "\n",
    "# xplottype = 'succ_rate' # 'succ_rate', 'subblockID', 'gazenum_pers', 'pullnum_pers'\n",
    "xplottype = 'self_force'  # 'self_force', 'partner_force'\n",
    "yplottypes = ['pull_pull_weight','across_pullgaze_weight','within_gazepull_weight']\n",
    "nyplottypes = np.shape(yplottypes)[0]\n",
    "\n",
    "animalcolors = ['red','blue','purple','darkblue']\n",
    "\n",
    "# Set up the figure grid\n",
    "fig, axes = plt.subplots(nTrialConds, nyplottypes, \n",
    "                         figsize=(5 * nyplottypes, 4 * nTrialConds), \n",
    "                         sharex=False, sharey=False)\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "# Plotting each unique condition and y-axis type\n",
    "unique_conditions = summary_all_tgt['forceContType'].unique()\n",
    "\n",
    "for i, condition in enumerate(unique_conditions):\n",
    "    # Filter data for the current condition\n",
    "    condition_data = summary_all_tgt[summary_all_tgt['forceContType'] == condition]\n",
    "    \n",
    "    selfanimals = np.unique(condition_data['self_animal'])\n",
    "    # selfanimals = ['kanga']\n",
    "    nanimals = np.shape(selfanimals)[0]\n",
    "    \n",
    "    for ianimal in np.arange(0,nanimals,1):\n",
    "        \n",
    "        selfanimal = selfanimals[ianimal]\n",
    "        \n",
    "        condition_data_ianimal = condition_data[condition_data['self_animal']==selfanimal]\n",
    "        \n",
    "        for j, yplot in enumerate(yplottypes):\n",
    "            ax = axes[i, j] if nTrialConds > 1 else axes[j]  # Adjust for single-row cases\n",
    "\n",
    "            data_cleaned = condition_data_ianimal[[xplottype, yplot]].reset_index(drop=True)\n",
    "            data_cleaned['mean_weight'] = np.nan\n",
    "\n",
    "            nrows = np.shape(data_cleaned)[0]\n",
    "            for irow in np.arange(0,nrows,1):    \n",
    "                tgt_weight = data_cleaned[yplot][irow][timelag_rowID].flatten()\n",
    "                data_cleaned['mean_weight'][irow] = np.nanmean(tgt_weight)\n",
    "            #\n",
    "            data_cleaned = data_cleaned[~np.isnan(data_cleaned['mean_weight'])]\n",
    "\n",
    "            # Create a regression plot for each y-axis type within the current condition\n",
    "            seaborn.regplot(data=data_cleaned, x=xplottype, y='mean_weight', ax=ax, \n",
    "                            scatter_kws={'s': 10, 'color': animalcolors[ianimal]}, \n",
    "                            line_kws={'color': animalcolors[ianimal]})\n",
    "\n",
    "            try:\n",
    "            # Calculate correlation coefficient and p-value\n",
    "                r_value, p_value = st.pearsonr(data_cleaned[xplottype], data_cleaned['mean_weight'])\n",
    "            except:\n",
    "                r_value = np.nan\n",
    "                p_value = np.nan\n",
    "\n",
    "            # Add text for the correlation statistics\n",
    "            ax.text(0.05, 0.95-0.1*ianimal, selfanimal+':'+f\"r = {r_value:.2f}\\np = {p_value:.3f}\", \n",
    "                    transform=ax.transAxes, fontsize=10, verticalalignment='top', color=animalcolors[ianimal])\n",
    "\n",
    "\n",
    "            # Set titles and labels\n",
    "            ax.set_title(f\"{condition} - {yplot}\")\n",
    "            if i == nTrialConds - 1:\n",
    "                ax.set_xlabel(xplottype)\n",
    "            #\n",
    "            ax.set_ylabel('mean weight')\n",
    "            if doMI_firstblock:\n",
    "                ax.set_ylabel('MI with the first block')\n",
    "            if doMI_preblock:\n",
    "                ax.set_ylabel('MI with the previous block')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_allanimal_summary_DBNspecific/'+savefile_sufix+'/'+cameraID+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    fig.savefig(figsavefolder+xplottype+\"level_vs_\"+timelag_tgt_name+\"_DBNweight_separatedanimal_allcondition_versionof_\"+datatypename+\".pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc7c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatypename = ''\n",
    "summary_all_tgt = summary_all_results\n",
    "# datatypename = 'deltafirstforce'\n",
    "# summary_all_tgt = summary_all_results_deltafirstforce\n",
    "\n",
    "nTrialConds = np.shape(np.unique(summary_all_tgt['forceContType']))[0]\n",
    "\n",
    "xplottype = 'self_force' # 'self_focce' or 'other_force' or 'subblockID'\n",
    "yplottypes = ['pull_pull_weight','across_pullgaze_weight','within_gazepull_weight']\n",
    "nyplottypes = np.shape(yplottypes)[0]\n",
    "\n",
    "animalcolors = ['red','blue','purple','darkblue']\n",
    "\n",
    "slopes_all_result = pd.DataFrame(columns=['self_animal','date','tasktype','xplottype','yplottype','slope',])\n",
    "\n",
    "# Set up the figure grid\n",
    "fig, axes = plt.subplots(nTrialConds, nyplottypes, \n",
    "                         figsize=(5 * nyplottypes, 4 * nTrialConds), \n",
    "                         sharex=False, sharey=False)\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "# Plotting each unique condition and y-axis type\n",
    "unique_conditions = summary_all_tgt['forceContType'].unique()\n",
    "\n",
    "for i, condition in enumerate(unique_conditions):\n",
    "    # Filter data for the current condition\n",
    "    condition_data = summary_all_tgt[summary_all_tgt['forceContType'] == condition]\n",
    "    \n",
    "    selfanimals = np.unique(condition_data['self_animal'])\n",
    "    #  selfanimals = ['kanga']\n",
    "    nanimals = np.shape(selfanimals)[0]\n",
    "    \n",
    "    for j, yplot in enumerate(yplottypes):\n",
    "        ax = axes[i, j] if nTrialConds > 1 else axes[j]  # Adjust for single-row cases\n",
    "            \n",
    "        # plot for each animal separately\n",
    "        for ianimal in np.arange(0,nanimals,1):\n",
    "\n",
    "            selfanimal = selfanimals[ianimal]\n",
    "\n",
    "            condition_data_ianimal = condition_data[condition_data['self_animal']==selfanimal]\n",
    "\n",
    "            sessiondates = np.unique(condition_data_ianimal['date'])\n",
    "            nsessiondates = np.shape(sessiondates)[0]\n",
    "\n",
    "            for isessdate in np.arange(0,nsessiondates,1):\n",
    "\n",
    "                sessiondate = sessiondates[isessdate]\n",
    "\n",
    "                condition_data_ianimal_idate = condition_data_ianimal[condition_data_ianimal['date']==sessiondate]\n",
    "\n",
    "                data_cleaned = condition_data_ianimal_idate[[xplottype, yplot]].reset_index(drop=True)\n",
    "                data_cleaned['mean_weight'] = np.nan\n",
    "\n",
    "                nrows = np.shape(data_cleaned)[0]\n",
    "                for irow in np.arange(0,nrows,1):    \n",
    "                    tgt_weight = data_cleaned[yplot][irow][timelag_rowID].flatten()\n",
    "                    data_cleaned['mean_weight'][irow] = np.nanmean(tgt_weight)\n",
    "                #\n",
    "                data_cleaned = data_cleaned[~np.isnan(data_cleaned['mean_weight'])]\n",
    "                \n",
    "                # Create a regression plot for each y-axis type within the current condition\n",
    "                seaborn.regplot(data=data_cleaned, x=xplottype, y='mean_weight', ax=ax, ci=None,\n",
    "                                scatter_kws={'s':10,'color':'gray'}, \n",
    "                                line_kws={'color': animalcolors[ianimal],'linewidth': 1})\n",
    "\n",
    "                try:\n",
    "                    slope, intercept, r_value, p_value, std_err = st.linregress(data_cleaned[xplottype], \n",
    "                                                                                data_cleaned['mean_weight'])\n",
    "                except:\n",
    "                    slope = np.nan\n",
    "                    \n",
    "                slopes_all_result = slopes_all_result.append({'self_animal':selfanimal,\n",
    "                                                              'date':sessiondate,\n",
    "                                                              'tasktype':condition,\n",
    "                                                              'xplottype':xplottype,\n",
    "                                                              'yplottype':yplot,\n",
    "                                                              'slope':slope}, ignore_index=True)\n",
    "            \n",
    "            # run wilcoxcon on the slope\n",
    "            ind_slope_tgt = (slopes_all_result['self_animal']==selfanimal) &\\\n",
    "                            (slopes_all_result['tasktype']==condition) &\\\n",
    "                            (slopes_all_result['xplottype']==xplottype) &\\\n",
    "                            (slopes_all_result['yplottype']==yplot)\n",
    "            slopes_tgt = slopes_all_result[ind_slope_tgt]\n",
    "            slopes_tgt = slopes_tgt[~np.isnan(slopes_tgt['slope'])]\n",
    "                            \n",
    "            try:\n",
    "                _,p_value = st.wilcoxon(slopes_tgt['slope'])\n",
    "            except:\n",
    "                p_value = np.nan \n",
    "                \n",
    "            # Add text for the correlation statistics\n",
    "            ax.text(0.05, 0.95-0.1*ianimal, selfanimal+':'+f\"p = {p_value:.3f}\", \n",
    "                    transform=ax.transAxes, fontsize=10, verticalalignment='top', color=animalcolors[ianimal])\n",
    "\n",
    "        \n",
    "        # run wilcoxcon on the slope\n",
    "        ind_slope_tgt = (slopes_all_result['tasktype']==condition) &\\\n",
    "                        (slopes_all_result['xplottype']==xplottype) &\\\n",
    "                        (slopes_all_result['yplottype']==yplot)\n",
    "        slopes_tgt = slopes_all_result[ind_slope_tgt]\n",
    "        slopes_tgt = slopes_tgt[~np.isnan(slopes_tgt['slope'])]\n",
    "        \n",
    "        try:\n",
    "            _,p_value = st.wilcoxon(slopes_tgt['slope'])\n",
    "        except:\n",
    "            p_value = np.nan \n",
    "         \n",
    "        # Add text for the correlation statistics\n",
    "        ax.text(0.05, 0.95-0.1*nanimals, 'all animals:'+f\"p = {p_value:.3f}\", \n",
    "                transform=ax.transAxes, fontsize=10, verticalalignment='top', color='k')\n",
    "\n",
    "        # Set titles and labels\n",
    "        ax.set_title(f\"{condition} - {yplot}\")\n",
    "        if i == nTrialConds - 1:\n",
    "            ax.set_xlabel(xplottype)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(yplot)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_allanimal_summary_DBNspecific/'+savefile_sufix+'/'+cameraID+'/'    \n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    fig.savefig(figsavefolder+xplottype+\"level_vs_\"+timelag_tgt_name+\"_DBNweight_separatedanimal_separatedays_allcondition_versionof_\"+datatypename+\".pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = slopes_all_result[(slopes_all_result['yplottype']=='pull_pull_weight')&\\\n",
    "                  (slopes_all_result['tasktype']=='self_change_MC')]\n",
    "aaa = aaa[~np.isnan(aaa['slope'])]\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f5ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.wilcoxon(aaa['slope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a880ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f35fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18148622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2234d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4dadb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271b0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117a94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2584223d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c634d699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f42ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
