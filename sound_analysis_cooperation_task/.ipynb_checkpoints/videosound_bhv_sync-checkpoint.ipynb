{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85902bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.io import wavfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2fe3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load camera audios\n",
    "# camera1_audios = \"/ysm-gpfs/pi/jadi/VideoTracker_SocialInter/test_video_3d/20220920_Dodson_Scorch_camera12/20220920_Dodson_Scorch_camera-1_sound.wav\"\n",
    "# camera2_audios = \"/ysm-gpfs/pi/jadi/VideoTracker_SocialInter/test_video_3d/20220920_Dodson_Scorch_camera12/20220920_Dodson_Scorch_camera-2_sound.wav\"\n",
    "\n",
    "camera1_audios = \"/gpfs/gibbs/pi/jadi/VideoTracker_SocialInter/test_video_cooperative_task_3d/20221122_Eddie_Sparkle_camera12/20221122_Sparkle_1.wav\"\n",
    "\n",
    "start_trial_beep = \"/home/ws523/marmoset_tracking_DLCv2/following_up_analysis/start_trial_beep.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c97cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load camera1 audio\n",
    "cam1_audio_samplerate, cam1_audio_data = wavfile.read(camera1_audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52156822",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam1_audio_samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8802230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cam1_audio_time = np.arange(0,np.shape(cam1_audio_data)[0],1)/cam1_audio_samplerate\n",
    "plt_timepoint = np.arange(np.round(cam1_audio_samplerate*0),np.round(cam1_audio_samplerate*100),1)\n",
    "plt_timepoint = plt_timepoint.astype(int)\n",
    "plt.plot(cam1_audio_time[plt_timepoint],cam1_audio_data[plt_timepoint,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae6038",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam1_audio_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c1c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the starting time of the trial/session based on camera1 audio\n",
    "camera1_starttime = round(np.where(cam1_audio_data[:,0]>10000)[0][0]/cam1_audio_samplerate,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be91a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load camera2 audio\n",
    "cam2_audio_samplerate, cam2_audio_data = wavfile.read(camera2_audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd59b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam2_audio_time = np.arange(0,np.shape(cam2_audio_data)[0],1)/cam2_audio_samplerate\n",
    "plt_timepoint = np.arange(np.round(cam2_audio_samplerate*0),np.round(cam2_audio_samplerate*100),1)\n",
    "plt_timepoint = plt_timepoint.astype(int)\n",
    "plt.plot(cam2_audio_time[plt_timepoint],cam2_audio_data[plt_timepoint,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564d129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the starting time of the trial/session based on camera2 audio\n",
    "camera2_starttime = round(np.where(cam2_audio_data[:,1]>10000)[0][0]/cam2_audio_samplerate,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f656116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean audios\n",
    "ind = np.arange(0,np.min([np.shape(cam1_audio_data)[0],np.shape(cam2_audio_data)[0]]),1)\n",
    "cam_mean_audio_data = (cam1_audio_data[ind,0]+cam1_audio_data[ind,1]+cam2_audio_data[ind,0]+cam2_audio_data[ind,1])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce29f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_mean_audio_time = np.arange(0,np.shape(cam_mean_audio_data)[0],1)/cam1_audio_samplerate\n",
    "plt_timepoint = np.arange(np.round(cam1_audio_samplerate*0),np.round(cam1_audio_samplerate*100),1)\n",
    "plt_timepoint = plt_timepoint.astype(int)\n",
    "plt.plot(cam_mean_audio_time[plt_timepoint],cam_mean_audio_data[plt_timepoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the starting time of the trial/session based on mean camera audios\n",
    "camera_mean_starttime = round(np.where(cam_mean_audio_data[:]>5000)[0][0]/cam1_audio_samplerate,2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ddb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera1_starttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd87ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera2_starttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d61036",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_mean_starttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6fab8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
