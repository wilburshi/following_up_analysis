{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1849ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import scipy\n",
    "import string\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.models import DynamicBayesianNetwork as DBN\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.estimators import HillClimbSearch,BicScore\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee0ed4",
   "metadata": {},
   "source": [
    "### function - get body part location for each pair of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.body_part_locs_eachpair import body_part_locs_eachpair\n",
    "from ana_functions.body_part_locs_singlecam import body_part_locs_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ae6f98",
   "metadata": {},
   "source": [
    "### function - align the two cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b03438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_align import camera_align       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494356c2",
   "metadata": {},
   "source": [
    "### function - merge the two pairs of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_merge import camera_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc7f6a",
   "metadata": {},
   "source": [
    "### function - find social gaze time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f6ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.find_socialgaze_timepoint import find_socialgaze_timepoint\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam import find_socialgaze_timepoint_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7e75b",
   "metadata": {},
   "source": [
    "### function - define time point of behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_timepoint import bhv_events_timepoint\n",
    "from ana_functions.bhv_events_timepoint_singlecam import bhv_events_timepoint_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4ab8c",
   "metadata": {},
   "source": [
    "### function - plot behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ba678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.plot_bhv_events import plot_bhv_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c724b",
   "metadata": {},
   "source": [
    "### function - plot inter-pull interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.plot_interpull_interval import plot_interpull_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d535a6",
   "metadata": {},
   "source": [
    "### function - make demo videos with skeleton and inportant vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4de83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.tracking_video_singlecam_demo import tracking_video_singlecam_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69920a6a",
   "metadata": {},
   "source": [
    "### function - interval between all behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a804dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_interval import bhv_events_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ac4ea0",
   "metadata": {},
   "source": [
    "### function - train the dynamic bayesian network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037084bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.train_DBN import train_DBN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c0b97",
   "metadata": {},
   "source": [
    "### function - train the dynamic bayesian network - Alec's methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.train_DBN_alec import train_DBN_alec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d1858b",
   "metadata": {},
   "source": [
    "### methods used by Alec - separate into different \"trials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ae9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.train_DBN_alec import train_DBN_alec_eachtrial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819c438",
   "metadata": {},
   "source": [
    "## Analyze each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94968120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gaze angle threshold\n",
    "# angle_thres = np.pi/36 # 5 degree\n",
    "# angle_thres = np.pi/18 # 10 degree\n",
    "# angle_thres = np.pi/2 # 90 degree\n",
    "# angle_thres_name = '90'\n",
    "# angle_thres = 2*np.pi/3 # 120 degree (60 degree of the eye sight direction)\n",
    "# angle_thres_name = '60'\n",
    "angle_thres = 3*np.pi/4 # 135 degree (45 degree of the eye sight direction)\n",
    "angle_thres_name = '45'\n",
    "\n",
    "# get the fps of the analyzed video\n",
    "fps = 30\n",
    "\n",
    "# frame number of the demo video\n",
    "nframes = 15*30\n",
    "\n",
    "# re-analyze the video or not\n",
    "reanalyze_video = 0\n",
    "\n",
    "# all the videos (no misaligned ones)\n",
    "# dodson scorch\n",
    "if 0:\n",
    "    dates_list = [\n",
    "                  \"20220909\",\"20220912\",\"20220915\",\"20220920\",\"20220922\",\"20220923\",\"20221010\",\n",
    "                  \"20221011\",\"20221013\",\"20221014\",\"20221015\",\"20221017\",\n",
    "                  \"20221018\",\"20221019\",\"20221020\",\"20221021\",\"20221022\",\"20221026\",\"20221028\",\"20221030\",\n",
    "                  \"20221107\",\"20221108\",\"20221109\",\"20221110\",\"20221111\",\"20221114\",\"20221115\",\"20221116\",\n",
    "\n",
    "                  \"20221117\",\"20221118\",\"20221121\",\"20221122\",\"20221123\",\"20221125\",\"20221128\",\"20221129\",              \n",
    "                  \"20221205\",\"20221206\",\"20221209\",\"20221212\",\"20221214\",\"20221216\",\"20221219\",\"20221220\",\"20221221\",\n",
    "                  \"20230208\",\"20230209\",\"20230213\",\"20230214\",\"20230111\",\"20230112\",\"20230201\",\"20230215\",\n",
    "                  \"20230116\",\"20230117\",\"20230118\",\"20230124\"         \n",
    "                 ]\n",
    "# eddie sparkle\n",
    "if 1:\n",
    "    dates_list = [\n",
    "                  \"20221122\",\"20221125\",\"20221128\",\"20221129\",\"20221130\",\"20221202\",\"20221206\",\n",
    "                  \"20221207\",\"20221208\",\"20221209\",\"20230126\",\"20230127\",\"20230130\",\"20230201\",\"20230203-1\",\n",
    "                  \"20230206\",\"20230207\",\"20230208-1\",\"20230209\",\"20230222\",\"20230223-1\",\"20230227-1\",\n",
    "                  \"20230228-1\",\"20230302-1\",\"20230307-2\",\"20230313\",\"20230315\",\"20230316\",\"20230317\",\n",
    "                  \"20230321\",\"20230322\",\"20230324\",\"20230327\",\"20230328\",\n",
    "                  \"20230330\",\"20230331\",\"20230403\",\"20230404\",\"20230405\",\n",
    "                  \"20230406\",\"20230407\"\n",
    "               ]\n",
    "# ginger kanga\n",
    "if 0:\n",
    "    dates_list = [\n",
    "                  \"20230209\",\"20230213\",\"20230214\",\"20230216\",\"20230222\",\"20230223\",\"20230228\",\"20230302\",\n",
    "                  \"20230303\",\"20230307\",\"20230314\",\"20230315\",\"20230316\",\"20230317\",\"20230320\",\"20230322\",\n",
    "                  \"20230323\",\"20230327\",\"20230328\",\"20230330\",\"20230331\",\"20230405\",\"20230406\",\"20230410\",\n",
    "                  \"20230412\",\"20230413\"\n",
    "               ]\n",
    "#    \n",
    "# dates_list = [\"20230328\",\"20230407\"]\n",
    "\n",
    "ndates = np.shape(dates_list)[0]\n",
    "\n",
    "# dodson scorch\n",
    "if 0:\n",
    "    animal1_fixedorder = ['dodson']\n",
    "    animal2_fixedorder = ['scorch']\n",
    "\n",
    "    animal1_filename = \"Dodson\"\n",
    "    animal2_filename = \"Scorch\"\n",
    "    \n",
    "# eddie sparkle\n",
    "if 1:\n",
    "    animal1_fixedorder = ['eddie']\n",
    "    animal2_fixedorder = ['sparkle']\n",
    "\n",
    "    animal1_filename = \"Eddie\"\n",
    "    animal2_filename = \"Sparkle\"\n",
    "    \n",
    "# ginger kanga\n",
    "if 0:\n",
    "    animal1_fixedorder = ['ginger']\n",
    "    animal2_fixedorder = ['kanga']\n",
    "\n",
    "    animal1_filename = \"Ginger\"\n",
    "    animal2_filename = \"Kanga\"\n",
    "\n",
    "# aligned with the audio\n",
    "# get the session start time from \"videosound_bhv_sync.py/.ipynb\"\n",
    "# currently the session_start_time will be manually typed in. It can be updated after a better method is used\n",
    "\n",
    "# all the videos (no misaligned ones)\n",
    "# dodson scorch \n",
    "if 0:\n",
    "    session_start_times = [ \n",
    "                             6.50, 18.10, 0,      33.03, 549.0, 116.80, 6.50,\n",
    "                             2.80, 27.80, 272.50, 27.90, 27.00,\n",
    "                            28.70, 45.30, 21.10,  27.10, 51.90,  21.00, 30.80, 17.50,                      \n",
    "                            15.70,  2.65, 27.30,   0.00,  0.00,  71.80,  0.00,  0.00, \n",
    "\n",
    "                            75.50, 20.20,  0.00, 24.20,  36.70, 26.40, 22.50, 28.50,                       \n",
    "                             0.00,  0.00, 21.70, 84.70,  17.00, 19.80, 23.50, 25.20,  0.00,\n",
    "                             0.00,  0.00,  0.00,  0.00, 130.00, 14.20, 24.20, 33.00,\n",
    "                            28.80, 67.40, 67.00, 24.80                            \n",
    "                          ] # in second\n",
    "# eddie sparkle\n",
    "if 1:\n",
    "    session_start_times = [ \n",
    "                             8.00,38.00,1.00,3.00,5.00,9.50,1.00,\n",
    "                             4.50,4.50,5.00,38.00,166.00,4.20,3.80,3.60,\n",
    "                             7.50,9.00,7.50,8.50,14.50,7.80,8.00,7.50,\n",
    "                             8.00,8.00,4.00,123.00,14.00,8.80,\n",
    "                             7.00,7.50,5.50,11.00,9.00,\n",
    "                             17.00,4.50,9.30,25.50,20.40,\n",
    "                             21.30,24.80\n",
    "                          ] # in second \n",
    "# ginger kanga\n",
    "if 0:\n",
    "    session_start_times = [ \n",
    "                             0.00,  0.00,  0.00, 48.00, 26.20, 18.00, 23.00, 28.50,\n",
    "                            34.00, 25.50, 25.50, 31.50, 28.00, 30.50, 22.20, 29.00,\n",
    "                            33.00, 32.50, 36.50, 24.20, 32.70, 22.00, 20.00, 32.20,\n",
    "                            18.20, 22.80\n",
    "                          ] # in second  \n",
    "#  \n",
    "# session_start_times = [9.00,24.80] # in second\n",
    "\n",
    "session_start_frames = session_start_times * fps # fps is 30Hz\n",
    "\n",
    "\n",
    "# video tracking results info\n",
    "animalnames_videotrack = ['dodson','scorch'] # does not really mean dodson and scorch, instead, indicate animal1 and animal2\n",
    "bodypartnames_videotrack = ['rightTuft','whiteBlaze','leftTuft','rightEye','leftEye','mouth']\n",
    "\n",
    "\n",
    "# which camera to analyzed\n",
    "cameraID = 'camera-2'\n",
    "cameraID_short = 'cam2'\n",
    "\n",
    "\n",
    "# location of levers and tubes for camera 2\n",
    "# get this information using DLC animal tracking GUI, the results are stored: \n",
    "# /home/ws523/marmoset_tracking_DLCv2/marmoset_tracking_with_lever_tube-weikang-2023-04-13/labeled-data/\n",
    "considerlevertube = 1\n",
    "considertubeonly = 0\n",
    "# # camera 1\n",
    "# lever_locs_camI = {'dodson':np.array([645,600]),'scorch':np.array([425,435])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1350,630]),'scorch':np.array([555,345])}\n",
    "# # camera 2\n",
    "# # lever_locs_camI = {'dodson':np.array([1335,685]),'scorch':np.array([550,715])}\n",
    "# # tube_locs_camI  = {'dodson':np.array([1530,495]),'scorch':np.array([270,490])}\n",
    "lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "tube_locs_camI  = {'dodson':np.array([1650,490]),'scorch':np.array([250,490])}\n",
    "# # camera 3\n",
    "# lever_locs_camI = {'dodson':np.array([1580,440]),'scorch':np.array([1296,540])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1470,375]),'scorch':np.array([805,475])}\n",
    "\n",
    "\n",
    "if np.shape(session_start_times)[0] != np.shape(dates_list)[0]:\n",
    "    exit()\n",
    "\n",
    "    \n",
    "DAGs_all_dates = np.zeros((ndates,4,4))\n",
    "DAGs_thres_dates = np.zeros((ndates,4,4))\n",
    "ntempres_dates = np.zeros((ndates,1,1))\n",
    "tasktypes_all_dates = np.zeros((ndates,1))\n",
    "coopthres_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "succ_rate_all_dates = np.zeros((ndates,1))\n",
    "interpullintv_all_dates = np.zeros((ndates,1))\n",
    "trialnum_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "owgaze1_num_all_dates = np.zeros((ndates,1))\n",
    "owgaze2_num_all_dates = np.zeros((ndates,1))\n",
    "mtgaze1_num_all_dates = np.zeros((ndates,1))\n",
    "mtgaze2_num_all_dates = np.zeros((ndates,1))\n",
    "pull1_num_all_dates = np.zeros((ndates,1))\n",
    "pull2_num_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "\n",
    "try:\n",
    "    # dummy\n",
    "    \n",
    "    # load saved data\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/DAGs_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        DAGs_all_dates = pickle.load(f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/DAGs_thres_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        DAGs_thres_dates = pickle.load(f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/ntempres_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        ntempres_dates = pickle.load(f)\n",
    "\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/owgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        owgaze1_num_all_dates = pickle.load(f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/owgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        owgaze2_num_all_dates = pickle.load(f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/mtgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        mtgaze1_num_all_dates = pickle.load(f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/mtgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        mtgaze2_num_all_dates = pickle.load(f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/pull1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        pull1_num_all_dates = pickle.load(f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/pull2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        pull2_num_all_dates = pickle.load(f)\n",
    "\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/tasktypes_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        tasktypes_all_dates = pickle.load(f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/coopthres_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        coopthres_all_dates = pickle.load(f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/succ_rate_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        succ_rate_all_dates = pickle.load(f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/interpullintv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        interpullintv_all_dates = pickle.load(f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/trialnum_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        trialnum_all_dates = pickle.load(f)\n",
    "\n",
    "    print('all data from all dates are loaded')\n",
    "\n",
    "except:\n",
    "\n",
    "    print('analyze all dates')\n",
    "\n",
    "    for idate in np.arange(0,ndates,1):\n",
    "        date_tgt = dates_list[idate]\n",
    "        session_start_time = session_start_times[idate]\n",
    "\n",
    "        # folder and file path\n",
    "        camera12_analyzed_path = \"/gpfs/ysm/pi/jadi/VideoTracker_SocialInter/test_video_cooperative_task_3d/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera12/\"\n",
    "        camera23_analyzed_path = \"/gpfs/ysm/pi/jadi/VideoTracker_SocialInter/test_video_cooperative_task_3d/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera23/\"\n",
    "        \n",
    "        singlecam_ana_type = \"DLC_dlcrnetms5_marmoset_tracking_with_middle_cameraSep1shuffle1_150000\"\n",
    "        try: \n",
    "            bodyparts_camI_camIJ = camera12_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "            # get the bodypart data from files\n",
    "            bodyparts_locs_camI = body_part_locs_singlecam(bodyparts_camI_camIJ,singlecam_ana_type,animalnames_videotrack,bodypartnames_videotrack,date_tgt)\n",
    "        except:\n",
    "            bodyparts_camI_camIJ = camera23_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "            # get the bodypart data from files\n",
    "            bodyparts_locs_camI = body_part_locs_singlecam(bodyparts_camI_camIJ,singlecam_ana_type,animalnames_videotrack,bodypartnames_videotrack,date_tgt)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # load behavioral results\n",
    "        try:\n",
    "            bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "            trial_record_json = bhv_data_path +date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_TrialRecord_1.json\"\n",
    "            bhv_data_json = bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_bhv_data_1.json\"\n",
    "            session_info_json = bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_session_info_1.json\"\n",
    "            #\n",
    "            trial_record = pd.read_json(trial_record_json)\n",
    "            bhv_data = pd.read_json(bhv_data_json)\n",
    "            session_info = pd.read_json(session_info_json)\n",
    "        except:\n",
    "            bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "            trial_record_json = bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_TrialRecord_1.json\"\n",
    "            bhv_data_json = bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_bhv_data_1.json\"\n",
    "            session_info_json = bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_session_info_1.json\"\n",
    "            #\n",
    "            trial_record = pd.read_json(trial_record_json)\n",
    "            bhv_data = pd.read_json(bhv_data_json)\n",
    "            session_info = pd.read_json(session_info_json)\n",
    "\n",
    "        # get animal info from the session information\n",
    "        animal1 = session_info['lever1_animal'][0].lower()\n",
    "        animal2 = session_info['lever2_animal'][0].lower()\n",
    "\n",
    "        \n",
    "        # get task type and cooperation threshold\n",
    "        try:\n",
    "            coop_thres = session_info[\"pulltime_thres\"][0]\n",
    "            tasktype = session_info[\"task_type\"][0]\n",
    "        except:\n",
    "            coop_thres = 0\n",
    "            tasktype = 1\n",
    "        tasktypes_all_dates[idate] = tasktype\n",
    "        coopthres_all_dates[idate] = coop_thres   \n",
    "\n",
    "        # clean up the trial_record\n",
    "        warnings.filterwarnings('ignore')\n",
    "        trial_record_clean = pd.DataFrame(columns=trial_record.columns)\n",
    "        for itrial in np.arange(0,np.max(trial_record['trial_number']),1):\n",
    "            # trial_record_clean.loc[itrial] = trial_record[trial_record['trial_number']==itrial+1].iloc[[0]]\n",
    "            trial_record_clean = trial_record_clean.append(trial_record[trial_record['trial_number']==itrial+1].iloc[[0]])\n",
    "        trial_record_clean = trial_record_clean.reset_index(drop = True)\n",
    "\n",
    "        # change bhv_data time to the absolute time\n",
    "        time_points_new = pd.DataFrame(np.zeros(np.shape(bhv_data)[0]),columns=[\"time_points_new\"])\n",
    "        for itrial in np.arange(0,np.max(trial_record_clean['trial_number']),1):\n",
    "            ind = bhv_data[\"trial_number\"]==itrial+1\n",
    "            new_time_itrial = bhv_data[ind][\"time_points\"] + trial_record_clean[\"trial_starttime\"].iloc[itrial]\n",
    "            time_points_new[\"time_points_new\"][ind] = new_time_itrial\n",
    "        bhv_data[\"time_points\"] = time_points_new[\"time_points_new\"]\n",
    "        bhv_data = bhv_data[bhv_data[\"time_points\"] != 0]\n",
    "\n",
    "\n",
    "        # analyze behavior results\n",
    "        # succ_rate_all_dates[idate] = np.sum(trial_record_clean[\"rewarded\"]>0)/np.shape(trial_record_clean)[0]\n",
    "        succ_rate_all_dates[idate] = np.sum((bhv_data['behavior_events']==3)|(bhv_data['behavior_events']==4))/np.sum((bhv_data['behavior_events']==1)|(bhv_data['behavior_events']==2))\n",
    "        trialnum_all_dates[idate] = np.shape(trial_record_clean)[0]\n",
    "        #\n",
    "        pullid = np.array(bhv_data[(bhv_data['behavior_events']==1) | (bhv_data['behavior_events']==2)][\"behavior_events\"])\n",
    "        pulltime = np.array(bhv_data[(bhv_data['behavior_events']==1) | (bhv_data['behavior_events']==2)][\"time_points\"])\n",
    "        pullid_diff = np.abs(pullid[1:] - pullid[0:-1])\n",
    "        pulltime_diff = pulltime[1:] - pulltime[0:-1]\n",
    "        interpull_intv = pulltime_diff[pullid_diff==1]\n",
    "        interpull_intv = interpull_intv[interpull_intv<10]\n",
    "        mean_interpull_intv = np.nanmean(interpull_intv)\n",
    "        std_interpull_intv = np.nanstd(interpull_intv)\n",
    "        #\n",
    "        interpullintv_all_dates[idate] = mean_interpull_intv\n",
    "        # \n",
    "        pull1_num_all_dates[idate] = np.sum(bhv_data['behavior_events']==1) \n",
    "        pull2_num_all_dates[idate] = np.sum(bhv_data['behavior_events']==2)\n",
    "\n",
    "        \n",
    "        # load behavioral event results\n",
    "        try:\n",
    "            # dummy\n",
    "            print('load social gaze with '+cameraID+' only of '+date_tgt)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_look_ornot.pkl', 'rb') as f:\n",
    "                output_look_ornot = pickle.load(f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allvectors.pkl', 'rb') as f:\n",
    "                output_allvectors = pickle.load(f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allangles.pkl', 'rb') as f:\n",
    "                output_allangles = pickle.load(f)  \n",
    "        except:   \n",
    "            print('analyze social gaze with '+cameraID+' only of '+date_tgt)\n",
    "            # get social gaze information \n",
    "            output_look_ornot, output_allvectors, output_allangles = find_socialgaze_timepoint_singlecam(bodyparts_locs_camI,lever_locs_camI,tube_locs_camI,considerlevertube,considertubeonly,angle_thres)\n",
    "            # save data\n",
    "            current_dir = os.getcwd()+'/bhv_events_singlecam_'+animal1_fixedorder[0]+animal2_fixedorder[0]\n",
    "            add_date_dir = os.path.join(current_dir,cameraID+'/'+date_tgt)\n",
    "            if not os.path.exists(add_date_dir):\n",
    "                os.makedirs(add_date_dir)\n",
    "            #\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_look_ornot.pkl', 'wb') as f:\n",
    "                pickle.dump(output_look_ornot, f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allvectors.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allvectors, f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allangles.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allangles, f)\n",
    "            \n",
    "        look_at_other_or_not_merge = output_look_ornot['look_at_other_or_not_merge']\n",
    "        look_at_tube_or_not_merge = output_look_ornot['look_at_tube_or_not_merge']\n",
    "        look_at_lever_or_not_merge = output_look_ornot['look_at_lever_or_not_merge']\n",
    "        # change the unit to second\n",
    "        session_start_time = session_start_times[idate]\n",
    "        look_at_other_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_other_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_lever_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_lever_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_tube_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_tube_or_not_merge['dodson'])[0],1)/fps - session_start_time \n",
    "\n",
    "        # find time point of behavioral events\n",
    "        output_time_points_socialgaze ,output_time_points_levertube = bhv_events_timepoint_singlecam(bhv_data,look_at_other_or_not_merge,look_at_lever_or_not_merge,look_at_tube_or_not_merge)\n",
    "        time_point_pull1 = output_time_points_socialgaze['time_point_pull1']\n",
    "        time_point_pull2 = output_time_points_socialgaze['time_point_pull2']\n",
    "        oneway_gaze1 = output_time_points_socialgaze['oneway_gaze1']\n",
    "        oneway_gaze2 = output_time_points_socialgaze['oneway_gaze2']\n",
    "        mutual_gaze1 = output_time_points_socialgaze['mutual_gaze1']\n",
    "        mutual_gaze2 = output_time_points_socialgaze['mutual_gaze2']\n",
    "            \n",
    "                \n",
    "        # # plot behavioral events\n",
    "        if np.isin(animal1,animal1_fixedorder):\n",
    "                plot_bhv_events(date_tgt,animal1, animal2, session_start_time, 600, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "        else:\n",
    "                plot_bhv_events(date_tgt,animal2, animal1, session_start_time, 600, time_point_pull2, time_point_pull1, oneway_gaze2, oneway_gaze1, mutual_gaze2, mutual_gaze1)\n",
    "        #\n",
    "        # save behavioral events plot\n",
    "        if 0:\n",
    "            current_dir = os.getcwd()+'/bhv_events_singlecam_'+animal1_fixedorder[0]+animal2_fixedorder[0]\n",
    "            add_date_dir = os.path.join(current_dir,cameraID+'/'+date_tgt)\n",
    "            if not os.path.exists(add_date_dir):\n",
    "                os.makedirs(add_date_dir)\n",
    "            plt.savefig(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/'+date_tgt+\"_\"+cameraID_short+\".pdf\")\n",
    "\n",
    "        #\n",
    "        owgaze1_num_all_dates[idate] = np.shape(oneway_gaze1)[0]\n",
    "        owgaze2_num_all_dates[idate] = np.shape(oneway_gaze2)[0]\n",
    "        mtgaze1_num_all_dates[idate] = np.shape(mutual_gaze1)[0]\n",
    "        mtgaze2_num_all_dates[idate] = np.shape(mutual_gaze2)[0]\n",
    "\n",
    "        \n",
    "        # plot the tracking demo video\n",
    "        if 0: \n",
    "            if np.isin(animal1,animal1_fixedorder):\n",
    "                tracking_video_singlecam_demo(bodyparts_locs_camI,output_look_ornot,output_allvectors,output_allangles,\n",
    "                                              lever_locs_camI,tube_locs_camI,time_point_pull1,time_point_pull2,\n",
    "                                              animalnames_videotrack,bodypartnames_videotrack,date_tgt,\n",
    "                                              animal1_filename,animal2_filename,session_start_time,fps,nframes,cameraID,video_file_original)\n",
    "            else:\n",
    "                tracking_video_singlecam_demo(bodyparts_locs_camI,output_look_ornot,output_allvectors,output_allangles,\n",
    "                                              lever_locs_camI,tube_locs_camI,time_point_pull2,time_point_pull1,\n",
    "                                              animalnames_videotrack,bodypartnames_videotrack,date_tgt,\n",
    "                                              animal1_filename,animal2_filename,session_start_time,fps,nframes,cameraID,video_file_original)\n",
    "        \n",
    "        \n",
    "\n",
    "        # # plot inter-pull interval\n",
    "        # plot_interpull_interval(animal1, animal2, time_point_pull1, time_point_pull2)\n",
    "\n",
    "        # # train the dynamic bayesian network - simple model\n",
    "        # temp_resolu = 0.5 # temporala resolution in the DBN model 0.5 means 500ms\n",
    "        # model = train_DBN(totalsess_time,temp_resolu, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "        # plot the simple DBN\n",
    "        # pos=nx.spring_layout(model)\n",
    "        # nx.draw(model,pos,with_labels = True)\n",
    "        # labels = nx.get_edge_attributes(model,'weight')\n",
    "        # nx.draw_networkx_edge_labels(model,pos,edge_labels=labels\n",
    "        # model.get_cpds()\n",
    "\n",
    "        # # train the dynamic bayesian network - Alec's model\n",
    "        # temp_resolu = 2 # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "        # totalsess_time = 660 # total session time in s\n",
    "        # best_model, edges, DAGs,_,_,_ = train_DBN_alec(totalsess_time, temp_resolu, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "\n",
    "        # # train the dynamic bayesian network - Alec's model for separate \"trials\"\n",
    "        # temp_resolu = 2 # temporala resolution in the DBN model 0.5 means 500ms\n",
    "        # totalsess_time = 600 # total session time in s\n",
    "        # DAGs_itrial, weighted_graphs,_,_,_ = train_DBN_alec_eachtrial(totalsess_time, temp_resolu, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "        \n",
    "        \n",
    "        # # train the dynamic bayesian network - Alec's model, try different time step\n",
    "        if 1:\n",
    "            print('DBN analysis for '+date_tgt)\n",
    "            # use bhv event to decide temporal resolution\n",
    "            totalsess_time = 600 # total session time in s\n",
    "            low_lim,up_lim,_ = bhv_events_interval(totalsess_time, session_start_time, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "            # temp_resolus  = np.arange(low_lim,up_lim,0.1)\n",
    "            # temp_resolus = [0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6,6.5,7,7.5,8,8.5] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "            temp_resolus = np.arange(0.1,1.1,0.1)\n",
    "            \n",
    "            ntemp_reses = np.shape(temp_resolus)[0]\n",
    "\n",
    "            DAGs_all_tempres = np.zeros([4,4])\n",
    "            for temp_resolu in temp_resolus:\n",
    "                if np.isin(animal1,animal1_fixedorder):\n",
    "                    best_model,edges,DAGs,eventnames,from_pops,to_pops = train_DBN_alec(totalsess_time, session_start_time, temp_resolu, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "                else:\n",
    "                    best_model,edges,DAGs,eventnames,from_pops,to_pops = train_DBN_alec(totalsess_time, session_start_time, temp_resolu, time_point_pull2, time_point_pull1, oneway_gaze2, oneway_gaze1, mutual_gaze2, mutual_gaze1)     \n",
    "                print(edges)\n",
    "                DAGs[0][np.isnan(DAGs[0])]=0\n",
    "                DAGs_all_tempres = DAGs_all_tempres + DAGs[0]\n",
    "\n",
    "            DAGs_all_tempres = DAGs_all_tempres/ntemp_reses\n",
    "            DAGs_thres_tempres = np.zeros([4,4])\n",
    "            DAGs_thres_tempres[DAGs_all_tempres>0.5]=1\n",
    "            #\n",
    "            DAGs_all_dates[idate,:,:]= DAGs_all_tempres\n",
    "            DAGs_thres_dates[idate,:,:] = DAGs_thres_tempres\n",
    "            ntempres_dates[idate,:,:] = ntemp_reses\n",
    "            #\n",
    "            # edge_list = [(from_pop,to_pop) for from_pop in from_pops for to_pop in to_pops]\n",
    "            # ind_edges = np.reshape(np.transpose(np.mean(DAGs_thres_dates,axis=0)>0.15),(16,1))\n",
    "            # edges_good = [edge_list[i] for i in np.where(ind_edges)[0]]\n",
    "\n",
    "\n",
    "# save data\n",
    "if 1:\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/DAGs_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(DAGs_all_dates, f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/DAGs_thres_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(DAGs_thres_dates, f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/ntempres_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(ntempres_dates, f)\n",
    "\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/owgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(owgaze1_num_all_dates, f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/owgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(owgaze2_num_all_dates, f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/mtgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(mtgaze1_num_all_dates, f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/mtgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(mtgaze2_num_all_dates, f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/pull1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(pull1_num_all_dates, f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/pull2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(pull2_num_all_dates, f)\n",
    "\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/tasktypes_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(tasktypes_all_dates, f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/coopthres_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(coopthres_all_dates, f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/succ_rate_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(succ_rate_all_dates, f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/interpullintv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(interpullintv_all_dates, f)\n",
    "    with open('data_saved_original_singlecam/'+cameraID+'/trialnum_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(trialnum_all_dates, f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf23e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "nframes = 6*30\n",
    "bodyparts_locs_camN = bodyparts_locs_camI\n",
    "lever_loc_both = lever_locs_camI\n",
    "tube_loc_both = tube_locs_camI\n",
    "bodyparts_camN_camNM = bodyparts_camI_camIJ\n",
    "# tracking_video_singlecam_demo(bodyparts_locs_camN,output_look_ornot,output_allvectors,output_allangles,\n",
    "#                               lever_loc_both, tube_loc_both,time_point_pull1,time_point_pull2,animalnames_videotrack,\n",
    "#                               bodypartnames_videotrack,date_tgt,animal1_filename,animal2_filename,session_start_time,\n",
    "#                               fps,nframes,cameraID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90213b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a37fa17c",
   "metadata": {},
   "source": [
    "### compare the single camera tracking (camera 1, 2, and 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f1eb3",
   "metadata": {},
   "source": [
    "#### calculate the correlation between the social gaze time series of camera 1(3) and camera 2 for each animal (animal1 and 2 not the name) in each session, and pull them together across sessions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaze angle threshold\n",
    "# angle_thres = np.pi/36 # 5 degree\n",
    "# angle_thres = np.pi/18 # 10 degree\n",
    "# angle_thres = np.pi/2 # 90 degree\n",
    "# angle_thres_name = '90'\n",
    "# angle_thres = 2*np.pi/3 # 120 degree (60 degree of the eye sight direction)\n",
    "# angle_thres_name = '60'\n",
    "angle_thres = 3*np.pi/4 # 135 degree (45 degree of the eye sight direction)\n",
    "angle_thres_name = '45'\n",
    "\n",
    "# get the fps of the analyzed video\n",
    "fps = 30\n",
    "\n",
    "# frame number of the demo video\n",
    "nframes = 15*30\n",
    "\n",
    "\n",
    "# all the videos (no misaligned ones)\n",
    "# dodson scorch\n",
    "if 0:\n",
    "    dates_list = [\n",
    "                  \"20220909\",\"20220912\",\"20220915\",\"20220920\",\"20220922\",\"20220923\",\"20221010\",\n",
    "                  \"20221011\",\"20221013\",\"20221014\",\"20221015\",\"20221017\",\n",
    "                  \"20221018\",\"20221019\",\"20221020\",\"20221021\",\"20221022\",\"20221026\",\"20221028\",\"20221030\",\n",
    "                  \"20221107\",\"20221108\",\"20221109\",\"20221110\",\"20221111\",\"20221114\",\"20221115\",\"20221116\",\n",
    "\n",
    "                  \"20221117\",\"20221118\",\"20221121\",\"20221122\",\"20221123\",\"20221125\",\"20221128\",\"20221129\",              \n",
    "                  \"20221205\",\"20221206\",\"20221209\",\"20221212\",\"20221214\",\"20221216\",\"20221219\",\"20221220\",\"20221221\",\n",
    "                  \"20230208\",\"20230209\",\"20230213\",\"20230214\",\"20230111\",\"20230112\",\"20230201\",\"20230215\",\n",
    "                  # \"20230116\",\"20230117\",\"20230118\",\"20230124\",\"20230125\",\"20230126\",\"20230127\"          \n",
    "                 ]\n",
    "# eddie sparkle\n",
    "if 1:\n",
    "    dates_list = [\n",
    "                  \"20221122\",\"20221125\",\"20221128\",\"20221129\",\"20221130\",\"20221202\",\"20221206\",\n",
    "                  \"20221207\",\"20221208\",\"20221209\",\"20230126\",\"20230127\",\"20230130\",\"20230201\",\"20230203-1\",\n",
    "                  \"20230206\",\"20230207\",\"20230208-1\",\"20230209\",\"20230222\",\"20230223-1\",\"20230227-1\",\n",
    "                  \"20230228-1\",\"20230302-1\",\"20230307-2\",\"20230313\",\"20230315\",\"20230316\",\"20230317\",\n",
    "                  \"20230321\",\"20230322\",\"20230324\",\"20230327\",\"20230328\",\n",
    "                  \"20230407\"\n",
    "               ]\n",
    "# ginger kanga\n",
    "if 0:\n",
    "    dates_list = [\n",
    "                  \"20230209\",\"20230213\",\"20230214\",\"20230216\",\"20230222\",\"20230223\",\"20230228\",\"20230302\",\n",
    "                  \"20230303\",\"20230307\",\"20230314\",\"20230315\",\"20230316\",\"20230317\",\"20230320\",\"20230322\",\n",
    "                  \"20230323\",\"20230327\",\"20230328\",\"20230330\",\"20230331\",\"20230405\",\"20230406\",\"20230410\",\n",
    "                  \"20230412\",\"20230413\"\n",
    "               ]\n",
    "#    \n",
    "# dates_list = [\"20230328\",\"20230407\"]\n",
    "\n",
    "ndates = np.shape(dates_list)[0]\n",
    "\n",
    "# eddie sparkle\n",
    "if 0:\n",
    "    animal1_fixedorder = ['dodson']\n",
    "    animal2_fixedorder = ['scorch']\n",
    "\n",
    "    animal1_filename = \"Dodson\"\n",
    "    animal2_filename = \"Scorch\"\n",
    "    \n",
    "# eddie sparkle\n",
    "if 1:\n",
    "    animal1_fixedorder = ['eddie']\n",
    "    animal2_fixedorder = ['sparkle']\n",
    "\n",
    "    animal1_filename = \"Eddie\"\n",
    "    animal2_filename = \"Sparkle\"\n",
    "    \n",
    "# ginger kanga\n",
    "if 0:\n",
    "    animal1_fixedorder = ['ginger']\n",
    "    animal2_fixedorder = ['kanga']\n",
    "\n",
    "    animal1_filename = \"Ginger\"\n",
    "    animal2_filename = \"Kanga\"\n",
    "\n",
    "    \n",
    "# aligned with the audio\n",
    "# get the session start time from \"videosound_bhv_sync.py/.ipynb\"\n",
    "# currently the session_start_time will be manually typed in. It can be updated after a better method is used\n",
    "\n",
    "# all the videos (no misaligned ones)\n",
    "# dodson scorch \n",
    "if 0:\n",
    "    session_start_times = [ \n",
    "                             6.50, 18.10, 0,      33.03, 549.0, 116.80, 6.50,\n",
    "                             2.80, 27.80, 272.50, 27.90, 27.00,\n",
    "                            28.70, 45.30, 21.10,  27.10, 51.90,  21.00, 30.80, 17.50,                      \n",
    "                            15.70,  2.65, 27.30,   0.00,  0.00,  71.80,  0.00,  0.00, \n",
    "\n",
    "                            75.50, 20.20,  0.00, 24.20,  36.70, 26.40, 22.50, 28.50,                       \n",
    "                             0.00,  0.00, 21.70, 84.70,  17.00, 19.80, 23.50, 25.20,  0.00,\n",
    "                             0.00,  0.00,  0.00,  0.00, 130.00, 14.20, 24.20, 33.00,\n",
    "                            # 28.80, 67.40, 67.00, 24.80,  34.00, 90.00, 39.80                            \n",
    "                          ] # in second\n",
    "# eddie sparkle\n",
    "if 1:\n",
    "    session_start_times = [ \n",
    "                             8.00,38.00,1.00,3.00,5.00,9.50,1.00,\n",
    "                             4.50,4.50,5.00,38.00,166.00,4.20,3.80,3.60,\n",
    "                             7.50,9.00,7.50,8.50,14.50,7.80,8.00,7.50,\n",
    "                             8.00,8.00,4.00,123.00,14.00,8.80,\n",
    "                             7.00,7.50,5.50,11.00,9.00,\n",
    "                             24.80\n",
    "                          ] # in second \n",
    "# ginger kanga\n",
    "if 0:\n",
    "    session_start_times = [ \n",
    "                             0.00,  0.00,  0.00, 48.00, 26.20, 18.00, 23.00, 28.50,\n",
    "                            34.00, 25.50, 25.50, 31.50, 28.00, 30.50, 22.20, 29.00,\n",
    "                            33.00, 32.50, 36.50, 24.20, 32.70, 22.00, 20.00, 32.20,\n",
    "                            18.20, 22.80\n",
    "                          ] # in second  \n",
    "#  \n",
    "# session_start_times = [9.00,24.80] # in second\n",
    "\n",
    "session_start_frames = session_start_times * fps # fps is 30Hz\n",
    "\n",
    "\n",
    "# video tracking results info\n",
    "animalnames_videotrack = ['dodson','scorch'] # does not really mean dodson and scorch, instead, indicate animal1 and animal2\n",
    "bodypartnames_videotrack = ['rightTuft','whiteBlaze','leftTuft','rightEye','leftEye','mouth']\n",
    "\n",
    "\n",
    "\n",
    "# location of levers and tubes for camera 2\n",
    "# get this information using DLC animal tracking GUI, the results are stored: \n",
    "# /home/ws523/marmoset_tracking_DLCv2/marmoset_tracking_with_lever_tube-weikang-2023-04-13/labeled-data/\n",
    "considerlevertube = 1\n",
    "considertubeonly = 0\n",
    "# # camera 1\n",
    "lever_locs_cam1 = {'dodson':np.array([645,600]),'scorch':np.array([425,435])}\n",
    "tube_locs_cam1  = {'dodson':np.array([1350,630]),'scorch':np.array([555,345])}\n",
    "# # camera 2\n",
    "# # lever_locs_cam2 = {'dodson':np.array([1335,685]),'scorch':np.array([550,715])}\n",
    "# # tube_locs_cam2  = {'dodson':np.array([1530,495]),'scorch':np.array([270,490])}\n",
    "lever_locs_cam2 = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "tube_locs_cam2  = {'dodson':np.array([1650,490]),'scorch':np.array([250,490])}\n",
    "# # camera 3\n",
    "lever_locs_cam3 = {'dodson':np.array([1580,440]),'scorch':np.array([1296,540])}\n",
    "tube_locs_cam3  = {'dodson':np.array([1470,375]),'scorch':np.array([805,475])}\n",
    "\n",
    "\n",
    "if np.shape(session_start_times)[0] != np.shape(dates_list)[0]:\n",
    "    exit()\n",
    "\n",
    "\n",
    "corr_cam12_anm1 = np.zeros((ndates,1))   \n",
    "corr_cam12_anm2 = np.zeros((ndates,1)) \n",
    "corr_cam23_anm1 = np.zeros((ndates,1)) \n",
    "corr_cam23_anm2 = np.zeros((ndates,1)) \n",
    "\n",
    "\n",
    "nshuffles = 1\n",
    "corr_cam12_anm1_shuffle = np.zeros((ndates*nshuffles,1))   \n",
    "corr_cam12_anm2_shuffle = np.zeros((ndates*nshuffles,1)) \n",
    "corr_cam23_anm1_shuffle = np.zeros((ndates*nshuffles,1)) \n",
    "corr_cam23_anm2_shuffle = np.zeros((ndates*nshuffles,1)) \n",
    "\n",
    "\n",
    "try:\n",
    "    dummy\n",
    "\n",
    "except:\n",
    "\n",
    "    print('analyze all dates')\n",
    "\n",
    "    for idate in np.arange(0,ndates,1):\n",
    "        date_tgt = dates_list[idate]\n",
    "        session_start_time = session_start_times[idate]\n",
    "\n",
    "        \n",
    "        # load behavioral event results\n",
    "        try:\n",
    "            # dummy\n",
    "            print('load social gaze with camera-1 only of '+date_tgt)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-1/\"+date_tgt+'/output_look_ornot.pkl', 'rb') as f:\n",
    "                output_look_ornot_cam1 = pickle.load(f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-1/\"+date_tgt+'/output_allvectors.pkl', 'rb') as f:\n",
    "                output_allvectors_cam1 = pickle.load(f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-1/\"+date_tgt+'/output_allangles.pkl', 'rb') as f:\n",
    "                output_allangles_cam1 = pickle.load(f) \n",
    "            #\n",
    "            print('load social gaze with camera-2 only of '+date_tgt)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-2/\"+date_tgt+'/output_look_ornot.pkl', 'rb') as f:\n",
    "                output_look_ornot_cam2 = pickle.load(f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-2/\"+date_tgt+'/output_allvectors.pkl', 'rb') as f:\n",
    "                output_allvectors_cam2 = pickle.load(f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-2/\"+date_tgt+'/output_allangles.pkl', 'rb') as f:\n",
    "                output_allangles_cam2 = pickle.load(f)     \n",
    "            #\n",
    "            print('load social gaze with camera-3 only of '+date_tgt)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-3/\"+date_tgt+'/output_look_ornot.pkl', 'rb') as f:\n",
    "                output_look_ornot_cam3 = pickle.load(f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-3/\"+date_tgt+'/output_allvectors.pkl', 'rb') as f:\n",
    "                output_allvectors_cam3 = pickle.load(f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-3/\"+date_tgt+'/output_allangles.pkl', 'rb') as f:\n",
    "                output_allangles_cam3 = pickle.load(f) \n",
    "         \n",
    "        except: \n",
    "            \n",
    "            # folder and file path\n",
    "            camera12_analyzed_path = \"/gpfs/ysm/pi/jadi/VideoTracker_SocialInter/test_video_cooperative_task_3d/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera12/\"\n",
    "            camera23_analyzed_path = \"/gpfs/ysm/pi/jadi/VideoTracker_SocialInter/test_video_cooperative_task_3d/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera23/\"\n",
    "\n",
    "            singlecam_ana_type = \"DLC_dlcrnetms5_marmoset_tracking_with_middle_cameraSep1shuffle1_150000\"\n",
    "            # get the bodypart data from files - camera 1\n",
    "            bodyparts_cam1_cam12 = camera12_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera-1\"+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "            bodyparts_locs_cam1 = body_part_locs_singlecam(bodyparts_cam1_cam12,singlecam_ana_type,animalnames_videotrack,bodypartnames_videotrack,date_tgt)\n",
    "            # get the bodypart data from files - camera 2\n",
    "            bodyparts_cam2_cam12 = camera12_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera-2\"+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "            bodyparts_locs_cam2 = body_part_locs_singlecam(bodyparts_cam2_cam12,singlecam_ana_type,animalnames_videotrack,bodypartnames_videotrack,date_tgt)\n",
    "            # get the bodypart data from files - camera 3\n",
    "            bodyparts_cam3_cam23 = camera23_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera-3\"+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "            bodyparts_locs_cam3 = body_part_locs_singlecam(bodyparts_cam3_cam23,singlecam_ana_type,animalnames_videotrack,bodypartnames_videotrack,date_tgt)\n",
    "        \n",
    "            # analyze bhv events - camera 1\n",
    "            print('analyze social gaze with camera-1 only of '+date_tgt)\n",
    "            # get social gaze information \n",
    "            output_look_ornot_cam1,output_allvectors_cam1,output_allangles_cam1 = find_socialgaze_timepoint_singlecam(bodyparts_locs_cam1,lever_locs_cam1,tube_locs_cam1,considerlevertube,considertubeonly,angle_thres)\n",
    "            # save data\n",
    "            current_dir = os.getcwd()+'/bhv_events_singlecam_'+animal1_fixedorder[0]+animal2_fixedorder[0]\n",
    "            add_date_dir = os.path.join(current_dir,'/camera-1/'+date_tgt)\n",
    "            if not os.path.exists(add_date_dir):\n",
    "                os.makedirs(add_date_dir)\n",
    "            #\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-1/\"+date_tgt+'/output_look_ornot.pkl', 'wb') as f:\n",
    "                pickle.dump(output_look_ornot_cam1, f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-1/\"+date_tgt+'/output_allvectors.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allvectors_cam1, f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-1/\"+date_tgt+'/output_allangles.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allangles_cam1, f)\n",
    "            #\n",
    "            # analyze bhv events - camera 2\n",
    "            print('analyze social gaze with camera-2 only of '+date_tgt)\n",
    "            # get social gaze information \n",
    "            output_look_ornot_cam2,output_allvectors_cam2,output_allangles_cam2 = find_socialgaze_timepoint_singlecam(bodyparts_locs_cam2,lever_locs_cam2,tube_locs_cam2,considerlevertube,considertubeonly,angle_thres)\n",
    "            # save data\n",
    "            current_dir = os.getcwd()+'/bhv_events_singlecam_'+animal1_fixedorder[0]+animal2_fixedorder[0]\n",
    "            add_date_dir = os.path.join(current_dir,'/camera-2/'+date_tgt)\n",
    "            if not os.path.exists(add_date_dir):\n",
    "                os.makedirs(add_date_dir)\n",
    "            #\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-2/\"+date_tgt+'/output_look_ornot.pkl', 'wb') as f:\n",
    "                pickle.dump(output_look_ornot_cam2, f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-2/\"+date_tgt+'/output_allvectors.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allvectors_cam2, f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-2/\"+date_tgt+'/output_allangles.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allangles_cam2, f)\n",
    "            #\n",
    "            # analyze bhv events - camera 3\n",
    "            print('analyze social gaze with camera-3 only of '+date_tgt)\n",
    "            # get social gaze information \n",
    "            output_look_ornot_cam3,output_allvectors_cam3,output_allangles_cam3 = find_socialgaze_timepoint_singlecam(bodyparts_locs_cam3,lever_locs_cam3,tube_locs_cam3,considerlevertube,considertubeonly,angle_thres)\n",
    "            # save data\n",
    "            current_dir = os.getcwd()+'/bhv_events_singlecam_'+animal1_fixedorder[0]+animal2_fixedorder[0]\n",
    "            add_date_dir = os.path.join(current_dir,'/camera-3/'+date_tgt)\n",
    "            if not os.path.exists(add_date_dir):\n",
    "                os.makedirs(add_date_dir)\n",
    "            #\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-3/\"+date_tgt+'/output_look_ornot.pkl', 'wb') as f:\n",
    "                pickle.dump(output_look_ornot_cam3, f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-3/\"+date_tgt+'/output_allvectors.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allvectors_cam3, f)\n",
    "            with open(\"bhv_events_singlecam_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/camera-3/\"+date_tgt+'/output_allangles.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allangles_cam3, f)\n",
    "            \n",
    "        \n",
    "        # correlation among camera 1, 2, 3, and for each animal\n",
    "        nframes_cam1 = np.shape(output_look_ornot_cam1['look_at_other_or_not_merge']['dodson'])[0]\n",
    "        nframes_cam2 = np.shape(output_look_ornot_cam2['look_at_other_or_not_merge']['dodson'])[0]\n",
    "        nframes_cam3 = np.shape(output_look_ornot_cam3['look_at_other_or_not_merge']['dodson'])[0]        \n",
    "        nframes_cam12 = np.min([nframes_cam1,nframes_cam2])\n",
    "        nframes_cam23 = np.min([nframes_cam2,nframes_cam3])\n",
    "        #\n",
    "        corr_cam12_anm1[idate] = np.corrcoef(output_look_ornot_cam1['look_at_other_or_not_merge']['dodson'][0:nframes_cam12],\n",
    "                                             output_look_ornot_cam2['look_at_other_or_not_merge']['dodson'][0:nframes_cam12])[0,1]\n",
    "        corr_cam12_anm2[idate] = np.corrcoef(output_look_ornot_cam1['look_at_other_or_not_merge']['scorch'][0:nframes_cam12],\n",
    "                                             output_look_ornot_cam2['look_at_other_or_not_merge']['scorch'][0:nframes_cam12])[0,1]\n",
    "        corr_cam23_anm1[idate] = np.corrcoef(output_look_ornot_cam2['look_at_other_or_not_merge']['dodson'][0:nframes_cam23],\n",
    "                                             output_look_ornot_cam3['look_at_other_or_not_merge']['dodson'][0:nframes_cam23])[0,1]\n",
    "        corr_cam23_anm2[idate] = np.corrcoef(output_look_ornot_cam2['look_at_other_or_not_merge']['scorch'][0:nframes_cam23],\n",
    "                                             output_look_ornot_cam3['look_at_other_or_not_merge']['scorch'][0:nframes_cam23])[0,1]\n",
    "\n",
    "        \n",
    "        # bootstrapping shuffling\n",
    "        for ishuffle in np.arange(0,nshuffles,1):\n",
    "            \n",
    "            corr_cam12_anm1_shuffle[idate*nshuffles+ishuffle] = np.corrcoef(\n",
    "                np.random.permutation(output_look_ornot_cam1['look_at_other_or_not_merge']['dodson'][0:nframes_cam12]),\n",
    "                np.random.permutation(output_look_ornot_cam2['look_at_other_or_not_merge']['dodson'][0:nframes_cam12]))[0,1]\n",
    "            corr_cam12_anm2_shuffle[idate*nshuffles+ishuffle] = np.corrcoef(\n",
    "                np.random.permutation(output_look_ornot_cam1['look_at_other_or_not_merge']['scorch'][0:nframes_cam12]),\n",
    "                np.random.permutation(output_look_ornot_cam2['look_at_other_or_not_merge']['scorch'][0:nframes_cam12]))[0,1]\n",
    "            corr_cam23_anm1_shuffle[idate*nshuffles+ishuffle] = np.corrcoef(\n",
    "                np.random.permutation(output_look_ornot_cam2['look_at_other_or_not_merge']['dodson'][0:nframes_cam23]),\n",
    "                np.random.permutation(output_look_ornot_cam3['look_at_other_or_not_merge']['dodson'][0:nframes_cam23]))[0,1]\n",
    "            corr_cam23_anm2_shuffle[idate*nshuffles+ishuffle] = np.corrcoef(\n",
    "                np.random.permutation(output_look_ornot_cam2['look_at_other_or_not_merge']['scorch'][0:nframes_cam23]),\n",
    "                np.random.permutation(output_look_ornot_cam3['look_at_other_or_not_merge']['scorch'][0:nframes_cam23]))[0,1]\n",
    "            \n",
    "            \n",
    "        \n",
    "# plot the histogram\n",
    "fig, axs = plt.subplots(2,2,figsize=(10, 10))\n",
    "axs[0,0].hist(corr_cam12_anm1, bins=np.arange(0,1.01,0.05))\n",
    "axs[0,0].set_title('camera 1 and 2, animal 1')\n",
    "axs[0,1].hist(corr_cam12_anm2, bins=np.arange(0,1.01,0.05))\n",
    "axs[0,1].set_title('camera 1 and 2, animal 2')\n",
    "axs[1,0].hist(corr_cam23_anm1, bins=np.arange(0,1.01,0.05))\n",
    "axs[1,0].set_title('camera 2 and 3, animal 1')\n",
    "axs[1,0].set_xlabel('Pearson correlation r')\n",
    "axs[1,1].hist(corr_cam23_anm2, bins=np.arange(0,1.01,0.05))\n",
    "axs[1,1].set_title('camera 2 and 3, animal 2')\n",
    "axs[1,1].set_xlabel('Pearson correlation r');\n",
    "\n",
    "# plot the histogram with shuffle\n",
    "fig2, axs2 = plt.subplots(2,2,figsize=(10, 10))\n",
    "axs2[0,0].hist(corr_cam12_anm1, bins=np.arange(0,1.01,0.05))\n",
    "axs2[0,0].hist(corr_cam12_anm1_shuffle, bins=np.arange(0,1.01,0.05))\n",
    "axs2[0,0].set_title('camera 1 and 2, animal 1')\n",
    "axs2[0,1].hist(corr_cam12_anm2, bins=np.arange(0,1.01,0.05))\n",
    "axs2[0,1].hist(corr_cam12_anm2_shuffle, bins=np.arange(0,1.01,0.05))\n",
    "axs2[0,1].set_title('camera 1 and 2, animal 2')\n",
    "axs2[1,0].hist(corr_cam23_anm1, bins=np.arange(0,1.01,0.05))\n",
    "axs2[1,0].hist(corr_cam23_anm1_shuffle, bins=np.arange(0,1.01,0.05))\n",
    "axs2[1,0].set_title('camera 2 and 3, animal 1')\n",
    "axs2[1,0].set_xlabel('Pearson correlation r')\n",
    "axs2[1,1].hist(corr_cam23_anm2, bins=np.arange(0,1.01,0.05))\n",
    "axs2[1,1].hist(corr_cam23_anm2_shuffle, bins=np.arange(0,1.01,0.05))\n",
    "axs2[1,1].set_title('camera 2 and 3, animal 2')\n",
    "axs2[1,1].set_xlabel('Pearson correlation r')\n",
    "axs2[1,1].legend({'shuffled','data'});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a366d89f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d544d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e002b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7e08ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3827e076",
   "metadata": {},
   "source": [
    "### plot the transition probability from social gaze to pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coopthres_all_dates[tasktypes_all_dates==1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c618d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "#\n",
    "# sort the data based on task type, coorpthre and dates\n",
    "# coopthres_forsort = (tasktypes_all_dates)*coopthres_all_dates/2\n",
    "# coopthres_forsort[coopthres_forsort==0] = 100 # get the cooperation threshold for sorting\n",
    "# sorting_df = pd.DataFrame({'dates': dates_list, 'coopthres': coopthres_forsort.ravel()}, columns=['dates', 'coopthres'])\n",
    "# sorting_df = sorting_df.sort_values(by=['coopthres','dates'], ascending = [False, True])\n",
    "sorting_df = pd.DataFrame({'dates':dates_list,'tasktype':tasktypes_all_dates.ravel(),\n",
    "                           'coopthres':coopthres_all_dates.ravel()}, columns=['dates','tasktype','coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['tasktype','coopthres','dates'], ascending = [True,False,True])\n",
    "#\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,2,0],'o-',label = \"socialgaze1->pull1\")\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,2,1],'o-',label = \"socialgaze1->pull2\")\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,3,0],'o-',label = \"socialgaze2->pull1\")\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,3,1],'o-',label = \"socialgaze2->pull2\")\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.set_ylim(-0.1,1.1)\n",
    "ax1.set_ylabel(\"transition probability\",fontsize=13)\n",
    "#\n",
    "plt.xticks(np.arange(0,ndates,1),np.array(dates_list)[sorting_df.index], rotation=90,fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.title(\"transition probability from social gaze to pull\", fontsize = 14)\n",
    "#\n",
    "tasktypes = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','novision']\n",
    "taskswitches = np.where((np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)|\n",
    "                        (np.array(sorting_df['tasktype'])[1:]-np.array(sorting_df['tasktype'])[:-1]!=0))[0]+0.5\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.plot([taskswitch,taskswitch],[-0.15,1.15],'k--')\n",
    "taskswitches = np.concatenate(([0],taskswitches))\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.text(taskswitch+0.25,-0.075,tasktypes[itaskswitch],fontsize=10)\n",
    "#\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bddde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "grouptypes = ['self reward','3s threshold','2s threshold','1.5s threshold','1s threshold', 'novision']\n",
    "\n",
    "gaze1_pull1 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],2,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],2,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],2,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],2,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],2,0],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],2,0]\n",
    "              ]\n",
    "gaze1_pull2 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],2,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],2,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],2,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],2,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],2,1],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],2,1]\n",
    "              ]\n",
    "gaze2_pull1 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],3,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],3,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],3,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],3,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],3,0],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],3,0]\n",
    "              ]\n",
    "gaze2_pull2 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],3,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],3,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],3,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],3,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],3,1],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],3,1]\n",
    "              ]\n",
    "gaze1_pull1_plot = plt.boxplot(gaze1_pull1,positions=np.array(np.arange(len(gaze1_pull1)))*4.0-1.05,widths=0.6)\n",
    "gaze1_pull2_plot = plt.boxplot(gaze1_pull2,positions=np.array(np.arange(len(gaze1_pull2)))*4.0-0.35,widths=0.6)\n",
    "gaze2_pull1_plot = plt.boxplot(gaze2_pull1,positions=np.array(np.arange(len(gaze2_pull1)))*4.0+0.35,widths=0.6)\n",
    "gaze2_pull2_plot = plt.boxplot(gaze2_pull2,positions=np.array(np.arange(len(gaze2_pull2)))*4.0+1.05,widths=0.6)\n",
    "#\n",
    "def define_box_properties(plot_name, color_code, label):\n",
    "    for k, v in plot_name.items():\n",
    "        plt.setp(plot_name.get(k), color=color_code)\n",
    "    plt.plot([], c=color_code, label=label)\n",
    "    plt.legend()\n",
    "#\n",
    "define_box_properties(gaze1_pull1_plot, '#0343DF', 'social_gaze1->pull1')\n",
    "define_box_properties(gaze1_pull2_plot, '#FFA500', 'social_gaze1->pull2')\n",
    "define_box_properties(gaze2_pull1_plot, '#008000', 'social_gaze2->pull1')\n",
    "define_box_properties(gaze2_pull2_plot, '#8C000F', 'social_gaze2->pull2')\n",
    "#\n",
    "# set the x label values\n",
    "plt.xticks(np.arange(0, len(grouptypes)*4, 4), grouptypes);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0edf68",
   "metadata": {},
   "source": [
    "### plot the transition probability from pull to social gaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef786b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates':dates_list,'tasktype':tasktypes_all_dates.ravel(),\n",
    "                           'coopthres':coopthres_all_dates.ravel()}, columns=['dates','tasktype','coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['tasktype','coopthres','dates'], ascending = [True,False,True])\n",
    "#\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,0,2],'o-',label = \"pull1->socialgaze1\")\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,1,2],'o-',label = \"pull2->socialgaze1\")\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,0,3],'o-',label = \"pull1->socialgaze2\")\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,1,3],'o-',label = \"pull2->socialgaze2\")\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.set_ylim(-0.1,1.1)\n",
    "ax1.set_ylabel(\"transition probability\",fontsize=13)\n",
    "#\n",
    "plt.xticks(np.arange(0,ndates,1),np.array(dates_list)[sorting_df.index], rotation=90,fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.title(\"transition probability from pull to social gaze\", fontsize = 14)\n",
    "#\n",
    "tasktypes = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','novision']\n",
    "taskswitches = np.where((np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)|\n",
    "                        (np.array(sorting_df['tasktype'])[1:]-np.array(sorting_df['tasktype'])[:-1]!=0))[0]+0.5\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.plot([taskswitch,taskswitch],[-0.15,1.15],'k--')\n",
    "taskswitches = np.concatenate(([0],taskswitches))\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.text(taskswitch+0.25,-0.075,tasktypes[itaskswitch],fontsize=10)\n",
    "#\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "grouptypes = ['self reward','3s threshold','2s threshold','1.5s threshold','1s threshold','novision']\n",
    "\n",
    "pull1_gaze1 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],0,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],0,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],0,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],0,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],0,2],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],0,2]\n",
    "              ]\n",
    "pull2_gaze1 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],1,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],1,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],1,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],1,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],1,2],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],1,2]\n",
    "              ]\n",
    "pull1_gaze2 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],0,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],0,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],0,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],0,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],0,3],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],0,3]\n",
    "              ]\n",
    "pull2_gaze2 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],1,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],1,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],1,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],1,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],1,3],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],1,3] \n",
    "              ]\n",
    "pull1_gaze1_plot = plt.boxplot(pull1_gaze1,positions=np.array(np.arange(len(pull1_gaze1)))*4.0-1.05,widths=0.6)\n",
    "pull2_gaze1_plot = plt.boxplot(pull2_gaze1,positions=np.array(np.arange(len(pull2_gaze1)))*4.0-0.35,widths=0.6)\n",
    "pull1_gaze2_plot = plt.boxplot(pull1_gaze2,positions=np.array(np.arange(len(pull1_gaze2)))*4.0+0.35,widths=0.6)\n",
    "pull2_gaze2_plot = plt.boxplot(pull2_gaze2,positions=np.array(np.arange(len(pull2_gaze2)))*4.0+1.05,widths=0.6)\n",
    "#\n",
    "def define_box_properties(plot_name, color_code, label):\n",
    "    for k, v in plot_name.items():\n",
    "        plt.setp(plot_name.get(k), color=color_code)\n",
    "    plt.plot([], c=color_code, label=label)\n",
    "    plt.legend()\n",
    "#\n",
    "define_box_properties(pull1_gaze1_plot, '#0343DF', 'pull1->gaze1')\n",
    "define_box_properties(pull2_gaze1_plot, '#FFA500', 'pull2->gaze1')\n",
    "define_box_properties(pull1_gaze2_plot, '#008000', 'pull1->gaze2')\n",
    "define_box_properties(pull2_gaze2_plot, '#8C000F', 'pull2->gaze2')\n",
    "#\n",
    "# set the x label values\n",
    "plt.xticks(np.arange(0, len(grouptypes)*4, 4), grouptypes);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a41800",
   "metadata": {},
   "source": [
    "### plot the transition probability from pull to pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2573b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates':dates_list,'tasktype':tasktypes_all_dates.ravel(),\n",
    "                           'coopthres':coopthres_all_dates.ravel()}, columns=['dates','tasktype','coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['tasktype','coopthres','dates'], ascending = [True,False,True])\n",
    "#\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,0,0],'o-',label = \"pull1->pull1\")\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,1,1],'o-',label = \"pull2->pull2\")\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,0,1],'o-',label = \"pull1->pull2\")\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,1,0],'o-',label = \"pull2->pull1\")\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.set_ylim(-0.1,1.1)\n",
    "ax1.set_ylabel(\"transition probability\",fontsize=13)\n",
    "#\n",
    "plt.xticks(np.arange(0,ndates,1),np.array(dates_list)[sorting_df.index], rotation=90,fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.title(\"transition probability from pull to pull\", fontsize = 14)\n",
    "#\n",
    "tasktypes = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','novision']\n",
    "taskswitches = np.where((np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)|\n",
    "                        (np.array(sorting_df['tasktype'])[1:]-np.array(sorting_df['tasktype'])[:-1]!=0))[0]+0.5\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.plot([taskswitch,taskswitch],[-0.15,1.15],'k--')\n",
    "taskswitches = np.concatenate(([0],taskswitches))\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.text(taskswitch+0.25,-0.075,tasktypes[itaskswitch],fontsize=10)\n",
    "#\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264bf00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "grouptypes = ['self reward','3s threshold','2s threshold','1.5s threshold','1s threshold','novision']\n",
    "\n",
    "pull1_pull1 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],0,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],0,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],0,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],0,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],0,0],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],0,0]\n",
    "              ]\n",
    "pull2_pull2 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],1,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],1,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],1,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],1,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],1,1],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],1,1]\n",
    "              ]\n",
    "pull1_pull2 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],0,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],0,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],0,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],0,1],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],0,1],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],0,1]\n",
    "              ]\n",
    "pull2_pull1 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],1,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],1,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],1,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],1,0],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],1,0],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],1,0]\n",
    "              ]\n",
    "pull1_pull1_plot = plt.boxplot(pull1_pull1,positions=np.array(np.arange(len(gaze1_pull1)))*4.0-1.05,widths=0.6)\n",
    "pull2_pull2_plot = plt.boxplot(pull2_pull2,positions=np.array(np.arange(len(gaze1_pull2)))*4.0-0.35,widths=0.6)\n",
    "pull1_pull2_plot = plt.boxplot(pull1_pull2,positions=np.array(np.arange(len(gaze2_pull1)))*4.0+0.35,widths=0.6)\n",
    "pull2_pull1_plot = plt.boxplot(pull2_pull1,positions=np.array(np.arange(len(gaze2_pull2)))*4.0+1.05,widths=0.6)\n",
    "#\n",
    "def define_box_properties(plot_name, color_code, label):\n",
    "    for k, v in plot_name.items():\n",
    "        plt.setp(plot_name.get(k), color=color_code)\n",
    "    plt.plot([], c=color_code, label=label)\n",
    "    plt.legend()\n",
    "#\n",
    "define_box_properties(pull1_pull1_plot, '#0343DF', 'pull1->pull1')\n",
    "define_box_properties(pull2_pull2_plot, '#FFA500', 'pull2->pull2')\n",
    "define_box_properties(pull1_pull2_plot, '#008000', 'pull1->pull2')\n",
    "define_box_properties(pull2_pull1_plot, '#8C000F', 'pull2->pull1')\n",
    "#\n",
    "# set the x label values\n",
    "plt.xticks(np.arange(0, len(grouptypes)*4, 4), grouptypes);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f2b51",
   "metadata": {},
   "source": [
    "### plot the transition probability from social gaze to social gaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29712c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates':dates_list,'tasktype':tasktypes_all_dates.ravel(),\n",
    "                           'coopthres':coopthres_all_dates.ravel()}, columns=['dates','tasktype','coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['tasktype','coopthres','dates'], ascending = [True,False,True])\n",
    "#\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,2,2],'o-',label = \"socialgaze1->socialgaze1\")\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,3,3],'o-',label = \"socialgaze2->socialgaze2\")\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,2,3],'o-',label = \"socialgaze1->socialgaze2\")\n",
    "ax1.plot(DAGs_all_dates[sorting_df.index,3,2],'o-',label = \"socialgaze2->socialgaze1\")\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.set_ylim(-0.1,1.1)\n",
    "ax1.set_ylabel(\"transition probability\",fontsize=13)\n",
    "#\n",
    "plt.xticks(np.arange(0,ndates,1),np.array(dates_list)[sorting_df.index], rotation=90,fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.title(\"transition probability from social gaze to social gaze\", fontsize = 14)\n",
    "#\n",
    "tasktypes = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','novision']\n",
    "taskswitches = np.where((np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)|\n",
    "                        (np.array(sorting_df['tasktype'])[1:]-np.array(sorting_df['tasktype'])[:-1]!=0))[0]+0.5\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.plot([taskswitch,taskswitch],[-0.15,1.15],'k--')\n",
    "taskswitches = np.concatenate(([0],taskswitches))\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.text(taskswitch+0.25,-0.075,tasktypes[itaskswitch],fontsize=10)\n",
    "#\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e49296",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "grouptypes = ['self reward','3s threshold','2s threshold','1.5s threshold','1s threshold']\n",
    "\n",
    "gaze1_gaze1 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],2,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],2,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],2,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],2,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],2,2],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],2,2]\n",
    "              ]\n",
    "gaze2_gaze2 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],3,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],3,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],3,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],3,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],3,3],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],3,3]\n",
    "              ]\n",
    "gaze1_gaze2 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],2,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],2,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],2,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],2,3],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],2,3],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],2,3]\n",
    "              ]\n",
    "gaze2_gaze1 = [DAGs_all_dates[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0],3,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0],3,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0],3,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0],3,2],\n",
    "               DAGs_all_dates[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0],3,2],\n",
    "               DAGs_all_dates[np.transpose((tasktypes_all_dates==5))[0],3,2]\n",
    "              ]\n",
    "gaze1_gaze1_plot = plt.boxplot(gaze1_gaze1,positions=np.array(np.arange(len(gaze1_gaze1)))*4.0-1.05,widths=0.6)\n",
    "gaze2_gaze2_plot = plt.boxplot(gaze2_gaze2,positions=np.array(np.arange(len(gaze2_gaze2)))*4.0-0.35,widths=0.6)\n",
    "gaze1_gaze2_plot = plt.boxplot(gaze1_gaze2,positions=np.array(np.arange(len(gaze1_gaze2)))*4.0+0.35,widths=0.6)\n",
    "gaze2_gaze1_plot = plt.boxplot(gaze2_gaze1,positions=np.array(np.arange(len(gaze2_gaze1)))*4.0+1.05,widths=0.6)\n",
    "#\n",
    "def define_box_properties(plot_name, color_code, label):\n",
    "    for k, v in plot_name.items():\n",
    "        plt.setp(plot_name.get(k), color=color_code)\n",
    "    plt.plot([], c=color_code, label=label)\n",
    "    plt.legend()\n",
    "#\n",
    "define_box_properties(gaze1_gaze1_plot, '#0343DF', 'gaze1->gaze1')\n",
    "define_box_properties(gaze2_gaze2_plot, '#FFA500', 'gaze2->gaze2')\n",
    "define_box_properties(gaze1_gaze2_plot, '#008000', 'gaze1->gaze2')\n",
    "define_box_properties(gaze2_gaze1_plot, '#8C000F', 'gaze2->gaze1')\n",
    "#\n",
    "# set the x label values\n",
    "plt.xticks(np.arange(0, len(grouptypes)*4, 4), grouptypes);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0435e118",
   "metadata": {},
   "source": [
    "### plot between behavioral measures - successful rate vs interpull interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9517d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1,figsize=(5, 5))\n",
    "\n",
    "# ind = (tasktypes_all_dates != 1) & (coopthres_all_dates == 1)\n",
    "ind = (tasktypes_all_dates != 1) \n",
    "#\n",
    "xxx = interpullintv_all_dates[ind]\n",
    "yyy = succ_rate_all_dates[ind]\n",
    "axs.plot(xxx,yyy,'o')\n",
    "axs.set_xlabel('interpull interval')\n",
    "axs.set_ylabel('successful rate')\n",
    "# axs.set_xlim([-0.1,1.1])\n",
    "axs.set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy)\n",
    "axs.text(2, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52292b04",
   "metadata": {},
   "source": [
    "### sanity check: plot the pull transition probability vs behavioral measures - successful rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09861ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3,figsize=(15, 10))\n",
    "\n",
    "# ind = (tasktypes_all_dates != 1) & (succ_rate_all_dates*trialnum_all_dates > 20)\n",
    "# ind = (tasktypes_all_dates != 1) & (interpullintv_all_dates < 10)\n",
    "# ind = (tasktypes_all_dates != 1) & (coopthres_all_dates == 1)\n",
    "ind = (tasktypes_all_dates != 1)\n",
    "#\n",
    "xxx  = succ_rate_all_dates[ind]\n",
    "yyy1 = DAGs_all_dates[np.transpose(ind)[0],0,0]\n",
    "y1label = \"pull1->pull1\"\n",
    "yyy2 = DAGs_all_dates[np.transpose(ind)[0],1,1]\n",
    "y2label = \"pull2->pull2\"\n",
    "yyy3 = DAGs_all_dates[np.transpose(ind)[0],0,1]\n",
    "y3label = \"pull1->pull2\"\n",
    "yyy4 = DAGs_all_dates[np.transpose(ind)[0],1,0]\n",
    "y4label = \"pull2->pull1\"\n",
    "#\n",
    "axs[0,0].plot(xxx,yyy1,'o')\n",
    "axs[0,0].set_xlabel('successful rate')\n",
    "axs[0,0].set_ylabel('transition probability '+y1label)\n",
    "axs[0,0].set_xlim([-0.1,1.1])\n",
    "axs[0,0].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy1)\n",
    "axs[0,0].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[0,1].plot(xxx,yyy2,'o')\n",
    "axs[0,1].set_xlabel('successful rate')\n",
    "axs[0,1].set_ylabel('transition probability '+y2label)\n",
    "axs[0,1].set_xlim([-0.1,1.1])\n",
    "axs[0,1].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy2)\n",
    "axs[0,1].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,0].plot(xxx,yyy3,'o')\n",
    "axs[1,0].set_xlabel('successful rate')\n",
    "axs[1,0].set_ylabel('transition probability '+y3label)\n",
    "axs[1,0].set_xlim([-0.1,1.1])\n",
    "axs[1,0].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy3)\n",
    "axs[1,0].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,1].plot(xxx,yyy4,'o')\n",
    "axs[1,1].set_xlabel('successful rate')\n",
    "axs[1,1].set_ylabel('transition probability '+y4label)\n",
    "axs[1,1].set_xlim([-0.1,1.1])\n",
    "axs[1,1].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy4)\n",
    "axs[1,1].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[0,2].plot(np.concatenate((xxx, xxx)),np.concatenate((yyy1, yyy2)),'o')\n",
    "axs[0,2].set_xlabel('successful rate')\n",
    "axs[0,2].set_ylabel('transition probability pull1(2)->1(2)')\n",
    "axs[0,2].set_xlim([-0.1,1.1])\n",
    "axs[0,2].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(np.concatenate((xxx, xxx)),np.concatenate((yyy1, yyy2)))\n",
    "axs[0,2].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,2].plot(np.concatenate((xxx, xxx)),np.concatenate((yyy3, yyy4)),'o')\n",
    "axs[1,2].set_xlabel('successful rate')\n",
    "axs[1,2].set_ylabel('transition probability pull1(2)->2(1)')\n",
    "axs[1,2].set_xlim([-0.1,1.1])\n",
    "axs[1,2].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(np.concatenate((xxx, xxx)),np.concatenate((yyy3, yyy4)))\n",
    "axs[1,2].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7fbb9f",
   "metadata": {},
   "source": [
    "### sanity check: plot the pull transition probability vs behavioral measures - interpull interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2193a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3,figsize=(15, 10))\n",
    "\n",
    "# ind = (tasktypes_all_dates != 1) & (succ_rate_all_dates*trialnum_all_dates > 20)\n",
    "# ind = (tasktypes_all_dates != 1) & (interpullintv_all_dates < 10)\n",
    "# ind = (tasktypes_all_dates != 1) & (coopthres_all_dates == 1)\n",
    "ind = (tasktypes_all_dates != 1) \n",
    "#\n",
    "xxx  = interpullintv_all_dates[ind]\n",
    "yyy1 = DAGs_all_dates[np.transpose(ind)[0],0,0]\n",
    "y1label = \"pull1->pull1\"\n",
    "yyy2 = DAGs_all_dates[np.transpose(ind)[0],1,1]\n",
    "y2label = \"pull2->pull2\"\n",
    "yyy3 = DAGs_all_dates[np.transpose(ind)[0],0,1]\n",
    "y3label = \"pull1->pull2\"\n",
    "yyy4 = DAGs_all_dates[np.transpose(ind)[0],1,0]\n",
    "y4label = \"pull2->pull1\"\n",
    "#\n",
    "axs[0,0].plot(xxx,yyy1,'o')\n",
    "axs[0,0].set_xlabel('interpull interval')\n",
    "axs[0,0].set_ylabel('transition probability '+y1label)\n",
    "#axs[0,0].set_xlim([-0.1,1.1])\n",
    "axs[0,0].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy1)\n",
    "axs[0,0].text(2, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[0,1].plot(xxx,yyy2,'o')\n",
    "axs[0,1].set_xlabel('interpull interval')\n",
    "axs[0,1].set_ylabel('transition probability '+y2label)\n",
    "#axs[0,1].set_xlim([-0.1,1.1])\n",
    "axs[0,1].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy2)\n",
    "axs[0,1].text(2, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,0].plot(xxx,yyy3,'o')\n",
    "axs[1,0].set_xlabel('interpull interval')\n",
    "axs[1,0].set_ylabel('transition probability '+y3label)\n",
    "#axs[1,0].set_xlim([-0.1,1.1])\n",
    "axs[1,0].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy3)\n",
    "axs[1,0].text(2, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,1].plot(xxx,yyy4,'o')\n",
    "axs[1,1].set_xlabel('interpull interval')\n",
    "axs[1,1].set_ylabel('transition probability '+y4label)\n",
    "#axs[1,1].set_xlim([-0.1,1.1])\n",
    "axs[1,1].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy4)\n",
    "axs[1,1].text(2, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[0,2].plot(np.concatenate((xxx, xxx)),np.concatenate((yyy1, yyy2)),'o')\n",
    "axs[0,2].set_xlabel('interpull interval')\n",
    "axs[0,2].set_ylabel('transition probability pull1(2)->1(2)')\n",
    "#axs[0,2].set_xlim([-0.1,1.1])\n",
    "axs[0,2].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(np.concatenate((xxx, xxx)),np.concatenate((yyy1, yyy2)))\n",
    "axs[0,2].text(2, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,2].plot(np.concatenate((xxx, xxx)),np.concatenate((yyy3, yyy4)),'o')\n",
    "axs[1,2].set_xlabel('interpull interval')\n",
    "axs[1,2].set_ylabel('transition probability pull2(1)->1(2)')\n",
    "#axs[1,2].set_xlim([-0.1,1.1])\n",
    "axs[1,2].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(np.concatenate((xxx, xxx)),np.concatenate((yyy3, yyy4)))\n",
    "axs[1,2].text(2, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9921a9",
   "metadata": {},
   "source": [
    "### plot the gaze->pull transition probability vs behavioral measures - successful rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05adab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3,figsize=(15, 10))\n",
    "\n",
    "# ind = (tasktypes_all_dates != 1) & (succ_rate_all_dates*trialnum_all_dates > 20)\n",
    "# ind = (tasktypes_all_dates != 1) & (interpullintv_all_dates < 10)\n",
    "# ind = (tasktypes_all_dates != 1) & (coopthres_all_dates == 1)\n",
    "ind = (tasktypes_all_dates != 1)\n",
    "\n",
    "xxx  = succ_rate_all_dates[ind]\n",
    "yyy1 = DAGs_all_dates[np.transpose(ind)[0],2,0]\n",
    "y1label = \"socialgaze1->pull1\"\n",
    "yyy2 = DAGs_all_dates[np.transpose(ind)[0],3,1]\n",
    "y2label = \"socialgaze2->pull2\"\n",
    "yyy3 = DAGs_all_dates[np.transpose(ind)[0],2,1]\n",
    "y3label = \"socialgaze1->pull2\"\n",
    "yyy4 = DAGs_all_dates[np.transpose(ind)[0],3,0]\n",
    "y4label = \"socialgaze2->pull1\"\n",
    "\n",
    "#\n",
    "axs[0,0].plot(xxx,yyy1,'o')\n",
    "axs[0,0].set_xlabel('successful rate')\n",
    "axs[0,0].set_ylabel('transition probability '+y1label)\n",
    "axs[0,0].set_xlim([-0.1,1.1])\n",
    "axs[0,0].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy1)\n",
    "axs[0,0].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[0,1].plot(xxx,yyy2,'o')\n",
    "axs[0,1].set_xlabel('successful rate')\n",
    "axs[0,1].set_ylabel('transition probability '+y2label)\n",
    "axs[0,1].set_xlim([-0.1,1.1])\n",
    "axs[0,1].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy2)\n",
    "axs[0,1].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,0].plot(xxx,yyy3,'o')\n",
    "axs[1,0].set_xlabel('successful rate')\n",
    "axs[1,0].set_ylabel('transition probability '+y3label)\n",
    "axs[1,0].set_xlim([-0.1,1.1])\n",
    "axs[1,0].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy3)\n",
    "axs[1,0].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,1].plot(xxx,yyy4,'o')\n",
    "axs[1,1].set_xlabel('successful rate')\n",
    "axs[1,1].set_ylabel('transition probability '+y4label)\n",
    "axs[1,1].set_xlim([-0.1,1.1])\n",
    "axs[1,1].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy4)\n",
    "axs[1,1].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[0,2].plot(np.concatenate((xxx, xxx)),np.concatenate((yyy1, yyy2)),'o')\n",
    "axs[0,2].set_xlabel('successful rate')\n",
    "axs[0,2].set_ylabel('transition probability socialgaze1(2)->pull1(2)')\n",
    "axs[0,2].set_xlim([-0.1,1.1])\n",
    "axs[0,2].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(np.concatenate((xxx, xxx)),np.concatenate((yyy1, yyy2)))\n",
    "axs[0,2].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,2].plot(np.concatenate((xxx, xxx)),np.concatenate((yyy3, yyy4)),'o')\n",
    "axs[1,2].set_xlabel('successful rate')\n",
    "axs[1,2].set_ylabel('transition probability socialgaze1(2)->pull2(1)')\n",
    "axs[1,2].set_xlim([-0.1,1.1])\n",
    "axs[1,2].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(np.concatenate((xxx, xxx)),np.concatenate((yyy3, yyy4)))\n",
    "axs[1,2].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78598eb0",
   "metadata": {},
   "source": [
    "### plot the pull -> gaze transition probability vs behavioral measures - successful rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296450f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3,figsize=(15, 10))\n",
    "\n",
    "# ind = (tasktypes_all_dates != 1) & (succ_rate_all_dates*trialnum_all_dates > 20)\n",
    "# ind = (tasktypes_all_dates != 1) & (interpullintv_all_dates < 10)\n",
    "# ind = (tasktypes_all_dates != 1) & (coopthres_all_dates == 1)\n",
    "ind = (tasktypes_all_dates != 1)\n",
    "\n",
    "xxx  = succ_rate_all_dates[ind]\n",
    "yyy1 = DAGs_all_dates[np.transpose(ind)[0],0,2]\n",
    "y1label = \"pull1->socialgaze1\"\n",
    "yyy2 = DAGs_all_dates[np.transpose(ind)[0],1,3]\n",
    "y2label = \"pull2->socialgaze2\"\n",
    "yyy3 = DAGs_all_dates[np.transpose(ind)[0],1,2]\n",
    "y3label = \"pull2->socialgaze1\"\n",
    "yyy4 = DAGs_all_dates[np.transpose(ind)[0],0,3]\n",
    "y4label = \"pull1->socialgaze2\"\n",
    "\n",
    "#\n",
    "axs[0,0].plot(xxx,yyy1,'o')\n",
    "axs[0,0].set_xlabel('successful rate')\n",
    "axs[0,0].set_ylabel('transition probability '+y1label)\n",
    "axs[0,0].set_xlim([-0.1,1.1])\n",
    "axs[0,0].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy1)\n",
    "axs[0,0].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[0,1].plot(xxx,yyy2,'o')\n",
    "axs[0,1].set_xlabel('successful rate')\n",
    "axs[0,1].set_ylabel('transition probability '+y2label)\n",
    "axs[0,1].set_xlim([-0.1,1.1])\n",
    "axs[0,1].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy2)\n",
    "axs[0,1].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,0].plot(xxx,yyy3,'o')\n",
    "axs[1,0].set_xlabel('successful rate')\n",
    "axs[1,0].set_ylabel('transition probability '+y3label)\n",
    "axs[1,0].set_xlim([-0.1,1.1])\n",
    "axs[1,0].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy3)\n",
    "axs[1,0].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,1].plot(xxx,yyy4,'o')\n",
    "axs[1,1].set_xlabel('successful rate')\n",
    "axs[1,1].set_ylabel('transition probability '+y4label)\n",
    "axs[1,1].set_xlim([-0.1,1.1])\n",
    "axs[1,1].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy4)\n",
    "axs[1,1].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[0,2].plot(np.concatenate((xxx, xxx)),np.concatenate((yyy1, yyy2)),'o')\n",
    "axs[0,2].set_xlabel('successful rate')\n",
    "axs[0,2].set_ylabel('transition probability pull1(2)->socialgaze1(2)')\n",
    "axs[0,2].set_xlim([-0.1,1.1])\n",
    "axs[0,2].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(np.concatenate((xxx, xxx)),np.concatenate((yyy1, yyy2)))\n",
    "axs[0,2].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,2].plot(np.concatenate((xxx, xxx)),np.concatenate((yyy3, yyy4)),'o')\n",
    "axs[1,2].set_xlabel('successful rate')\n",
    "axs[1,2].set_ylabel('transition probability pull2(1)->socialgaze1(2)')\n",
    "axs[1,2].set_xlim([-0.1,1.1])\n",
    "axs[1,2].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(np.concatenate((xxx, xxx)),np.concatenate((yyy3, yyy4)))\n",
    "axs[1,2].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc1c1c",
   "metadata": {},
   "source": [
    "### plot the gaze -> gaze transition probability vs behavioral measures - successful rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbb159",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3,figsize=(15, 10))\n",
    "\n",
    "# ind = (tasktypes_all_dates != 1) & (succ_rate_all_dates*trialnum_all_dates > 20)\n",
    "# ind = (tasktypes_all_dates != 1) & (interpullintv_all_dates < 10)\n",
    "# ind = (tasktypes_all_dates != 1) & (coopthres_all_dates == 1)\n",
    "ind = (tasktypes_all_dates != 1)\n",
    "\n",
    "xxx  = succ_rate_all_dates[ind]\n",
    "yyy1 = DAGs_all_dates[np.transpose(ind)[0],2,2]\n",
    "y1label = \"socialgaze1->socialgaze1\"\n",
    "yyy2 = DAGs_all_dates[np.transpose(ind)[0],3,3]\n",
    "y2label = \"socialgaze2->socialgaze2\"\n",
    "yyy3 = DAGs_all_dates[np.transpose(ind)[0],2,3]\n",
    "y3label = \"socialgaze1->socialgaze2\"\n",
    "yyy4 = DAGs_all_dates[np.transpose(ind)[0],3,2]\n",
    "y4label = \"socialgaze2->socialgaze1\"\n",
    "\n",
    "#\n",
    "axs[0,0].plot(xxx,yyy1,'o')\n",
    "axs[0,0].set_xlabel('successful rate')\n",
    "axs[0,0].set_ylabel('transition probability '+y1label)\n",
    "axs[0,0].set_xlim([-0.1,1.1])\n",
    "axs[0,0].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy1)\n",
    "axs[0,0].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[0,1].plot(xxx,yyy2,'o')\n",
    "axs[0,1].set_xlabel('successful rate')\n",
    "axs[0,1].set_ylabel('transition probability '+y2label)\n",
    "axs[0,1].set_xlim([-0.1,1.1])\n",
    "axs[0,1].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy2)\n",
    "axs[0,1].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,0].plot(xxx,yyy3,'o')\n",
    "axs[1,0].set_xlabel('successful rate')\n",
    "axs[1,0].set_ylabel('transition probability '+y3label)\n",
    "axs[1,0].set_xlim([-0.1,1.1])\n",
    "axs[1,0].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy3)\n",
    "axs[1,0].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,1].plot(xxx,yyy4,'o')\n",
    "axs[1,1].set_xlabel('successful rate')\n",
    "axs[1,1].set_ylabel('transition probability '+y4label)\n",
    "axs[1,1].set_xlim([-0.1,1.1])\n",
    "axs[1,1].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy4)\n",
    "axs[1,1].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[0,2].plot(np.concatenate((xxx, xxx)),np.concatenate((yyy1, yyy2)),'o')\n",
    "axs[0,2].set_xlabel('successful rate')\n",
    "axs[0,2].set_ylabel('transition probability socialgaze1(2)->socialgaze1(2)')\n",
    "axs[0,2].set_xlim([-0.1,1.1])\n",
    "axs[0,2].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(np.concatenate((xxx, xxx)),np.concatenate((yyy1, yyy2)))\n",
    "axs[0,2].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,2].plot(np.concatenate((xxx, xxx)),np.concatenate((yyy3, yyy4)),'o')\n",
    "axs[1,2].set_xlabel('successful rate')\n",
    "axs[1,2].set_ylabel('transition probability socialgaze2(1)->socialgaze1(2)')\n",
    "axs[1,2].set_xlim([-0.1,1.1])\n",
    "axs[1,2].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(np.concatenate((xxx, xxx)),np.concatenate((yyy3, yyy4)))\n",
    "axs[1,2].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6972b05",
   "metadata": {},
   "source": [
    "### plot the gaze->pull transition probability vs gaze/pull ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates':dates_list,'tasktype':tasktypes_all_dates.ravel(),\n",
    "                           'coopthres':coopthres_all_dates.ravel()}, columns=['dates','tasktype','coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['tasktype','coopthres','dates'], ascending = [True,False,True])\n",
    "\n",
    "gaze_numbers = (owgaze1_num_all_dates+owgaze2_num_all_dates+mtgaze1_num_all_dates+mtgaze2_num_all_dates)\n",
    "gaze_pull_ratios = (owgaze1_num_all_dates+owgaze2_num_all_dates+mtgaze1_num_all_dates+mtgaze2_num_all_dates)/(pull1_num_all_dates+pull2_num_all_dates)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "#\n",
    "ax1.plot(gaze_numbers[sorting_df.index],'o-',label = \"all social gazes\")\n",
    "\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.set_ylabel(\"total social gaze numbers\",fontsize=13)\n",
    "#\n",
    "plt.xticks(np.arange(0,ndates,1),np.array(dates_list)[sorting_df.index], rotation=90,fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "#\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(gaze_pull_ratios[sorting_df.index],'ro-',label = \"gaze to pull ratio\")\n",
    "ax2.legend(fontsize=12)\n",
    "ax2.set_ylabel(\"gaze to pull ratio\",fontsize=13)\n",
    "#\n",
    "tasktypes = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','novision']\n",
    "taskswitches = np.where((np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)|\n",
    "                        (np.array(sorting_df['tasktype'])[1:]-np.array(sorting_df['tasktype'])[:-1]!=0))[0]+0.5\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax2.plot([taskswitch,taskswitch],[0,30],'k--')\n",
    "taskswitches = np.concatenate(([0],taskswitches))\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax2.text(taskswitch+0.25,-0.075,tasktypes[itaskswitch],fontsize=10)\n",
    "#\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941cf70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_numbers = (owgaze1_num_all_dates+owgaze2_num_all_dates+mtgaze1_num_all_dates+mtgaze2_num_all_dates)\n",
    "gaze_pull_ratios = (owgaze1_num_all_dates+owgaze2_num_all_dates+mtgaze1_num_all_dates+mtgaze2_num_all_dates)/(pull1_num_all_dates+pull2_num_all_dates)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "grouptypes = ['self reward','3s threshold','2s threshold','1.5s threshold','1s threshold']\n",
    "\n",
    "gaze_numbers_groups = [np.transpose(gaze_pull_ratios[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0]])[0],\n",
    "                       np.transpose(gaze_pull_ratios[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0]])[0],\n",
    "                       np.transpose(gaze_pull_ratios[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0]])[0],\n",
    "                       np.transpose(gaze_pull_ratios[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0]])[0],\n",
    "                       np.transpose(gaze_pull_ratios[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0]])[0],\n",
    "                       np.transpose(gaze_pull_ratios[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==5))[0]])[0]\n",
    "       \n",
    "                      ]\n",
    "\n",
    "gaze_numbers_plot = plt.boxplot(gaze_numbers_groups)\n",
    "\n",
    "plt.xticks(np.arange(1, len(grouptypes)+1, 1), grouptypes, fontsize = 12);\n",
    "plt.title('average gaze to pull ratio',fontsize = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_numbers = (owgaze1_num_all_dates+owgaze2_num_all_dates+mtgaze1_num_all_dates+mtgaze2_num_all_dates)\n",
    "gaze_pull_ratios = (owgaze1_num_all_dates+owgaze2_num_all_dates+mtgaze1_num_all_dates+mtgaze2_num_all_dates)/(pull1_num_all_dates+pull2_num_all_dates)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "grouptypes = ['self reward','3s threshold','2s threshold','1.5s threshold','1s threshold','novision']\n",
    "\n",
    "gaze_numbers_groups = [np.transpose(gaze_numbers[np.transpose((coopthres_all_dates==0)&(tasktypes_all_dates==1))[0]])[0],\n",
    "                       np.transpose(gaze_numbers[np.transpose((coopthres_all_dates==3)&(tasktypes_all_dates==3))[0]])[0],\n",
    "                       np.transpose(gaze_numbers[np.transpose((coopthres_all_dates==2)&(tasktypes_all_dates==3))[0]])[0],\n",
    "                       np.transpose(gaze_numbers[np.transpose((coopthres_all_dates==1.5)&(tasktypes_all_dates==3))[0]])[0],\n",
    "                       np.transpose(gaze_numbers[np.transpose((coopthres_all_dates==1)&(tasktypes_all_dates==3))[0]])[0],\n",
    "                       np.transpose(gaze_numbers[np.transpose((tasktypes_all_dates==5))[0]])[0]\n",
    "                      ]\n",
    "\n",
    "gaze_numbers_plot = plt.boxplot(gaze_numbers_groups)\n",
    "\n",
    "plt.xticks(np.arange(1, len(grouptypes)+1, 1), grouptypes, fontsize = 12);\n",
    "plt.title('average total gaze numbers',fontsize = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bcd3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_pull_ratios = (owgaze1_num_all_dates+owgaze2_num_all_dates+mtgaze1_num_all_dates+mtgaze2_num_all_dates)/(pull1_num_all_dates+pull2_num_all_dates)\n",
    "# gaze_pull_ratios = (owgaze1_num_all_dates+owgaze2_num_all_dates+mtgaze1_num_all_dates+mtgaze2_num_all_dates)\n",
    "fig, axs = plt.subplots(2,3,figsize=(15, 10))\n",
    "\n",
    "# ind = (tasktypes_all_dates != 1) & (succ_rate_all_dates*trialnum_all_dates > 20)\n",
    "# ind = (tasktypes_all_dates != 1) & (interpullintv_all_dates < 10)\n",
    "# ind = (tasktypes_all_dates != 1) & (coopthres_all_dates == 1)\n",
    "ind = (tasktypes_all_dates != 1)\n",
    "\n",
    "xxx  = gaze_pull_ratios[ind]\n",
    "yyy1 = DAGs_all_dates[np.transpose(ind)[0],2,0]\n",
    "y1label = \"socialgaze1->pull1\"\n",
    "yyy2 = DAGs_all_dates[np.transpose(ind)[0],3,1]\n",
    "y2label = \"socialgaze2->pull2\"\n",
    "yyy3 = DAGs_all_dates[np.transpose(ind)[0],2,1]\n",
    "y3label = \"socialgaze1->pull2\"\n",
    "yyy4 = DAGs_all_dates[np.transpose(ind)[0],3,0]\n",
    "y4label = \"socialgaze2->pull1\"\n",
    "\n",
    "#\n",
    "axs[0,0].plot(xxx,yyy1,'o')\n",
    "axs[0,0].set_xlabel('gaze-pull ratios')\n",
    "axs[0,0].set_ylabel('transition probability '+y1label)\n",
    "# axs[0,0].set_xlim([-0.1,1.1])\n",
    "axs[0,0].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy1)\n",
    "axs[0,0].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[0,1].plot(xxx,yyy2,'o')\n",
    "axs[0,1].set_xlabel('gaze-pull ratios')\n",
    "axs[0,1].set_ylabel('transition probability '+y2label)\n",
    "# axs[0,1].set_xlim([-0.1,1.1])\n",
    "axs[0,1].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy2)\n",
    "axs[0,1].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,0].plot(xxx,yyy3,'o')\n",
    "axs[1,0].set_xlabel('gaze-pull ratios')\n",
    "axs[1,0].set_ylabel('transition probability '+y3label)\n",
    "# axs[1,0].set_xlim([-0.1,1.1])\n",
    "axs[1,0].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy3)\n",
    "axs[1,0].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,1].plot(xxx,yyy4,'o')\n",
    "axs[1,1].set_xlabel('gaze-pull ratios')\n",
    "axs[1,1].set_ylabel('transition probability '+y4label)\n",
    "# axs[1,1].set_xlim([-0.1,1.1])\n",
    "axs[1,1].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(xxx,yyy4)\n",
    "axs[1,1].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[0,2].plot(np.concatenate((xxx, xxx)),np.concatenate((yyy1, yyy2)),'o')\n",
    "axs[0,2].set_xlabel('gaze-pull ratios')\n",
    "axs[0,2].set_ylabel('transition probability socialgaze1(2)->pull1(2)')\n",
    "# axs[0,2].set_xlim([-0.1,1.1])\n",
    "axs[0,2].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(np.concatenate((xxx, xxx)),np.concatenate((yyy1, yyy2)))\n",
    "axs[0,2].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "#\n",
    "axs[1,2].plot(np.concatenate((xxx, xxx)),np.concatenate((yyy3, yyy4)),'o')\n",
    "axs[1,2].set_xlabel('gaze-pull ratios')\n",
    "axs[1,2].set_ylabel('transition probability socialgaze1(2)->pull2(1)')\n",
    "# axs[1,2].set_xlim([-0.1,1.1])\n",
    "axs[1,2].set_ylim([-0.1,1.1])\n",
    "r,p = scipy.stats.pearsonr(np.concatenate((xxx, xxx)),np.concatenate((yyy3, yyy4)))\n",
    "axs[1,2].text(0, 1, 'corr r = '+str(np.round(r,2))+'; '+'corr p = '+str(np.round(p,2)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f936ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d188541b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ee1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d13d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cafbb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c0480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f398d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ffd1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ee99f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
