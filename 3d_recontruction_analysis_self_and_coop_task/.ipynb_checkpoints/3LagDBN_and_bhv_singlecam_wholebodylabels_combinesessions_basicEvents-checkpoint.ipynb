{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca6246b",
   "metadata": {},
   "source": [
    "### In this script, DBN is run on the combined sessions, combined for each condition\n",
    "### In this script, DBN is run with 1s time bin, 3 time lag \n",
    "### In this script, the animal tracking is done with only one camera - camera 2 (middle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd279dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "import sklearn\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import string\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.models import DynamicBayesianNetwork as DBN\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.estimators import HillClimbSearch,BicScore\n",
    "from pgmpy.base import DAG\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee0ed4",
   "metadata": {},
   "source": [
    "### function - get body part location for each pair of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1724bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.body_part_locs_eachpair import body_part_locs_eachpair\n",
    "from ana_functions.body_part_locs_singlecam import body_part_locs_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ae6f98",
   "metadata": {},
   "source": [
    "### function - align the two cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b03438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_align import camera_align       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494356c2",
   "metadata": {},
   "source": [
    "### function - merge the two pairs of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bda6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_merge import camera_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc7f6a",
   "metadata": {},
   "source": [
    "### function - find social gaze time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f6ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.find_socialgaze_timepoint import find_socialgaze_timepoint\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam import find_socialgaze_timepoint_singlecam\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam_wholebody import find_socialgaze_timepoint_singlecam_wholebody"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7e75b",
   "metadata": {},
   "source": [
    "### function - define time point of behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dfb672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_timepoint import bhv_events_timepoint\n",
    "from ana_functions.bhv_events_timepoint_singlecam import bhv_events_timepoint_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4ab8c",
   "metadata": {},
   "source": [
    "### function - plot behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb2ba678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.plot_bhv_events import plot_bhv_events\n",
    "from ana_functions.plot_bhv_events_levertube import plot_bhv_events_levertube\n",
    "from ana_functions.draw_self_loop import draw_self_loop\n",
    "import matplotlib.patches as mpatches \n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d535a6",
   "metadata": {},
   "source": [
    "### function - make demo videos with skeleton and inportant vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec4de83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.tracking_video_singlecam_demo import tracking_video_singlecam_demo\n",
    "from ana_functions.tracking_video_singlecam_wholebody_demo import tracking_video_singlecam_wholebody_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69920a6a",
   "metadata": {},
   "source": [
    "### function - interval between all behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a804dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_interval import bhv_events_interval\n",
    "from ana_functions.bhv_events_interval import bhv_events_interval_certainEdges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c0b97",
   "metadata": {},
   "source": [
    "### function - train the dynamic bayesian network - multi time lag (3 lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "003d7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag\n",
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag_create_df_only\n",
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag_training_only\n",
    "from ana_functions.train_DBN_multiLag import graph_to_matrix\n",
    "from ana_functions.train_DBN_multiLag import get_weighted_dags\n",
    "from ana_functions.train_DBN_multiLag import get_significant_edges\n",
    "from ana_functions.train_DBN_multiLag import threshold_edges\n",
    "from ana_functions.train_DBN_multiLag import Modulation_Index\n",
    "from ana_functions.EfficientTimeShuffling import EfficientShuffle\n",
    "from ana_functions.AicScore import AicScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819c438",
   "metadata": {},
   "source": [
    "## Analyze each session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e84fc",
   "metadata": {},
   "source": [
    "### prepare the basic behavioral data (especially the time stamps for each bhv events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9dc05cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instead of using gaze angle threshold, use the target rectagon to deside gaze info\n",
    "# ...need to update\n",
    "sqr_thres_tubelever = 75 # draw the square around tube and lever\n",
    "sqr_thres_face = 1.15 # a ratio for defining face boundary\n",
    "sqr_thres_body = 4 # how many times to enlongate the face box boundry to the body\n",
    "\n",
    "\n",
    "# get the fps of the analyzed video\n",
    "fps = 30\n",
    "\n",
    "# frame number of the demo video\n",
    "# nframes = 0.5*30 # second*30fps\n",
    "nframes = 2*30 # second*30fps\n",
    "\n",
    "# re-analyze the video or not\n",
    "reanalyze_video = 0\n",
    "redo_anystep = 0\n",
    "\n",
    "# only analyze the best (five) sessions for each conditions\n",
    "do_bestsession = 1\n",
    "if do_bestsession:\n",
    "    savefile_sufix = '_bestsessions'\n",
    "else:\n",
    "    savefile_sufix = ''\n",
    "    \n",
    "# all the videos (no misaligned ones)\n",
    "# aligned with the audio\n",
    "# get the session start time from \"videosound_bhv_sync.py/.ipynb\"\n",
    "# currently the session_start_time will be manually typed in. It can be updated after a better method is used\n",
    "\n",
    "# dodson scorch\n",
    "if 0:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [\n",
    "                      \"20220909\",\"20220912\",\"20220915\",\"20220920\",\"20220922\",\"20220923\",\"20221010\",\n",
    "                      \"20221011\",\"20221013\",\"20221014\",\"20221015\",\"20221017\",\"20230215\",     \n",
    "                      \"20221018\",\"20221019\",\"20221020\",\"20221021\",\"20221022\",\"20221026\",\"20221028\",\"20221030\",\n",
    "                      \"20221107\",\"20221108\",\"20221109\",\"20221110\",\"20221111\",\"20221114\",\"20221115\",\"20221116\",\n",
    "                      \"20221117\",\"20221118\",\"20221121\",\"20221122\",\"20221123\",\"20221125\",\"20221128\",\"20221129\",              \n",
    "                      \"20221205\",\"20221206\",\"20221209\",\"20221212\",\"20221214\",\"20221216\",\"20221219\",\"20221220\",\n",
    "                      \"20221221\",\"20230208\",\"20230209\",\"20230213\",\"20230214\",\"20230111\",\"20230112\",\"20230201\",\n",
    "\n",
    "                     ]\n",
    "        session_start_times = [ \n",
    "                                 6.50, 18.10, 0,      33.03, 549.0, 116.80, 6.50,\n",
    "                                 2.80, 27.80, 272.50, 27.90, 27.00,  33.00,\n",
    "                                28.70, 45.30, 21.10,  27.10, 51.90,  21.00, 30.80, 17.50,                      \n",
    "                                15.70,  2.65, 27.30,   0.00,  0.00,  71.80,  0.00,  0.00, \n",
    "                                75.50, 20.20,  0.00,  24.20, 36.70,  26.40, 22.50, 28.50,                       \n",
    "                                 0.00,  0.00, 21.70,  84.70, 17.00,  19.80, 23.50, 25.20,  \n",
    "                                 0.00,  0.00,  0.00,   0.00,  0.00, 130.00, 14.20, 24.20, \n",
    "                              ] # in second\n",
    "    elif do_bestsession:\n",
    "        # pick only five sessions for each conditions\n",
    "        dates_list = [\n",
    "                      # \"20220912\",\n",
    "                      \"20220915\",\"20220920\",\"20221010\",\"20230208\",\n",
    "                      \"20221011\",\"20221013\",\"20221015\",\"20221017\",\n",
    "                      \"20221022\",\"20221026\",\"20221028\",\"20221030\",\"20230209\",\n",
    "                      \"20221125\",\"20221128\",\"20221129\",\"20230214\",\"20230215\",                  \n",
    "                      \"20221205\",\"20221206\",\"20221209\",\"20221214\",\"20230112\",\n",
    "                      \"20230117\",\"20230118\",\"20230124\",\n",
    "                      # \"20230126\",\n",
    "                     ]\n",
    "        session_start_times = [ \n",
    "                                # 18.10, \n",
    "                                 0.00, 33.03,  6.50,  0.00, \n",
    "                                 2.80, 27.80, 27.90, 27.00,  \n",
    "                                51.90, 21.00, 30.80, 17.50,  0.00,                    \n",
    "                                26.40, 22.50, 28.50,  0.00, 33.00,                     \n",
    "                                 0.00,  0.00, 21.70, 17.00, 14.20, \n",
    "                                 0.00,  0.00,  0.00, \n",
    "                                 # 0.00,  \n",
    "                              ] # in second\n",
    "    \n",
    "    animal1_fixedorder = ['dodson']\n",
    "    animal2_fixedorder = ['scorch']\n",
    "\n",
    "    animal1_filename = \"Dodson\"\n",
    "    animal2_filename = \"Scorch\"\n",
    "    \n",
    "# eddie sparkle\n",
    "if 0:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [\n",
    "                      \"20221122\",\"20221125\",\"20221128\",\"20221129\",\"20221130\",\"20221202\",\"20221206\",\n",
    "                      \"20221207\",\"20221208\",\"20221209\",\"20230126\",\"20230127\",\"20230130\",\"20230201\",\"20230203-1\",\n",
    "                      \"20230206\",\"20230207\",\"20230208-1\",\"20230209\",\"20230222\",\"20230223-1\",\"20230227-1\",\n",
    "                      \"20230228-1\",\"20230302-1\",\"20230307-2\",\"20230313\",\"20230315\",\"20230316\",\"20230317\",\n",
    "                      \"20230321\",\"20230322\",\"20230324\",\"20230327\",\"20230328\",\n",
    "                      \"20230330\",\"20230331\",\"20230403\",\"20230404\",\"20230405\",\"20230406\",\"20230407\",\n",
    "                      \n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                 8.00,38.00,1.00,3.00,5.00,9.50,1.00,\n",
    "                                 4.50,4.50,5.00,38.00,166.00,4.20,3.80,3.60,\n",
    "                                 7.50,9.00,7.50,8.50,14.50,7.80,8.00,7.50,\n",
    "                                 8.00,8.00,4.00,123.00,14.00,8.80,\n",
    "                                 7.00,7.50,5.50,11.00,9.00,\n",
    "                                 17.00,4.50,9.30,25.50,20.40,21.30,24.80,\n",
    "                                 \n",
    "                              ] # in second\n",
    "    elif do_bestsession:   \n",
    "        dates_list = [\n",
    "                      \"20221122\",  \"20221125\",  \n",
    "                      \"20221202\",  \"20221206\",  \"20230126\",  \"20230130\",  \"20230201\",\n",
    "                      \"20230207\",  \"20230208-1\",\"20230209\",  \"20230222\",  \"20230223-1\",\n",
    "                      \"20230227-1\",\"20230228-1\",\"20230302-1\",\"20230307-2\",\"20230313\",\n",
    "                      \"20230321\",  \"20230322\",  \"20230324\",  \"20230327\",  \"20230328\",\n",
    "                      \"20230331\",  \"20230403\",  \"20230404\",  \"20230405\",  \"20230406\"\n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                  8.00,  38.00, \n",
    "                                  9.50,   1.00, 38.00,  4.20,  3.80,\n",
    "                                  9.00,   7.50,  8.50, 14.50,  7.80,\n",
    "                                  8.00,   7.50,  8.00,  8.00,  4.00,\n",
    "                                  7.00,   7.50,  5.50, 11.00,  9.00,\n",
    "                                  4.50,   9.30, 25.50, 20.40, 21.30,\n",
    "                              ] # in second\n",
    "    \n",
    "    animal1_fixedorder = ['eddie']\n",
    "    animal2_fixedorder = ['sparkle']\n",
    "\n",
    "    animal1_filename = \"Eddie\"\n",
    "    animal2_filename = \"Sparkle\"\n",
    "    \n",
    "# ginger kanga\n",
    "if 0:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [\n",
    "                      \"20230209\",\"20230213\",\"20230214\",\"20230216\",\"20230222\",\"20230223\",\"20230228\",\"20230302\",\n",
    "                      \"20230303\",\"20230307\",\"20230314\",\"20230315\",\"20230316\",\"20230317\"         \n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                 0.00,  0.00,  0.00, 48.00, 26.20, 18.00, 23.00, 28.50,\n",
    "                                34.00, 25.50, 25.50, 31.50, 28.00, 30.50\n",
    "                              ] # in second \n",
    "    elif do_bestsession:   \n",
    "        dates_list = [\n",
    "                      #\"20230213\",\n",
    "                      \"20230214\",\"20230216\",\n",
    "                      \"20230228\",\"20230302\",\"20230303\",\"20230307\",          \n",
    "                      \"20230314\",\"20230315\",\"20230316\",\"20230317\",\n",
    "                      \"20230301\",\"20230320\",\"20230321\",\"20230322\",\n",
    "                      \"20230323\",\"20230412\",\"20230413\",\"20230517\",\"20230614\",\"20230615\",\n",
    "                      \"20230522_ws\",\"20230524\",\"20230605_1\",\"20230606\",\"20230607\"\n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                # 0.00, \n",
    "                                 0.00, 48.00, \n",
    "                                23.00, 28.50, 34.00, 25.50, \n",
    "                                25.50, 31.50, 28.00, 30.50,\n",
    "                                33.50, 22.20, 50.00,  0.00, \n",
    "                                33.00, 18.20, 22.80, 31.00, 24.00, 21.00,\n",
    "                                 0.00,  0.00,  0.00,  0.00,  0.00,\n",
    "                              ] # in second \n",
    "    \n",
    "    animal1_fixedorder = ['ginger']\n",
    "    animal2_fixedorder = ['kanga']\n",
    "\n",
    "    animal1_filename = \"Ginger\"\n",
    "    animal2_filename = \"Kanga\"\n",
    "\n",
    "    \n",
    "# dannon kanga\n",
    "if 1:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [\n",
    "                      \"20230718\",\"20230720\",\"20230914\",\"20230829\",\"20230907\",\"20230915\",\n",
    "                      \"20230918\",\"20230926\",\"20230928\",\"20231002\",\"20231010\",\"20231011\",\n",
    "                      \"20231013\",\n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                 0, 0, 0, 0, 0, 0, \n",
    "                                 0, 0, 0, 0, 0, 0,\n",
    "                                 0, 0, 0, 0, \n",
    "                              ] # in second \n",
    "    elif do_bestsession:   \n",
    "        dates_list = [\n",
    "                      \"20230718\",\"20230720\",\"20230914\",\"20230829\",\"20230907\",\"20230915\",\n",
    "                      \"20230918\",\"20230926\",\"20230928\",\"20231002\",\"20231010\",\"20231011\",\n",
    "                      \"20231013\",\"20231020\",\"20231024\",\"20231025\",\n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                 0, 0, 0, 0, 0, 0, \n",
    "                                 0, 0, 0, 0, 0, 0,\n",
    "                                 0, 0, 0, 0, \n",
    "                              ] # in second \n",
    "    \n",
    "    animal1_fixedorder = ['dannon']\n",
    "    animal2_fixedorder = ['kanga']\n",
    "\n",
    "    animal1_filename = \"Dannon\"\n",
    "    animal2_filename = \"Kanga\"\n",
    "    \n",
    "#    \n",
    "# dates_list = [\"20230718\"]\n",
    "# session_start_times = [0.00] # in second\n",
    "\n",
    "ndates = np.shape(dates_list)[0]\n",
    "\n",
    "session_start_frames = session_start_times * fps # fps is 30Hz\n",
    "\n",
    "totalsess_time = 600\n",
    "\n",
    "# video tracking results info\n",
    "animalnames_videotrack = ['dodson','scorch'] # does not really mean dodson and scorch, instead, indicate animal1 and animal2\n",
    "bodypartnames_videotrack = ['rightTuft','whiteBlaze','leftTuft','rightEye','leftEye','mouth']\n",
    "\n",
    "\n",
    "# which camera to analyzed\n",
    "cameraID = 'camera-2'\n",
    "cameraID_short = 'cam2'\n",
    "\n",
    "\n",
    "# location of levers and tubes for camera 2\n",
    "# get this information using DLC animal tracking GUI, the results are stored: \n",
    "# /home/ws523/marmoset_tracking_DLCv2/marmoset_tracking_with_lever_tube-weikang-2023-04-13/labeled-data/\n",
    "considerlevertube = 1\n",
    "considertubeonly = 0\n",
    "# # camera 1\n",
    "# lever_locs_camI = {'dodson':np.array([645,600]),'scorch':np.array([425,435])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1350,630]),'scorch':np.array([555,345])}\n",
    "# # camera 2\n",
    "lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "tube_locs_camI  = {'dodson':np.array([1550,515]),'scorch':np.array([350,515])}\n",
    "# # lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "# # tube_locs_camI  = {'dodson':np.array([1650,490]),'scorch':np.array([250,490])}\n",
    "# # camera 3\n",
    "# lever_locs_camI = {'dodson':np.array([1580,440]),'scorch':np.array([1296,540])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1470,375]),'scorch':np.array([805,475])}\n",
    "\n",
    "\n",
    "if np.shape(session_start_times)[0] != np.shape(dates_list)[0]:\n",
    "    exit()\n",
    "\n",
    "    \n",
    "# define bhv events summarizing variables     \n",
    "tasktypes_all_dates = np.zeros((ndates,1))\n",
    "coopthres_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "succ_rate_all_dates = np.zeros((ndates,1))\n",
    "interpullintv_all_dates = np.zeros((ndates,1))\n",
    "trialnum_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "owgaze1_num_all_dates = np.zeros((ndates,1))\n",
    "owgaze2_num_all_dates = np.zeros((ndates,1))\n",
    "mtgaze1_num_all_dates = np.zeros((ndates,1))\n",
    "mtgaze2_num_all_dates = np.zeros((ndates,1))\n",
    "pull1_num_all_dates = np.zeros((ndates,1))\n",
    "pull2_num_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "bhv_intv_all_dates = dict.fromkeys(dates_list, [])\n",
    "pull_edges_intv_all_dates = dict.fromkeys(dates_list, [])\n",
    "\n",
    "\n",
    "# where to save the summarizing data\n",
    "data_saved_folder = '/gpfs/gibbs/pi/jadi/VideoTracker_SocialInter/3d_recontruction_analysis_self_and_coop_task_data_saved/'\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c7a76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data from all dates are loaded\n"
     ]
    }
   ],
   "source": [
    "# basic behavior analysis (define time stamps for each bhv events, etc)\n",
    "\n",
    "try:\n",
    "    if redo_anystep:\n",
    "        dummy\n",
    "    \n",
    "    # load saved data\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    \n",
    "    with open(data_saved_subfolder+'/owgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        owgaze1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/owgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        owgaze2_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/mtgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        mtgaze1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/mtgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        mtgaze2_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/pull1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        pull1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/pull2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        pull2_num_all_dates = pickle.load(f)\n",
    "\n",
    "    with open(data_saved_subfolder+'/tasktypes_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        tasktypes_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/coopthres_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        coopthres_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/succ_rate_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        succ_rate_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/interpullintv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        interpullintv_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/trialnum_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        trialnum_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/bhv_intv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        bhv_intv_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/pull_edges_intv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        pull_edges_intv_all_dates = pickle.load(f)\n",
    "\n",
    "    print('all data from all dates are loaded')\n",
    "\n",
    "except:\n",
    "\n",
    "    print('analyze all dates')\n",
    "\n",
    "    for idate in np.arange(0,ndates,1):\n",
    "        date_tgt = dates_list[idate]\n",
    "        session_start_time = session_start_times[idate]\n",
    "\n",
    "        # folder and file path\n",
    "        camera12_analyzed_path = \"/gpfs/gibbs/pi/jadi/VideoTracker_SocialInter/test_video_cooperative_task_3d/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera12/\"\n",
    "        camera23_analyzed_path = \"/gpfs/gibbs/pi/jadi/VideoTracker_SocialInter/test_video_cooperative_task_3d/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera23/\"\n",
    "        \n",
    "        singlecam_ana_type = \"DLC_dlcrnetms5_marmoset_tracking_with_middle_cameraSep1shuffle1_150000\"\n",
    "        try: \n",
    "            bodyparts_camI_camIJ = camera12_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "            # get the bodypart data from files\n",
    "            bodyparts_locs_camI = body_part_locs_singlecam(bodyparts_camI_camIJ,singlecam_ana_type,animalnames_videotrack,bodypartnames_videotrack,date_tgt)\n",
    "            video_file_original = camera12_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+\".mp4\"\n",
    "        except:\n",
    "            bodyparts_camI_camIJ = camera23_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "            # get the bodypart data from files\n",
    "            bodyparts_locs_camI = body_part_locs_singlecam(bodyparts_camI_camIJ,singlecam_ana_type,animalnames_videotrack,bodypartnames_videotrack,date_tgt)\n",
    "            video_file_original = camera23_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+\".mp4\"        \n",
    "        \n",
    "        \n",
    "        # load behavioral results\n",
    "        try:\n",
    "            bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "            trial_record_json = glob.glob(bhv_data_path +date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "            bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_bhv_data_\" + \"*.json\")\n",
    "            session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_session_info_\" + \"*.json\")\n",
    "            #\n",
    "            trial_record = pd.read_json(trial_record_json[0])\n",
    "            bhv_data = pd.read_json(bhv_data_json[0])\n",
    "            session_info = pd.read_json(session_info_json[0])\n",
    "        except:\n",
    "            bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "            trial_record_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "            bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_bhv_data_\" + \"*.json\")\n",
    "            session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_session_info_\" + \"*.json\")\n",
    "            #\n",
    "            trial_record = pd.read_json(trial_record_json[0])\n",
    "            bhv_data = pd.read_json(bhv_data_json[0])\n",
    "            session_info = pd.read_json(session_info_json[0])\n",
    "\n",
    "        # get animal info from the session information\n",
    "        animal1 = session_info['lever1_animal'][0].lower()\n",
    "        animal2 = session_info['lever2_animal'][0].lower()\n",
    "\n",
    "        \n",
    "        # get task type and cooperation threshold\n",
    "        try:\n",
    "            coop_thres = session_info[\"pulltime_thres\"][0]\n",
    "            tasktype = session_info[\"task_type\"][0]\n",
    "        except:\n",
    "            coop_thres = 0\n",
    "            tasktype = 1\n",
    "        tasktypes_all_dates[idate] = tasktype\n",
    "        coopthres_all_dates[idate] = coop_thres   \n",
    "\n",
    "        # clean up the trial_record\n",
    "        warnings.filterwarnings('ignore')\n",
    "        trial_record_clean = pd.DataFrame(columns=trial_record.columns)\n",
    "        for itrial in np.arange(0,np.max(trial_record['trial_number']),1):\n",
    "            # trial_record_clean.loc[itrial] = trial_record[trial_record['trial_number']==itrial+1].iloc[[0]]\n",
    "            trial_record_clean = trial_record_clean.append(trial_record[trial_record['trial_number']==itrial+1].iloc[[0]])\n",
    "        trial_record_clean = trial_record_clean.reset_index(drop = True)\n",
    "\n",
    "        # change bhv_data time to the absolute time\n",
    "        time_points_new = pd.DataFrame(np.zeros(np.shape(bhv_data)[0]),columns=[\"time_points_new\"])\n",
    "        for itrial in np.arange(0,np.max(trial_record_clean['trial_number']),1):\n",
    "            ind = bhv_data[\"trial_number\"]==itrial+1\n",
    "            new_time_itrial = bhv_data[ind][\"time_points\"] + trial_record_clean[\"trial_starttime\"].iloc[itrial]\n",
    "            time_points_new[\"time_points_new\"][ind] = new_time_itrial\n",
    "        bhv_data[\"time_points\"] = time_points_new[\"time_points_new\"]\n",
    "        bhv_data = bhv_data[bhv_data[\"time_points\"] != 0]\n",
    "\n",
    "\n",
    "        # analyze behavior results\n",
    "        # succ_rate_all_dates[idate] = np.sum(trial_record_clean[\"rewarded\"]>0)/np.shape(trial_record_clean)[0]\n",
    "        succ_rate_all_dates[idate] = np.sum((bhv_data['behavior_events']==3)|(bhv_data['behavior_events']==4))/np.sum((bhv_data['behavior_events']==1)|(bhv_data['behavior_events']==2))\n",
    "        trialnum_all_dates[idate] = np.shape(trial_record_clean)[0]\n",
    "        #\n",
    "        pullid = np.array(bhv_data[(bhv_data['behavior_events']==1) | (bhv_data['behavior_events']==2)][\"behavior_events\"])\n",
    "        pulltime = np.array(bhv_data[(bhv_data['behavior_events']==1) | (bhv_data['behavior_events']==2)][\"time_points\"])\n",
    "        pullid_diff = np.abs(pullid[1:] - pullid[0:-1])\n",
    "        pulltime_diff = pulltime[1:] - pulltime[0:-1]\n",
    "        interpull_intv = pulltime_diff[pullid_diff==1]\n",
    "        interpull_intv = interpull_intv[interpull_intv<10]\n",
    "        mean_interpull_intv = np.nanmean(interpull_intv)\n",
    "        std_interpull_intv = np.nanstd(interpull_intv)\n",
    "        #\n",
    "        interpullintv_all_dates[idate] = mean_interpull_intv\n",
    "        # \n",
    "        pull1_num_all_dates[idate] = np.sum(bhv_data['behavior_events']==1) \n",
    "        pull2_num_all_dates[idate] = np.sum(bhv_data['behavior_events']==2)\n",
    "\n",
    "        \n",
    "        # load behavioral event results\n",
    "        try:\n",
    "            # dummy\n",
    "            print('load social gaze with '+cameraID+' only of '+date_tgt)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_look_ornot.pkl', 'rb') as f:\n",
    "                output_look_ornot = pickle.load(f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allvectors.pkl', 'rb') as f:\n",
    "                output_allvectors = pickle.load(f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allangles.pkl', 'rb') as f:\n",
    "                output_allangles = pickle.load(f)  \n",
    "        except:   \n",
    "            print('analyze social gaze with '+cameraID+' only of '+date_tgt)\n",
    "            # get social gaze information \n",
    "            output_look_ornot, output_allvectors, output_allangles = find_socialgaze_timepoint_singlecam_wholebody(bodyparts_locs_camI,lever_locs_camI,tube_locs_camI,\n",
    "                                                                                                                   considerlevertube,considertubeonly,sqr_thres_tubelever,\n",
    "                                                                                                                   sqr_thres_face,sqr_thres_body)\n",
    "            # save data\n",
    "            current_dir = data_saved_folder+'/bhv_events_singlecam_wholebody/'+animal1_fixedorder[0]+animal2_fixedorder[0]\n",
    "            add_date_dir = os.path.join(current_dir,cameraID+'/'+date_tgt)\n",
    "            if not os.path.exists(add_date_dir):\n",
    "                os.makedirs(add_date_dir)\n",
    "            #\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_look_ornot.pkl', 'wb') as f:\n",
    "                pickle.dump(output_look_ornot, f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allvectors.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allvectors, f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allangles.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allangles, f)\n",
    "  \n",
    "\n",
    "        look_at_other_or_not_merge = output_look_ornot['look_at_other_or_not_merge']\n",
    "        look_at_tube_or_not_merge = output_look_ornot['look_at_tube_or_not_merge']\n",
    "        look_at_lever_or_not_merge = output_look_ornot['look_at_lever_or_not_merge']\n",
    "        # change the unit to second\n",
    "        session_start_time = session_start_times[idate]\n",
    "        look_at_other_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_other_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_lever_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_lever_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_tube_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_tube_or_not_merge['dodson'])[0],1)/fps - session_start_time \n",
    "\n",
    "        # find time point of behavioral events\n",
    "        output_time_points_socialgaze ,output_time_points_levertube = bhv_events_timepoint_singlecam(bhv_data,look_at_other_or_not_merge,look_at_lever_or_not_merge,look_at_tube_or_not_merge)\n",
    "        time_point_pull1 = output_time_points_socialgaze['time_point_pull1']\n",
    "        time_point_pull2 = output_time_points_socialgaze['time_point_pull2']\n",
    "        oneway_gaze1 = output_time_points_socialgaze['oneway_gaze1']\n",
    "        oneway_gaze2 = output_time_points_socialgaze['oneway_gaze2']\n",
    "        mutual_gaze1 = output_time_points_socialgaze['mutual_gaze1']\n",
    "        mutual_gaze2 = output_time_points_socialgaze['mutual_gaze2']\n",
    "            \n",
    "                \n",
    "        # # plot behavioral events\n",
    "        if np.isin(animal1,animal1_fixedorder):\n",
    "                plot_bhv_events(date_tgt,animal1, animal2, session_start_time, 600, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "        else:\n",
    "                plot_bhv_events(date_tgt,animal2, animal1, session_start_time, 600, time_point_pull2, time_point_pull1, oneway_gaze2, oneway_gaze1, mutual_gaze2, mutual_gaze1)\n",
    "        #\n",
    "        # save behavioral events plot\n",
    "        if 0:\n",
    "            current_dir = data_saved_folder+'/bhv_events_singlecam_wholebody/'+animal1_fixedorder[0]+animal2_fixedorder[0]\n",
    "            add_date_dir = os.path.join(current_dir,cameraID+'/'+date_tgt)\n",
    "            if not os.path.exists(add_date_dir):\n",
    "                os.makedirs(add_date_dir)\n",
    "            plt.savefig(data_saved_folder+\"/bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/'+date_tgt+\"_\"+cameraID_short+\".pdf\")\n",
    "\n",
    "        #\n",
    "        owgaze1_num_all_dates[idate] = np.shape(oneway_gaze1)[0]\n",
    "        owgaze2_num_all_dates[idate] = np.shape(oneway_gaze2)[0]\n",
    "        mtgaze1_num_all_dates[idate] = np.shape(mutual_gaze1)[0]\n",
    "        mtgaze2_num_all_dates[idate] = np.shape(mutual_gaze2)[0]\n",
    "\n",
    "        # analyze the events interval, especially for the pull to other and other to pull interval\n",
    "        # could be used for define time bin for DBN\n",
    "        if np.isin(animal1,animal1_fixedorder):\n",
    "            _,_,_,pullTOother_itv, otherTOpull_itv = bhv_events_interval(totalsess_time, session_start_time, time_point_pull1, time_point_pull2, \n",
    "                                                                         oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "            #\n",
    "            pull_other_pool_itv = np.concatenate((pullTOother_itv,otherTOpull_itv))\n",
    "            bhv_intv_all_dates[date_tgt] = {'pull_to_other':pullTOother_itv,'other_to_pull':otherTOpull_itv,\n",
    "                            'pull_other_pooled': pull_other_pool_itv}\n",
    "            \n",
    "            all_pull_edges_intervals = bhv_events_interval_certainEdges(totalsess_time, session_start_time, time_point_pull1, time_point_pull2, \n",
    "                                                                        oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "            pull_edges_intv_all_dates[date_tgt] = all_pull_edges_intervals\n",
    "        else:\n",
    "            _,_,_,pullTOother_itv, otherTOpull_itv = bhv_events_interval(totalsess_time, session_start_time, time_point_pull2, time_point_pull1, \n",
    "                                                                         oneway_gaze2, oneway_gaze1, mutual_gaze2, mutual_gaze1)\n",
    "            #\n",
    "            pull_other_pool_itv = np.concatenate((pullTOother_itv,otherTOpull_itv))\n",
    "            bhv_intv_all_dates[date_tgt] = {'pull_to_other':pullTOother_itv,'other_to_pull':otherTOpull_itv,\n",
    "                            'pull_other_pooled': pull_other_pool_itv}\n",
    "            \n",
    "            all_pull_edges_intervals = bhv_events_interval_certainEdges(totalsess_time, session_start_time, time_point_pull2, time_point_pull1, \n",
    "                                                                        oneway_gaze2, oneway_gaze1, mutual_gaze2, mutual_gaze1)\n",
    "            pull_edges_intv_all_dates[date_tgt] = all_pull_edges_intervals\n",
    "   \n",
    "\n",
    "        # plot the tracking demo video\n",
    "        if 0: \n",
    "            tracking_video_singlecam_wholebody_demo(bodyparts_locs_camI,output_look_ornot,output_allvectors,output_allangles,\n",
    "                                              lever_locs_camI,tube_locs_camI,time_point_pull1,time_point_pull2,\n",
    "                                              animalnames_videotrack,bodypartnames_videotrack,date_tgt,\n",
    "                                              animal1_filename,animal2_filename,session_start_time,fps,nframes,cameraID,\n",
    "                                              video_file_original,sqr_thres_tubelever,sqr_thres_face,sqr_thres_body)         \n",
    "        \n",
    "\n",
    "    # save data\n",
    "    if 0:\n",
    "        \n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "        if not os.path.exists(data_saved_subfolder):\n",
    "            os.makedirs(data_saved_subfolder)\n",
    "                \n",
    "        # with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        #     pickle.dump(DBN_input_data_alltypes, f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/owgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(owgaze1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/owgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(owgaze2_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/mtgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(mtgaze1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/mtgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(mtgaze2_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/pull1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(pull1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/pull2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(pull2_num_all_dates, f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/tasktypes_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(tasktypes_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/coopthres_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(coopthres_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/succ_rate_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(succ_rate_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/interpullintv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(interpullintv_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/trialnum_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(trialnum_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/bhv_intv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(bhv_intv_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/pull_edges_intv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(pull_edges_intv_all_dates, f)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74a94f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05469293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee58a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aada694",
   "metadata": {},
   "source": [
    "#### redefine the tasktype and cooperation threshold to merge them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d0e6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100: self; 3: 3s coop; 2: 2s coop; 1.5: 1.5s coop; 1: 1s coop; -1: no-vision\n",
    "\n",
    "tasktypes_all_dates[tasktypes_all_dates==5] = -1 # change the task type code for no-vision\n",
    "coopthres_forsort = (tasktypes_all_dates-1)*coopthres_all_dates/2\n",
    "coopthres_forsort[coopthres_forsort==0] = 100 # get the cooperation threshold for sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900d890",
   "metadata": {},
   "source": [
    "### plot behavioral events interval to get a sense about time bin\n",
    "#### only focus on pull_to_other_bhv_interval and other_bhv_to_pull_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7b179dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.17551724 3.37112069 1.43739837 1.16428571 1.46451613 1.37892157\n",
      " 1.75773196 1.51359517 0.93787879 1.4323741  1.36269113 3.8137931\n",
      " 2.25642857 3.97307692 6.03207547 4.61976744]\n",
      "2.007204116638079\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates': dates_list, 'coopthres': coopthres_forsort.ravel()}, columns=['dates', 'coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['coopthres','dates'], ascending = [False, True])\n",
    "\n",
    "#\n",
    "#tasktypes = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','no-vision']\n",
    "tasktypes = ['self','coop(1s)','no-vision']\n",
    "#\n",
    "ind=(sorting_df['coopthres']==100)|(sorting_df['coopthres']==1)|(sorting_df['coopthres']==-1)\n",
    "sorting_df = sorting_df[ind]\n",
    "dates_list_sorted = np.array(dates_list)[sorting_df.index]\n",
    "ndates_sorted = np.shape(dates_list_sorted)[0]\n",
    "\n",
    "pull_other_intv_forplots = {}\n",
    "pull_other_intv_mean = np.zeros((1,ndates_sorted))[0]\n",
    "pull_other_intv_ii = []\n",
    "for ii in np.arange(0,ndates_sorted,1):\n",
    "    pull_other_intv_ii = pd.Series(bhv_intv_all_dates[dates_list_sorted[ii]]['pull_other_pooled'])\n",
    "    # remove the interval that is too large\n",
    "    # pull_other_intv_ii[pull_other_intv_ii>(np.nanmean(pull_other_intv_ii)+2*np.nanstd(pull_other_intv_ii))]= np.nan    \n",
    "    pull_other_intv_ii[pull_other_intv_ii>25]= np.nan\n",
    "    pull_other_intv_forplots[ii] = pull_other_intv_ii\n",
    "    pull_other_intv_mean[ii] = np.nanmean(pull_other_intv_ii)\n",
    "    \n",
    "    \n",
    "#\n",
    "pull_other_intv_forplots = pd.DataFrame(pull_other_intv_forplots)\n",
    "\n",
    "#\n",
    "pull_other_intv_forplots_df = pd.DataFrame(pull_other_intv_forplots)\n",
    "pull_other_intv_forplots_df.columns = list(dates_list_sorted)\n",
    "\n",
    "#\n",
    "# plot\n",
    "# pull_other_intv_forplots.plot(kind = 'box',ax=ax1, positions=np.arange(0,ndates_sorted,1))\n",
    "seaborn.violinplot(ax=ax1,data=pull_other_intv_forplots_df,color='skyblue')\n",
    "# plt.boxplot(pull_other_intv_forplots)\n",
    "# plt.plot(np.arange(0,ndates_sorted,1),pull_other_intv_mean,'r*',markersize=10)\n",
    "#\n",
    "ax1.set_ylabel(\"bhv event interval(around pulls)\",fontsize=13)\n",
    "ax1.set_ylim([-2,16])\n",
    "#\n",
    "plt.xticks(np.arange(0,ndates_sorted,1),dates_list_sorted, rotation=90,fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "#\n",
    "taskswitches = np.where(np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)[0]+0.5\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.plot([taskswitch,taskswitch],[-2,15],'k--')\n",
    "taskswitches = np.concatenate(([0],taskswitches))\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.text(taskswitch+0.25,-1,tasktypes[itaskswitch],fontsize=10)\n",
    "ax1.text(taskswitch-5,15,'mean='+\"{:.3f}\".format(np.nanmean(pull_other_intv_forplots)),fontsize=10)\n",
    "\n",
    "print(pull_other_intv_mean)\n",
    "print(np.nanmean(pull_other_intv_forplots))\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"bhvInterval_hist_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3831554",
   "metadata": {},
   "source": [
    "#### only focus on pull_to_other_bhv_interval and other_bhv_to_pull_interval; pool sessions within a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates': dates_list, 'coopthres': coopthres_forsort.ravel()}, columns=['dates', 'coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['coopthres','dates'], ascending = [False, True])\n",
    "\n",
    "#\n",
    "#tasktypes = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','no-vision']\n",
    "tasktypes = ['self','coop(1s)','no-vision']\n",
    "#\n",
    "ind=(sorting_df['coopthres']==100)|(sorting_df['coopthres']==1)|(sorting_df['coopthres']==-1)\n",
    "sorting_df = sorting_df[ind]\n",
    "dates_list_sorted = np.array(dates_list)[sorting_df.index]\n",
    "ndates_sorted = np.shape(dates_list_sorted)[0]\n",
    "\n",
    "pull_other_intv_forplots = {}\n",
    "pull_other_intv_mean = np.zeros((1,ndates_sorted))[0]\n",
    "pull_other_intv_ii = []\n",
    "for ii in np.arange(0,ndates_sorted,1):\n",
    "    pull_other_intv_ii = pd.Series(bhv_intv_all_dates[dates_list_sorted[ii]]['pull_other_pooled'])\n",
    "    # remove the interval that is too large\n",
    "    # pull_other_intv_ii[pull_other_intv_ii>(np.nanmean(pull_other_intv_ii)+2*np.nanstd(pull_other_intv_ii))]= np.nan    \n",
    "    pull_other_intv_ii[pull_other_intv_ii>25]= np.nan\n",
    "    pull_other_intv_forplots[ii] = pull_other_intv_ii\n",
    "    pull_other_intv_mean[ii] = np.nanmean(pull_other_intv_ii)\n",
    "    \n",
    "#\n",
    "pull_other_intv_forplots = pd.DataFrame(pull_other_intv_forplots)\n",
    "pull_other_intv_forplots.columns = dates_list_sorted \n",
    "\n",
    "pull_other_intv_forplots = [\n",
    "    np.array(pull_other_intv_forplots[list(sorting_df[sorting_df['coopthres']==100]['dates'])].stack().reset_index(drop=True)),\n",
    "    np.array(pull_other_intv_forplots[list(sorting_df[sorting_df['coopthres']==1]['dates'])].stack().reset_index(drop=True)),\n",
    "    np.array(pull_other_intv_forplots[list(sorting_df[sorting_df['coopthres']==-1]['dates'])].stack().reset_index(drop=True))\n",
    "]\n",
    "#\n",
    "pull_other_intv_forplots_df = pd.DataFrame(pull_other_intv_forplots).T\n",
    "pull_other_intv_forplots_df.columns = tasktypes\n",
    "\n",
    "# plt.boxplot(pull_other_intv_forplots,whis=1.5, meanline=True)\n",
    "seaborn.violinplot(ax=ax1,data=pull_other_intv_forplots_df)\n",
    "\n",
    "plt.xticks(np.arange(0, len(tasktypes), 1), tasktypes, fontsize = 14);\n",
    "ax1.set_ylim([-2,20])\n",
    "ax1.set_ylabel(\"bhv event interval(around pulls)\",fontsize=14)\n",
    "ax1.set_title(\"animal pair: \"+animal1_fixedorder[0]+' '+animal2_fixedorder[0],fontsize=15)\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"bhvInterval_hist_combinedsessions_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15978aac",
   "metadata": {},
   "source": [
    "#### focus on different pull edges intervals\n",
    "#### seperate individual animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b937f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates': dates_list, 'coopthres': coopthres_forsort.ravel()}, columns=['dates', 'coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['coopthres','dates'], ascending = [False, True])\n",
    "\n",
    "#\n",
    "# tasktypes = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','no-vision']\n",
    "tasktypes = ['self','coop(1s)','no-vision']\n",
    "#\n",
    "ind=(sorting_df['coopthres']==100)|(sorting_df['coopthres']==1)|(sorting_df['coopthres']==-1)\n",
    "sorting_df = sorting_df[ind]\n",
    "dates_list_sorted = np.array(dates_list)[sorting_df.index]\n",
    "ndates_sorted = np.shape(dates_list_sorted)[0]\n",
    "    \n",
    "#\n",
    "plotanimals = [animal1_fixedorder[0],animal2_fixedorder[0]]\n",
    "nanimals = np.shape(plotanimals)[0]\n",
    "#\n",
    "plottypes = [['pull_to_pull_interval','pull_to_pull_interval'],\n",
    "             ['pull2_to_pull1_interval','pull1_to_pull2_interval'],           \n",
    "             ['pull2_to_gaze1_interval','pull1_to_gaze2_interval'],\n",
    "             ['gaze2_to_pull1_interval','gaze1_to_pull2_interval'],\n",
    "             ['gaze1_to_pull1_interval','gaze2_to_pull2_interval'],\n",
    "             ['pull1_to_gaze1_interval','pull2_to_gaze2_interval'],\n",
    "           ]\n",
    "nplottypes = np.shape(plottypes)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(nplottypes,nanimals)\n",
    "fig.set_figheight(nplottypes*5)\n",
    "fig.set_figwidth(nanimals*10)\n",
    "\n",
    "\n",
    "for ianimal in np.arange(0,nanimals,1):\n",
    "    plotanimal = plotanimals[ianimal]\n",
    "    \n",
    "    for iplottype in np.arange(0,nplottypes,1):\n",
    "        plottype = plottypes[iplottype][ianimal]\n",
    "    \n",
    "        pull_other_intv_forplots = {}\n",
    "        pull_other_intv_mean = np.zeros((1,ndates_sorted))[0]\n",
    "        pull_other_intv_ii = []\n",
    "        for ii in np.arange(0,ndates_sorted,1):\n",
    "            pull_other_intv_ii = pd.Series(pull_edges_intv_all_dates[dates_list_sorted[ii]][plottype])\n",
    "            # remove the interval that is too large\n",
    "            # pull_other_intv_ii[pull_other_intv_ii>(np.nanmean(pull_other_intv_ii)+2*np.nanstd(pull_other_intv_ii))]= np.nan    \n",
    "            pull_other_intv_ii[pull_other_intv_ii>25]= np.nan\n",
    "            pull_other_intv_forplots[ii] = pull_other_intv_ii\n",
    "            pull_other_intv_mean[ii] = np.nanmean(pull_other_intv_ii)\n",
    "\n",
    "\n",
    "        #\n",
    "        pull_other_intv_forplots = pd.DataFrame(pull_other_intv_forplots)\n",
    "        #\n",
    "        pull_other_intv_forplots_df = pd.DataFrame(pull_other_intv_forplots)\n",
    "        pull_other_intv_forplots_df.columns = list(dates_list_sorted)\n",
    "\n",
    "        #\n",
    "        # plot\n",
    "        # pull_other_intv_forplots.plot(kind = 'box',ax=axs[iplottype,ianimal], positions=np.arange(0,ndates_sorted,1))\n",
    "        seaborn.violinplot(ax=axs[iplottype,ianimal],data=pull_other_intv_forplots_df,color='skyblue')\n",
    "        # plt.boxplot(pull_other_intv_forplots)\n",
    "        #axs[iplottype,ianimal].plot(np.arange(0,ndates_sorted,1),pull_other_intv_mean,'r*',markersize=10)\n",
    "        #\n",
    "        axs[iplottype,ianimal].set_ylabel(plottype,fontsize=13)\n",
    "        axs[iplottype,ianimal].set_ylim([-2,25])\n",
    "        #\n",
    "        axs[iplottype,ianimal].set_xticks(np.arange(0,ndates_sorted,1))\n",
    "        if iplottype == nplottypes-1:\n",
    "            axs[iplottype,ianimal].set_xticklabels(dates_list_sorted, rotation=45,fontsize=10)\n",
    "        else:\n",
    "            axs[iplottype,ianimal].set_xticklabels('')\n",
    "        axs[iplottype,ianimal].set_yticks(np.arange(-2,24,2))\n",
    "        axs[iplottype,ianimal].set_title('to animal:'+plotanimal)\n",
    "        #\n",
    "        taskswitches = np.where(np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)[0]+0.5\n",
    "        for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "            taskswitch = taskswitches[itaskswitch]\n",
    "            axs[iplottype,ianimal].plot([taskswitch,taskswitch],[-2,25],'k--')\n",
    "        taskswitches = np.concatenate(([0],taskswitches))\n",
    "        for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "            taskswitch = taskswitches[itaskswitch]\n",
    "            axs[iplottype,ianimal].text(taskswitch+0.25,-1,tasktypes[itaskswitch],fontsize=10)\n",
    "        axs[iplottype,ianimal].text(taskswitch-5,23,'mean='+\"{:.3f}\".format(np.nanmean(pull_other_intv_forplots)),fontsize=10)\n",
    "\n",
    "        #print(pull_other_intv_mean)\n",
    "        #print(np.nanmean(pull_other_intv_forplots))\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"Pull_Edge_Interval_hist_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a5cfe5",
   "metadata": {},
   "source": [
    "#### focus on different pull edges intervals\n",
    "#### seperate individual animals； pool sessions within a task type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5915c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates': dates_list, 'coopthres': coopthres_forsort.ravel()}, columns=['dates', 'coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['coopthres','dates'], ascending = [False, True])\n",
    "\n",
    "#\n",
    "# tasktypes = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','no-vision']\n",
    "tasktypes = ['self','coop(1s)','no-vision']\n",
    "#\n",
    "ind=(sorting_df['coopthres']==100)|(sorting_df['coopthres']==1)|(sorting_df['coopthres']==-1)\n",
    "sorting_df = sorting_df[ind]\n",
    "dates_list_sorted = np.array(dates_list)[sorting_df.index]\n",
    "ndates_sorted = np.shape(dates_list_sorted)[0]\n",
    "    \n",
    "#\n",
    "plotanimals = [animal1_fixedorder[0],animal2_fixedorder[0]]\n",
    "nanimals = np.shape(plotanimals)[0]\n",
    "#\n",
    "plottypes = [['pull_to_pull_interval','pull_to_pull_interval'],\n",
    "             ['pull2_to_pull1_interval','pull1_to_pull2_interval'],           \n",
    "             ['pull2_to_gaze1_interval','pull1_to_gaze2_interval'],\n",
    "             ['gaze2_to_pull1_interval','gaze1_to_pull2_interval'],\n",
    "             ['gaze1_to_pull1_interval','gaze2_to_pull2_interval'],\n",
    "             ['pull1_to_gaze1_interval','pull2_to_gaze2_interval'],\n",
    "           ]\n",
    "nplottypes = np.shape(plottypes)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(nplottypes,nanimals)\n",
    "fig.set_figheight(nplottypes*5)\n",
    "fig.set_figwidth(nanimals*5)\n",
    "\n",
    "\n",
    "for ianimal in np.arange(0,nanimals,1):\n",
    "    plotanimal = plotanimals[ianimal]\n",
    "    \n",
    "    for iplottype in np.arange(0,nplottypes,1):\n",
    "        plottype = plottypes[iplottype][ianimal]\n",
    "    \n",
    "        pull_other_intv_forplots = {}\n",
    "        pull_other_intv_mean = np.zeros((1,ndates_sorted))[0]\n",
    "        pull_other_intv_ii = []\n",
    "        for ii in np.arange(0,ndates_sorted,1):\n",
    "            pull_other_intv_ii = pd.Series(pull_edges_intv_all_dates[dates_list_sorted[ii]][plottype])\n",
    "            # remove the interval that is too large\n",
    "            # pull_other_intv_ii[pull_other_intv_ii>(np.nanmean(pull_other_intv_ii)+2*np.nanstd(pull_other_intv_ii))]= np.nan    \n",
    "            pull_other_intv_ii[pull_other_intv_ii>25]= np.nan\n",
    "            pull_other_intv_forplots[ii] = pull_other_intv_ii\n",
    "            pull_other_intv_mean[ii] = np.nanmean(pull_other_intv_ii)\n",
    "\n",
    "        #\n",
    "        pull_other_intv_forplots = pd.DataFrame(pull_other_intv_forplots)\n",
    "        pull_other_intv_forplots.columns = dates_list_sorted \n",
    "\n",
    "        pull_other_intv_forplots = [\n",
    "            np.array(pull_other_intv_forplots[list(sorting_df[sorting_df['coopthres']==100]['dates'])].stack().reset_index(drop=True)),\n",
    "            np.array(pull_other_intv_forplots[list(sorting_df[sorting_df['coopthres']==1]['dates'])].stack().reset_index(drop=True)),\n",
    "            np.array(pull_other_intv_forplots[list(sorting_df[sorting_df['coopthres']==-1]['dates'])].stack().reset_index(drop=True))\n",
    "        ]\n",
    "\n",
    "        #\n",
    "        pull_other_intv_forplots_df = pd.DataFrame(pull_other_intv_forplots).T\n",
    "        pull_other_intv_forplots_df.columns = tasktypes\n",
    "\n",
    "        #\n",
    "        if plottype == 'pull_to_pull_interval':\n",
    "            pull_other_intv_base_df = pd.DataFrame.copy(pull_other_intv_forplots_df)\n",
    "            pull_other_intv_base_df['interval_type']='cross animal pulls'\n",
    "        \n",
    "        pull_other_intv_forplots_df['interval_type']='y axis dependency'\n",
    "        df_long=pd.concat([pull_other_intv_base_df,pull_other_intv_forplots_df])\n",
    "        df_long2 = df_long.melt(id_vars=['interval_type'], value_vars=['self', 'coop(1s)', 'no-vision'],var_name='condition', value_name='value')\n",
    "                        \n",
    "        # axs[iplottype,ianimal].boxplot(pull_other_intv_forplots,whis=1.5)\n",
    "        # seaborn.violinplot(ax=axs[iplottype,ianimal],data=pull_other_intv_forplots_df)\n",
    "        seaborn.violinplot(ax=axs[iplottype,ianimal],data=df_long2,x='condition',y='value',hue='interval_type',split=True,gap=5)\n",
    "\n",
    "        axs[iplottype,ianimal].set_xticks(np.arange(0, len(tasktypes), 1))\n",
    "        if iplottype == nplottypes-1:\n",
    "            axs[iplottype,ianimal].set_xticklabels(tasktypes, fontsize = 14)\n",
    "        else:\n",
    "            axs[iplottype,ianimal].set_xticklabels('')\n",
    "        ax=axs[iplottype,ianimal].set_ylim([-2,25])\n",
    "        ax=axs[iplottype,ianimal].set_ylabel(plottype,fontsize=13)\n",
    "        ax=axs[iplottype,ianimal].set_title('to animal:'+plotanimal,fontsize=15)\n",
    "\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        \n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"Pull_Edge_Interval_hist_combinedsessions_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c061dd",
   "metadata": {},
   "source": [
    "### plot some other basis behavioral measures\n",
    "#### social gaze number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbf18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_numbers = (owgaze1_num_all_dates+owgaze2_num_all_dates+mtgaze1_num_all_dates+mtgaze2_num_all_dates)/30\n",
    "gaze_pull_ratios = (owgaze1_num_all_dates+owgaze2_num_all_dates+mtgaze1_num_all_dates+mtgaze2_num_all_dates)/(pull1_num_all_dates+pull2_num_all_dates)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# grouptypes = ['self reward','3s threshold','2s threshold','1.5s threshold','1s threshold','novision']\n",
    "grouptypes = ['self reward','cooperative','no-vision']\n",
    "\n",
    "gaze_numbers_groups = [np.transpose(gaze_numbers[np.transpose(coopthres_forsort==100)[0]])[0],\n",
    "                      # np.transpose(gaze_numbers[np.transpose(coopthres_forsort==3)[0]])[0],\n",
    "                      # np.transpose(gaze_numbers[np.transpose(coopthres_forsort==2)[0]])[0],\n",
    "                      # np.transpose(gaze_numbers[np.transpose(coopthres_forsort==1.5)[0]])[0],\n",
    "                       np.transpose(gaze_numbers[np.transpose(coopthres_forsort==1)[0]])[0],\n",
    "                       np.transpose(gaze_numbers[np.transpose(coopthres_forsort==-1)[0]])[0]]\n",
    "\n",
    "gaze_numbers_plot = plt.boxplot(gaze_numbers_groups,whis=1.5, meanline=True)\n",
    "# gaze_numbers_plot = seaborn.violinplot(gaze_numbers_groups)\n",
    "# seaborn.swarmplot(gaze_numbers_groups)\n",
    "\n",
    "plt.xticks(np.arange(0+1, len(grouptypes)+1, 1), grouptypes, fontsize = 14);\n",
    "ax1.set_ylim([240/30,3000/30])\n",
    "ax1.set_ylabel(\"average social gaze time (s)\",fontsize=14)\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"averaged_gazenumbers_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e1548e",
   "metadata": {},
   "source": [
    "### prepare the input data for DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d188541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define DBN related summarizing variables\n",
    "DBN_group_typenames = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','no-vision']\n",
    "DBN_group_typeIDs  =  [1,3,3,  3,3,5]\n",
    "DBN_group_coopthres = [0,3,2,1.5,1,0]\n",
    "nDBN_groups = np.shape(DBN_group_typenames)[0]\n",
    "\n",
    "prepare_input_data = 0\n",
    "\n",
    "DBN_input_data_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "\n",
    "# DBN resolutions (make sure they are the same as in the later part of the code)\n",
    "totalsess_time = 600 # total session time in s\n",
    "# temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "ntemp_reses = np.shape(temp_resolus)[0]\n",
    "\n",
    "mergetempRos = 0\n",
    "\n",
    "# # train the dynamic bayesian network - Alec's model \n",
    "#   prepare the multi-session table; one time lag; multi time steps (temporal resolution) as separate files\n",
    "\n",
    "# prepare the DBN input data\n",
    "if prepare_input_data:\n",
    "    \n",
    "    for idate in np.arange(0,ndates,1):\n",
    "        date_tgt = dates_list[idate]\n",
    "        session_start_time = session_start_times[idate]\n",
    "\n",
    "        # load behavioral results\n",
    "        try:\n",
    "            bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "            trial_record_json = glob.glob(bhv_data_path +date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "            bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_bhv_data_\" + \"*.json\")\n",
    "            session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_session_info_\" + \"*.json\")\n",
    "            #\n",
    "            trial_record = pd.read_json(trial_record_json[0])\n",
    "            bhv_data = pd.read_json(bhv_data_json[0])\n",
    "            session_info = pd.read_json(session_info_json[0])\n",
    "        except:\n",
    "            bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "            trial_record_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "            bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_bhv_data_\" + \"*.json\")\n",
    "            session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_session_info_\" + \"*.json\")\n",
    "            #\n",
    "            trial_record = pd.read_json(trial_record_json[0])\n",
    "            bhv_data = pd.read_json(bhv_data_json[0])\n",
    "            session_info = pd.read_json(session_info_json[0])\n",
    "            \n",
    "        # get animal info\n",
    "        animal1 = session_info['lever1_animal'][0].lower()\n",
    "        animal2 = session_info['lever2_animal'][0].lower()\n",
    "        \n",
    "        # clean up the trial_record\n",
    "        warnings.filterwarnings('ignore')\n",
    "        trial_record_clean = pd.DataFrame(columns=trial_record.columns)\n",
    "        for itrial in np.arange(0,np.max(trial_record['trial_number']),1):\n",
    "            # trial_record_clean.loc[itrial] = trial_record[trial_record['trial_number']==itrial+1].iloc[[0]]\n",
    "            trial_record_clean = trial_record_clean.append(trial_record[trial_record['trial_number']==itrial+1].iloc[[0]])\n",
    "        trial_record_clean = trial_record_clean.reset_index(drop = True)\n",
    "\n",
    "        # change bhv_data time to the absolute time\n",
    "        time_points_new = pd.DataFrame(np.zeros(np.shape(bhv_data)[0]),columns=[\"time_points_new\"])\n",
    "        for itrial in np.arange(0,np.max(trial_record_clean['trial_number']),1):\n",
    "            ind = bhv_data[\"trial_number\"]==itrial+1\n",
    "            new_time_itrial = bhv_data[ind][\"time_points\"] + trial_record_clean[\"trial_starttime\"].iloc[itrial]\n",
    "            time_points_new[\"time_points_new\"][ind] = new_time_itrial\n",
    "        bhv_data[\"time_points\"] = time_points_new[\"time_points_new\"]\n",
    "        bhv_data = bhv_data[bhv_data[\"time_points\"] != 0]\n",
    "            \n",
    "        # get task type and cooperation threshold\n",
    "        try:\n",
    "            coop_thres = session_info[\"pulltime_thres\"][0]\n",
    "            tasktype = session_info[\"task_type\"][0]\n",
    "        except:\n",
    "            coop_thres = 0\n",
    "            tasktype = 1\n",
    "\n",
    "        # load behavioral event results\n",
    "        print('load social gaze with '+cameraID+' only of '+date_tgt)\n",
    "        with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_look_ornot.pkl', 'rb') as f:\n",
    "            output_look_ornot = pickle.load(f)\n",
    "        with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allvectors.pkl', 'rb') as f:\n",
    "            output_allvectors = pickle.load(f)\n",
    "        with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allangles.pkl', 'rb') as f:\n",
    "            output_allangles = pickle.load(f)  \n",
    "        #\n",
    "        look_at_other_or_not_merge = output_look_ornot['look_at_other_or_not_merge']\n",
    "        look_at_tube_or_not_merge = output_look_ornot['look_at_tube_or_not_merge']\n",
    "        look_at_lever_or_not_merge = output_look_ornot['look_at_lever_or_not_merge']\n",
    "        # change the unit to second\n",
    "        session_start_time = session_start_times[idate]\n",
    "        look_at_other_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_other_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_lever_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_lever_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_tube_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_tube_or_not_merge['dodson'])[0],1)/fps - session_start_time \n",
    "\n",
    "        # find time point of behavioral events\n",
    "        output_time_points_socialgaze ,output_time_points_levertube = bhv_events_timepoint_singlecam(bhv_data,look_at_other_or_not_merge,look_at_lever_or_not_merge,look_at_tube_or_not_merge)\n",
    "        time_point_pull1 = output_time_points_socialgaze['time_point_pull1']\n",
    "        time_point_pull2 = output_time_points_socialgaze['time_point_pull2']\n",
    "        oneway_gaze1 = output_time_points_socialgaze['oneway_gaze1']\n",
    "        oneway_gaze2 = output_time_points_socialgaze['oneway_gaze2']\n",
    "        mutual_gaze1 = output_time_points_socialgaze['mutual_gaze1']\n",
    "        mutual_gaze2 = output_time_points_socialgaze['mutual_gaze2']   \n",
    "\n",
    "\n",
    "        if mergetempRos:\n",
    "            temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "            # use bhv event to decide temporal resolution\n",
    "            #\n",
    "            #low_lim,up_lim,_ = bhv_events_interval(totalsess_time, session_start_time, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "            #temp_resolus = temp_resolus = np.arange(low_lim,up_lim,0.1)\n",
    "\n",
    "        ntemp_reses = np.shape(temp_resolus)[0]           \n",
    "\n",
    "        # try different temporal resolutions\n",
    "        for temp_resolu in temp_resolus:\n",
    "            bhv_df = []\n",
    "\n",
    "            if np.isin(animal1,animal1_fixedorder):\n",
    "                bhv_df_itr,_,_ = train_DBN_multiLag_create_df_only(totalsess_time, session_start_time, temp_resolu, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "            else:\n",
    "                bhv_df_itr,_,_ = train_DBN_multiLag_create_df_only(totalsess_time, session_start_time, temp_resolu, time_point_pull2, time_point_pull1, oneway_gaze2, oneway_gaze1, mutual_gaze2, mutual_gaze1)     \n",
    "\n",
    "            if len(bhv_df)==0:\n",
    "                bhv_df = bhv_df_itr\n",
    "            else:\n",
    "                bhv_df = pd.concat([bhv_df,bhv_df_itr])                   \n",
    "                bhv_df = bhv_df.reset_index(drop=True)        \n",
    "\n",
    "            # merge sessions from the same condition\n",
    "            for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "                iDBN_group_typename = DBN_group_typenames[iDBN_group] \n",
    "                iDBN_group_typeID =  DBN_group_typeIDs[iDBN_group] \n",
    "                iDBN_group_cothres = DBN_group_coopthres[iDBN_group] \n",
    "\n",
    "                # merge sessions \n",
    "                if (tasktype!=3):\n",
    "                    if (tasktype==iDBN_group_typeID):\n",
    "                        if (len(DBN_input_data_alltypes[iDBN_group_typename])==0):\n",
    "                            DBN_input_data_alltypes[iDBN_group_typename] = bhv_df\n",
    "                        else:\n",
    "                            DBN_input_data_alltypes[iDBN_group_typename] = pd.concat([DBN_input_data_alltypes[iDBN_group_typename],bhv_df])\n",
    "                else:\n",
    "                    if (coop_thres==iDBN_group_cothres):\n",
    "                        if (len(DBN_input_data_alltypes[iDBN_group_typename])==0):\n",
    "                            DBN_input_data_alltypes[iDBN_group_typename] = bhv_df\n",
    "                        else:\n",
    "                            DBN_input_data_alltypes[iDBN_group_typename] = pd.concat([DBN_input_data_alltypes[iDBN_group_typename],bhv_df])\n",
    "\n",
    "    # save data\n",
    "    if 1:\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "        if not os.path.exists(data_saved_subfolder):\n",
    "            os.makedirs(data_saved_subfolder)\n",
    "        if not mergetempRos:\n",
    "            with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'sReSo.pkl', 'wb') as f:\n",
    "                pickle.dump(DBN_input_data_alltypes, f)\n",
    "        else:\n",
    "            with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_mergeTempsReSo.pkl', 'wb') as f:\n",
    "                pickle.dump(DBN_input_data_alltypes, f)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a743731",
   "metadata": {},
   "source": [
    "### run the DBN model on the combined session data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d7d323",
   "metadata": {},
   "source": [
    "#### a test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d13d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run DBN on the large table with merged sessions\n",
    "\n",
    "mergetempRos = 0 # 1: merge different time bins\n",
    "\n",
    "moreSampSize = 0 # 1: use more sample size (more than just minimal row number and max row number)\n",
    "\n",
    "num_starting_points = 1 # number of random starting points/graphs\n",
    "nbootstraps = 1\n",
    "\n",
    "if 0:\n",
    "\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        samplingsizes = np.arange(1100,3000,100)\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "        nsamplings = np.shape(samplingsizes)[0]\n",
    "\n",
    "    weighted_graphs_diffTempRo_diffSampSize = {}\n",
    "    weighted_graphs_shuffled_diffTempRo_diffSampSize = {}\n",
    "    sig_edges_diffTempRo_diffSampSize = {}\n",
    "    DAGscores_diffTempRo_diffSampSize = {}\n",
    "    DAGscores_shuffled_diffTempRo_diffSampSize = {}\n",
    "\n",
    "    totalsess_time = 600 # total session time in s\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "\n",
    "    # try different temporal resolutions, remember to use the same settings as in the previous ones\n",
    "    for temp_resolu in temp_resolus:\n",
    "\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "        if not mergetempRos:\n",
    "            with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "                DBN_input_data_alltypes = pickle.load(f)\n",
    "        else:\n",
    "            with open(data_saved_subfolder+'//DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "                DBN_input_data_alltypes = pickle.load(f)\n",
    "\n",
    "                \n",
    "        # only try two sample sizes - minimal row number (require data downsample) and maximal row number (require data upsample)\n",
    "       \n",
    "        if not moreSampSize:\n",
    "            key_to_value_lengths = {k:len(v) for k, v in DBN_input_data_alltypes.items()}\n",
    "            key_to_value_lengths_array = np.fromiter(key_to_value_lengths.values(),dtype=float)\n",
    "            key_to_value_lengths_array[key_to_value_lengths_array==0]=np.nan\n",
    "            min_samplesize = np.nanmin(key_to_value_lengths_array)\n",
    "            min_samplesize = int(min_samplesize/100)*100\n",
    "            max_samplesize = np.nanmax(key_to_value_lengths_array)\n",
    "            max_samplesize = int(max_samplesize/100)*100\n",
    "            samplingsizes = [min_samplesize,max_samplesize]\n",
    "            samplingsizes_name = ['min_row_number','max_row_number']   \n",
    "            nsamplings = np.shape(samplingsizes)[0]\n",
    "            print(samplingsizes)\n",
    "                \n",
    "        # try different down/re-sampling size\n",
    "        # for jj in np.arange(0,nsamplings,1):\n",
    "        for jj in np.arange(0,1,1):\n",
    "            \n",
    "            isamplingsize = samplingsizes[jj]\n",
    "            \n",
    "            DAGs_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            DAGs_shuffle_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            DAGs_scores_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            DAGs_shuffle_scores_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "\n",
    "            weighted_graphs_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            weighted_graphs_shuffled_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            sig_edges_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "\n",
    "            # different session conditions (aka DBN groups)\n",
    "            # for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "            for iDBN_group in np.arange(0,1,1):\n",
    "                iDBN_group_typename = DBN_group_typenames[iDBN_group] \n",
    "                iDBN_group_typeID =  DBN_group_typeIDs[iDBN_group] \n",
    "                iDBN_group_cothres = DBN_group_coopthres[iDBN_group] \n",
    "\n",
    "                try:\n",
    "                    bhv_df_all = DBN_input_data_alltypes[iDBN_group_typename]\n",
    "                    # bhv_df = bhv_df_all.sample(30*100,replace = True, random_state = round(time())) # take the subset for DBN training\n",
    "\n",
    "                    #Anirban(Alec) shuffle, slow\n",
    "                    # bhv_df_shuffle, df_shufflekeys = EfficientShuffle(bhv_df,round(time()))\n",
    "\n",
    "\n",
    "                    # define DBN graph structures; make sure they are the same as in the train_DBN_multiLag\n",
    "                    colnames = list(bhv_df_all.columns)\n",
    "                    eventnames = [\"pull1\",\"pull2\",\"owgaze1\",\"owgaze2\"]\n",
    "                    nevents = np.size(eventnames)\n",
    "\n",
    "                    all_pops = list(bhv_df_all.columns)\n",
    "                    from_pops = [pop for pop in all_pops if not pop.endswith('t3')]\n",
    "                    to_pops = [pop for pop in all_pops if pop.endswith('t3')]\n",
    "                    causal_whitelist = [(from_pop,to_pop) for from_pop in from_pops for to_pop in to_pops]\n",
    "\n",
    "                    nFromNodes = np.shape(from_pops)[0]\n",
    "                    nToNodes = np.shape(to_pops)[0]\n",
    "\n",
    "                    DAGs_randstart = np.zeros((num_starting_points, nFromNodes, nToNodes))\n",
    "                    DAGs_randstart_shuffle = np.zeros((num_starting_points, nFromNodes, nToNodes))\n",
    "                    score_randstart = np.zeros((num_starting_points))\n",
    "                    score_randstart_shuffle = np.zeros((num_starting_points))\n",
    "\n",
    "                    # step 1: randomize the starting point for num_starting_points times\n",
    "                    for istarting_points in np.arange(0,num_starting_points,1):\n",
    "\n",
    "                        # try different down/re-sampling size\n",
    "                        bhv_df = bhv_df_all.sample(isamplingsize,replace = True, random_state = istarting_points) # take the subset for DBN training\n",
    "                        aic = AicScore(bhv_df)\n",
    "\n",
    "                        #Anirban(Alec) shuffle, slow\n",
    "                        bhv_df_shuffle, df_shufflekeys = EfficientShuffle(bhv_df,round(time()))\n",
    "                        aic_shuffle = AicScore(bhv_df_shuffle)\n",
    "\n",
    "                        np.random.seed(istarting_points)\n",
    "                        random.seed(istarting_points)\n",
    "                        starting_edges = random.sample(causal_whitelist, np.random.randint(1,len(causal_whitelist)))\n",
    "                        starting_graph = DAG()\n",
    "                        starting_graph.add_nodes_from(nodes=all_pops)\n",
    "                        starting_graph.add_edges_from(ebunch=starting_edges)\n",
    "\n",
    "                        best_model,edges,DAGs = train_DBN_multiLag_training_only(bhv_df,starting_graph,colnames,eventnames,from_pops,to_pops)           \n",
    "                        DAGs[0][np.isnan(DAGs[0])]=0\n",
    "\n",
    "                        DAGs_randstart[istarting_points,:,:] = DAGs[0]\n",
    "                        score_randstart[istarting_points] = aic.score(best_model)\n",
    "\n",
    "                        # step 2: add the shffled data results\n",
    "                        # shuffled bhv_df\n",
    "                        best_model,edges,DAGs = train_DBN_multiLag_training_only(bhv_df_shuffle,starting_graph,colnames,eventnames,from_pops,to_pops)           \n",
    "                        DAGs[0][np.isnan(DAGs[0])]=0\n",
    "\n",
    "                        DAGs_randstart_shuffle[istarting_points,:,:] = DAGs[0]\n",
    "                        score_randstart_shuffle[istarting_points] = aic_shuffle.score(best_model)\n",
    "\n",
    "                    DAGs_alltypes[iDBN_group_typename] = DAGs_randstart \n",
    "                    DAGs_shuffle_alltypes[iDBN_group_typename] = DAGs_randstart_shuffle\n",
    "\n",
    "                    DAGs_scores_alltypes[iDBN_group_typename] = score_randstart\n",
    "                    DAGs_shuffle_scores_alltypes[iDBN_group_typename] = score_randstart_shuffle\n",
    "\n",
    "                    weighted_graphs = get_weighted_dags(DAGs_alltypes[iDBN_group_typename],nbootstraps)\n",
    "                    weighted_graphs_shuffled = get_weighted_dags(DAGs_shuffle_alltypes[iDBN_group_typename],nbootstraps)\n",
    "                    sig_edges = get_significant_edges(weighted_graphs,weighted_graphs_shuffled)\n",
    "\n",
    "                    weighted_graphs_alltypes[iDBN_group_typename] = weighted_graphs\n",
    "                    weighted_graphs_shuffled_alltypes[iDBN_group_typename] = weighted_graphs_shuffled\n",
    "                    sig_edges_alltypes[iDBN_group_typename] = sig_edges\n",
    "                    \n",
    "                except:\n",
    "                    DAGs_alltypes[iDBN_group_typename] = [] \n",
    "                    DAGs_shuffle_alltypes[iDBN_group_typename] = []\n",
    "\n",
    "                    DAGs_scores_alltypes[iDBN_group_typename] = []\n",
    "                    DAGs_shuffle_scores_alltypes[iDBN_group_typename] = []\n",
    "\n",
    "                    weighted_graphs_alltypes[iDBN_group_typename] = []\n",
    "                    weighted_graphs_shuffled_alltypes[iDBN_group_typename] = []\n",
    "                    sig_edges_alltypes[iDBN_group_typename] = []\n",
    "                \n",
    "            DAGscores_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = DAGs_scores_alltypes\n",
    "            DAGscores_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = DAGs_shuffle_scores_alltypes\n",
    "\n",
    "            weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = weighted_graphs_alltypes\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = weighted_graphs_shuffled_alltypes\n",
    "            sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = sig_edges_alltypes\n",
    "\n",
    "    print(weighted_graphs_diffTempRo_diffSampSize)\n",
    "            \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d647783a",
   "metadata": {},
   "source": [
    "#### run on the entire population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cafbb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run DBN on the large table with merged sessions\n",
    "\n",
    "mergetempRos = 0 # 1: merge different time bins\n",
    "\n",
    "moreSampSize = 0 # 1: use more sample size (more than just minimal row number and max row number)\n",
    "\n",
    "num_starting_points = 100 # number of random starting points/graphs\n",
    "nbootstraps = 95\n",
    "\n",
    "try:\n",
    "    # dumpy\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(data_saved_subfolder):\n",
    "        os.makedirs(data_saved_subfolder)\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/DAGscores_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'rb') as f:\n",
    "            DAGscores_diffTempRo_diffSampSize = pickle.load(f) \n",
    "        with open(data_saved_subfolder+'/DAGscores_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'rb') as f:\n",
    "            DAGscores_shuffled_diffTempRo_diffSampSize = pickle.load(f) \n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/DAGscores_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "            DAGscores_diffTempRo_diffSampSize = pickle.load(f) \n",
    "        with open(data_saved_subfolder+'/DAGscores_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "            DAGscores_shuffled_diffTempRo_diffSampSize = pickle.load(f) \n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "except:\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        samplingsizes = np.arange(1100,3000,100)\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "        nsamplings = np.shape(samplingsizes)[0]\n",
    "\n",
    "    weighted_graphs_diffTempRo_diffSampSize = {}\n",
    "    weighted_graphs_shuffled_diffTempRo_diffSampSize = {}\n",
    "    sig_edges_diffTempRo_diffSampSize = {}\n",
    "    DAGscores_diffTempRo_diffSampSize = {}\n",
    "    DAGscores_shuffled_diffTempRo_diffSampSize = {}\n",
    "\n",
    "    totalsess_time = 600 # total session time in s\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "\n",
    "    # try different temporal resolutions, remember to use the same settings as in the previous ones\n",
    "    for temp_resolu in temp_resolus:\n",
    "\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "        if not mergetempRos:\n",
    "            with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "                DBN_input_data_alltypes = pickle.load(f)\n",
    "        else:\n",
    "            with open(data_saved_subfolder+'//DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "                DBN_input_data_alltypes = pickle.load(f)\n",
    "\n",
    "                \n",
    "        # only try two sample sizes - minimal row number (require data downsample) and maximal row number (require data upsample)\n",
    "       \n",
    "        if not moreSampSize:\n",
    "            key_to_value_lengths = {k:len(v) for k, v in DBN_input_data_alltypes.items()}\n",
    "            key_to_value_lengths_array = np.fromiter(key_to_value_lengths.values(),dtype=float)\n",
    "            key_to_value_lengths_array[key_to_value_lengths_array==0]=np.nan\n",
    "            min_samplesize = np.nanmin(key_to_value_lengths_array)\n",
    "            min_samplesize = int(min_samplesize/100)*100\n",
    "            max_samplesize = np.nanmax(key_to_value_lengths_array)\n",
    "            max_samplesize = int(max_samplesize/100)*100\n",
    "            samplingsizes = [min_samplesize,max_samplesize]\n",
    "            samplingsizes_name = ['min_row_number','max_row_number']   \n",
    "            nsamplings = np.shape(samplingsizes)[0]\n",
    "            print(samplingsizes)\n",
    "                \n",
    "        # try different down/re-sampling size\n",
    "        for jj in np.arange(0,nsamplings,1):\n",
    "            \n",
    "            isamplingsize = samplingsizes[jj]\n",
    "            \n",
    "            DAGs_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            DAGs_shuffle_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            DAGs_scores_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            DAGs_shuffle_scores_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "\n",
    "            weighted_graphs_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            weighted_graphs_shuffled_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            sig_edges_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "\n",
    "            # different session conditions (aka DBN groups)\n",
    "            for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "                iDBN_group_typename = DBN_group_typenames[iDBN_group] \n",
    "                iDBN_group_typeID =  DBN_group_typeIDs[iDBN_group] \n",
    "                iDBN_group_cothres = DBN_group_coopthres[iDBN_group] \n",
    "\n",
    "                try:\n",
    "                    bhv_df_all = DBN_input_data_alltypes[iDBN_group_typename]\n",
    "                    # bhv_df = bhv_df_all.sample(30*100,replace = True, random_state = round(time())) # take the subset for DBN training\n",
    "\n",
    "                    #Anirban(Alec) shuffle, slow\n",
    "                    # bhv_df_shuffle, df_shufflekeys = EfficientShuffle(bhv_df,round(time()))\n",
    "\n",
    "\n",
    "                    # define DBN graph structures; make sure they are the same as in the train_DBN_multiLag\n",
    "                    colnames = list(bhv_df_all.columns)\n",
    "                    eventnames = [\"pull1\",\"pull2\",\"owgaze1\",\"owgaze2\"]\n",
    "                    nevents = np.size(eventnames)\n",
    "\n",
    "                    all_pops = list(bhv_df_all.columns)\n",
    "                    from_pops = [pop for pop in all_pops if not pop.endswith('t3')]\n",
    "                    to_pops = [pop for pop in all_pops if pop.endswith('t3')]\n",
    "                    causal_whitelist = [(from_pop,to_pop) for from_pop in from_pops for to_pop in to_pops]\n",
    "\n",
    "                    nFromNodes = np.shape(from_pops)[0]\n",
    "                    nToNodes = np.shape(to_pops)[0]\n",
    "\n",
    "                    DAGs_randstart = np.zeros((num_starting_points, nFromNodes, nToNodes))\n",
    "                    DAGs_randstart_shuffle = np.zeros((num_starting_points, nFromNodes, nToNodes))\n",
    "                    score_randstart = np.zeros((num_starting_points))\n",
    "                    score_randstart_shuffle = np.zeros((num_starting_points))\n",
    "\n",
    "                    # step 1: randomize the starting point for num_starting_points times\n",
    "                    for istarting_points in np.arange(0,num_starting_points,1):\n",
    "\n",
    "                        # try different down/re-sampling size\n",
    "                        bhv_df = bhv_df_all.sample(isamplingsize,replace = True, random_state = istarting_points) # take the subset for DBN training\n",
    "                        aic = AicScore(bhv_df)\n",
    "\n",
    "                        #Anirban(Alec) shuffle, slow\n",
    "                        bhv_df_shuffle, df_shufflekeys = EfficientShuffle(bhv_df,round(time()))\n",
    "                        aic_shuffle = AicScore(bhv_df_shuffle)\n",
    "\n",
    "                        np.random.seed(istarting_points)\n",
    "                        random.seed(istarting_points)\n",
    "                        starting_edges = random.sample(causal_whitelist, np.random.randint(1,len(causal_whitelist)))\n",
    "                        starting_graph = DAG()\n",
    "                        starting_graph.add_nodes_from(nodes=all_pops)\n",
    "                        starting_graph.add_edges_from(ebunch=starting_edges)\n",
    "\n",
    "                        best_model,edges,DAGs = train_DBN_multiLag_training_only(bhv_df,starting_graph,colnames,eventnames,from_pops,to_pops)           \n",
    "                        DAGs[0][np.isnan(DAGs[0])]=0\n",
    "\n",
    "                        DAGs_randstart[istarting_points,:,:] = DAGs[0]\n",
    "                        score_randstart[istarting_points] = aic.score(best_model)\n",
    "\n",
    "                        # step 2: add the shffled data results\n",
    "                        # shuffled bhv_df\n",
    "                        best_model,edges,DAGs = train_DBN_multiLag_training_only(bhv_df_shuffle,starting_graph,colnames,eventnames,from_pops,to_pops)           \n",
    "                        DAGs[0][np.isnan(DAGs[0])]=0\n",
    "\n",
    "                        DAGs_randstart_shuffle[istarting_points,:,:] = DAGs[0]\n",
    "                        score_randstart_shuffle[istarting_points] = aic_shuffle.score(best_model)\n",
    "\n",
    "                    DAGs_alltypes[iDBN_group_typename] = DAGs_randstart \n",
    "                    DAGs_shuffle_alltypes[iDBN_group_typename] = DAGs_randstart_shuffle\n",
    "\n",
    "                    DAGs_scores_alltypes[iDBN_group_typename] = score_randstart\n",
    "                    DAGs_shuffle_scores_alltypes[iDBN_group_typename] = score_randstart_shuffle\n",
    "\n",
    "                    weighted_graphs = get_weighted_dags(DAGs_alltypes[iDBN_group_typename],nbootstraps)\n",
    "                    weighted_graphs_shuffled = get_weighted_dags(DAGs_shuffle_alltypes[iDBN_group_typename],nbootstraps)\n",
    "                    sig_edges = get_significant_edges(weighted_graphs,weighted_graphs_shuffled)\n",
    "\n",
    "                    weighted_graphs_alltypes[iDBN_group_typename] = weighted_graphs\n",
    "                    weighted_graphs_shuffled_alltypes[iDBN_group_typename] = weighted_graphs_shuffled\n",
    "                    sig_edges_alltypes[iDBN_group_typename] = sig_edges\n",
    "                    \n",
    "                except:\n",
    "                    DAGs_alltypes[iDBN_group_typename] = [] \n",
    "                    DAGs_shuffle_alltypes[iDBN_group_typename] = []\n",
    "\n",
    "                    DAGs_scores_alltypes[iDBN_group_typename] = []\n",
    "                    DAGs_shuffle_scores_alltypes[iDBN_group_typename] = []\n",
    "\n",
    "                    weighted_graphs_alltypes[iDBN_group_typename] = []\n",
    "                    weighted_graphs_shuffled_alltypes[iDBN_group_typename] = []\n",
    "                    sig_edges_alltypes[iDBN_group_typename] = []\n",
    "                \n",
    "            DAGscores_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = DAGs_scores_alltypes\n",
    "            DAGscores_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = DAGs_shuffle_scores_alltypes\n",
    "\n",
    "            weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = weighted_graphs_alltypes\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = weighted_graphs_shuffled_alltypes\n",
    "            sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = sig_edges_alltypes\n",
    "\n",
    "            \n",
    "    # save data\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(data_saved_subfolder):\n",
    "        os.makedirs(data_saved_subfolder)\n",
    "    if moreSampSize:  \n",
    "        with open(data_saved_subfolder+'/DAGscores_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'wb') as f:\n",
    "            pickle.dump(DAGscores_diffTempRo_diffSampSize, f)\n",
    "        with open(data_saved_subfolder+'/DAGscores_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'wb') as f:\n",
    "            pickle.dump(DAGscores_shuffled_diffTempRo_diffSampSize, f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'wb') as f:\n",
    "            pickle.dump(weighted_graphs_diffTempRo_diffSampSize, f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'wb') as f:\n",
    "            pickle.dump(weighted_graphs_shuffled_diffTempRo_diffSampSize, f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'wb') as f:\n",
    "            pickle.dump(sig_edges_diffTempRo_diffSampSize, f)\n",
    "\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/DAGscores_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(DAGscores_diffTempRo_diffSampSize, f)\n",
    "        with open(data_saved_subfolder+'/DAGscores_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(DAGscores_shuffled_diffTempRo_diffSampSize, f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(weighted_graphs_diffTempRo_diffSampSize, f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(weighted_graphs_shuffled_diffTempRo_diffSampSize, f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(sig_edges_diffTempRo_diffSampSize, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf1eea",
   "metadata": {},
   "source": [
    "### plot graphs - show the edge with arrows; show the best time bin and row number; show the three time lag separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FOR PLOT!! \n",
    "# define DBN related summarizing variables\n",
    "DBN_group_typenames = ['self','coop(1s)','no-vision']\n",
    "DBN_group_typeIDs  =  [1,3,5]\n",
    "DBN_group_coopthres = [0,1,0]\n",
    "nDBN_groups = np.shape(DBN_group_typenames)[0]\n",
    "\n",
    "\n",
    "# make sure these variables are the same as in the previous steps\n",
    "# temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "ntemp_reses = np.shape(temp_resolus)[0]\n",
    "#\n",
    "if moreSampSize:\n",
    "    # different data (down/re)sampling numbers\n",
    "    # samplingsizes = np.arange(1100,3000,100)\n",
    "    samplingsizes = [1100]\n",
    "    # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "    # samplingsizes = [100,500]\n",
    "    # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "    samplingsizes_name = list(map(str, samplingsizes))\n",
    "else:\n",
    "    samplingsizes_name = ['min_row_number']   \n",
    "nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "# make sure these variables are consistent with the train_DBN_alec.py settings\n",
    "# eventnames = [\"pull1\",\"pull2\",\"gaze1\",\"gaze2\"]\n",
    "eventnames = [\"M1pull\",\"M2pull\",\"M1gaze\",\"M2gaze\"]\n",
    "eventnode_locations = [[0,1],[1,1],[0,0],[1,0]]\n",
    "eventname_locations = [[-0.5,1.0],[1.2,1],[-0.6,0],[1.2,0]]\n",
    "# indicate where edge starts\n",
    "# for the self edge, it's the center of the self loop\n",
    "nodearrow_locations = [[[0.00,1.25],[0.25,1.10],[-.10,0.75],[0.15,0.65]],\n",
    "                       [[0.75,1.00],[1.00,1.25],[0.85,0.65],[1.10,0.75]],\n",
    "                       [[0.00,0.25],[0.25,0.35],[0.00,-.25],[0.25,-.10]],\n",
    "                       [[0.75,0.35],[1.00,0.25],[0.75,0.00],[1.00,-.25]]]\n",
    "# indicate where edge goes\n",
    "# for the self edge, it's the theta1 and theta2 (with fixed radius)\n",
    "nodearrow_directions = [[[ -45,-180],[0.50,0.00],[0.00,-.50],[0.50,-.50]],\n",
    "                        [[-.50,0.00],[ -45,-180],[-.50,-.50],[0.00,-.50]],\n",
    "                        [[0.00,0.50],[0.50,0.50],[ 180,  45],[0.50,0.00]],\n",
    "                        [[-.50,0.50],[0.00,0.50],[-.50,0.00],[ 180,  45]]]\n",
    "\n",
    "nevents = np.size(eventnames)\n",
    "# eventnodes_color = ['b','r','y','g']\n",
    "eventnodes_color = ['#BF3EFF','#FF7F00','#BF3EFF','#FF7F00']\n",
    "eventnodes_shape = [\"o\",\"o\",\"^\",\"^\"]\n",
    "    \n",
    "savefigs = 1\n",
    "\n",
    "# different session conditions (aka DBN groups)\n",
    "# different time lags (t_-3, t_-2 and t_-1)\n",
    "fig, axs = plt.subplots(6,nDBN_groups)\n",
    "fig.set_figheight(48)\n",
    "fig.set_figwidth(8*nDBN_groups)\n",
    "\n",
    "time_lags = ['t_-3','t_-2','t_-1']\n",
    "fromRowIDs =[[0,1,2,3],[4,5,6,7],[8,9,10,11]]\n",
    "ntime_lags = np.shape(time_lags)[0]\n",
    "\n",
    "temp_resolu = temp_resolus[0]\n",
    "j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "for ilag in np.arange(0,ntime_lags,1):\n",
    "    \n",
    "    time_lag_name = time_lags[ilag]\n",
    "    fromRowID = fromRowIDs[ilag]\n",
    "    \n",
    "    for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "\n",
    "        try:\n",
    "\n",
    "            iDBN_group_typename = DBN_group_typenames[iDBN_group]\n",
    "\n",
    "            weighted_graphs_tgt = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            weighted_graphs_shuffled_tgt = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            # sig_edges_tgt = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            sig_edges_tgt = get_significant_edges(weighted_graphs_tgt,weighted_graphs_shuffled_tgt)\n",
    "           \n",
    "            #sig_edges_tgt = sig_edges_tgt*((weighted_graphs_tgt.mean(axis=0)>0.5)*1)\n",
    "            \n",
    "            sig_avg_dags = weighted_graphs_tgt.mean(axis = 0) * sig_edges_tgt\n",
    "            sig_avg_dags = sig_avg_dags[fromRowID,:]\n",
    "\n",
    "            # plot\n",
    "            axs[ilag*2+0,iDBN_group].set_title(iDBN_group_typename,fontsize=18)\n",
    "            axs[ilag*2+0,iDBN_group].set_xlim([-0.5,1.5])\n",
    "            axs[ilag*2+0,iDBN_group].set_ylim([-0.5,1.5])\n",
    "            axs[ilag*2+0,iDBN_group].set_xticks([])\n",
    "            axs[ilag*2+0,iDBN_group].set_xticklabels([])\n",
    "            axs[ilag*2+0,iDBN_group].set_yticks([])\n",
    "            axs[ilag*2+0,iDBN_group].set_yticklabels([])\n",
    "            axs[ilag*2+0,iDBN_group].spines['top'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['right'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['bottom'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['left'].set_visible(False)\n",
    "            # axs[ilag*2+0,iDBN_group].axis('equal')\n",
    "\n",
    "            \n",
    "            for ieventnode in np.arange(0,nevents,1):\n",
    "                # plot the event nodes\n",
    "                axs[ilag*2+0,iDBN_group].plot(eventnode_locations[ieventnode][0],eventnode_locations[ieventnode][1],\n",
    "                                              eventnodes_shape[ieventnode],markersize=60,markerfacecolor=eventnodes_color[ieventnode],\n",
    "                                              markeredgecolor='none')              \n",
    "                #axs[ilag*2+0,iDBN_group].text(eventname_locations[ieventnode][0],eventname_locations[ieventnode][1],\n",
    "                #                       eventnames[ieventnode],fontsize=15)\n",
    "                \n",
    "                clmap = mpl.cm.get_cmap('Greens')\n",
    "                \n",
    "                # plot the event edges\n",
    "                for ifromNode in np.arange(0,nevents,1):\n",
    "                    for itoNode in np.arange(0,nevents,1):\n",
    "                        edge_weight_tgt = sig_avg_dags[ifromNode,itoNode]\n",
    "                        if edge_weight_tgt>0:\n",
    "                            if not ifromNode == itoNode:\n",
    "                                #axs[ilag*2+0,iDBN_group].plot(eventnode_locations[ifromNode],eventnode_locations[itoNode],'k-',linewidth=edge_weight_tgt*3)\n",
    "                                axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0],\n",
    "                                                        nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                        nodearrow_directions[ifromNode][itoNode][0],\n",
    "                                                        nodearrow_directions[ifromNode][itoNode][1],\n",
    "                                                        # head_width=0.08*abs(edge_weight_tgt),\n",
    "                                                        # width=0.04*abs(edge_weight_tgt),\n",
    "                                                        head_width=0.08,\n",
    "                                                        width=0.04,   \n",
    "                                                        color = clmap(edge_weight_tgt))\n",
    "                            if ifromNode == itoNode:\n",
    "                                ring = mpatches.Wedge(nodearrow_locations[ifromNode][itoNode],\n",
    "                                                      .1, nodearrow_directions[ifromNode][itoNode][0],\n",
    "                                                      nodearrow_directions[ifromNode][itoNode][1], \n",
    "                                                      # 0.04*abs(edge_weight_tgt),\n",
    "                                                      0.04,\n",
    "                                                      color = clmap(edge_weight_tgt))\n",
    "                                p = PatchCollection(\n",
    "                                    [ring], \n",
    "                                    facecolor=clmap(edge_weight_tgt), \n",
    "                                    edgecolor=clmap(edge_weight_tgt)\n",
    "                                )\n",
    "                                axs[ilag*2+0,iDBN_group].add_collection(p)\n",
    "                                # add arrow head\n",
    "                                if ifromNode < 2:\n",
    "                                    axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0]-0.1+0.02*edge_weight_tgt,\n",
    "                                                            nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                            0,-0.05,color=clmap(edge_weight_tgt),\n",
    "                                                            # head_width=0.08*edge_weight_tgt,width=0.04*edge_weight_tgt\n",
    "                                                            head_width=0.08,width=0.04      \n",
    "                                                            )\n",
    "                                else:\n",
    "                                    axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0]-0.1+0.02*edge_weight_tgt,\n",
    "                                                            nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                            0,0.02,color=clmap(edge_weight_tgt),\n",
    "                                                            # head_width=0.08*edge_weight_tgt,width=0.04*edge_weight_tgt\n",
    "                                                            head_width=0.08,width=0.04      \n",
    "                                                            )\n",
    "\n",
    "            # heatmap for the weights\n",
    "            sig_avg_dags_df = pd.DataFrame(sig_avg_dags)\n",
    "            sig_avg_dags_df.columns = eventnames\n",
    "            sig_avg_dags_df.index = eventnames\n",
    "            vmin,vmax = 0,1\n",
    "            import matplotlib as mpl\n",
    "            norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "            im = axs[ilag*2+1,iDBN_group].pcolormesh(sig_avg_dags_df,cmap=\"Greens\",norm=norm)\n",
    "            #\n",
    "            if iDBN_group == nDBN_groups-1:\n",
    "                cax = axs[ilag*2+1,iDBN_group].inset_axes([1.04, 0.2, 0.05, 0.8])\n",
    "                fig.colorbar(im, ax=axs[ilag*2+1,iDBN_group], cax=cax,label='edge confidence')\n",
    "\n",
    "            axs[ilag*2+1,iDBN_group].axis('equal')\n",
    "            axs[ilag*2+1,iDBN_group].set_xlabel('to Node',fontsize=14)\n",
    "            axs[ilag*2+1,iDBN_group].set_xticks(np.arange(0.5,4.5,1))\n",
    "            axs[ilag*2+1,iDBN_group].set_xticklabels(eventnames)\n",
    "            if iDBN_group == 0:\n",
    "                axs[ilag*2+1,iDBN_group].set_ylabel('from Node',fontsize=14)\n",
    "                axs[ilag*2+1,iDBN_group].set_yticks(np.arange(0.5,4.5,1))\n",
    "                axs[ilag*2+1,iDBN_group].set_yticklabels(eventnames)\n",
    "                axs[ilag*2+1,iDBN_group].text(-1.5,1,time_lag_name+' time lag',rotation=90,fontsize=20)\n",
    "                axs[ilag*2+0,iDBN_group].text(-1.25,0,time_lag_name+' time lag',rotation=90,fontsize=20)\n",
    "            else:\n",
    "                axs[ilag*2+1,iDBN_group].set_yticks([])\n",
    "                axs[ilag*2+1,iDBN_group].set_yticklabels([])\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    if moreSampSize:\n",
    "        plt.savefig(figsavefolder+\"threeTimeLag_DAGs_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows.pdf')\n",
    "    else:  \n",
    "        plt.savefig(figsavefolder+\"threeTimeLag_DAGs_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'_'+j_sampsize_name+'.pdf')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34546be",
   "metadata": {},
   "source": [
    "### plot graphs - show the edge differences, use one condition as the base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FOR PLOT!! \n",
    "# define DBN related summarizing variables\n",
    "DBN_group_typenames = ['self','coop(1s)','no-vision']\n",
    "DBN_group_typeIDs  =  [1,3,5]\n",
    "DBN_group_coopthres = [0,1,0]\n",
    "nDBN_groups = np.shape(DBN_group_typenames)[0]\n",
    "\n",
    "# make sure these variables are the same as in the previous steps\n",
    "# temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "ntemp_reses = np.shape(temp_resolus)[0]\n",
    "#\n",
    "if moreSampSize:\n",
    "    # different data (down/re)sampling numbers\n",
    "    # samplingsizes = np.arange(1100,3000,100)\n",
    "    samplingsizes = [1100]\n",
    "    # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "    # samplingsizes = [100,500]\n",
    "    # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "    samplingsizes_name = list(map(str, samplingsizes))\n",
    "else:\n",
    "    samplingsizes_name = ['min_row_number']   \n",
    "nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "basecondition = 'self'\n",
    "\n",
    "# make sure these variables are consistent with the train_DBN_alec.py settings\n",
    "# eventnames = [\"pull1\",\"pull2\",\"gaze1\",\"gaze2\"]\n",
    "eventnames = [\"M1pull\",\"M2pull\",\"M1gaze\",\"M2gaze\"]\n",
    "eventnode_locations = [[0,1],[1,1],[0,0],[1,0]]\n",
    "eventname_locations = [[-0.5,1.0],[1.2,1],[-0.6,0],[1.2,0]]\n",
    "# indicate where edge starts\n",
    "# for the self edge, it's the center of the self loop\n",
    "nodearrow_locations = [[[0.00,1.25],[0.25,1.10],[-.10,0.75],[0.15,0.65]],\n",
    "                       [[0.75,1.00],[1.00,1.25],[0.85,0.65],[1.10,0.75]],\n",
    "                       [[0.00,0.25],[0.25,0.35],[0.00,-.25],[0.25,-.10]],\n",
    "                       [[0.75,0.35],[1.00,0.25],[0.75,0.00],[1.00,-.25]]]\n",
    "# indicate where edge goes\n",
    "# for the self edge, it's the theta1 and theta2 (with fixed radius)\n",
    "nodearrow_directions = [[[ -45,-180],[0.50,0.00],[0.00,-.50],[0.50,-.50]],\n",
    "                        [[-.50,0.00],[ -45,-180],[-.50,-.50],[0.00,-.50]],\n",
    "                        [[0.00,0.50],[0.50,0.50],[ 180,  45],[0.50,0.00]],\n",
    "                        [[-.50,0.50],[0.00,0.50],[-.50,0.00],[ 180,  45]]]\n",
    "\n",
    "nevents = np.size(eventnames)\n",
    "# eventnodes_color = ['b','r','y','g']\n",
    "eventnodes_color = ['#BF3EFF','#FF7F00','#BF3EFF','#FF7F00']\n",
    "eventnodes_shape = [\"o\",\"o\",\"^\",\"^\"]\n",
    "\n",
    "nFromNodes = nevents\n",
    "nToNodes = nevents\n",
    "    \n",
    "savefigs = 1\n",
    "\n",
    "# different session conditions (aka DBN groups)\n",
    "# different time lags (t_-3, t_-2 and t_-1)\n",
    "fig, axs = plt.subplots(6,nDBN_groups)\n",
    "fig.set_figheight(48)\n",
    "fig.set_figwidth(8*nDBN_groups)\n",
    "\n",
    "time_lags = ['t_-3','t_-2','t_-1']\n",
    "fromRowIDs =[[0,1,2,3],[4,5,6,7],[8,9,10,11]]\n",
    "ntime_lags = np.shape(time_lags)[0]\n",
    "\n",
    "temp_resolu = temp_resolus[0]\n",
    "j_sampsize_name = samplingsizes_name[0]    \n",
    "    \n",
    "weighted_graphs_tgt = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][basecondition]\n",
    "weighted_graphs_shuffled_tgt = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][basecondition]\n",
    "#sig_edges_tgt = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][basecondition]\n",
    "sig_edges_tgt = get_significant_edges(weighted_graphs_tgt,weighted_graphs_shuffled_tgt)\n",
    "           \n",
    "# sig_edges_tgt = sig_edges_tgt*((weighted_graphs_tgt.mean(axis=0)>0.5)*1)\n",
    "\n",
    "weighted_graphs_base = weighted_graphs_tgt\n",
    "\n",
    "sig_edges_base = sig_edges_tgt\n",
    "\n",
    "sig_avg_dags_base =  weighted_graphs_base.mean(axis = 0) * sig_edges_base\n",
    "    \n",
    "    \n",
    "for ilag in np.arange(0,ntime_lags,1):\n",
    "    \n",
    "    time_lag_name = time_lags[ilag]\n",
    "    fromRowID = fromRowIDs[ilag]\n",
    "    \n",
    "       \n",
    "    for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "\n",
    "        try:\n",
    "\n",
    "            iDBN_group_typename = DBN_group_typenames[iDBN_group]\n",
    "\n",
    "\n",
    "            weighted_graphs_tgt = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            weighted_graphs_shuffled_tgt = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            # sig_edges_tgt = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            sig_edges_tgt = get_significant_edges(weighted_graphs_tgt,weighted_graphs_shuffled_tgt)\n",
    "           \n",
    "            #sig_edges_tgt = sig_edges_tgt*((weighted_graphs_tgt.mean(axis=0)>0.5)*1)\n",
    "            \n",
    "            if 0:\n",
    "                weighted_graphs_delta = (weighted_graphs_tgt-weighted_graphs_base)\n",
    "                weighted_graphs_delta = weighted_graphs_delta.mean(axis=0)\n",
    "                #\n",
    "                sig_edges_delta = ((sig_edges_tgt+sig_edges_base)>0)*1\n",
    "            else:\n",
    "                weighted_graphs_delta,sig_edges_delta = Modulation_Index(weighted_graphs_base, weighted_graphs_tgt,\n",
    "                                                                         sig_edges_base, sig_edges_tgt, 150)\n",
    "                weighted_graphs_delta = weighted_graphs_delta.mean(axis=0)\n",
    "                \n",
    "            sig_avg_dags = weighted_graphs_delta * sig_edges_delta\n",
    "            sig_avg_dags = sig_avg_dags[fromRowID,:]\n",
    "\n",
    "            # plot\n",
    "            axs[ilag*2+0,iDBN_group].set_title(iDBN_group_typename,fontsize=18)\n",
    "            axs[ilag*2+0,iDBN_group].set_xlim([-0.5,1.5])\n",
    "            axs[ilag*2+0,iDBN_group].set_ylim([-0.5,1.5])\n",
    "            axs[ilag*2+0,iDBN_group].set_xticks([])\n",
    "            axs[ilag*2+0,iDBN_group].set_xticklabels([])\n",
    "            axs[ilag*2+0,iDBN_group].set_yticks([])\n",
    "            axs[ilag*2+0,iDBN_group].set_yticklabels([])\n",
    "            axs[ilag*2+0,iDBN_group].spines['top'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['right'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['bottom'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['left'].set_visible(False)\n",
    "            # axs[ilag*2+0,iDBN_group].axis('equal')\n",
    "\n",
    "            for ieventnode in np.arange(0,nevents,1):\n",
    "                # plot the event nodes\n",
    "                axs[ilag*2+0,iDBN_group].plot(eventnode_locations[ieventnode][0],eventnode_locations[ieventnode][1],\n",
    "                                              eventnodes_shape[ieventnode],markersize=60,markerfacecolor=eventnodes_color[ieventnode],\n",
    "                                              markeredgecolor='none')              \n",
    "                \n",
    "                axs[ilag*2+0,iDBN_group].text(eventname_locations[ieventnode][0],eventname_locations[ieventnode][1],\n",
    "                                       eventnames[ieventnode],fontsize=10)\n",
    "                \n",
    "                clmap = mpl.cm.get_cmap('bwr')\n",
    "                \n",
    "                # plot the event edges\n",
    "                for ifromNode in np.arange(0,nevents,1):\n",
    "                    for itoNode in np.arange(0,nevents,1):\n",
    "                        edge_weight_tgt = sig_avg_dags[ifromNode,itoNode]\n",
    "                        if edge_weight_tgt!=0:\n",
    "                            if not ifromNode == itoNode:\n",
    "                                #axs[ilag*2+0,iDBN_group].plot(eventnode_locations[ifromNode],eventnode_locations[itoNode],'k-',linewidth=edge_weight_tgt*3)\n",
    "                                axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0],\n",
    "                                                        nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                        nodearrow_directions[ifromNode][itoNode][0],\n",
    "                                                        nodearrow_directions[ifromNode][itoNode][1],\n",
    "                                                        # head_width=0.08*abs(edge_weight_tgt),\n",
    "                                                        # width=0.04*abs(edge_weight_tgt),\n",
    "                                                        head_width=0.08,\n",
    "                                                        width=0.04,       \n",
    "                                                        color = clmap((1+edge_weight_tgt)/2))\n",
    "                            if ifromNode == itoNode:\n",
    "                                ring = mpatches.Wedge(nodearrow_locations[ifromNode][itoNode],\n",
    "                                                      .1, nodearrow_directions[ifromNode][itoNode][0],\n",
    "                                                      nodearrow_directions[ifromNode][itoNode][1], \n",
    "                                                      # 0.04*abs(edge_weight_tgt)\n",
    "                                                      0.04\n",
    "                                                     )\n",
    "                                p = PatchCollection(\n",
    "                                    [ring], \n",
    "                                    facecolor=clmap((1+edge_weight_tgt)/2), \n",
    "                                    edgecolor=clmap((1+edge_weight_tgt)/2)\n",
    "                                )\n",
    "                                axs[ilag*2+0,iDBN_group].add_collection(p)\n",
    "                                # add arrow head\n",
    "                                if ifromNode < 2:\n",
    "                                    axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0]-0.1+0.02*edge_weight_tgt,\n",
    "                                                            nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                            0,-0.05,color=clmap((1+edge_weight_tgt)/2),\n",
    "                                                            # head_width=0.08*edge_weight_tgt,width=0.04*edge_weight_tgt\n",
    "                                                            head_width=0.08,width=0.04      \n",
    "                                                            )\n",
    "                                else:\n",
    "                                    axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0]-0.1+0.02*edge_weight_tgt,\n",
    "                                                            nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                            0,0.02,color=clmap((1+edge_weight_tgt)/2),\n",
    "                                                            # head_width=0.08*edge_weight_tgt,width=0.04*edge_weight_tgt\n",
    "                                                            head_width=0.08,width=0.04      \n",
    "                                                            )\n",
    "\n",
    "            # heatmap for the weights\n",
    "            sig_avg_dags_df = pd.DataFrame(sig_avg_dags)\n",
    "            sig_avg_dags_df.columns = eventnames\n",
    "            sig_avg_dags_df.index = eventnames\n",
    "            vmin,vmax = -1,1\n",
    "            norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "            im = axs[ilag*2+1,iDBN_group].pcolormesh(sig_avg_dags_df,cmap=\"bwr\",norm=norm)\n",
    "            #-\n",
    "            if iDBN_group == nDBN_groups-1:\n",
    "                cax = axs[ilag*2+1,iDBN_group].inset_axes([1.04, 0.2, 0.05, 0.8])\n",
    "                fig.colorbar(im, ax=axs[ilag*2+1,iDBN_group], cax=cax,label='edge confidence')\n",
    "\n",
    "            axs[ilag*2+1,iDBN_group].axis('equal')\n",
    "            axs[ilag*2+1,iDBN_group].set_xlabel('to Node',fontsize=14)\n",
    "            axs[ilag*2+1,iDBN_group].set_xticks(np.arange(0.5,4.5,1))\n",
    "            axs[ilag*2+1,iDBN_group].set_xticklabels(eventnames)\n",
    "            if iDBN_group == 0:\n",
    "                axs[ilag*2+1,iDBN_group].set_ylabel('from Node',fontsize=14)\n",
    "                axs[ilag*2+1,iDBN_group].set_yticks(np.arange(0.5,4.5,1))\n",
    "                axs[ilag*2+1,iDBN_group].set_yticklabels(eventnames)\n",
    "                axs[ilag*2+1,iDBN_group].text(-1.5,1,time_lag_name+' time lag',rotation=90,fontsize=20)\n",
    "                axs[ilag*2+0,iDBN_group].text(-1.25,0,time_lag_name+' time lag',rotation=90,fontsize=20)\n",
    "            else:\n",
    "                axs[ilag*2+1,iDBN_group].set_yticks([])\n",
    "                axs[ilag*2+1,iDBN_group].set_yticklabels([])\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    if moreSampSize:\n",
    "        plt.savefig(figsavefolder+\"threeTimeLag_DAGs_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_EdgeFifferenceFrom_'+basecondition+'AsBase.pdf')\n",
    "    else:\n",
    "        plt.savefig(figsavefolder+\"threeTimeLag_DAGs_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'_'+j_sampsize_name+'_EdgeFifferenceFrom_'+basecondition+'AsBase.pdf')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feeea79",
   "metadata": {},
   "source": [
    "## Plots that include all pairs\n",
    "## Plots the frequency/distribution of certain edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe04c2f",
   "metadata": {},
   "source": [
    "### pull <-> pull; with animal gaze -> pull; across animal pull -> gaze; with animal pull -> gaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "mergetempRos = 0 # 1: merge different time bins\n",
    "\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "temp_resolu = 1\n",
    "\n",
    "# ONLY FOR PLOT!! \n",
    "# define DBN related summarizing variables\n",
    "DBN_group_typenames = ['self','coop(1s)','no-vision']\n",
    "DBN_group_typeIDs  =  [1,3,5]\n",
    "DBN_group_coopthres = [0,1,0]\n",
    "nDBN_groups = np.shape(DBN_group_typenames)[0]\n",
    "\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    \n",
    "    # initiate figure\n",
    "    fig, axs = plt.subplots(nDBN_groups,2) # nDBN_groups(3) task conditions; 2 animal individual\n",
    "    fig.set_figheight(8*nDBN_groups)\n",
    "    fig.set_figwidth(15*2)\n",
    "    \n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    if not mergetempRos:\n",
    "        with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder+animal2_fixedorder+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "            DBN_input_data_alltypes = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'//DBN_input_data_alltypes_'+animal1_fixedorder+animal2_fixedorder+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "            DBN_input_data_alltypes = pickle.load(f)\n",
    "            \n",
    "    for igroup in np.arange(0,nDBN_groups,1):\n",
    "        DBN_group_typename = DBN_group_typenames[igroup]\n",
    "        \n",
    "        DBN_input_data_igroup = DBN_input_data_alltypes[DBN_group_typename]\n",
    "              \n",
    "        # from animal 1    \n",
    "        # 1s lag; pull1->pull2\n",
    "        xxx = ((np.array(DBN_input_data_igroup['pull1_t0'])==1)&(np.array(DBN_input_data_igroup['pull2_t1'])==1))*1\n",
    "        # axs[igroup,0].plot(xxx,'k',label='pull1->pull2')\n",
    "        if np.sum(xxx)>0:\n",
    "            xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "            xxx = np.where(xxx==1)[0]\n",
    "            kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "            log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "            axs[igroup,0].plot(xxx_plot,np.exp(log_dens),'k',label='pull1->pull2')\n",
    "        \n",
    "        # 1s lag; gaze1->pull1\n",
    "        # xxx = ((np.array(DBN_input_data_igroup['owgaze1_t0'])==1)&(np.array(DBN_input_data_igroup['pull1_t1'])==1))*1\n",
    "        # #axs[igroup,0].plot(xxx,'g',label='gaze1->pull1')\n",
    "        # if np.sum(xxx)>0:\n",
    "        #     xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "        #     xxx = np.where(xxx==1)[0]\n",
    "        #     kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "        #     log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "        #     axs[igroup,0].plot(xxx_plot,np.exp(log_dens),'g',label='gaze1->pull1')\n",
    "        \n",
    "        # 1s lag; gaze1->pull2\n",
    "        xxx = ((np.array(DBN_input_data_igroup['owgaze1_t0'])==1)&(np.array(DBN_input_data_igroup['pull2_t1'])==1))*1\n",
    "        # axs[igroup,0].plot(xxx,'r',label='gaze1->pull2')\n",
    "        if np.sum(xxx)>0:\n",
    "            xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "            xxx = np.where(xxx==1)[0]\n",
    "            kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "            log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "            axs[igroup,0].plot(xxx_plot,np.exp(log_dens),'r',label='gaze1->pull2')\n",
    "        \n",
    "        # 1s lag; pull1->gaze2\n",
    "        xxx = ((np.array(DBN_input_data_igroup['pull1_t0'])==1)&(np.array(DBN_input_data_igroup['owgaze2_t1'])==1))*1\n",
    "        # axs[igroup,0].plot(xxx,'b',label='pull1->gaze2')\n",
    "        if np.sum(xxx)>0:\n",
    "            xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "            xxx = np.where(xxx==1)[0]\n",
    "            kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "            log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "            axs[igroup,0].plot(xxx_plot,np.exp(log_dens),'b',label='pull1->gaze2')\n",
    "\n",
    "        axs[igroup,0].set_xlabel('time/s',fontsize=15)\n",
    "        axs[igroup,0].set_ylabel('probability density',fontsize=15)\n",
    "        axs[igroup,0].set_title('from '+animal1_fixedorder+' in '+DBN_group_typename,fontsize = 16)\n",
    "        if igroup == nDBN_groups-1:\n",
    "            axs[igroup,0].legend()\n",
    "            \n",
    "        # from animal 2\n",
    "        # 1s lag; pull2->pull1\n",
    "        xxx = ((np.array(DBN_input_data_igroup['pull2_t0'])==1)&(np.array(DBN_input_data_igroup['pull1_t1'])==1))*1\n",
    "        #axs[igroup,1].plot(xxx,'k',label='pull2->pull1')\n",
    "        if np.sum(xxx)>0:\n",
    "            xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "            xxx = np.where(xxx==1)[0]\n",
    "            kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "            log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "            axs[igroup,1].plot(xxx_plot,np.exp(log_dens),'k',label='pull2->pull1')\n",
    "            \n",
    "        # 1s lag; gaze2->pull2\n",
    "        # xxx = ((np.array(DBN_input_data_igroup['owgaze2_t0'])==1)&(np.array(DBN_input_data_igroup['pull2_t1'])==1))*1\n",
    "        # #axs[igroup,1].plot(xxx,'g',label='gaze2->pull2')\n",
    "        # if np.sum(xxx)>0:\n",
    "        #     xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "        #     xxx = np.where(xxx==1)[0]\n",
    "        #     kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "        #     log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "        #     axs[igroup,1].plot(xxx_plot,np.exp(log_dens),'g',label='gaze2->pull2')\n",
    "        \n",
    "        # 1s lag; gaze2->pull1\n",
    "        xxx = ((np.array(DBN_input_data_igroup['owgaze2_t0'])==1)&(np.array(DBN_input_data_igroup['pull1_t1'])==1))*1\n",
    "        #axs[igroup,1].plot(xxx,'r',label='gaze2->pull1')\n",
    "        if np.sum(xxx)>0:\n",
    "            xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "            xxx = np.where(xxx==1)[0]\n",
    "            kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "            log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "            axs[igroup,1].plot(xxx_plot,np.exp(log_dens),'r',label='gaze2->pull1')\n",
    "        \n",
    "        # 1s lag; pull2->gaze1\n",
    "        xxx = ((np.array(DBN_input_data_igroup['pull2_t0'])==1)&(np.array(DBN_input_data_igroup['owgaze1_t1'])==1))*1\n",
    "        #axs[igroup,1].plot(xxx,'b',label='pull2->gaze1')\n",
    "        if np.sum(xxx)>0:\n",
    "            xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "            xxx = np.where(xxx==1)[0]\n",
    "            kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "            log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "            axs[igroup,1].plot(xxx_plot,np.exp(log_dens),'b',label='pull2->gaze1')\n",
    "            \n",
    "        axs[igroup,1].set_xlabel('time/s',fontsize=15)\n",
    "        axs[igroup,1].set_ylabel('probability density',fontsize=15)\n",
    "        axs[igroup,1].set_title('from '+animal2_fixedorder+' in '+DBN_group_typename,fontsize = 16)\n",
    "        if igroup == nDBN_groups-1:\n",
    "            axs[igroup,1].legend()\n",
    "            \n",
    "    \n",
    "    savefig = 1\n",
    "    if savefig:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'eventpair_appearanceDensity_Resolu'+str(temp_resolu)+'s_1stimelag_'+animal1_fixedorder+animal2_fixedorder+'.pdf')\n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29bb916",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx1 = ((np.array(DBN_input_data_igroup['pull1_t0'])==1)&(np.array(DBN_input_data_igroup['pull2_t1'])==1))*1\n",
    "xxx2 = ((np.array(DBN_input_data_igroup['pull2_t0'])==1)&(np.array(DBN_input_data_igroup['owgaze1_t1'])==1))*1\n",
    "xxx3 = ((np.array(DBN_input_data_igroup['owgaze1_t0'])==1)&(np.array(DBN_input_data_igroup['pull2_t1'])==1))*1\n",
    "xxx4 = ((np.array(DBN_input_data_igroup['pull2_t0'])==1)&(np.array(DBN_input_data_igroup['pull1_t1'])==1))*1\n",
    "rr,pp = scipy.stats.spearmanr(xxx1, xxx4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5d9ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84a64be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ce20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34a4f374",
   "metadata": {},
   "source": [
    "### across animal pull -> gaze; across animal gaze -> pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1defc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "mergetempRos = 0 # 1: merge different time bins\n",
    "\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "temp_resolu = 1\n",
    "\n",
    "# ONLY FOR PLOT!! \n",
    "# define DBN related summarizing variables\n",
    "DBN_group_typenames = ['self','coop(1s)','no-vision']\n",
    "DBN_group_typeIDs  =  [1,3,5]\n",
    "DBN_group_coopthres = [0,1,0]\n",
    "nDBN_groups = np.shape(DBN_group_typenames)[0]\n",
    "\n",
    "# type of pulls (allpulls,succpulls, failedpulls)\n",
    "pulltype = 'succpulls'\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    \n",
    "    # initiate figure\n",
    "    fig, axs = plt.subplots(nDBN_groups,2) # nDBN_groups(3) task conditions; 2 animal individual\n",
    "    fig.set_figheight(8*nDBN_groups)\n",
    "    fig.set_figwidth(15*2)\n",
    "    \n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    if not mergetempRos:\n",
    "        with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder+animal2_fixedorder+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "            DBN_input_data_alltypes = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'//DBN_input_data_alltypes_'+animal1_fixedorder+animal2_fixedorder+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "            DBN_input_data_alltypes = pickle.load(f)\n",
    "    # successful and failed pulls\n",
    "    data_saved_subfolder_sfpulls = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    if not mergetempRos:\n",
    "        with open(data_saved_subfolder_sfpulls +'/DBN_input_data_alltypes_'+animal1_fixedorder+animal2_fixedorder+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "            DBN_input_data_alltypes_sfpulls = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder_sfpulls+'/DBN_input_data_alltypes_'+animal1_fixedorder+animal2_fixedorder+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "            DBN_input_data_alltypes_sfpulls = pickle.load(f)\n",
    "            \n",
    "    for igroup in np.arange(0,nDBN_groups,1):\n",
    "        DBN_group_typename = DBN_group_typenames[igroup]\n",
    "        \n",
    "        DBN_input_data_igroup = DBN_input_data_alltypes[DBN_group_typename]\n",
    "              \n",
    "        # from animal 1    \n",
    "        # 1s lag; pull1->pull2\n",
    "        if pulltype == 'allpulls':\n",
    "            xxx = np.array(DBN_input_data_igroup['pull1_t0'])*0.0005\n",
    "        elif pulltype == 'succpulls':\n",
    "            xxx = np.array(DBN_input_data_alltypes_sfpulls['succpull'][DBN_group_typename]['pull1_t0'])*0.0005\n",
    "        elif pulltype == 'failedpulls':\n",
    "            xxx = np.array(DBN_input_data_alltypes_sfpulls['failedpull'][DBN_group_typename]['pull1_t0'])*0.0005\n",
    "        axs[igroup,0].plot(xxx,'k',label='pull1->pull2')\n",
    "        if 0:\n",
    "            xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "            xxx = np.where(xxx==1)[0]\n",
    "            kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "            log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "            axs[igroup,0].plot(xxx_plot,np.exp(log_dens),'k',label='pull1->pull2')\n",
    "        \n",
    "        # 1s lag; gaze1->pull1\n",
    "        # xxx = ((np.array(DBN_input_data_igroup['owgaze1_t0'])==1)&(np.array(DBN_input_data_igroup['pull1_t1'])==1))*1\n",
    "        # #axs[igroup,0].plot(xxx,'g',label='gaze1->pull1')\n",
    "        # if np.sum(xxx)>0:\n",
    "        #     xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "        #     xxx = np.where(xxx==1)[0]\n",
    "        #     kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "        #     log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "        #     axs[igroup,0].plot(xxx_plot,np.exp(log_dens),'g',label='gaze1->pull1')\n",
    "        \n",
    "        # 1s lag; gaze1->pull2\n",
    "        xxx = ((np.array(DBN_input_data_igroup['owgaze1_t0'])==1)&(np.array(DBN_input_data_igroup['pull2_t1'])==1))*1\n",
    "        # axs[igroup,0].plot(xxx,'r',label='gaze1->pull2')\n",
    "        if np.sum(xxx)>0:\n",
    "            xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "            xxx = np.where(xxx==1)[0]\n",
    "            kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "            log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "            axs[igroup,0].plot(xxx_plot,np.exp(log_dens),'r',label='gaze1->pull2')\n",
    "        \n",
    "        # 1s lag; pull1->gaze2\n",
    "        xxx = ((np.array(DBN_input_data_igroup['pull1_t0'])==1)&(np.array(DBN_input_data_igroup['owgaze2_t1'])==1))*1\n",
    "        # axs[igroup,0].plot(xxx,'b',label='pull1->gaze2')\n",
    "        if np.sum(xxx)>0:\n",
    "            xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "            xxx = np.where(xxx==1)[0]\n",
    "            kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "            log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "            axs[igroup,0].plot(xxx_plot,np.exp(log_dens),'b',label='pull1->gaze2')\n",
    "\n",
    "        axs[igroup,0].set_xlabel('time/s',fontsize=15)\n",
    "        axs[igroup,0].set_ylabel('probability density',fontsize=15)\n",
    "        axs[igroup,0].set_title('from '+animal1_fixedorder+' in '+DBN_group_typename,fontsize = 16)\n",
    "        if igroup == nDBN_groups-1:\n",
    "            axs[igroup,0].legend()\n",
    "            \n",
    "        # from animal 2\n",
    "        # 1s lag; pull2->pull1\n",
    "        if pulltype == 'allpulls':\n",
    "            xxx = np.array(DBN_input_data_igroup['pull2_t0'])*0.0005\n",
    "        elif pulltype == 'succpulls':\n",
    "            xxx = np.array(DBN_input_data_alltypes_sfpulls['succpull'][DBN_group_typename]['pull2_t0'])*0.0005\n",
    "        elif pulltype == 'failedpulls':\n",
    "            xxx = np.array(DBN_input_data_alltypes_sfpulls['failedpull'][DBN_group_typename]['pull2_t0'])*0.0005\n",
    "        axs[igroup,1].plot(xxx,'k',label='pull2->pull1')\n",
    "        if 0:\n",
    "            xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "            xxx = np.where(xxx==1)[0]\n",
    "            kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "            log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "            axs[igroup,1].plot(xxx_plot,np.exp(log_dens),'k',label='pull2->pull1')\n",
    "            \n",
    "        # 1s lag; gaze2->pull2\n",
    "        # xxx = ((np.array(DBN_input_data_igroup['owgaze2_t0'])==1)&(np.array(DBN_input_data_igroup['pull2_t1'])==1))*1\n",
    "        # #axs[igroup,1].plot(xxx,'g',label='gaze2->pull2')\n",
    "        # if np.sum(xxx)>0:\n",
    "        #     xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "        #     xxx = np.where(xxx==1)[0]\n",
    "        #     kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "        #     log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "        #     axs[igroup,1].plot(xxx_plot,np.exp(log_dens),'g',label='gaze2->pull2')\n",
    "        \n",
    "        # 1s lag; gaze2->pull1\n",
    "        xxx = ((np.array(DBN_input_data_igroup['owgaze2_t0'])==1)&(np.array(DBN_input_data_igroup['pull1_t1'])==1))*1\n",
    "        #axs[igroup,1].plot(xxx,'r',label='gaze2->pull1')\n",
    "        if np.sum(xxx)>0:\n",
    "            xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "            xxx = np.where(xxx==1)[0]\n",
    "            kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "            log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "            axs[igroup,1].plot(xxx_plot,np.exp(log_dens),'r',label='gaze2->pull1')\n",
    "        \n",
    "        # 1s lag; pull2->gaze1\n",
    "        xxx = ((np.array(DBN_input_data_igroup['pull2_t0'])==1)&(np.array(DBN_input_data_igroup['owgaze1_t1'])==1))*1\n",
    "        #axs[igroup,1].plot(xxx,'b',label='pull2->gaze1')\n",
    "        if np.sum(xxx)>0:\n",
    "            xxx_plot = np.linspace(0, np.shape(xxx)[0], 50000)\n",
    "            xxx = np.where(xxx==1)[0]\n",
    "            kde = KernelDensity(kernel=\"gaussian\", bandwidth=10).fit(xxx.reshape(-1, 1))\n",
    "            log_dens = kde.score_samples(xxx_plot.reshape(-1, 1))\n",
    "            axs[igroup,1].plot(xxx_plot,np.exp(log_dens),'b',label='pull2->gaze1')\n",
    "            \n",
    "        axs[igroup,1].set_xlabel('time/s',fontsize=15)\n",
    "        axs[igroup,1].set_ylabel('probability density',fontsize=15)\n",
    "        axs[igroup,1].set_title('from '+animal2_fixedorder+' in '+DBN_group_typename,fontsize = 16)\n",
    "        if igroup == nDBN_groups-1:\n",
    "            axs[igroup,1].legend()\n",
    "            \n",
    "    \n",
    "    savefig = 1\n",
    "    if savefig:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'eventpair_appearanceDensity_with'+pulltype+'_Resolu'+str(temp_resolu)+'s_1stimelag_'+animal1_fixedorder+animal2_fixedorder+'.pdf')\n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f72b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15716da1",
   "metadata": {},
   "source": [
    "### pull - pull dependency and leader/follower pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c367a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "mergetempRos = 0 # 1: merge different time bins\n",
    "\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "temp_resolu = 1\n",
    "\n",
    "# ONLY FOR PLOT!! \n",
    "# define DBN related summarizing variables\n",
    "DBN_group_typenames = ['self','coop(1s)','no-vision']\n",
    "DBN_group_typeIDs  =  [1,3,5]\n",
    "DBN_group_coopthres = [0,1,0]\n",
    "nDBN_groups = np.shape(DBN_group_typenames)[0]\n",
    "\n",
    "# type of pulls (allpulls,succpulls, failedpulls)\n",
    "pulltype = 'allpulls'\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    \n",
    "    # initiate figure\n",
    "    # fig, axs = plt.subplots(nDBN_groups,2) # nDBN_groups(3) task conditions; 2 animal individual\n",
    "    # fig.set_figheight(8*nDBN_groups)\n",
    "    # fig.set_figwidth(15*2)\n",
    "    \n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    if not mergetempRos:\n",
    "        with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder+animal2_fixedorder+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "            DBN_input_data_alltypes = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'//DBN_input_data_alltypes_'+animal1_fixedorder+animal2_fixedorder+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "            DBN_input_data_alltypes = pickle.load(f)\n",
    "    # successful and failed pulls\n",
    "    data_saved_subfolder_sfpulls = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    if not mergetempRos:\n",
    "        with open(data_saved_subfolder_sfpulls +'/DBN_input_data_alltypes_'+animal1_fixedorder+animal2_fixedorder+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "            DBN_input_data_alltypes_sfpulls = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder_sfpulls+'/DBN_input_data_alltypes_'+animal1_fixedorder+animal2_fixedorder+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "            DBN_input_data_alltypes_sfpulls = pickle.load(f)\n",
    "            \n",
    "    for igroup in np.arange(0,nDBN_groups,1):\n",
    "        DBN_group_typename = DBN_group_typenames[igroup]\n",
    "        \n",
    "        DBN_input_data_igroup = DBN_input_data_alltypes[DBN_group_typename]\n",
    "              \n",
    "        # from animal 1    \n",
    "        # 1s lag; pull1->pull2\n",
    "        if pulltype == 'allpulls':\n",
    "            xxx = ((np.array(DBN_input_data_igroup['pull1_t2'])==1)&(np.array(DBN_input_data_igroup['pull2_t3'])==1))\n",
    "        elif pulltype == 'succpulls':\n",
    "            xxx = ((np.array(DBN_input_data_alltypes_sfpulls['succpull'][DBN_group_typename]['pull1_t2'])==1)&\n",
    "                   (np.array(DBN_input_data_alltypes_sfpulls['succpull'][DBN_group_typename]['pull2_t3'])==1))\n",
    "        elif pulltype == 'failedpulls':\n",
    "            xxx = ((np.array(DBN_input_data_alltypes_sfpulls['failedpull'][DBN_group_typename]['pull1_t2'])==1)&\n",
    "                   (np.array(DBN_input_data_alltypes_sfpulls['failedpull'][DBN_group_typename]['pull2_t3'])==1))        \n",
    "        print(animal1_fixedorder+' leads pull ratio:'+str(np.sum(xxx)/np.sum((np.array(DBN_input_data_igroup['pull1_t2'])==1))))\n",
    "            \n",
    "        # from animal 2\n",
    "        # 1s lag; pull2->pull1\n",
    "        if pulltype == 'allpulls':\n",
    "            xxx = ((np.array(DBN_input_data_igroup['pull2_t2'])==1)&(np.array(DBN_input_data_igroup['pull1_t3'])==1))\n",
    "        elif pulltype == 'succpulls':\n",
    "            xxx = ((np.array(DBN_input_data_alltypes_sfpulls['succpull'][DBN_group_typename]['pull2_t2'])==1)&\n",
    "                   (np.array(DBN_input_data_alltypes_sfpulls['succpull'][DBN_group_typename]['pull1_t3'])==1))\n",
    "        elif pulltype == 'failedpulls':\n",
    "            xxx = ((np.array(DBN_input_data_alltypes_sfpulls['failedpull'][DBN_group_typename]['pull2_t2'])==1)&\n",
    "                   (np.array(DBN_input_data_alltypes_sfpulls['failedpull'][DBN_group_typename]['pull1_t3'])==1))\n",
    "        print(animal2_fixedorder+' leads pull ratio:'+str(np.sum(xxx)/np.sum((np.array(DBN_input_data_igroup['pull2_t2'])==1))))\n",
    "\n",
    "        \n",
    "            \n",
    "    \n",
    "    savefig = 0\n",
    "    if savefig:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'eventpair_appearanceDensity_with'+pulltype+'_Resolu'+str(temp_resolu)+'s_1stimelag_'+animal1_fixedorder+animal2_fixedorder+'.pdf')\n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed62ef",
   "metadata": {},
   "source": [
    "## Plots that include all pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bbfff1",
   "metadata": {},
   "source": [
    "### VERSION 1: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis show the time lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32fb524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "#\n",
    "fig, axs = plt.subplots(2,nanimalpairs)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(5*nanimalpairs)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    if 0:\n",
    "        MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "        MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    else:\n",
    "        MI_coop_self,_ = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 150)\n",
    "        MI_coop_self = MI_coop_self.mean(axis = 0)\n",
    "        MI_nov_coop,_  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 150)\n",
    "        MI_nov_coop = MI_nov_coop.mean(axis = 0)\n",
    "        \n",
    "    #\n",
    "    t3MI_coop_self = MI_coop_self[[0,1,2,3],:]\n",
    "    t2MI_coop_self = MI_coop_self[[4,5,6,7],:]\n",
    "    t1MI_coop_self = MI_coop_self[[8,9,10,11],:]\n",
    "    t3MI_nov_coop = MI_nov_coop[[0,1,2,3],:]\n",
    "    t2MI_nov_coop = MI_nov_coop[[4,5,6,7],:]\n",
    "    t1MI_nov_coop = MI_nov_coop[[8,9,10,11],:]\n",
    "    #\n",
    "    pull_pull_fromNodes = [0,1]\n",
    "    pull_pull_toNodes = [1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes = [2,3]\n",
    "    gaze_gaze_toNodes = [3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes = [0,1,2,3]\n",
    "    within_pullgaze_toNodes = [2,3,0,1]\n",
    "    #\n",
    "    across_pullgaze_fromNodes = [0,1,2,3]\n",
    "    across_pullgaze_toNodes = [3,2,1,0]\n",
    "\n",
    "    \n",
    "    # plot coop self modulation\n",
    "    # pull-pull\n",
    "    xxx1 = [np.mean(t3MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t2MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t1MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes])]\n",
    "    line1 = axs[0,ianimalpair].plot(xxx1,'*--',markersize = 13,label='pull<->pull')\n",
    "    # gaze-gaze\n",
    "    xxx2 = [np.mean(t3MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes])]\n",
    "    line2 = axs[0,ianimalpair].plot(xxx2,'o--',markersize = 13,label='gaze<->gaze')\n",
    "    # within animal pullgaze\n",
    "    xxx3 = [np.mean(t3MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes])]\n",
    "    line3 = axs[0,ianimalpair].plot(xxx3,'v--',markersize = 13,label='within animal pull<->gaze')\n",
    "    # across animal pullgaze\n",
    "    xxx4 = [np.mean(t3MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes])]\n",
    "    line4 = axs[0,ianimalpair].plot(xxx4,'^--',markersize = 13,label='across animal pull<->gaze')\n",
    "    #\n",
    "    axs[0,ianimalpair].set_ylim([-1.05,1.05])\n",
    "    axs[0,ianimalpair].set_xticks([0,1,2])\n",
    "    axs[0,ianimalpair].set_xticklabels([])\n",
    "    axs[0,ianimalpair].set_yticks([-1,-0.5,0,0.5,1])\n",
    "    if ianimalpair == 0:\n",
    "        axs[0,ianimalpair].tick_params(axis='y', labelsize=13)\n",
    "        axs[0,ianimalpair].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "    else:\n",
    "        axs[0,ianimalpair].set_yticklabels([])\n",
    "    axs[0,ianimalpair].set_title('pair:'+animal1_fixedorder+'-'+animal2_fixedorder,fontsize = 16)\n",
    "\n",
    "\n",
    "    # plot novision coop modulation\n",
    "    # pull-pull\n",
    "    xxx1 = [np.mean(t3MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes])]\n",
    "    line1 = axs[1,ianimalpair].plot(xxx1,'*--',markersize = 13,label='pull<->pull')\n",
    "    # gaze-gaze\n",
    "    xxx2 = [np.mean(t3MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes])]\n",
    "    line2 = axs[1,ianimalpair].plot(xxx2,'o--',markersize = 13,label='gaze<->gaze')\n",
    "    # within animal pullgaze\n",
    "    xxx3 = [np.mean(t3MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes])]\n",
    "    line3 = axs[1,ianimalpair].plot(xxx3,'v--',markersize = 13,label='within animal pull<->gaze')\n",
    "    # across animal pullgaze\n",
    "    xxx4 = [np.mean(t3MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes])]\n",
    "    line4 = axs[1,ianimalpair].plot(xxx4,'^--',markersize = 13,label='across animal pull<->gaze')\n",
    "    #\n",
    "    axs[1,ianimalpair].set_ylim([-1.05,1.05])\n",
    "    axs[1,ianimalpair].set_xticks([0,1,2])\n",
    "    axs[1,ianimalpair].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "    axs[1,ianimalpair].set_xlabel('time lag',fontsize=15)\n",
    "    axs[1,ianimalpair].set_yticks([-1,-0.5,0,0.5,1])\n",
    "    if ianimalpair == 0:\n",
    "        axs[1,ianimalpair].tick_params(axis='y', labelsize=13)\n",
    "        axs[1,ianimalpair].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "        axs[1,ianimalpair].legend()\n",
    "    else:\n",
    "        axs[1,ianimalpair].set_yticklabels([])\n",
    "    axs[1,ianimalpair].set_title('pair:'+animal1_fixedorder+'-'+animal2_fixedorder,fontsize = 16)\n",
    "    \n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_summary_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_summary_'+str(temp_resolu)+'_'+j_sampsize_name+'.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33085d8b",
   "metadata": {},
   "source": [
    "### VERSION 2: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis show the time lag; combined into four edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animalpairs_datashapes = ['o','v','^','*']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(2,4)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(5*4)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "        MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    else:\n",
    "        MI_coop_self,_ = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 150)\n",
    "        MI_coop_self = MI_coop_self.mean(axis = 0)\n",
    "        MI_nov_coop,_  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 150)\n",
    "        MI_nov_coop = MI_nov_coop.mean(axis = 0)\n",
    "    #\n",
    "    t3MI_coop_self = MI_coop_self[[0,1,2,3],:]\n",
    "    t2MI_coop_self = MI_coop_self[[4,5,6,7],:]\n",
    "    t1MI_coop_self = MI_coop_self[[8,9,10,11],:]\n",
    "    t3MI_nov_coop = MI_nov_coop[[0,1,2,3],:]\n",
    "    t2MI_nov_coop = MI_nov_coop[[4,5,6,7],:]\n",
    "    t1MI_nov_coop = MI_nov_coop[[8,9,10,11],:]\n",
    "    #\n",
    "    pull_pull_fromNodes = [0,1]\n",
    "    pull_pull_toNodes = [1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes = [2,3]\n",
    "    gaze_gaze_toNodes = [3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes = [0,1,2,3]\n",
    "    within_pullgaze_toNodes = [2,3,0,1]\n",
    "    #\n",
    "    across_pullgaze_fromNodes = [0,1,2,3]\n",
    "    across_pullgaze_toNodes = [3,2,1,0]\n",
    "\n",
    "    \n",
    "    # plot coop self modulation\n",
    "    # pull-pull\n",
    "    xxx1 = [np.mean(t3MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t2MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t1MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes])]\n",
    "    line1 = axs[0,0].plot(xxx1,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='r')\n",
    "    # gaze-gaze\n",
    "    xxx2 = [np.mean(t3MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes])]\n",
    "    line2 = axs[0,1].plot(xxx2,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='b')\n",
    "    # within animal pullgaze\n",
    "    xxx3 = [np.mean(t3MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes])]\n",
    "    line3 = axs[0,2].plot(xxx3,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='g')\n",
    "    # across animal pullgaze\n",
    "    xxx4 = [np.mean(t3MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes])]\n",
    "    line4 = axs[0,3].plot(xxx4,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='y')\n",
    "    #\n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze','within animal pull<->gaze','across animal pull<->gaze']\n",
    "    for iplot in np.arange(0,4,1):\n",
    "        axs[0,iplot].set_xlim([-0.1,2.1])\n",
    "        axs[0,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[0,iplot].set_xticks([0,1,2])\n",
    "        axs[0,iplot].set_xticklabels([])\n",
    "        axs[0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        #\n",
    "        if iplot == 0:\n",
    "            axs[0,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[0,iplot].set_yticklabels([])\n",
    "        axs[0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[0,iplot].plot([-1,3],[0,0],'k--')\n",
    "\n",
    "    # plot novision coop modulation\n",
    "    # pull-pull\n",
    "    xxx1 = [np.mean(t3MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes])]\n",
    "    line1 = axs[1,0].plot(xxx1,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='r')\n",
    "    # gaze-gaze\n",
    "    xxx2 = [np.mean(t3MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes])]\n",
    "    line2 = axs[1,1].plot(xxx2,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='b')\n",
    "    # within animal pullgaze\n",
    "    xxx3 = [np.mean(t3MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes])]\n",
    "    line3 = axs[1,2].plot(xxx3,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='g')\n",
    "    # across animal pullgaze\n",
    "    xxx4 = [np.mean(t3MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes])]\n",
    "    line4 = axs[1,3].plot(xxx4,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='y')\n",
    "     #\n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze','within animal pull<->gaze','across animal pull<->gaze']\n",
    "    for iplot in np.arange(0,4,1):\n",
    "        axs[1,iplot].set_xlim([-0.1,2.1])\n",
    "        axs[1,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[1,iplot].set_xticks([0,1,2])\n",
    "        axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "        axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "        axs[1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        if iplot == 0:\n",
    "            axs[1,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[1,iplot].set_yticklabels([])\n",
    "        axs[1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[1,iplot].plot([-1,3],[0,0],'k--')\n",
    "        \n",
    "    axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "                     'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "                     'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2],\n",
    "                     'pair:'+animal1_fixedorders[3][0:2]+'/'+animal2_fixedorders[3][0:2]],fontsize=17)\n",
    "    \n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_summary_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_summary_'+str(temp_resolu)+'_'+j_sampsize_name+'.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8cd65a",
   "metadata": {},
   "source": [
    "### VERSION 3: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis show the time lag; combined into six edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animalpairs_datashapes = ['o','v','^','*']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(2,6)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(5*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    if 0:\n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 150)\n",
    "        MI_coop_self = MI_coop_self.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 150)\n",
    "        MI_nov_coop = MI_nov_coop.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop   \n",
    "    \n",
    "    #\n",
    "    t3MI_coop_self = MI_coop_self[[0,1,2,3],:]\n",
    "    t2MI_coop_self = MI_coop_self[[4,5,6,7],:]\n",
    "    t1MI_coop_self = MI_coop_self[[8,9,10,11],:]\n",
    "    t3MI_nov_coop = MI_nov_coop[[0,1,2,3],:]\n",
    "    t2MI_nov_coop = MI_nov_coop[[4,5,6,7],:]\n",
    "    t1MI_nov_coop = MI_nov_coop[[8,9,10,11],:]\n",
    "    #\n",
    "    pull_pull_fromNodes = [0,1]\n",
    "    pull_pull_toNodes = [1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes = [2,3]\n",
    "    gaze_gaze_toNodes = [3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes = [0,1]\n",
    "    within_pullgaze_toNodes = [2,3]\n",
    "    #\n",
    "    across_pullgaze_fromNodes = [0,1]\n",
    "    across_pullgaze_toNodes = [3,2]\n",
    "    #\n",
    "    within_gazepull_fromNodes = [2,3]\n",
    "    within_gazepull_toNodes = [0,1]\n",
    "    #\n",
    "    across_gazepull_fromNodes = [2,3]\n",
    "    across_gazepull_toNodes = [1,0]\n",
    "\n",
    "    \n",
    "    # plot coop self modulation\n",
    "    # pull-pull\n",
    "    xxx1 = [np.mean(t3MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t2MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t1MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes])]\n",
    "    line1 = axs[0,0].plot(xxx1,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='r')\n",
    "    # gaze-gaze\n",
    "    xxx2 = [np.mean(t3MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes])]\n",
    "    line2 = axs[0,1].plot(xxx2,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='b')\n",
    "    # within animal pullgaze\n",
    "    xxx3 = [np.mean(t3MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes])]\n",
    "    line3 = axs[0,2].plot(xxx3,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#008080')\n",
    "    # across animal pullgaze\n",
    "    xxx4 = [np.mean(t3MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes])]\n",
    "    line4 = axs[0,3].plot(xxx4,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#D1B26F')\n",
    "    # within animal gazepull\n",
    "    xxx5 = [np.mean(t3MI_coop_self[within_gazepull_fromNodes,within_gazepull_toNodes]),\n",
    "            np.mean(t2MI_coop_self[within_gazepull_fromNodes,within_gazepull_toNodes]),\n",
    "            np.mean(t1MI_coop_self[within_gazepull_fromNodes,within_gazepull_toNodes])]\n",
    "    line5 = axs[0,4].plot(xxx5,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#7FFF00')\n",
    "    # across animal gazepull\n",
    "    xxx6 = [np.mean(t3MI_coop_self[across_gazepull_fromNodes,across_gazepull_toNodes]),\n",
    "            np.mean(t2MI_coop_self[across_gazepull_fromNodes,across_gazepull_toNodes]),\n",
    "            np.mean(t1MI_coop_self[across_gazepull_fromNodes,across_gazepull_toNodes])]\n",
    "    line6 = axs[0,5].plot(xxx6,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#FAC205')\n",
    "    #\n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[0,iplot].set_xlim([-0.1,2.1])\n",
    "        axs[0,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[0,iplot].set_xticks([0,1,2])\n",
    "        axs[0,iplot].set_xticklabels([])\n",
    "        axs[0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        #\n",
    "        if iplot == 0:\n",
    "            axs[0,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[0,iplot].set_yticklabels([])\n",
    "        axs[0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[0,iplot].plot([-1,3],[0,0],'k--')\n",
    "\n",
    "    # plot novision coop modulation\n",
    "    # pull-pull\n",
    "    xxx1 = [np.mean(t3MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes])]\n",
    "    line1 = axs[1,0].plot(xxx1,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='r')\n",
    "    # gaze-gaze\n",
    "    xxx2 = [np.mean(t3MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes])]\n",
    "    line2 = axs[1,1].plot(xxx2,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='b')\n",
    "    # within animal pullgaze\n",
    "    xxx3 = [np.mean(t3MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes])]\n",
    "    line3 = axs[1,2].plot(xxx3,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#008080')\n",
    "    # across animal pullgaze\n",
    "    xxx4 = [np.mean(t3MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes])]\n",
    "    line4 = axs[1,3].plot(xxx4,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#D1B26F')\n",
    "    # within animal gazepull\n",
    "    xxx5 = [np.mean(t3MI_nov_coop[within_gazepull_fromNodes,within_gazepull_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[within_gazepull_fromNodes,within_gazepull_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[within_gazepull_fromNodes,within_gazepull_toNodes])]\n",
    "    line5 = axs[1,4].plot(xxx5,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#7FFF00')\n",
    "    # across animal gazepull\n",
    "    xxx6 = [np.mean(t3MI_nov_coop[across_gazepull_fromNodes,across_gazepull_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[across_gazepull_fromNodes,across_gazepull_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[across_gazepull_fromNodes,across_gazepull_toNodes])]\n",
    "    line6 = axs[1,5].plot(xxx6,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#FAC205')\n",
    "    #\n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[1,iplot].set_xlim([-0.1,2.1])\n",
    "        axs[1,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[1,iplot].set_xticks([0,1,2])\n",
    "        axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "        axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "        axs[1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        if iplot == 0:\n",
    "            axs[1,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[1,iplot].set_yticklabels([])\n",
    "        axs[1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[1,iplot].plot([-1,3],[0,0],'k--')\n",
    "        \n",
    "    axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "                     'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "                     'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2],\n",
    "                     'pair:'+animal1_fixedorders[3][0:2]+'/'+animal2_fixedorders[3][0:2]],fontsize=17)\n",
    "    \n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_detailed_summary_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_detailed_summary_'+str(temp_resolu)+'_'+j_sampsize_name+'.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee15a992",
   "metadata": {},
   "source": [
    "### VERSION 4: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis shows the pairs. y axis averaged the MI among time lag and show CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a5da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animalpairs_datashapes = ['o','v','^','*']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(2,6)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(5*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 150)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 150)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    pull_pull_fromNodes_all = [0,1,4,5,8,9]\n",
    "    pull_pull_toNodes_all = [1,0,1,0,1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes_all = [2,3,6,7,10,11]\n",
    "    gaze_gaze_toNodes_all = [3,2,3,2,3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes_all = [0,1,4,5,8,9]\n",
    "    within_pullgaze_toNodes_all = [2,3,2,3,2,3]\n",
    "    #\n",
    "    across_pullgaze_fromNodes_all = [0,1,4,5,8,9]\n",
    "    across_pullgaze_toNodes_all = [3,2,3,2,3,2]\n",
    "    #\n",
    "    within_gazepull_fromNodes_all = [2,3,6,7,10,11]\n",
    "    within_gazepull_toNodes_all = [0,1,0,1,0,1]\n",
    "    #\n",
    "    across_gazepull_fromNodes_all = [2,3,6,7,10,11]\n",
    "    across_gazepull_toNodes_all = [1,0,1,0,1,0]\n",
    "\n",
    "    \n",
    "    # plot coop self modulation\n",
    "    \n",
    "    # pull-pull\n",
    "    xxx1 = np.mean(MI_coop_self_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all])\n",
    "    # err1 = np.std(MI_coop_self_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all])\n",
    "    err1 = st.sem(MI_coop_self_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all].flatten())\n",
    "    axs[0,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 5)\n",
    "    line1 = axs[0,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # gaze-gaze\n",
    "    xxx2 = np.mean(MI_coop_self_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all])\n",
    "    # err2 = np.std(MI_coop_self_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all])\n",
    "    err2 = st.sem(MI_coop_self_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all].flatten())\n",
    "    axs[0,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 5)\n",
    "    line2 = axs[0,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal gazepull\n",
    "    xxx3 = np.mean(MI_coop_self_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all])\n",
    "    # err3 = np.std(MI_coop_self_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all])\n",
    "    err3 = st.sem(MI_coop_self_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all].flatten())\n",
    "    axs[0,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 5)\n",
    "    line3 = axs[0,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal gazepull\n",
    "    xxx4 = np.mean(MI_coop_self_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all])\n",
    "    # err4 = np.std(MI_coop_self_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all])\n",
    "    err4 = st.sem(MI_coop_self_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all].flatten())\n",
    "    axs[0,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 5)\n",
    "    line4 = axs[0,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal pullgaze\n",
    "    xxx5 = np.mean(MI_coop_self_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all])\n",
    "    #err5 = np.std(MI_coop_self_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all])\n",
    "    err5 = st.sem(MI_coop_self_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all].flatten())\n",
    "    axs[0,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 5)\n",
    "    line5 = axs[0,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal pullgaze\n",
    "    xxx6 = np.mean(MI_coop_self_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all])\n",
    "    # err6 = np.std(MI_coop_self_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all])\n",
    "    err6 = st.sem(MI_coop_self_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all].flatten())\n",
    "    axs[0,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 5)\n",
    "    line6 = axs[0,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    \n",
    "    #\n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 ]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[0,iplot].set_xlim([-0.1,nanimalpairs-0.9])\n",
    "        axs[0,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[0,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "        axs[0,iplot].set_xticklabels([])\n",
    "        axs[0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        #\n",
    "        if iplot == 0:\n",
    "            axs[0,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[0,iplot].set_yticklabels([])\n",
    "        axs[0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[0,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "\n",
    "    # plot novision coop modulation\n",
    "    # pull-pull\n",
    "    xxx1 = np.mean(MI_nov_coop_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all])\n",
    "    # err1 = np.std(MI_nov_coop_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all])\n",
    "    err1 = st.sem(MI_nov_coop_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all].flatten())\n",
    "    axs[1,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 5)\n",
    "    line1 = axs[1,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # gaze-gaze\n",
    "    xxx2 = np.mean(MI_nov_coop_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all])\n",
    "    # err2 = np.std(MI_nov_coop_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all])\n",
    "    err2 = st.sem(MI_nov_coop_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all].flatten())\n",
    "    axs[1,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 5)\n",
    "    line2 = axs[1,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal gazepull\n",
    "    xxx3 = np.mean(MI_nov_coop_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all])\n",
    "    # err3 = np.std(MI_nov_coop_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all])\n",
    "    err3 = st.sem(MI_nov_coop_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all].flatten())\n",
    "    axs[1,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 5)\n",
    "    line3 = axs[1,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal gazepull\n",
    "    xxx4 = np.mean(MI_nov_coop_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all])\n",
    "    # err4 = np.std(MI_nov_coop_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all])\n",
    "    err4 = st.sem(MI_nov_coop_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all].flatten())\n",
    "    axs[1,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 5)\n",
    "    line4 = axs[1,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal pullgaze\n",
    "    xxx5 = np.mean(MI_nov_coop_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all])\n",
    "    #err5 = np.std(MI_nov_coop_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all])\n",
    "    err5 = st.sem(MI_nov_coop_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all].flatten())\n",
    "    axs[1,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 5)\n",
    "    line5 = axs[1,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal pullgaze\n",
    "    xxx6 = np.mean(MI_nov_coop_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all])\n",
    "    # err6 = np.std(MI_nov_coop_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all])\n",
    "    err6 = st.sem(MI_nov_coop_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all].flatten())\n",
    "    axs[1,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 5)\n",
    "    line6 = axs[1,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    \n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 ]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[1,iplot].set_xlim([-0.1,nanimalpairs-0.9])\n",
    "        axs[1,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[1,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "        #axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "        axs[1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA','DA/KA'],fontsize = 13)\n",
    "        #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "        axs[1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        if iplot == 0:\n",
    "            axs[1,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[1,iplot].set_yticklabels([])\n",
    "        axs[1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[1,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "        \n",
    "    #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "    #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "    #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "    \n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_mergedLag_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_meanSEM.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_mergedLag_'+str(temp_resolu)+'_'+j_sampsize_name+'_meanSEM.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8346193d",
   "metadata": {},
   "source": [
    "### version 5: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis shows the pairs. y axis averaged the MI only for 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72961be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animalpairs_datashapes = ['o','o','o','o']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(2,6)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(5*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 150)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 150)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    pull_pull_fromNodes_all = [8,9]\n",
    "    pull_pull_toNodes_all = [1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes_all = [10,11]\n",
    "    gaze_gaze_toNodes_all = [3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes_all = [8,9]\n",
    "    within_pullgaze_toNodes_all = [2,3]\n",
    "    #\n",
    "    across_pullgaze_fromNodes_all = [8,9]\n",
    "    across_pullgaze_toNodes_all = [3,2]\n",
    "    #\n",
    "    within_gazepull_fromNodes_all = [10,11]\n",
    "    within_gazepull_toNodes_all = [0,1]\n",
    "    #\n",
    "    across_gazepull_fromNodes_all = [10,11]\n",
    "    across_gazepull_toNodes_all = [1,0]\n",
    "\n",
    "    \n",
    "    # plot coop self modulation\n",
    "    \n",
    "    # pull-pull\n",
    "    a = MI_coop_self_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all].flatten()\n",
    "    xxx1 = np.mean(a)\n",
    "    err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "    line1 = axs[0,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # gaze-gaze\n",
    "    a = (MI_coop_self_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all]).flatten()\n",
    "    xxx2 = np.mean(a)\n",
    "    err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "    line2 = axs[0,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal gazepull\n",
    "    a = (MI_coop_self_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all]).flatten()\n",
    "    xxx3 = np.mean(a)\n",
    "    err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "    line3 = axs[0,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal gazepull\n",
    "    a = (MI_coop_self_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all]).flatten()\n",
    "    xxx4 = np.mean(a)\n",
    "    err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "    line4 = axs[0,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal pullgaze\n",
    "    a = (MI_coop_self_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all]).flatten()\n",
    "    xxx5 = np.mean(a)\n",
    "    err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "    line5 = axs[0,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal pullgaze\n",
    "    a = (MI_coop_self_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all]).flatten()\n",
    "    xxx6 = np.mean(a)\n",
    "    err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "    line6 = axs[0,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    \n",
    "    #\n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 ]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[0,iplot].set_xlim([-0.3,nanimalpairs-0.7])\n",
    "        axs[0,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[0,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "        axs[0,iplot].set_xticklabels([])\n",
    "        axs[0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        #\n",
    "        if iplot == 0:\n",
    "            axs[0,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[0,iplot].set_yticklabels([])\n",
    "        axs[0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[0,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "\n",
    "    # plot novision coop modulation\n",
    "    # pull-pull\n",
    "    a = MI_nov_coop_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all].flatten()\n",
    "    xxx1 = np.mean(a)\n",
    "    err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "    line1 = axs[1,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # gaze-gaze\n",
    "    a = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all]).flatten()\n",
    "    xxx2 = np.mean(a)\n",
    "    err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "    line2 = axs[1,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal gazepull\n",
    "    a = (MI_nov_coop_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all]).flatten()\n",
    "    xxx3 = np.mean(a)\n",
    "    err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "    line3 = axs[1,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal gazepull\n",
    "    a = (MI_nov_coop_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all]).flatten()\n",
    "    xxx4 = np.mean(a)\n",
    "    err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "    line4 = axs[1,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal pullgaze\n",
    "    a = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all]).flatten()\n",
    "    xxx5 = np.mean(a)\n",
    "    err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "    line5 = axs[1,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal pullgaze\n",
    "    a = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all]).flatten()\n",
    "    xxx6 = np.mean(a)\n",
    "    err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "    line6 = axs[1,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    \n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 ]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[1,iplot].set_xlim([-0.3,nanimalpairs-0.7])\n",
    "        axs[1,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[1,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "        #axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "        axs[1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA','DA/KA'],fontsize = 13)\n",
    "        #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "        axs[1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        if iplot == 0:\n",
    "            axs[1,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[1,iplot].set_yticklabels([])\n",
    "        axs[1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[1,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "        \n",
    "    #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "    #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "    #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "    \n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_1secondLag_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_mean95CI.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_1secondLag_'+str(temp_resolu)+'_'+j_sampsize_name+'_mean95CI.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e72e3",
   "metadata": {},
   "source": [
    "### version 6: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis shows the pairs. y axis showed the MI; separate animal 1 and 2; merge time lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da12c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animalpairs_datashapes = ['o','o','o','o']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(4,6)\n",
    "fig.set_figheight(8*4)\n",
    "fig.set_figwidth(8*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 150)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 150)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    \n",
    "    #\n",
    "    pull_pull_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "    pull_pull_toNodes_all = [[1,1,1],[0,0,0]]\n",
    "    #\n",
    "    gaze_gaze_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "    gaze_gaze_toNodes_all = [[3,3,3],[2,2,2]]\n",
    "    #\n",
    "    within_pullgaze_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "    within_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "    #\n",
    "    across_pullgaze_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "    across_pullgaze_toNodes_all = [[3,3,3],[2,2,2]]\n",
    "    #\n",
    "    within_gazepull_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "    within_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "    #\n",
    "    across_gazepull_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "    across_gazepull_toNodes_all = [[1,1,1],[0,0,0]]\n",
    "    \n",
    "    animalshortnames = ['A1','A2']\n",
    "\n",
    "    \n",
    "    for ianimal in np.arange(0,2,1):\n",
    "        \n",
    "        anishortname = animalshortnames[ianimal]\n",
    "        \n",
    "        \n",
    "        # plot coop self modulation\n",
    "\n",
    "        # pull-pull\n",
    "        a = MI_coop_self_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[2*ianimal+0,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_coop_self_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[2*ianimal+0,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_coop_self_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[2*ianimal+0,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_coop_self_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[2*ianimal+0,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_coop_self_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[2*ianimal+0,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_coop_self_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[2*ianimal+0,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        #\n",
    "        plottypes = ['from '+anishortname+' across animal pull<->pull','from '+anishortname+' across animal gaze<->gaze',\n",
    "                     'from '+anishortname+' within animal gaze->pull','from '+anishortname+' across animal gaze->pull',\n",
    "                     'from '+anishortname+' within animal pull->gaze','from '+anishortname+' across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[2*ianimal+0,iplot].set_xlim([-0.3,nanimalpairs-0.7])\n",
    "            axs[2*ianimal+0,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[2*ianimal+0,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "            axs[2*ianimal+0,iplot].set_xticklabels([],fontsize = 13)\n",
    "            axs[2*ianimal+0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            #\n",
    "            if iplot == 0:\n",
    "                axs[2*ianimal+0,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[2*ianimal+0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "            else:\n",
    "                axs[2*ianimal+0,iplot].set_yticklabels([])\n",
    "            axs[2*ianimal+0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[2*ianimal+0,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "\n",
    "        # plot novision coop modulation\n",
    "        # pull-pull\n",
    "        a = MI_nov_coop_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[2*ianimal+1,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[2*ianimal+1,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_nov_coop_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[2*ianimal+1,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_nov_coop_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[2*ianimal+1,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[2*ianimal+1,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[2*ianimal+1,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        plottypes = ['from '+anishortname+' across animal pull<->pull','from '+anishortname+' across animal gaze<->gaze',\n",
    "                     'from '+anishortname+' within animal gaze->pull','from '+anishortname+' across animal gaze->pull',\n",
    "                     'from '+anishortname+' within animal pull->gaze','from '+anishortname+' across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[2*ianimal+1,iplot].set_xlim([-0.3,nanimalpairs-0.7])\n",
    "            axs[2*ianimal+1,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[2*ianimal+1,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "            axs[2*ianimal+1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA','DA/KA'],fontsize = 13)\n",
    "            #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "            axs[2*ianimal+1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            if iplot == 0:\n",
    "                axs[2*ianimal+1,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[2*ianimal+1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "            else:\n",
    "                axs[1,iplot].set_yticklabels([])\n",
    "            axs[2*ianimal+1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[2*ianimal+1,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "\n",
    "        #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "\n",
    "savefig = 0\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_mergedLag_IndiAnimal_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_mean95CI.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_mergedLag_IndiAnimal_'+str(temp_resolu)+'_'+j_sampsize_name+'_mean95CI.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b2cdfe",
   "metadata": {},
   "source": [
    "### version 7: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis shows the pairs. y axis showed the MI; separate animal 1 and 2; only for 1s time lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7466a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animalpairs_datashapes = ['o','o','o','o']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(4,6)\n",
    "fig.set_figheight(8*4)\n",
    "fig.set_figwidth(8*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 150)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 150)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    pull_pull_fromNodes_all = [8,9]\n",
    "    pull_pull_toNodes_all = [1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes_all = [10,11]\n",
    "    gaze_gaze_toNodes_all = [3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes_all = [8,9]\n",
    "    within_pullgaze_toNodes_all = [2,3]\n",
    "    #\n",
    "    across_pullgaze_fromNodes_all = [8,9]\n",
    "    across_pullgaze_toNodes_all = [3,2]\n",
    "    #\n",
    "    within_gazepull_fromNodes_all = [10,11]\n",
    "    within_gazepull_toNodes_all = [0,1]\n",
    "    #\n",
    "    across_gazepull_fromNodes_all = [10,11]\n",
    "    across_gazepull_toNodes_all = [1,0]\n",
    "\n",
    "    animalshortnames = ['A1','A2']\n",
    "    \n",
    "    for ianimal in np.arange(0,2,1):\n",
    "        \n",
    "        anishortname = animalshortnames[ianimal]\n",
    "        \n",
    "        # plot coop self modulation\n",
    "\n",
    "        # pull-pull\n",
    "        a = MI_coop_self_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[2*ianimal+0,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_coop_self_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[2*ianimal+0,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_coop_self_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[2*ianimal+0,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_coop_self_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[2*ianimal+0,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_coop_self_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[2*ianimal+0,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_coop_self_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[2*ianimal+0,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        #\n",
    "        plottypes = ['from '+anishortname+' across animal pull<->pull','from '+anishortname+' across animal gaze<->gaze',\n",
    "                     'from '+anishortname+' within animal gaze->pull','from '+anishortname+' across animal gaze->pull',\n",
    "                     'from '+anishortname+' within animal pull->gaze','from '+anishortname+' across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[2*ianimal+0,iplot].set_xlim([-0.3,nanimalpairs-0.7])\n",
    "            axs[2*ianimal+0,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[2*ianimal+0,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "            axs[2*ianimal+0,iplot].set_xticklabels([],fontsize = 13)\n",
    "            axs[2*ianimal+0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            #\n",
    "            if iplot == 0:\n",
    "                axs[2*ianimal+0,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[2*ianimal+0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "            else:\n",
    "                axs[2*ianimal+0,iplot].set_yticklabels([])\n",
    "            axs[2*ianimal+0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[2*ianimal+0,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "\n",
    "        # plot novision coop modulation\n",
    "        # pull-pull\n",
    "        a = MI_nov_coop_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[2*ianimal+1,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[2*ianimal+1,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_nov_coop_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[2*ianimal+1,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_nov_coop_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[2*ianimal+1,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[2*ianimal+1,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[2*ianimal+1,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        plottypes = ['from '+anishortname+' across animal pull<->pull','from '+anishortname+' across animal gaze<->gaze',\n",
    "                     'from '+anishortname+' within animal gaze->pull','from '+anishortname+' across animal gaze->pull',\n",
    "                     'from '+anishortname+' within animal pull->gaze','from '+anishortname+' across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[2*ianimal+1,iplot].set_xlim([-0.3,nanimalpairs-0.7])\n",
    "            axs[2*ianimal+1,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[2*ianimal+1,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "            #axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "            axs[2*ianimal+1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA','DA/KA'],fontsize = 13)\n",
    "            #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "            axs[2*ianimal+1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            if iplot == 0:\n",
    "                axs[2*ianimal+1,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[2*ianimal+1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "            else:\n",
    "                axs[2*ianimal+1,iplot].set_yticklabels([])\n",
    "            axs[2*ianimal+1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[2*ianimal+1,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "\n",
    "        #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "\n",
    "savefig = 0\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_1secondLag_IndiAnimal_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_mean95CI.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_1secondLag_IndiAnimal_'+str(temp_resolu)+'_'+j_sampsize_name+'_mean95CI.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c0220",
   "metadata": {},
   "source": [
    "### version 7-2-1: \n",
    "#### plot the key edges' modulation; \n",
    "#### only show the modulation among coop1s, self, no-vision; \n",
    "#### separate animal 1 and 2, plot individual animal; \n",
    "#### put all animal in one plot - based on the \"from Node\"; only for 1s time lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ff85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animalpairs_datashapes = ['o','o','o','o']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(2,6)\n",
    "fig.set_figheight(8*2)\n",
    "fig.set_figwidth(8*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 150)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 150)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    pull_pull_fromNodes_all = [8,9]\n",
    "    pull_pull_toNodes_all = [1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes_all = [10,11]\n",
    "    gaze_gaze_toNodes_all = [3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes_all = [8,9]\n",
    "    within_pullgaze_toNodes_all = [2,3]\n",
    "    #\n",
    "    across_pullgaze_fromNodes_all = [8,9]\n",
    "    across_pullgaze_toNodes_all = [3,2]\n",
    "    #\n",
    "    within_gazepull_fromNodes_all = [10,11]\n",
    "    within_gazepull_toNodes_all = [0,1]\n",
    "    #\n",
    "    across_gazepull_fromNodes_all = [10,11]\n",
    "    across_gazepull_toNodes_all = [1,0]\n",
    "\n",
    "    \n",
    "    for ianimal in np.arange(0,2,1):\n",
    "                \n",
    "        # plot coop self modulation\n",
    "\n",
    "        # pull-pull\n",
    "        a = MI_coop_self_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,0].errorbar(ianimal*nanimalpairs+ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[0,0].plot(ianimal*nanimalpairs+ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_coop_self_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,1].errorbar(ianimal*nanimalpairs+ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[0,1].plot(ianimal*nanimalpairs+ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_coop_self_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,2].errorbar(ianimal*nanimalpairs+ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[0,2].plot(ianimal*nanimalpairs+ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_coop_self_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,3].errorbar(ianimal*nanimalpairs+ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[0,3].plot(ianimal*nanimalpairs+ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_coop_self_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,4].errorbar(ianimal*nanimalpairs+ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[0,4].plot(ianimal*nanimalpairs+ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_coop_self_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,5].errorbar(ianimal*nanimalpairs+ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[0,5].plot(ianimal*nanimalpairs+ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        #\n",
    "        plottypes = ['From Node; across animal pull<->pull','From Node; across animal gaze<->gaze',\n",
    "                     'From Node; within animal gaze->pull','From Node; across animal gaze->pull',\n",
    "                     'From Node; within animal pull->gaze','From Node; across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[0,iplot].set_xlim([-0.3,nanimalpairs*2-0.7])\n",
    "            axs[0,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[0,iplot].set_xticks(np.arange(0,nanimalpairs*2,1))\n",
    "            axs[0,iplot].set_xticklabels([])\n",
    "            axs[0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            #\n",
    "            if iplot == 0:\n",
    "                axs[0,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "            else:\n",
    "                axs[0,iplot].set_yticklabels([])\n",
    "            axs[0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[0,iplot].plot([-1,nanimalpairs*2],[0,0],'k--')\n",
    "\n",
    "        # plot novision coop modulation\n",
    "        # pull-pull\n",
    "        a = MI_nov_coop_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,0].errorbar(ianimal*nanimalpairs+ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[1,0].plot(ianimal*nanimalpairs+ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,1].errorbar(ianimal*nanimalpairs+ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[1,1].plot(ianimal*nanimalpairs+ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_nov_coop_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,2].errorbar(ianimal*nanimalpairs+ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[1,2].plot(ianimal*nanimalpairs+ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_nov_coop_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,3].errorbar(ianimal*nanimalpairs+ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[1,3].plot(ianimal*nanimalpairs+ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,4].errorbar(ianimal*nanimalpairs+ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[1,4].plot(ianimal*nanimalpairs+ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,5].errorbar(ianimal*nanimalpairs+ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[1,5].plot(ianimal*nanimalpairs+ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        plottypes = ['From Node; across animal pull<->pull','From Node; across animal gaze<->gaze',\n",
    "                     'From Node; within animal gaze->pull','From Node; across animal gaze->pull',\n",
    "                     'From Node; within animal pull->gaze','From Node; across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[1,iplot].set_xlim([-0.3,nanimalpairs*2-0.7])\n",
    "            axs[1,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[1,iplot].set_xticks(np.arange(0,nanimalpairs*2,1))\n",
    "            #axs[1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA'],fontsize = 13)\n",
    "            axs[1,iplot].set_xticklabels(['E','Do','G','Da','Sp','Sc','K','K'],fontsize = 13)\n",
    "            #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "            axs[1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            if iplot == 0:\n",
    "                axs[1,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "            else:\n",
    "                axs[1,iplot].set_yticklabels([])\n",
    "            axs[1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[1,iplot].plot([-1,nanimalpairs*2],[0,0],'k--')\n",
    "\n",
    "        #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "\n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_1secondLag_IndiAnimal_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_mean95CI_basedonFromNodes.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_1secondLag_IndiAnimal_'+str(temp_resolu)+'_'+j_sampsize_name+'_mean95CI_basedonFromNodes.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e94bfb",
   "metadata": {},
   "source": [
    "### version 7-2-2: \n",
    "#### plot the key edges' modulation; \n",
    "#### only show the modulation among coop1s, self, no-vision; \n",
    "#### separate animal 1 and 2, plot individual animal; \n",
    "#### put all animal in one plot - based on the \"to Node\"; for one time lag or merged all time lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5145a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','dannon','ginger']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animalpairs_datashapes = ['o','o','o','o']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "timelag = 1 # 1 or 2 or 3 or 0(merged - merge all three lags) or 12 (merged lag 1 and 2)\n",
    "timelagname = '1second' # '1/2/3second' or 'merged' or '12merged'\n",
    "# timelagname = 'merged' # together with timelag = 0\n",
    "# timelagname = '12merged' # together with timelag = 12\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(2,6)\n",
    "fig.set_figheight(8*2)\n",
    "fig.set_figwidth(8*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 150)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 150)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    if timelag == 1:\n",
    "        pull_pull_fromNodes_all = [9,8]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [11,10]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [8,9]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [9,8]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [10,11]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [11,10]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "    elif timelag == 2:\n",
    "        pull_pull_fromNodes_all = [5,4]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [7,6]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [4,5]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [5,4]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [6,7]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [7,6]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "    elif timelag == 3:\n",
    "        pull_pull_fromNodes_all = [1,0]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [3,2]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [0,1]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [1,0]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [2,3]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [3,2]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "    elif timelag == 0:\n",
    "        pull_pull_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "        pull_pull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "        gaze_gaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "        within_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "        across_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "        within_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "        across_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "    elif timelag == 12:\n",
    "        pull_pull_fromNodes_all = [[5,9],[4,8]]\n",
    "        pull_pull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [[7,11],[6,10]]\n",
    "        gaze_gaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [[4,8],[5,9]]\n",
    "        within_pullgaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [[5,9],[4,8]]\n",
    "        across_pullgaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [[6,10],[7,11]]\n",
    "        within_gazepull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [[7,11],[6,10]]\n",
    "        across_gazepull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "    \n",
    "    \n",
    "    \n",
    "    for ianimal in np.arange(0,2,1):\n",
    "                \n",
    "        # plot coop self modulation\n",
    "\n",
    "        # pull-pull\n",
    "        a = MI_coop_self_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,0].errorbar(ianimal*nanimalpairs+ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[0,0].plot(ianimal*nanimalpairs+ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_coop_self_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,1].errorbar(ianimal*nanimalpairs+ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[0,1].plot(ianimal*nanimalpairs+ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_coop_self_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,2].errorbar(ianimal*nanimalpairs+ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[0,2].plot(ianimal*nanimalpairs+ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_coop_self_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,3].errorbar(ianimal*nanimalpairs+ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[0,3].plot(ianimal*nanimalpairs+ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_coop_self_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,4].errorbar(ianimal*nanimalpairs+ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[0,4].plot(ianimal*nanimalpairs+ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_coop_self_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,5].errorbar(ianimal*nanimalpairs+ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[0,5].plot(ianimal*nanimalpairs+ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        #\n",
    "        plottypes = ['To Node; across animal pull<->pull','To Node; across animal gaze<->gaze',\n",
    "                     'To Node; within animal gaze->pull','To Node; across animal gaze->pull',\n",
    "                     'To Node; within animal pull->gaze','To Node; across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[0,iplot].set_xlim([-0.3,nanimalpairs*2-0.7])\n",
    "            axs[0,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[0,iplot].set_xticks(np.arange(0,nanimalpairs*2,1))\n",
    "            axs[0,iplot].set_xticklabels(['E','Do','Da','G','Sp','Sc','K','K'],fontsize = 20)\n",
    "            axs[0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            #\n",
    "            if iplot == 0:\n",
    "                axs[0,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=22)\n",
    "            else:\n",
    "                axs[0,iplot].set_yticklabels([])\n",
    "            axs[0,iplot].set_title(plottypes[iplot],fontsize = 21)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[0,iplot].plot([-1,nanimalpairs*2],[0,0],'k--')\n",
    "\n",
    "        # plot novision coop modulation\n",
    "        # pull-pull\n",
    "        a = MI_nov_coop_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,0].errorbar(ianimal*nanimalpairs+ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[1,0].plot(ianimal*nanimalpairs+ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,1].errorbar(ianimal*nanimalpairs+ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[1,1].plot(ianimal*nanimalpairs+ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_nov_coop_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,2].errorbar(ianimal*nanimalpairs+ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[1,2].plot(ianimal*nanimalpairs+ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_nov_coop_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,3].errorbar(ianimal*nanimalpairs+ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[1,3].plot(ianimal*nanimalpairs+ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,4].errorbar(ianimal*nanimalpairs+ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[1,4].plot(ianimal*nanimalpairs+ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,5].errorbar(ianimal*nanimalpairs+ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[1,5].plot(ianimal*nanimalpairs+ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        plottypes = ['To Node; across animal pull<->pull','To Node; across animal gaze<->gaze',\n",
    "                     'To Node; within animal gaze->pull','To Node; across animal gaze->pull',\n",
    "                     'To Node; within animal pull->gaze','To Node; across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[1,iplot].set_xlim([-0.3,nanimalpairs*2-0.7])\n",
    "            axs[1,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[1,iplot].set_xticks(np.arange(0,nanimalpairs*2,1))\n",
    "            #axs[1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA'],fontsize = 13)\n",
    "            axs[1,iplot].set_xticklabels(['E','Do','Da','G','Sp','Sc','K','K'],fontsize = 20)\n",
    "            #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "            axs[1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            if iplot == 0:\n",
    "                axs[1,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=22)\n",
    "            else:\n",
    "                axs[1,iplot].set_yticklabels([])\n",
    "            axs[1,iplot].set_title(plottypes[iplot],fontsize = 21)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[1,iplot].plot([-1,nanimalpairs*2],[0,0],'k--')\n",
    "\n",
    "        #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "\n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_'+timelagname+'Lag_IndiAnimal_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_mean95CI_basedonToNodes.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_'+timelagname+'Lag_IndiAnimal_'+str(temp_resolu)+'_'+j_sampsize_name+'_mean95CI_basedonToNodes.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6740a217",
   "metadata": {},
   "source": [
    "### version 7-2-3: \n",
    "#### plot the key edges' modulation; \n",
    "#### only show the modulation among coop1s, self, no-vision; \n",
    "#### separate animal 1 and 2, plot individual animal; \n",
    "#### pool 1) all the animals, 2) male and female, 3) subordinate and dominant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce7e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','dannon','ginger']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animal_pooled_list = ['E','SP','DO','SC','DA','KwDA','G','KwG']\n",
    "\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "nanimalpooled = np.shape(animal_pooled_list)[0]\n",
    "\n",
    "timelag = 1 # 1 or 2 or 3 or 0(merged - merge all three lags) or 12 (merged lag 1 and 2)\n",
    "timelagname = '1second' # '1/2/3second' or 'merged' or '12merged'\n",
    "# timelagname = 'merged' # together with timelag = 0\n",
    "# timelagname = '12merged' # together with timelag = 12\n",
    "\n",
    "nMIbootstraps = 150\n",
    "\n",
    "# \n",
    "MI_coop_self_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps,6])\n",
    "MI_coop_self_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "MI_nov_coop_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps,6])\n",
    "MI_nov_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "ntimelags = 1\n",
    "if timelag == 0:\n",
    "    ntimelags = 3\n",
    "    MI_coop_self_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*3,6])\n",
    "    MI_coop_self_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "    MI_nov_coop_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*3,6])\n",
    "    MI_nov_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "if timelag == 12:\n",
    "    ntimelags = 2\n",
    "    MI_coop_self_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*2,6])\n",
    "    MI_coop_self_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "    MI_nov_coop_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*2,6])\n",
    "    MI_nov_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "#\n",
    "\n",
    "#\n",
    "#\n",
    "fig, axs = plt.subplots(3,2)\n",
    "fig.set_figheight(10*3)\n",
    "fig.set_figwidth(10*2.5)\n",
    "\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "        #\n",
    "        nMIbootstraps = 1\n",
    "    else:\n",
    "        nMIbootstraps = 150\n",
    "        #\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, nMIbootstraps)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, nMIbootstraps)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    if timelag == 1:\n",
    "        pull_pull_fromNodes_all = [9,8]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [11,10]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [8,9]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [9,8]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [10,11]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [11,10]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        ntimelags = 1\n",
    "        #\n",
    "    elif timelag == 2:\n",
    "        pull_pull_fromNodes_all = [5,4]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [7,6]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [4,5]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [5,4]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [6,7]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [7,6]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        ntimelags = 1\n",
    "        #\n",
    "    elif timelag == 3:\n",
    "        pull_pull_fromNodes_all = [1,0]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [3,2]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [0,1]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [1,0]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [2,3]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [3,2]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        ntimelags = 1\n",
    "        #\n",
    "    elif timelag == 0:\n",
    "        pull_pull_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "        pull_pull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "        gaze_gaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "        within_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "        across_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "        within_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "        across_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        ntimelags = 3\n",
    "        #\n",
    "    elif timelag == 12:\n",
    "        pull_pull_fromNodes_all = [[5,9],[4,8]]\n",
    "        pull_pull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [[7,11],[6,10]]\n",
    "        gaze_gaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [[4,8],[5,9]]\n",
    "        within_pullgaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [[5,9],[4,8]]\n",
    "        across_pullgaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [[6,10],[7,11]]\n",
    "        within_gazepull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [[7,11],[6,10]]\n",
    "        across_gazepull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        ntimelags = 2\n",
    "        #\n",
    "    \n",
    "    \n",
    "    for ianimal in np.arange(0,2,1):\n",
    "                \n",
    "        # coop self modulation\n",
    "        # pull-pull\n",
    "        a1 = MI_coop_self_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a1)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,0] = a1\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,0] = xxx1\n",
    "        # gaze-gaze\n",
    "        a2 = (MI_coop_self_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a2)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,1] = a2\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,1] = xxx2\n",
    "        # within animal gazepull\n",
    "        a3 = (MI_coop_self_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a3)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,2] = a3\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,2] = xxx3\n",
    "        # across animal gazepull\n",
    "        a4 = (MI_coop_self_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a4)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,3] = a4\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,3] = xxx4\n",
    "        # within animal pullgaze\n",
    "        a5 = (MI_coop_self_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a5)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,4] = a5\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,4] = xxx5\n",
    "        # across animal pullgaze\n",
    "        a6 = (MI_coop_self_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a6)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,5] = a6\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,5] = xxx6\n",
    "        \n",
    "        \n",
    "        # novision coop modulation\n",
    "        # pull-pull\n",
    "        a1 = MI_nov_coop_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a1)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,0] = a1\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,0] = xxx1\n",
    "        # gaze-gaze\n",
    "        a2 = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a2)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,1] = a2\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,1] = xxx2\n",
    "        # within animal gazepull\n",
    "        a3 = (MI_nov_coop_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a3)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,2] = a3\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,2] = xxx3\n",
    "        # across animal gazepull\n",
    "        a4 = (MI_nov_coop_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a4)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,3] = a4\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,3] = xxx4\n",
    "        # within animal pullgaze\n",
    "        a5 = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a5)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,4] = a5\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,4] = xxx5\n",
    "        # across animal pullgaze\n",
    "        a6 = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a6)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,5] = a6\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,5] = xxx6\n",
    "        \n",
    "\n",
    "# prepare the data\n",
    "# average all animals for each dependency\n",
    "MI_coop_self_all_IndiAni_all = MI_coop_self_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)\n",
    "MI_nov_coop_all_IndiAni_all = MI_nov_coop_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)\n",
    "MI_coop_self_all_IndiAni_allmean = np.nanmean(MI_coop_self_all_IndiAni_all,axis=0)\n",
    "MI_nov_coop_all_IndiAni_allmean = np.nanmean(MI_nov_coop_all_IndiAni_all,axis=0) \n",
    "MI_coop_self_all_IndiAni_allse = np.nanstd(MI_coop_self_all_IndiAni_all,axis=0)/np.sqrt(8*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_allse = np.nanstd(MI_nov_coop_all_IndiAni_all,axis=0)/np.sqrt(8*nMIbootstraps*ntimelags) \n",
    "\n",
    "# average all males and females for each dependency\n",
    "MI_coop_self_all_IndiAni_male = MI_coop_self_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_coop_all_IndiAni_male = MI_nov_coop_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_self_all_IndiAni_malemean = np.nanmean(MI_coop_self_all_IndiAni_male,axis=0)\n",
    "MI_nov_coop_all_IndiAni_malemean = np.nanmean(MI_nov_coop_all_IndiAni_male,axis=0) \n",
    "MI_coop_self_all_IndiAni_malese = np.nanstd(MI_coop_self_all_IndiAni_male,axis=0)/np.sqrt(3*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_malese = np.nanstd(MI_nov_coop_all_IndiAni_male,axis=0)/np.sqrt(3*nMIbootstraps*ntimelags) \n",
    "# average all males and females for each dependency\n",
    "MI_coop_self_all_IndiAni_female = MI_coop_self_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,8*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_coop_all_IndiAni_female = MI_nov_coop_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,8*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_self_all_IndiAni_femalemean = np.nanmean(MI_coop_self_all_IndiAni_female,axis=0)\n",
    "MI_nov_coop_all_IndiAni_femalemean = np.nanmean(MI_nov_coop_all_IndiAni_female,axis=0) \n",
    "MI_coop_self_all_IndiAni_femalese = np.nanstd(MI_coop_self_all_IndiAni_female,axis=0)/np.sqrt(5*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_femalese = np.nanstd(MI_nov_coop_all_IndiAni_female,axis=0)/np.sqrt(5*nMIbootstraps*ntimelags) \n",
    "\n",
    "# average all subordinate and dominant for each dependency\n",
    "MI_coop_self_all_IndiAni_sub = MI_coop_self_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1),np.arange(6*nMIbootstraps*ntimelags,7*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_coop_all_IndiAni_sub = MI_nov_coop_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1),np.arange(6*nMIbootstraps*ntimelags,7*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_self_all_IndiAni_submean = np.nanmean(MI_coop_self_all_IndiAni_sub,axis=0)\n",
    "MI_nov_coop_all_IndiAni_submean = np.nanmean(MI_nov_coop_all_IndiAni_sub,axis=0) \n",
    "MI_coop_self_all_IndiAni_subse = np.nanstd(MI_coop_self_all_IndiAni_sub,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_subse = np.nanstd(MI_nov_coop_all_IndiAni_sub,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "# average all subordinate and dominant for each dependency\n",
    "MI_coop_self_all_IndiAni_dom = MI_coop_self_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,6*nMIbootstraps*ntimelags,1),np.arange(7*nMIbootstraps*ntimelags,8*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_coop_all_IndiAni_dom = MI_nov_coop_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,6*nMIbootstraps*ntimelags,1),np.arange(7*nMIbootstraps*ntimelags,8*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_self_all_IndiAni_dommean = np.nanmean(MI_coop_self_all_IndiAni_dom,axis=0)\n",
    "MI_nov_coop_all_IndiAni_dommean = np.nanmean(MI_nov_coop_all_IndiAni_dom,axis=0) \n",
    "MI_coop_self_all_IndiAni_domse = np.nanstd(MI_coop_self_all_IndiAni_dom,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_domse = np.nanstd(MI_nov_coop_all_IndiAni_dom,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "\n",
    "# pool everything together\n",
    "MI_coop_self_all_IndiAni_pooled = {'all':MI_coop_self_all_IndiAni_all,\n",
    "                                   'male':MI_coop_self_all_IndiAni_male,\n",
    "                                   'female':MI_coop_self_all_IndiAni_female,\n",
    "                                   'subordinate':MI_coop_self_all_IndiAni_sub,\n",
    "                                   'dominant':MI_coop_self_all_IndiAni_dom}\n",
    "MI_nov_coop_all_IndiAni_pooled =  {'all':MI_nov_coop_all_IndiAni_all,\n",
    "                                   'male':MI_nov_coop_all_IndiAni_male,\n",
    "                                   'female':MI_nov_coop_all_IndiAni_female,\n",
    "                                   'subordinate':MI_nov_coop_all_IndiAni_sub,\n",
    "                                   'dominant':MI_nov_coop_all_IndiAni_dom}\n",
    "MI_coop_self_mean_IndiAni_pooled ={'all':MI_coop_self_mean_IndiAni,\n",
    "                                   'male':MI_coop_self_mean_IndiAni[[0,2,4],:],\n",
    "                                   'female':MI_coop_self_mean_IndiAni[[1,3,5,6,7],:],\n",
    "                                   'subordinate':MI_coop_self_mean_IndiAni[[0,2,4,6],:],\n",
    "                                   'dominant':MI_coop_self_mean_IndiAni[[1,3,5,7],:]}\n",
    "MI_nov_coop_mean_IndiAni_pooled = {'all':MI_nov_coop_mean_IndiAni,\n",
    "                                   'male':MI_nov_coop_mean_IndiAni[[0,2,4],:],\n",
    "                                   'female':MI_nov_coop_mean_IndiAni[[1,3,5,6,7],:],\n",
    "                                   'subordinate':MI_nov_coop_mean_IndiAni[[0,2,4,6],:],\n",
    "                                   'dominant':MI_nov_coop_mean_IndiAni[[1,3,5,7],:]}\n",
    "\n",
    "plottypes = ['all','male','female','subordinate','dominant']\n",
    "\n",
    "# for plot\n",
    "dependencynames = ['pull-pull','gaze-gaze','within_gazepull','across_gazepull','within_pullgaze','across_pullgaze']\n",
    "dependencytargets = ['pull-pull','within_gazepull','across_pullgaze']\n",
    "# dependencytargets = dependencynames\n",
    "\n",
    "for iplot in np.arange(0,5,1):\n",
    "    \n",
    "    plottype = plottypes[iplot]\n",
    "    \n",
    "    # average all animals for each dependency\n",
    "    # barplot\n",
    "    MI_coop_self_all_IndiAni_all_df = pd.DataFrame(MI_coop_self_all_IndiAni_pooled[plottype])\n",
    "    MI_coop_self_all_IndiAni_all_df.columns = dependencynames\n",
    "    MI_coop_self_all_IndiAni_all_df['MItype'] = 'coop-self'\n",
    "    #\n",
    "    MI_nov_coop_all_IndiAni_all_df = pd.DataFrame(MI_nov_coop_all_IndiAni_pooled[plottype])\n",
    "    MI_nov_coop_all_IndiAni_all_df.columns = dependencynames\n",
    "    MI_nov_coop_all_IndiAni_all_df['MItype'] = 'nov-coop'\n",
    "    #\n",
    "    df_long=pd.concat([MI_coop_self_all_IndiAni_all_df,MI_nov_coop_all_IndiAni_all_df])\n",
    "    df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "    #\n",
    "    # barplot based on all bootstrap data point\n",
    "    # seaborn.barplot(ax=ax1,data=df_long2,x='condition',y='value',hue='MItype',errorbar='ci',alpha=.5)\n",
    "    #\n",
    "    # swarmplot\n",
    "    MI_coop_self_mean_IndiAni_df = pd.DataFrame(MI_coop_self_mean_IndiAni_pooled[plottype])\n",
    "    MI_coop_self_mean_IndiAni_df.columns = dependencynames\n",
    "    MI_coop_self_mean_IndiAni_df['MItype'] = 'coop-self'\n",
    "    #\n",
    "    MI_nov_coop_mean_IndiAni_df = pd.DataFrame(MI_nov_coop_mean_IndiAni_pooled[plottype])\n",
    "    MI_nov_coop_mean_IndiAni_df.columns = dependencynames\n",
    "    MI_nov_coop_mean_IndiAni_df['MItype'] = 'nov-coop'\n",
    "    #\n",
    "    df_long=pd.concat([MI_coop_self_mean_IndiAni_df,MI_nov_coop_mean_IndiAni_df])\n",
    "    df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "    #\n",
    "    # barplot based on mean value for each animal\n",
    "    if iplot < 1:\n",
    "        seaborn.barplot(ax=axs.ravel()[iplot],data=df_long2,x='condition',y='value',hue='MItype',errorbar='se',alpha=.5,capsize=0.1)\n",
    "        seaborn.swarmplot(ax=axs.ravel()[iplot],data=df_long2,x='condition',y='value',hue='MItype',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "        axs.ravel()[iplot].set_xlabel('')\n",
    "        axs.ravel()[iplot].set_ylabel('Modulation Index',fontsize=20)\n",
    "        axs.ravel()[iplot].set_title(plottype+' animals',fontsize=24)\n",
    "        axs.ravel()[iplot].set_ylim([-1.05,1.05])\n",
    "    else:\n",
    "        seaborn.barplot(ax=axs.ravel()[iplot+1],data=df_long2,x='condition',y='value',hue='MItype',errorbar='se',alpha=.5,capsize=0.1)\n",
    "        seaborn.swarmplot(ax=axs.ravel()[iplot+1],data=df_long2,x='condition',y='value',hue='MItype',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "        axs.ravel()[iplot+1].set_xlabel('')\n",
    "        axs.ravel()[iplot+1].set_ylabel('Modulation Index',fontsize=20)\n",
    "        axs.ravel()[iplot+1].set_title(plottype+' animals',fontsize=24)\n",
    "        axs.ravel()[iplot+1].set_ylim([-1.05,1.05])\n",
    "\n",
    "\n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_'+timelagname+'Lag_IndiAnimal_summarized_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_subset.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_'+timelagname+'Lag_IndiAnimal_summarized_'+str(temp_resolu)+'_'+j_sampsize_name+'_subset.pdf')\n",
    "           \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e132a7f",
   "metadata": {},
   "source": [
    "### version 7-2-3-2:\n",
    "#### same as version 7-2-3, but group differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76da9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','dannon','ginger']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animal_pooled_list = ['E','SP','DO','SC','DA','KwDA','G','KwG']\n",
    "\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "nanimalpooled = np.shape(animal_pooled_list)[0]\n",
    "\n",
    "timelag = 1 # 1 or 2 or 3 or 0(merged - merge all three lags) or 12 (merged lag 1 and 2)\n",
    "timelagname = '1second' # '1/2/3second' or 'merged' or '12merged'\n",
    "# timelagname = 'merged' # together with timelag = 0\n",
    "# timelagname = '12merged' # together with timelag = 12\n",
    "\n",
    "nMIbootstraps = 150\n",
    "\n",
    "# \n",
    "MI_coop_self_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps,6])\n",
    "MI_coop_self_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "MI_nov_coop_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps,6])\n",
    "MI_nov_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "ntimelags = 1\n",
    "if timelag == 0:\n",
    "    ntimelags = 3\n",
    "    MI_coop_self_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*3,6])\n",
    "    MI_coop_self_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "    MI_nov_coop_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*3,6])\n",
    "    MI_nov_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "if timelag == 12:\n",
    "    ntimelags = 2\n",
    "    MI_coop_self_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*2,6])\n",
    "    MI_coop_self_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "    MI_nov_coop_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*2,6])\n",
    "    MI_nov_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "#\n",
    "\n",
    "#\n",
    "#\n",
    "fig, axs = plt.subplots(1,3)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10*3)\n",
    "\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "        #\n",
    "        nMIbootstraps = 1\n",
    "    else:\n",
    "        nMIbootstraps = 150\n",
    "        #\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, nMIbootstraps)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, nMIbootstraps)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    if timelag == 1:\n",
    "        pull_pull_fromNodes_all = [9,8]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [11,10]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [8,9]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [9,8]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [10,11]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [11,10]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        ntimelags = 1\n",
    "        #\n",
    "    elif timelag == 2:\n",
    "        pull_pull_fromNodes_all = [5,4]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [7,6]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [4,5]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [5,4]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [6,7]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [7,6]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        ntimelags = 1\n",
    "        #\n",
    "    elif timelag == 3:\n",
    "        pull_pull_fromNodes_all = [1,0]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [3,2]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [0,1]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [1,0]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [2,3]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [3,2]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        ntimelags = 1\n",
    "        #\n",
    "    elif timelag == 0:\n",
    "        pull_pull_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "        pull_pull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "        gaze_gaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "        within_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "        across_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "        within_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "        across_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        ntimelags = 3\n",
    "        #\n",
    "    elif timelag == 12:\n",
    "        pull_pull_fromNodes_all = [[5,9],[4,8]]\n",
    "        pull_pull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [[7,11],[6,10]]\n",
    "        gaze_gaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [[4,8],[5,9]]\n",
    "        within_pullgaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [[5,9],[4,8]]\n",
    "        across_pullgaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [[6,10],[7,11]]\n",
    "        within_gazepull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [[7,11],[6,10]]\n",
    "        across_gazepull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        ntimelags = 2\n",
    "        #\n",
    "    \n",
    "    \n",
    "    for ianimal in np.arange(0,2,1):\n",
    "                \n",
    "        # coop self modulation\n",
    "        # pull-pull\n",
    "        a1 = MI_coop_self_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a1)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,0] = a1\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,0] = xxx1\n",
    "        # gaze-gaze\n",
    "        a2 = (MI_coop_self_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a2)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,1] = a2\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,1] = xxx2\n",
    "        # within animal gazepull\n",
    "        a3 = (MI_coop_self_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a3)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,2] = a3\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,2] = xxx3\n",
    "        # across animal gazepull\n",
    "        a4 = (MI_coop_self_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a4)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,3] = a4\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,3] = xxx4\n",
    "        # within animal pullgaze\n",
    "        a5 = (MI_coop_self_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a5)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,4] = a5\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,4] = xxx5\n",
    "        # across animal pullgaze\n",
    "        a6 = (MI_coop_self_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a6)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,5] = a6\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,5] = xxx6\n",
    "        \n",
    "        \n",
    "        # novision coop modulation\n",
    "        # pull-pull\n",
    "        a1 = MI_nov_coop_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a1)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,0] = a1\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,0] = xxx1\n",
    "        # gaze-gaze\n",
    "        a2 = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a2)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,1] = a2\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,1] = xxx2\n",
    "        # within animal gazepull\n",
    "        a3 = (MI_nov_coop_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a3)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,2] = a3\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,2] = xxx3\n",
    "        # across animal gazepull\n",
    "        a4 = (MI_nov_coop_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a4)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,3] = a4\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,3] = xxx4\n",
    "        # within animal pullgaze\n",
    "        a5 = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a5)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,4] = a5\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,4] = xxx5\n",
    "        # across animal pullgaze\n",
    "        a6 = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a6)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,5] = a6\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,5] = xxx6\n",
    "        \n",
    "\n",
    "# prepare the data\n",
    "# average all animals for each dependency\n",
    "MI_coop_self_all_IndiAni_all = MI_coop_self_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)\n",
    "MI_nov_coop_all_IndiAni_all = MI_nov_coop_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)\n",
    "MI_coop_self_all_IndiAni_allmean = np.nanmean(MI_coop_self_all_IndiAni_all,axis=0)\n",
    "MI_nov_coop_all_IndiAni_allmean = np.nanmean(MI_nov_coop_all_IndiAni_all,axis=0) \n",
    "MI_coop_self_all_IndiAni_allse = np.nanstd(MI_coop_self_all_IndiAni_all,axis=0)/np.sqrt(8*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_allse = np.nanstd(MI_nov_coop_all_IndiAni_all,axis=0)/np.sqrt(8*nMIbootstraps*ntimelags) \n",
    "\n",
    "# average all males and females for each dependency\n",
    "MI_coop_self_all_IndiAni_male = MI_coop_self_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_coop_all_IndiAni_male = MI_nov_coop_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_self_all_IndiAni_malemean = np.nanmean(MI_coop_self_all_IndiAni_male,axis=0)\n",
    "MI_nov_coop_all_IndiAni_malemean = np.nanmean(MI_nov_coop_all_IndiAni_male,axis=0) \n",
    "MI_coop_self_all_IndiAni_malese = np.nanstd(MI_coop_self_all_IndiAni_male,axis=0)/np.sqrt(3*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_malese = np.nanstd(MI_nov_coop_all_IndiAni_male,axis=0)/np.sqrt(3*nMIbootstraps*ntimelags) \n",
    "# average all males and females for each dependency\n",
    "MI_coop_self_all_IndiAni_female = MI_coop_self_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,8*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_coop_all_IndiAni_female = MI_nov_coop_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,8*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_self_all_IndiAni_femalemean = np.nanmean(MI_coop_self_all_IndiAni_female,axis=0)\n",
    "MI_nov_coop_all_IndiAni_femalemean = np.nanmean(MI_nov_coop_all_IndiAni_female,axis=0) \n",
    "MI_coop_self_all_IndiAni_femalese = np.nanstd(MI_coop_self_all_IndiAni_female,axis=0)/np.sqrt(5*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_femalese = np.nanstd(MI_nov_coop_all_IndiAni_female,axis=0)/np.sqrt(5*nMIbootstraps*ntimelags) \n",
    "\n",
    "# average all subordinate and dominant for each dependency\n",
    "MI_coop_self_all_IndiAni_sub = MI_coop_self_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1),np.arange(6*nMIbootstraps*ntimelags,7*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_coop_all_IndiAni_sub = MI_nov_coop_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1),np.arange(6*nMIbootstraps*ntimelags,7*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_self_all_IndiAni_submean = np.nanmean(MI_coop_self_all_IndiAni_sub,axis=0)\n",
    "MI_nov_coop_all_IndiAni_submean = np.nanmean(MI_nov_coop_all_IndiAni_sub,axis=0) \n",
    "MI_coop_self_all_IndiAni_subse = np.nanstd(MI_coop_self_all_IndiAni_sub,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_subse = np.nanstd(MI_nov_coop_all_IndiAni_sub,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "# average all subordinate and dominant for each dependency\n",
    "MI_coop_self_all_IndiAni_dom = MI_coop_self_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,6*nMIbootstraps*ntimelags,1),np.arange(7*nMIbootstraps*ntimelags,8*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_coop_all_IndiAni_dom = MI_nov_coop_all_IndiAni.reshape(8*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,6*nMIbootstraps*ntimelags,1),np.arange(7*nMIbootstraps*ntimelags,8*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_self_all_IndiAni_dommean = np.nanmean(MI_coop_self_all_IndiAni_dom,axis=0)\n",
    "MI_nov_coop_all_IndiAni_dommean = np.nanmean(MI_nov_coop_all_IndiAni_dom,axis=0) \n",
    "MI_coop_self_all_IndiAni_domse = np.nanstd(MI_coop_self_all_IndiAni_dom,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_domse = np.nanstd(MI_nov_coop_all_IndiAni_dom,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "\n",
    "# pool everything together\n",
    "MI_coop_self_all_IndiAni_pooled = {'all':MI_coop_self_all_IndiAni_all,\n",
    "                                   'male':MI_coop_self_all_IndiAni_male,\n",
    "                                   'female':MI_coop_self_all_IndiAni_female,\n",
    "                                   'subordinate':MI_coop_self_all_IndiAni_sub,\n",
    "                                   'dominant':MI_coop_self_all_IndiAni_dom}\n",
    "MI_nov_coop_all_IndiAni_pooled =  {'all':MI_nov_coop_all_IndiAni_all,\n",
    "                                   'male':MI_nov_coop_all_IndiAni_male,\n",
    "                                   'female':MI_nov_coop_all_IndiAni_female,\n",
    "                                   'subordinate':MI_nov_coop_all_IndiAni_sub,\n",
    "                                   'dominant':MI_nov_coop_all_IndiAni_dom}\n",
    "MI_coop_self_mean_IndiAni_pooled ={'all':MI_coop_self_mean_IndiAni,\n",
    "                                   'male':MI_coop_self_mean_IndiAni[[0,2,4],:],\n",
    "                                   'female':MI_coop_self_mean_IndiAni[[1,3,5,6,7],:],\n",
    "                                   'subordinate':MI_coop_self_mean_IndiAni[[0,2,4,6],:],\n",
    "                                   'dominant':MI_coop_self_mean_IndiAni[[1,3,5,7],:]}\n",
    "MI_nov_coop_mean_IndiAni_pooled = {'all':MI_nov_coop_mean_IndiAni,\n",
    "                                   'male':MI_nov_coop_mean_IndiAni[[0,2,4],:],\n",
    "                                   'female':MI_nov_coop_mean_IndiAni[[1,3,5,6,7],:],\n",
    "                                   'subordinate':MI_nov_coop_mean_IndiAni[[0,2,4,6],:],\n",
    "                                   'dominant':MI_nov_coop_mean_IndiAni[[1,3,5,7],:]}\n",
    "\n",
    "# for plot\n",
    "dependencynames = ['pull-pull','gaze-gaze','within_gazepull','across_gazepull','within_pullgaze','across_pullgaze']\n",
    "dependencytargets = ['pull-pull','within_gazepull','across_pullgaze']\n",
    "# dependencytargets = dependencynames\n",
    "\n",
    "# plot 1\n",
    "# average all animals for each dependency\n",
    "# barplot\n",
    "MI_coop_self_all_IndiAni_all_df = pd.DataFrame(MI_coop_self_all_IndiAni_pooled['all'])\n",
    "MI_coop_self_all_IndiAni_all_df.columns = dependencynames\n",
    "MI_coop_self_all_IndiAni_all_df['MItype'] = 'coop-self'\n",
    "#\n",
    "MI_nov_coop_all_IndiAni_all_df = pd.DataFrame(MI_nov_coop_all_IndiAni_pooled['all'])\n",
    "MI_nov_coop_all_IndiAni_all_df.columns = dependencynames\n",
    "MI_nov_coop_all_IndiAni_all_df['MItype'] = 'nov-coop'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_self_all_IndiAni_all_df,MI_nov_coop_all_IndiAni_all_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on all bootstrap data point\n",
    "# seaborn.barplot(ax=ax1,data=df_long2,x='condition',y='value',hue='MItype',errorbar='ci',alpha=.5)\n",
    "#\n",
    "# swarmplot\n",
    "MI_coop_self_mean_IndiAni_df = pd.DataFrame(MI_coop_self_mean_IndiAni_pooled['all'])\n",
    "MI_coop_self_mean_IndiAni_df.columns = dependencynames\n",
    "MI_coop_self_mean_IndiAni_df['MItype'] = 'coop-self'\n",
    "#\n",
    "MI_nov_coop_mean_IndiAni_df = pd.DataFrame(MI_nov_coop_mean_IndiAni_pooled['all'])\n",
    "MI_nov_coop_mean_IndiAni_df.columns = dependencynames\n",
    "MI_nov_coop_mean_IndiAni_df['MItype'] = 'nov-coop'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_self_mean_IndiAni_df,MI_nov_coop_mean_IndiAni_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on mean value for each animal\n",
    "seaborn.barplot(ax=axs.ravel()[0],data=df_long2,x='condition',y='value',hue='MItype',errorbar='se',alpha=.5,capsize=0.1)\n",
    "seaborn.swarmplot(ax=axs.ravel()[0],data=df_long2,x='condition',y='value',hue='MItype',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs.ravel()[0].set_xlabel('')\n",
    "axs.ravel()[0].set_ylabel('Modulation Index',fontsize=20)\n",
    "axs.ravel()[0].set_title('all animals',fontsize=24)\n",
    "axs.ravel()[0].set_ylim([-1.35,1.35])\n",
    "\n",
    "# plot 2\n",
    "# average male and female animals for each dependency\n",
    "# barplot\n",
    "MI_coop_self_all_IndiAni_male_df = pd.DataFrame(MI_coop_self_all_IndiAni_pooled['male'])\n",
    "MI_coop_self_all_IndiAni_male_df.columns = dependencynames\n",
    "MI_coop_self_all_IndiAni_male_df['MItype'] = 'male coop-self'\n",
    "#\n",
    "MI_nov_coop_all_IndiAni_male_df = pd.DataFrame(MI_nov_coop_all_IndiAni_pooled['male'])\n",
    "MI_nov_coop_all_IndiAni_male_df.columns = dependencynames\n",
    "MI_nov_coop_all_IndiAni_male_df['MItype'] = 'male nov-coop'\n",
    "#\n",
    "MI_coop_self_all_IndiAni_female_df = pd.DataFrame(MI_coop_self_all_IndiAni_pooled['female'])\n",
    "MI_coop_self_all_IndiAni_female_df.columns = dependencynames\n",
    "MI_coop_self_all_IndiAni_female_df['MItype'] = 'female coop-self'\n",
    "#\n",
    "MI_nov_coop_all_IndiAni_female_df = pd.DataFrame(MI_nov_coop_all_IndiAni_pooled['female'])\n",
    "MI_nov_coop_all_IndiAni_female_df.columns = dependencynames\n",
    "MI_nov_coop_all_IndiAni_female_df['MItype'] = 'female nov-coop'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_self_all_IndiAni_male_df,MI_nov_coop_all_IndiAni_male_df,\n",
    "                   MI_coop_self_all_IndiAni_female_df,MI_nov_coop_all_IndiAni_female_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on all bootstrap data point\n",
    "# seaborn.barplot(ax=ax1,data=df_long2,x='condition',y='value',hue='MItype',errorbar='ci',alpha=.5)\n",
    "#\n",
    "# swarmplot\n",
    "MI_coop_self_mean_IndiAni_male_df = pd.DataFrame(MI_coop_self_mean_IndiAni_pooled['male'])\n",
    "MI_coop_self_mean_IndiAni_male_df.columns = dependencynames\n",
    "MI_coop_self_mean_IndiAni_male_df['MItype'] = 'male coop-self'\n",
    "#\n",
    "MI_nov_coop_mean_IndiAni_male_df = pd.DataFrame(MI_nov_coop_mean_IndiAni_pooled['male'])\n",
    "MI_nov_coop_mean_IndiAni_male_df.columns = dependencynames\n",
    "MI_nov_coop_mean_IndiAni_male_df['MItype'] = 'male nov-coop'\n",
    "#\n",
    "MI_coop_self_mean_IndiAni_female_df = pd.DataFrame(MI_coop_self_mean_IndiAni_pooled['female'])\n",
    "MI_coop_self_mean_IndiAni_female_df.columns = dependencynames\n",
    "MI_coop_self_mean_IndiAni_female_df['MItype'] = 'female coop-self'\n",
    "#\n",
    "MI_nov_coop_mean_IndiAni_female_df = pd.DataFrame(MI_nov_coop_mean_IndiAni_pooled['female'])\n",
    "MI_nov_coop_mean_IndiAni_female_df.columns = dependencynames\n",
    "MI_nov_coop_mean_IndiAni_female_df['MItype'] = 'female nov-coop'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_self_mean_IndiAni_male_df,MI_nov_coop_mean_IndiAni_male_df,\n",
    "                   MI_coop_self_mean_IndiAni_female_df,MI_nov_coop_mean_IndiAni_female_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on mean value for each animal\n",
    "seaborn.barplot(ax=axs.ravel()[1],data=df_long2,x='condition',y='value',hue='MItype',errorbar='se',alpha=.5,capsize=0.1)\n",
    "seaborn.swarmplot(ax=axs.ravel()[1],data=df_long2,x='condition',y='value',hue='MItype',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs.ravel()[1].set_xlabel('')\n",
    "axs.ravel()[1].set_ylabel('Modulation Index',fontsize=20)\n",
    "axs.ravel()[1].set_title('male vs female',fontsize=24)\n",
    "axs.ravel()[1].set_ylim([-1.35,1.35])\n",
    "\n",
    "# plot 3\n",
    "# average sub and dom animals for each dependency\n",
    "# barplot\n",
    "MI_coop_self_all_IndiAni_sub_df = pd.DataFrame(MI_coop_self_all_IndiAni_pooled['subordinate'])\n",
    "MI_coop_self_all_IndiAni_sub_df.columns = dependencynames\n",
    "MI_coop_self_all_IndiAni_sub_df['MItype'] = 'sub coop-self'\n",
    "#\n",
    "MI_nov_coop_all_IndiAni_sub_df = pd.DataFrame(MI_nov_coop_all_IndiAni_pooled['subordinate'])\n",
    "MI_nov_coop_all_IndiAni_sub_df.columns = dependencynames\n",
    "MI_nov_coop_all_IndiAni_sub_df['MItype'] = 'sub nov-coop'\n",
    "#\n",
    "MI_coop_self_all_IndiAni_dom_df = pd.DataFrame(MI_coop_self_all_IndiAni_pooled['dominant'])\n",
    "MI_coop_self_all_IndiAni_dom_df.columns = dependencynames\n",
    "MI_coop_self_all_IndiAni_dom_df['MItype'] = 'dom coop-self'\n",
    "#\n",
    "MI_nov_coop_all_IndiAni_dom_df = pd.DataFrame(MI_nov_coop_all_IndiAni_pooled['dominant'])\n",
    "MI_nov_coop_all_IndiAni_dom_df.columns = dependencynames\n",
    "MI_nov_coop_all_IndiAni_dom_df['MItype'] = 'dom nov-coop'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_self_all_IndiAni_sub_df,MI_nov_coop_all_IndiAni_sub_df,\n",
    "                   MI_coop_self_all_IndiAni_dom_df,MI_nov_coop_all_IndiAni_dom_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on all bootstrap data point\n",
    "# seaborn.barplot(ax=ax1,data=df_long2,x='condition',y='value',hue='MItype',errorbar='ci',alpha=.5)\n",
    "#\n",
    "# swarmplot\n",
    "MI_coop_self_mean_IndiAni_sub_df = pd.DataFrame(MI_coop_self_mean_IndiAni_pooled['subordinate'])\n",
    "MI_coop_self_mean_IndiAni_sub_df.columns = dependencynames\n",
    "MI_coop_self_mean_IndiAni_sub_df['MItype'] = 'sub coop-self'\n",
    "#\n",
    "MI_nov_coop_mean_IndiAni_sub_df = pd.DataFrame(MI_nov_coop_mean_IndiAni_pooled['subordinate'])\n",
    "MI_nov_coop_mean_IndiAni_sub_df.columns = dependencynames\n",
    "MI_nov_coop_mean_IndiAni_sub_df['MItype'] = 'sub nov-coop'\n",
    "#\n",
    "MI_coop_self_mean_IndiAni_dom_df = pd.DataFrame(MI_coop_self_mean_IndiAni_pooled['dominant'])\n",
    "MI_coop_self_mean_IndiAni_dom_df.columns = dependencynames\n",
    "MI_coop_self_mean_IndiAni_dom_df['MItype'] = 'dom coop-self'\n",
    "#\n",
    "MI_nov_coop_mean_IndiAni_dom_df = pd.DataFrame(MI_nov_coop_mean_IndiAni_pooled['dominant'])\n",
    "MI_nov_coop_mean_IndiAni_dom_df.columns = dependencynames\n",
    "MI_nov_coop_mean_IndiAni_dom_df['MItype'] = 'dom nov-coop'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_self_mean_IndiAni_sub_df,MI_nov_coop_mean_IndiAni_sub_df,\n",
    "                   MI_coop_self_mean_IndiAni_dom_df,MI_nov_coop_mean_IndiAni_dom_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on mean value for each animal\n",
    "seaborn.barplot(ax=axs.ravel()[2],data=df_long2,x='condition',y='value',hue='MItype',errorbar='se',alpha=.5,capsize=0.1)\n",
    "seaborn.swarmplot(ax=axs.ravel()[2],data=df_long2,x='condition',y='value',hue='MItype',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs.ravel()[2].set_xlabel('')\n",
    "axs.ravel()[2].set_ylabel('Modulation Index',fontsize=20)\n",
    "axs.ravel()[2].set_title('sub vs dom',fontsize=24)\n",
    "axs.ravel()[2].set_ylim([-1.35,1.35])\n",
    "\n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_'+timelagname+'Lag_IndiAnimal_summarized_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_subset_basedonToNodes.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_'+timelagname+'Lag_IndiAnimal_summarized_'+str(temp_resolu)+'_'+j_sampsize_name+'_subset_basedonToNodes.pdf')\n",
    "           \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad04a48b",
   "metadata": {},
   "source": [
    "### version 7-2-4: \n",
    "#### plot the key edges' modulation; \n",
    "#### only show the modulation among coop1s, self, no-vision; \n",
    "#### separate animal 1 and 2, plot individual animal; \n",
    "#### pool all the edges together for each individual animal and run the clustering analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb697a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','dannon','ginger']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animal_pooled_list = ['E','SP','DO','SC','DA','KwDA','G','KwG']\n",
    "\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "nanimalpooled = np.shape(animal_pooled_list)[0]\n",
    "\n",
    "timelag = 12 # 1 or 2 or 3 or 0(merged - merge all three lags) or 12 (merged lag 1 and 2)\n",
    "# timelagname = '3second' # '1/2/3second' or 'merged' or '12merged'\n",
    "# timelagname = 'merged' # together with timelag = 0\n",
    "timelagname = '12merged' # together with timelag = 12\n",
    "\n",
    "# \n",
    "MI_coop_self_all_IndiAni = np.zeros([nanimalpairs*2,150,6])\n",
    "MI_coop_self_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "MI_nov_coop_all_IndiAni = np.zeros([nanimalpairs*2,150,6])\n",
    "MI_nov_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "if timelag == 0:\n",
    "    MI_coop_self_all_IndiAni = np.zeros([nanimalpairs*2,150*3,6])\n",
    "    MI_coop_self_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "    MI_nov_coop_all_IndiAni = np.zeros([nanimalpairs*2,150*3,6])\n",
    "    MI_nov_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "if timelag == 12:\n",
    "    MI_coop_self_all_IndiAni = np.zeros([nanimalpairs*2,150*2,6])\n",
    "    MI_coop_self_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "    MI_nov_coop_all_IndiAni = np.zeros([nanimalpairs*2,150*2,6])\n",
    "    MI_nov_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "#\n",
    "\n",
    "#\n",
    "fig = plt.figure(figsize = (15*2, 15*2))\n",
    "ax1 = fig.add_subplot(2,2,1,projection='3d')\n",
    "ax2 = fig.add_subplot(2,2,2,projection='3d')\n",
    "ax3 = fig.add_subplot(2,2,3)\n",
    "ax4 = fig.add_subplot(2,2,4)\n",
    "\n",
    "\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 150)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 150)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    if timelag == 1:\n",
    "        pull_pull_fromNodes_all = [9,8]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [11,10]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [8,9]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [9,8]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [10,11]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [11,10]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "    elif timelag == 2:\n",
    "        pull_pull_fromNodes_all = [5,4]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [7,6]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [4,5]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [5,4]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [6,7]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [7,6]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "    elif timelag == 3:\n",
    "        pull_pull_fromNodes_all = [1,0]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [3,2]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [0,1]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [1,0]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [2,3]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [3,2]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "    elif timelag == 0:\n",
    "        pull_pull_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "        pull_pull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "        gaze_gaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "        within_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "        across_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "        within_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "        across_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "    elif timelag == 12:\n",
    "        pull_pull_fromNodes_all = [[5,9],[4,8]]\n",
    "        pull_pull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [[7,11],[6,10]]\n",
    "        gaze_gaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [[4,8],[5,9]]\n",
    "        within_pullgaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [[5,9],[4,8]]\n",
    "        across_pullgaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [[6,10],[7,11]]\n",
    "        within_gazepull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [[7,11],[6,10]]\n",
    "        across_gazepull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "    \n",
    "    \n",
    "    for ianimal in np.arange(0,2,1):\n",
    "                \n",
    "        # coop self modulation\n",
    "        # pull-pull\n",
    "        a1 = MI_coop_self_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a1)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,0] = a1\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,0] = xxx1\n",
    "        # gaze-gaze\n",
    "        a2 = (MI_coop_self_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a2)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,1] = a2\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,1] = xxx2\n",
    "        # within animal gazepull\n",
    "        a3 = (MI_coop_self_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a3)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,2] = a3\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,2] = xxx3\n",
    "        # across animal gazepull\n",
    "        a4 = (MI_coop_self_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a4)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,3] = a4\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,3] = xxx4\n",
    "        # within animal pullgaze\n",
    "        a5 = (MI_coop_self_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a5)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,4] = a5\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,4] = xxx5\n",
    "        # across animal pullgaze\n",
    "        a6 = (MI_coop_self_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a6)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,5] = a6\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,5] = xxx6\n",
    "        \n",
    "        \n",
    "        # novision coop modulation\n",
    "        # pull-pull\n",
    "        a1 = MI_nov_coop_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a1)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,0] = a1\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,0] = xxx1\n",
    "        # gaze-gaze\n",
    "        a2 = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a2)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,1] = a2\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,1] = xxx2\n",
    "        # within animal gazepull\n",
    "        a3 = (MI_nov_coop_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a3)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,2] = a3\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,2] = xxx3\n",
    "        # across animal gazepull\n",
    "        a4 = (MI_nov_coop_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a4)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,3] = a4\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,3] = xxx4\n",
    "        # within animal pullgaze\n",
    "        a5 = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a5)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,4] = a5\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,4] = xxx5\n",
    "        # across animal pullgaze\n",
    "        a6 = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a6)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,5] = a6\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,5] = xxx6\n",
    "        \n",
    "        \n",
    "# calculate the population level clustering\n",
    "#             \n",
    "# coop self modulation\n",
    "pca = PCA(n_components=3)\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "MI_coop_self_mean_IndiAni_PCA = pca.fit_transform(MI_coop_self_mean_IndiAni)\n",
    "if timelag == 0:\n",
    "    MI_coop_self_all_IndiAni_PCA = pca.fit_transform((MI_coop_self_all_IndiAni.reshape(8*150*3,6)))\n",
    "    MI_coop_self_all_IndiAni_PCA2 = pca.fit_transform((MI_coop_self_all_IndiAni.reshape(8,150*3*6)))\n",
    "    MI_coop_self_all_IndiAni_tsne = tsne.fit_transform(MI_coop_self_all_IndiAni.reshape(8*3*150,6))\n",
    "elif timelag == 12:\n",
    "    MI_coop_self_all_IndiAni_PCA = pca.fit_transform((MI_coop_self_all_IndiAni.reshape(8*150*2,6)))\n",
    "    MI_coop_self_all_IndiAni_PCA2 = pca.fit_transform((MI_coop_self_all_IndiAni.reshape(8,150*2*6)))\n",
    "    MI_coop_self_all_IndiAni_tsne = tsne.fit_transform(MI_coop_self_all_IndiAni.reshape(8*2*150,6))\n",
    "else:\n",
    "    MI_coop_self_all_IndiAni_PCA = pca.fit_transform((MI_coop_self_all_IndiAni.reshape(8*150,6)))\n",
    "    MI_coop_self_all_IndiAni_PCA2 = pca.fit_transform((MI_coop_self_all_IndiAni.reshape(8,150*6)))\n",
    "    MI_coop_self_all_IndiAni_tsne = tsne.fit_transform(MI_coop_self_all_IndiAni.reshape(8*150,6))\n",
    "\n",
    "# novision coop modulation\n",
    "pca = PCA(n_components=3)\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "if timelag == 0:\n",
    "    MI_nov_coop_mean_IndiAni_PCA = pca.fit_transform(MI_nov_coop_mean_IndiAni)\n",
    "    MI_nov_coop_all_IndiAni_PCA = pca.fit_transform((MI_nov_coop_all_IndiAni.reshape(8*3*150,6)))\n",
    "    MI_nov_coop_all_IndiAni_PCA2 = pca.fit_transform((MI_nov_coop_all_IndiAni.reshape(8,3*150*6)))\n",
    "    MI_nov_coop_all_IndiAni_tsne = tsne.fit_transform(MI_nov_coop_all_IndiAni.reshape(8*3*150,6))\n",
    "elif timelag == 12:\n",
    "    MI_nov_coop_mean_IndiAni_PCA = pca.fit_transform(MI_nov_coop_mean_IndiAni)\n",
    "    MI_nov_coop_all_IndiAni_PCA = pca.fit_transform((MI_nov_coop_all_IndiAni.reshape(8*2*150,6)))\n",
    "    MI_nov_coop_all_IndiAni_PCA2 = pca.fit_transform((MI_nov_coop_all_IndiAni.reshape(8,2*150*6)))\n",
    "    MI_nov_coop_all_IndiAni_tsne = tsne.fit_transform(MI_nov_coop_all_IndiAni.reshape(8*2*150,6))\n",
    "else:\n",
    "    MI_nov_coop_mean_IndiAni_PCA = pca.fit_transform(MI_nov_coop_mean_IndiAni)\n",
    "    MI_nov_coop_all_IndiAni_PCA = pca.fit_transform((MI_nov_coop_all_IndiAni.reshape(8*150,6)))\n",
    "    MI_nov_coop_all_IndiAni_PCA2 = pca.fit_transform((MI_nov_coop_all_IndiAni.reshape(8,150*6)))\n",
    "    MI_nov_coop_all_IndiAni_tsne = tsne.fit_transform(MI_nov_coop_all_IndiAni.reshape(8*150,6))\n",
    "\n",
    "    \n",
    "# plot\n",
    "for ianimalpooled in np.arange(0,nanimalpooled,1):\n",
    "    # plot the PCA clustering results\n",
    "    if 0:\n",
    "        ax1.scatter(MI_coop_self_mean_IndiAni_PCA[ianimalpooled,0],\n",
    "                    MI_coop_self_mean_IndiAni_PCA[ianimalpooled,1],\n",
    "                    MI_coop_self_mean_IndiAni_PCA[ianimalpooled,2],'o',s=60)\n",
    "        ax2.scatter(MI_nov_coop_mean_IndiAni_PCA[ianimalpooled,0],\n",
    "                    MI_nov_coop_mean_IndiAni_PCA[ianimalpooled,1],\n",
    "                    MI_nov_coop_mean_IndiAni_PCA[ianimalpooled,2],'o',s=60)\n",
    "    if 1:\n",
    "        if timelag == 0:\n",
    "            ax1.scatter(MI_coop_self_all_IndiAni_PCA[np.arange(0+ianimalpooled*450,450+ianimalpooled*450,1),0],\n",
    "                        MI_coop_self_all_IndiAni_PCA[np.arange(0+ianimalpooled*450,450+ianimalpooled*450,1),1],\n",
    "                        MI_coop_self_all_IndiAni_PCA[np.arange(0+ianimalpooled*450,450+ianimalpooled*450,1),2],'o',s=20)\n",
    "            ax2.scatter(MI_nov_coop_all_IndiAni_PCA[np.arange(0+ianimalpooled*450,450+ianimalpooled*450,1),0],\n",
    "                        MI_nov_coop_all_IndiAni_PCA[np.arange(0+ianimalpooled*450,450+ianimalpooled*450,1),1],\n",
    "                        MI_nov_coop_all_IndiAni_PCA[np.arange(0+ianimalpooled*450,450+ianimalpooled*450,1),2],'o',s=20)\n",
    "        elif timelag == 12:\n",
    "            ax1.scatter(MI_coop_self_all_IndiAni_PCA[np.arange(0+ianimalpooled*300,300+ianimalpooled*300,1),0],\n",
    "                        MI_coop_self_all_IndiAni_PCA[np.arange(0+ianimalpooled*300,300+ianimalpooled*300,1),1],\n",
    "                        MI_coop_self_all_IndiAni_PCA[np.arange(0+ianimalpooled*300,300+ianimalpooled*300,1),2],'o',s=20)\n",
    "            ax2.scatter(MI_nov_coop_all_IndiAni_PCA[np.arange(0+ianimalpooled*300,300+ianimalpooled*300,1),0],\n",
    "                        MI_nov_coop_all_IndiAni_PCA[np.arange(0+ianimalpooled*300,300+ianimalpooled*300,1),1],\n",
    "                        MI_nov_coop_all_IndiAni_PCA[np.arange(0+ianimalpooled*300,300+ianimalpooled*300,1),2],'o',s=20)      \n",
    "        else:\n",
    "            ax1.scatter(MI_coop_self_all_IndiAni_PCA[np.arange(0+ianimalpooled*150,150+ianimalpooled*150,1),0],\n",
    "                        MI_coop_self_all_IndiAni_PCA[np.arange(0+ianimalpooled*150,150+ianimalpooled*150,1),1],\n",
    "                        MI_coop_self_all_IndiAni_PCA[np.arange(0+ianimalpooled*150,150+ianimalpooled*150,1),2],'o',s=20)\n",
    "            ax2.scatter(MI_nov_coop_all_IndiAni_PCA[np.arange(0+ianimalpooled*150,150+ianimalpooled*150,1),0],\n",
    "                        MI_nov_coop_all_IndiAni_PCA[np.arange(0+ianimalpooled*150,150+ianimalpooled*150,1),1],\n",
    "                        MI_nov_coop_all_IndiAni_PCA[np.arange(0+ianimalpooled*150,150+ianimalpooled*150,1),2],'o',s=20)\n",
    "        \n",
    "    if 0:   \n",
    "        ax1.scatter(MI_coop_self_all_IndiAni_PCA2[ianimalpooled,0],\n",
    "                    MI_coop_self_all_IndiAni_PCA2[ianimalpooled,1],\n",
    "                    MI_coop_self_all_IndiAni_PCA2[ianimalpooled,2],'o',s=60)\n",
    "        ax2.scatter(MI_nov_coop_all_IndiAni_PCA2[ianimalpooled,0],\n",
    "                    MI_nov_coop_all_IndiAni_PCA2[ianimalpooled,1],\n",
    "                    MI_nov_coop_all_IndiAni_PCA2[ianimalpooled,2],'o',s=60)\n",
    "        \n",
    "    # plot the tsne clustering results\n",
    "    if timelag ==0:\n",
    "        ax3.scatter(MI_coop_self_all_IndiAni_tsne[np.arange(0+ianimalpooled*450,450+ianimalpooled*450,1),0],\n",
    "                    MI_coop_self_all_IndiAni_tsne[np.arange(0+ianimalpooled*450,450+ianimalpooled*450,1),1],s=20)\n",
    "        ax4.scatter(MI_nov_coop_all_IndiAni_tsne[np.arange(0+ianimalpooled*450,450+ianimalpooled*450,1),0],\n",
    "                    MI_nov_coop_all_IndiAni_tsne[np.arange(0+ianimalpooled*450,450+ianimalpooled*450,1),1],s=20)\n",
    "    elif timelag ==12:\n",
    "        ax3.scatter(MI_coop_self_all_IndiAni_tsne[np.arange(0+ianimalpooled*300,300+ianimalpooled*300,1),0],\n",
    "                    MI_coop_self_all_IndiAni_tsne[np.arange(0+ianimalpooled*300,300+ianimalpooled*300,1),1],s=20)\n",
    "        ax4.scatter(MI_nov_coop_all_IndiAni_tsne[np.arange(0+ianimalpooled*300,300+ianimalpooled*300,1),0],\n",
    "                    MI_nov_coop_all_IndiAni_tsne[np.arange(0+ianimalpooled*300,300+ianimalpooled*300,1),1],s=20)\n",
    "    else:\n",
    "        ax3.scatter(MI_coop_self_all_IndiAni_tsne[np.arange(0+ianimalpooled*150,150+ianimalpooled*150,1),0],\n",
    "                    MI_coop_self_all_IndiAni_tsne[np.arange(0+ianimalpooled*150,150+ianimalpooled*150,1),1],s=20)\n",
    "        ax4.scatter(MI_nov_coop_all_IndiAni_tsne[np.arange(0+ianimalpooled*150,150+ianimalpooled*150,1),0],\n",
    "                    MI_nov_coop_all_IndiAni_tsne[np.arange(0+ianimalpooled*150,150+ianimalpooled*150,1),1],s=20)\n",
    "        \n",
    "    \n",
    "    \n",
    "ax1.set_title('MI coop-self',fontsize=25)\n",
    "ax1.set_xlabel('PC1',fontsize=20)\n",
    "ax1.set_ylabel('PC2',fontsize=20)\n",
    "ax1.set_zlabel('PC3',fontsize=20)\n",
    "ax2.set_title('MI novision-coop',fontsize=25)\n",
    "ax2.set_xlabel('PC1',fontsize=20)\n",
    "ax2.set_ylabel('PC2',fontsize=20)\n",
    "ax2.set_zlabel('PC3',fontsize=20)\n",
    "ax3.set_title('MI coop-self',fontsize=25)\n",
    "ax4.set_title('MI novision-coop',fontsize=25)\n",
    "\n",
    "ax1.legend(animal_pooled_list,fontsize=20)\n",
    "ax2.legend(animal_pooled_list,fontsize=20)\n",
    "ax3.legend(animal_pooled_list,fontsize=20)\n",
    "ax4.legend(animal_pooled_list,fontsize=20)\n",
    "    \n",
    "    \n",
    "    \n",
    "savefig = 0\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_'+timelagname+'Lag_IndiAnimal_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_clustering.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_'+timelagname+'Lag_IndiAnimal_'+str(temp_resolu)+'_'+j_sampsize_name+'_clustering.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ec3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d335c99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f77796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec539601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6743a861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc6692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950499c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22925cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6df0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c171f05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
