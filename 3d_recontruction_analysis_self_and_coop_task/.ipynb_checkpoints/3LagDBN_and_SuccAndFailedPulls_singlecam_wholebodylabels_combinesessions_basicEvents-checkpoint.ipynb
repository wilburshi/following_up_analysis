{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca6246b",
   "metadata": {},
   "source": [
    "### In this script, DBN is run on the combined sessions, combined for each condition\n",
    "### In this script, DBN is run with 1s time bin, 3 time lag \n",
    "### In this script, DBN is run with failed and successful pulls\n",
    "### In this script, the animal tracking is done with only one camera - camera 2 (middle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd279dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "import string\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.models import DynamicBayesianNetwork as DBN\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.estimators import HillClimbSearch,BicScore\n",
    "from pgmpy.base import DAG\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee0ed4",
   "metadata": {},
   "source": [
    "### function - get body part location for each pair of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1724bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.body_part_locs_eachpair import body_part_locs_eachpair\n",
    "from ana_functions.body_part_locs_singlecam import body_part_locs_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ae6f98",
   "metadata": {},
   "source": [
    "### function - align the two cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b03438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_align import camera_align       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494356c2",
   "metadata": {},
   "source": [
    "### function - merge the two pairs of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bda6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_merge import camera_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc7f6a",
   "metadata": {},
   "source": [
    "### function - find social gaze time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f6ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.find_socialgaze_timepoint import find_socialgaze_timepoint\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam import find_socialgaze_timepoint_singlecam\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam_wholebody import find_socialgaze_timepoint_singlecam_wholebody"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7e75b",
   "metadata": {},
   "source": [
    "### function - define time point of behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dfb672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_timepoint import bhv_events_timepoint\n",
    "from ana_functions.bhv_events_timepoint_singlecam import bhv_events_timepoint_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4ab8c",
   "metadata": {},
   "source": [
    "### function - plot behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb2ba678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.plot_bhv_events import plot_bhv_events\n",
    "from ana_functions.plot_bhv_events_levertube import plot_bhv_events_levertube\n",
    "from ana_functions.draw_self_loop import draw_self_loop\n",
    "import matplotlib.patches as mpatches \n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c724b",
   "metadata": {},
   "source": [
    "### function - plot inter-pull interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9327925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.plot_interpull_interval import plot_interpull_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d535a6",
   "metadata": {},
   "source": [
    "### function - make demo videos with skeleton and inportant vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec4de83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.tracking_video_singlecam_demo import tracking_video_singlecam_demo\n",
    "from ana_functions.tracking_video_singlecam_wholebody_demo import tracking_video_singlecam_wholebody_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69920a6a",
   "metadata": {},
   "source": [
    "### function - interval between all behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a804dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_interval import bhv_events_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c0b97",
   "metadata": {},
   "source": [
    "### function - train the dynamic bayesian network - multi time lag (3 lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "003d7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.train_DBN_multiLag_morebhv import train_DBN_multiLag\n",
    "from ana_functions.train_DBN_multiLag_morebhv import train_DBN_multiLag_create_df_only\n",
    "from ana_functions.train_DBN_multiLag_morebhv import train_DBN_multiLag_training_only\n",
    "from ana_functions.train_DBN_multiLag_morebhv import graph_to_matrix\n",
    "from ana_functions.train_DBN_multiLag_morebhv import get_weighted_dags\n",
    "from ana_functions.train_DBN_multiLag_morebhv import get_significant_edges\n",
    "from ana_functions.train_DBN_multiLag_morebhv import threshold_edges\n",
    "from ana_functions.train_DBN_multiLag_morebhv import Modulation_Index\n",
    "from ana_functions.EfficientTimeShuffling import EfficientShuffle\n",
    "from ana_functions.AicScore import AicScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819c438",
   "metadata": {},
   "source": [
    "## Analyze each session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e84fc",
   "metadata": {},
   "source": [
    "### prepare the basic behavioral data (especially the time stamps for each bhv events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9dc05cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instead of using gaze angle threshold, use the target rectagon to deside gaze info\n",
    "# ...need to update\n",
    "sqr_thres_tubelever = 75 # draw the square around tube and lever\n",
    "sqr_thres_face = 1.15 # a ratio for defining face boundary\n",
    "sqr_thres_body = 4 # how many times to enlongate the face box boundry to the body\n",
    "\n",
    "\n",
    "# get the fps of the analyzed video\n",
    "fps = 30\n",
    "\n",
    "# frame number of the demo video\n",
    "# nframes = 0.5*30 # second*30fps\n",
    "nframes = 5*30 # second*30fps\n",
    "\n",
    "# re-analyze the video or not\n",
    "reanalyze_video = 0\n",
    "redo_anystep = 0\n",
    "\n",
    "# only analyze the best (five) sessions for each conditions\n",
    "do_bestsession = 1\n",
    "if do_bestsession:\n",
    "    savefile_sufix = '_bestsessions'\n",
    "else:\n",
    "    savefile_sufix = ''\n",
    "    \n",
    "# all the videos (no misaligned ones)\n",
    "# aligned with the audio\n",
    "# get the session start time from \"videosound_bhv_sync.py/.ipynb\"\n",
    "# currently the session_start_time will be manually typed in. It can be updated after a better method is used\n",
    "\n",
    "# dodson scorch\n",
    "if 0:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [\n",
    "                      \"20220909\",\"20220912\",\"20220915\",\"20220920\",\"20220922\",\"20220923\",\"20221010\",\n",
    "                      \"20221011\",\"20221013\",\"20221014\",\"20221015\",\"20221017\",\"20230215\",     \n",
    "                      \"20221018\",\"20221019\",\"20221020\",\"20221021\",\"20221022\",\"20221026\",\"20221028\",\"20221030\",\n",
    "                      \"20221107\",\"20221108\",\"20221109\",\"20221110\",\"20221111\",\"20221114\",\"20221115\",\"20221116\",\n",
    "                      \"20221117\",\"20221118\",\"20221121\",\"20221122\",\"20221123\",\"20221125\",\"20221128\",\"20221129\",              \n",
    "                      \"20221205\",\"20221206\",\"20221209\",\"20221212\",\"20221214\",\"20221216\",\"20221219\",\"20221220\",\n",
    "                      \"20221221\",\"20230208\",\"20230209\",\"20230213\",\"20230214\",\"20230111\",\"20230112\",\"20230201\",\n",
    "\n",
    "                     ]\n",
    "        session_start_times = [ \n",
    "                                 6.50, 18.10, 0,      33.03, 549.0, 116.80, 6.50,\n",
    "                                 2.80, 27.80, 272.50, 27.90, 27.00,  33.00,\n",
    "                                28.70, 45.30, 21.10,  27.10, 51.90,  21.00, 30.80, 17.50,                      \n",
    "                                15.70,  2.65, 27.30,   0.00,  0.00,  71.80,  0.00,  0.00, \n",
    "                                75.50, 20.20,  0.00,  24.20, 36.70,  26.40, 22.50, 28.50,                       \n",
    "                                 0.00,  0.00, 21.70,  84.70, 17.00,  19.80, 23.50, 25.20,  \n",
    "                                 0.00,  0.00,  0.00,   0.00,  0.00, 130.00, 14.20, 24.20, \n",
    "                              ] # in second\n",
    "    elif do_bestsession:\n",
    "        # pick only five sessions for each conditions\n",
    "        dates_list = [\n",
    "                      \"20220912\",\"20220915\",\"20220920\",\"20221010\",\"20230208\",\n",
    "                      \"20221011\",\"20221013\",\"20221015\",\"20221017\",\n",
    "                      \"20221022\",\"20221026\",\"20221028\",\"20221030\",\"20230209\",\n",
    "                      \"20221125\",\"20221128\",\"20221129\",\"20230214\",\"20230215\",                  \n",
    "                      \"20221205\",\"20221206\",\"20221209\",\"20221214\",\"20230112\",\n",
    "                      \"20230117\",\"20230118\",\"20230124\",\"20230126\",\n",
    "                     ]\n",
    "        session_start_times = [ \n",
    "                                18.10,  0.00, 33.03,  6.50,  0.00, \n",
    "                                 2.80, 27.80, 27.90, 27.00,  \n",
    "                                51.90, 21.00, 30.80, 17.50,  0.00,                    \n",
    "                                26.40, 22.50, 28.50,  0.00, 33.00,                     \n",
    "                                 0.00,  0.00, 21.70, 17.00, 14.20, \n",
    "                                 0.00,  0.00,  0.00,  0.00,  \n",
    "                              ] # in second\n",
    "    \n",
    "    animal1_fixedorder = ['dodson']\n",
    "    animal2_fixedorder = ['scorch']\n",
    "\n",
    "    animal1_filename = \"Dodson\"\n",
    "    animal2_filename = \"Scorch\"\n",
    "    \n",
    "# eddie sparkle\n",
    "if 1:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [\n",
    "                      \"20221122\",\"20221125\",\"20221128\",\"20221129\",\"20221130\",\"20221202\",\"20221206\",\n",
    "                      \"20221207\",\"20221208\",\"20221209\",\"20230126\",\"20230127\",\"20230130\",\"20230201\",\"20230203-1\",\n",
    "                      \"20230206\",\"20230207\",\"20230208-1\",\"20230209\",\"20230222\",\"20230223-1\",\"20230227-1\",\n",
    "                      \"20230228-1\",\"20230302-1\",\"20230307-2\",\"20230313\",\"20230315\",\"20230316\",\"20230317\",\n",
    "                      \"20230321\",\"20230322\",\"20230324\",\"20230327\",\"20230328\",\n",
    "                      \"20230330\",\"20230331\",\"20230403\",\"20230404\",\"20230405\",\"20230406\",\"20230407\",\n",
    "                      \n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                 8.00,38.00,1.00,3.00,5.00,9.50,1.00,\n",
    "                                 4.50,4.50,5.00,38.00,166.00,4.20,3.80,3.60,\n",
    "                                 7.50,9.00,7.50,8.50,14.50,7.80,8.00,7.50,\n",
    "                                 8.00,8.00,4.00,123.00,14.00,8.80,\n",
    "                                 7.00,7.50,5.50,11.00,9.00,\n",
    "                                 17.00,4.50,9.30,25.50,20.40,21.30,24.80,\n",
    "                                 \n",
    "                              ] # in second\n",
    "    elif do_bestsession:   \n",
    "        dates_list = [\n",
    "                      \"20221122\",  \"20221125\",  \n",
    "                      \"20221202\",  \"20221206\",  \"20230126\",  \"20230130\",  \"20230201\",\n",
    "                      \"20230207\",  \"20230208-1\",\"20230209\",  \"20230222\",  \"20230223-1\",\n",
    "                      \"20230227-1\",\"20230228-1\",\"20230302-1\",\"20230307-2\",\"20230313\",\n",
    "                      \"20230321\",  \"20230322\",  \"20230324\",  \"20230327\",  \"20230328\",\n",
    "                      \"20230331\",  \"20230403\",  \"20230404\",  \"20230405\",  \"20230406\"\n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                  8.00,  38.00, \n",
    "                                  9.50,   1.00, 38.00,  4.20,  3.80,\n",
    "                                  9.00,   7.50,  8.50, 14.50,  7.80,\n",
    "                                  8.00,   7.50,  8.00,  8.00,  4.00,\n",
    "                                  7.00,   7.50,  5.50, 11.00,  9.00,\n",
    "                                  4.50,   9.30, 25.50, 20.40, 21.30,\n",
    "                              ] # in second\n",
    "    \n",
    "    animal1_fixedorder = ['eddie']\n",
    "    animal2_fixedorder = ['sparkle']\n",
    "\n",
    "    animal1_filename = \"Eddie\"\n",
    "    animal2_filename = \"Sparkle\"\n",
    "    \n",
    "# ginger kanga\n",
    "if 0:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [\n",
    "                      \"20230209\",\"20230213\",\"20230214\",\"20230216\",\"20230222\",\"20230223\",\"20230228\",\"20230302\",\n",
    "                      \"20230303\",\"20230307\",\"20230314\",\"20230315\",\"20230316\",\"20230317\"         \n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                 0.00,  0.00,  0.00, 48.00, 26.20, 18.00, 23.00, 28.50,\n",
    "                                34.00, 25.50, 25.50, 31.50, 28.00, 30.50\n",
    "                              ] # in second \n",
    "    elif do_bestsession:   \n",
    "        dates_list = [\n",
    "                      \"20230213\",\"20230214\",\"20230216\",\n",
    "                      \"20230228\",\"20230302\",\"20230303\",\"20230307\",          \n",
    "                      \"20230314\",\"20230315\",\"20230316\",\"20230317\",\n",
    "                      \"20230301\",\"20230320\",\"20230321\",\"20230322\",\n",
    "                      \"20230323\",\"20230412\",\"20230413\",\"20230517\",\"20230614\",\"20230615\",\n",
    "                      \"20230522_ws\",\"20230524\",\"20230605_1\",\"20230606\",\"20230607\"\n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                 0.00,  0.00, 48.00, \n",
    "                                23.00, 28.50, 34.00, 25.50, \n",
    "                                25.50, 31.50, 28.00, 30.50,\n",
    "                                33.50, 22.20, 50.00,  0.00, \n",
    "                                33.00, 18.20, 22.80, 31.00, 24.00, 21.00,\n",
    "                                 0.00,  0.00,  0.00,  0.00,  0.00,\n",
    "                              ] # in second \n",
    "    \n",
    "    animal1_fixedorder = ['ginger']\n",
    "    animal2_fixedorder = ['kanga']\n",
    "\n",
    "    animal1_filename = \"Ginger\"\n",
    "    animal2_filename = \"Kanga\"\n",
    "\n",
    "    \n",
    "#    \n",
    "#dates_list = [\"20221128\"]\n",
    "#session_start_times = [1.00] # in second\n",
    "ndates = np.shape(dates_list)[0]\n",
    "\n",
    "session_start_frames = session_start_times * fps # fps is 30Hz\n",
    "\n",
    "totalsess_time = 600\n",
    "\n",
    "# video tracking results info\n",
    "animalnames_videotrack = ['dodson','scorch'] # does not really mean dodson and scorch, instead, indicate animal1 and animal2\n",
    "bodypartnames_videotrack = ['rightTuft','whiteBlaze','leftTuft','rightEye','leftEye','mouth']\n",
    "\n",
    "\n",
    "# which camera to analyzed\n",
    "cameraID = 'camera-2'\n",
    "cameraID_short = 'cam2'\n",
    "\n",
    "\n",
    "# location of levers and tubes for camera 2\n",
    "# get this information using DLC animal tracking GUI, the results are stored: \n",
    "# /home/ws523/marmoset_tracking_DLCv2/marmoset_tracking_with_lever_tube-weikang-2023-04-13/labeled-data/\n",
    "considerlevertube = 1\n",
    "considertubeonly = 0\n",
    "# # camera 1\n",
    "# lever_locs_camI = {'dodson':np.array([645,600]),'scorch':np.array([425,435])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1350,630]),'scorch':np.array([555,345])}\n",
    "# # camera 2\n",
    "lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "tube_locs_camI  = {'dodson':np.array([1550,515]),'scorch':np.array([350,515])}\n",
    "# # lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "# # tube_locs_camI  = {'dodson':np.array([1650,490]),'scorch':np.array([250,490])}\n",
    "# # camera 3\n",
    "# lever_locs_camI = {'dodson':np.array([1580,440]),'scorch':np.array([1296,540])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1470,375]),'scorch':np.array([805,475])}\n",
    "\n",
    "\n",
    "if np.shape(session_start_times)[0] != np.shape(dates_list)[0]:\n",
    "    exit()\n",
    "\n",
    "    \n",
    "# define bhv events summarizing variables     \n",
    "tasktypes_all_dates = np.zeros((ndates,1))\n",
    "coopthres_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "succ_rate_all_dates = np.zeros((ndates,1))\n",
    "interpullintv_all_dates = np.zeros((ndates,1))\n",
    "trialnum_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "owgaze1_num_all_dates = np.zeros((ndates,1))\n",
    "owgaze2_num_all_dates = np.zeros((ndates,1))\n",
    "mtgaze1_num_all_dates = np.zeros((ndates,1))\n",
    "mtgaze2_num_all_dates = np.zeros((ndates,1))\n",
    "pull1_num_all_dates = np.zeros((ndates,1))\n",
    "pull2_num_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "bhv_intv_all_dates = dict.fromkeys(dates_list, [])\n",
    "\n",
    "\n",
    "# where to save the summarizing data\n",
    "data_saved_folder = '/gpfs/gibbs/pi/jadi/VideoTracker_SocialInter/3d_recontruction_analysis_self_and_coop_task_data_saved/'\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c7a76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data from all dates are loaded\n"
     ]
    }
   ],
   "source": [
    "# basic behavior analysis (define time stamps for each bhv events, etc)\n",
    "\n",
    "try:\n",
    "    if redo_anystep:\n",
    "        dummy\n",
    "    \n",
    "    # load saved data\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    \n",
    "    with open(data_saved_subfolder+'/owgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        owgaze1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/owgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        owgaze2_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/mtgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        mtgaze1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/mtgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        mtgaze2_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/pull1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        pull1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/pull2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        pull2_num_all_dates = pickle.load(f)\n",
    "\n",
    "    with open(data_saved_subfolder+'/tasktypes_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        tasktypes_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/coopthres_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        coopthres_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/succ_rate_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        succ_rate_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/interpullintv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        interpullintv_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/trialnum_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        trialnum_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/bhv_intv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        bhv_intv_all_dates = pickle.load(f)\n",
    "\n",
    "    print('all data from all dates are loaded')\n",
    "\n",
    "except:\n",
    "\n",
    "    print('analyze all dates')\n",
    "\n",
    "    for idate in np.arange(0,ndates,1):\n",
    "        date_tgt = dates_list[idate]\n",
    "        session_start_time = session_start_times[idate]\n",
    "\n",
    "        # folder and file path\n",
    "        camera12_analyzed_path = \"/gpfs/gibbs/pi/jadi/VideoTracker_SocialInter/test_video_cooperative_task_3d/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera12/\"\n",
    "        camera23_analyzed_path = \"/gpfs/gibbs/pi/jadi/VideoTracker_SocialInter/test_video_cooperative_task_3d/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera23/\"\n",
    "        \n",
    "        singlecam_ana_type = \"DLC_dlcrnetms5_marmoset_tracking_with_middle_cameraSep1shuffle1_150000\"\n",
    "        try: \n",
    "            bodyparts_camI_camIJ = camera12_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "            # get the bodypart data from files\n",
    "            bodyparts_locs_camI = body_part_locs_singlecam(bodyparts_camI_camIJ,singlecam_ana_type,animalnames_videotrack,bodypartnames_videotrack,date_tgt)\n",
    "            video_file_original = camera12_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+\".mp4\"\n",
    "        except:\n",
    "            bodyparts_camI_camIJ = camera23_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "            # get the bodypart data from files\n",
    "            bodyparts_locs_camI = body_part_locs_singlecam(bodyparts_camI_camIJ,singlecam_ana_type,animalnames_videotrack,bodypartnames_videotrack,date_tgt)\n",
    "            video_file_original = camera23_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+\".mp4\"        \n",
    "        \n",
    "        \n",
    "        # load behavioral results\n",
    "        try:\n",
    "            bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "            trial_record_json = glob.glob(bhv_data_path +date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "            bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_bhv_data_\" + \"*.json\")\n",
    "            session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_session_info_\" + \"*.json\")\n",
    "            #\n",
    "            trial_record = pd.read_json(trial_record_json[0])\n",
    "            bhv_data = pd.read_json(bhv_data_json[0])\n",
    "            session_info = pd.read_json(session_info_json[0])\n",
    "        except:\n",
    "            bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "            trial_record_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "            bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_bhv_data_\" + \"*.json\")\n",
    "            session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_session_info_\" + \"*.json\")\n",
    "            #\n",
    "            trial_record = pd.read_json(trial_record_json[0])\n",
    "            bhv_data = pd.read_json(bhv_data_json[0])\n",
    "            session_info = pd.read_json(session_info_json[0])\n",
    "\n",
    "        # get animal info from the session information\n",
    "        animal1 = session_info['lever1_animal'][0].lower()\n",
    "        animal2 = session_info['lever2_animal'][0].lower()\n",
    "\n",
    "        \n",
    "        # get task type and cooperation threshold\n",
    "        try:\n",
    "            coop_thres = session_info[\"pulltime_thres\"][0]\n",
    "            tasktype = session_info[\"task_type\"][0]\n",
    "        except:\n",
    "            coop_thres = 0\n",
    "            tasktype = 1\n",
    "        tasktypes_all_dates[idate] = tasktype\n",
    "        coopthres_all_dates[idate] = coop_thres   \n",
    "\n",
    "        # clean up the trial_record\n",
    "        warnings.filterwarnings('ignore')\n",
    "        trial_record_clean = pd.DataFrame(columns=trial_record.columns)\n",
    "        for itrial in np.arange(0,np.max(trial_record['trial_number']),1):\n",
    "            # trial_record_clean.loc[itrial] = trial_record[trial_record['trial_number']==itrial+1].iloc[[0]]\n",
    "            trial_record_clean = trial_record_clean.append(trial_record[trial_record['trial_number']==itrial+1].iloc[[0]])\n",
    "        trial_record_clean = trial_record_clean.reset_index(drop = True)\n",
    "\n",
    "        # change bhv_data time to the absolute time\n",
    "        time_points_new = pd.DataFrame(np.zeros(np.shape(bhv_data)[0]),columns=[\"time_points_new\"])\n",
    "        for itrial in np.arange(0,np.max(trial_record_clean['trial_number']),1):\n",
    "            ind = bhv_data[\"trial_number\"]==itrial+1\n",
    "            new_time_itrial = bhv_data[ind][\"time_points\"] + trial_record_clean[\"trial_starttime\"].iloc[itrial]\n",
    "            time_points_new[\"time_points_new\"][ind] = new_time_itrial\n",
    "        bhv_data[\"time_points\"] = time_points_new[\"time_points_new\"]\n",
    "        bhv_data = bhv_data[bhv_data[\"time_points\"] != 0]\n",
    "\n",
    "\n",
    "        # analyze behavior results\n",
    "        # succ_rate_all_dates[idate] = np.sum(trial_record_clean[\"rewarded\"]>0)/np.shape(trial_record_clean)[0]\n",
    "        succ_rate_all_dates[idate] = np.sum((bhv_data['behavior_events']==3)|(bhv_data['behavior_events']==4))/np.sum((bhv_data['behavior_events']==1)|(bhv_data['behavior_events']==2))\n",
    "        trialnum_all_dates[idate] = np.shape(trial_record_clean)[0]\n",
    "        #\n",
    "        pullid = np.array(bhv_data[(bhv_data['behavior_events']==1) | (bhv_data['behavior_events']==2)][\"behavior_events\"])\n",
    "        pulltime = np.array(bhv_data[(bhv_data['behavior_events']==1) | (bhv_data['behavior_events']==2)][\"time_points\"])\n",
    "        pullid_diff = np.abs(pullid[1:] - pullid[0:-1])\n",
    "        pulltime_diff = pulltime[1:] - pulltime[0:-1]\n",
    "        interpull_intv = pulltime_diff[pullid_diff==1]\n",
    "        interpull_intv = interpull_intv[interpull_intv<10]\n",
    "        mean_interpull_intv = np.nanmean(interpull_intv)\n",
    "        std_interpull_intv = np.nanstd(interpull_intv)\n",
    "        #\n",
    "        interpullintv_all_dates[idate] = mean_interpull_intv\n",
    "        # \n",
    "        pull1_num_all_dates[idate] = np.sum(bhv_data['behavior_events']==1) \n",
    "        pull2_num_all_dates[idate] = np.sum(bhv_data['behavior_events']==2)\n",
    "\n",
    "        \n",
    "        # load behavioral event results\n",
    "        try:\n",
    "            # dummy\n",
    "            print('load social gaze with '+cameraID+' only of '+date_tgt)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_look_ornot.pkl', 'rb') as f:\n",
    "                output_look_ornot = pickle.load(f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allvectors.pkl', 'rb') as f:\n",
    "                output_allvectors = pickle.load(f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allangles.pkl', 'rb') as f:\n",
    "                output_allangles = pickle.load(f)  \n",
    "        except:   \n",
    "            print('analyze social gaze with '+cameraID+' only of '+date_tgt)\n",
    "            # get social gaze information \n",
    "            output_look_ornot, output_allvectors, output_allangles = find_socialgaze_timepoint_singlecam_wholebody(bodyparts_locs_camI,lever_locs_camI,tube_locs_camI,\n",
    "                                                                                                                   considerlevertube,considertubeonly,sqr_thres_tubelever,\n",
    "                                                                                                                   sqr_thres_face,sqr_thres_body)\n",
    "            # save data\n",
    "            current_dir = data_saved_folder+'/bhv_events_singlecam_wholebody/'+animal1_fixedorder[0]+animal2_fixedorder[0]\n",
    "            add_date_dir = os.path.join(current_dir,cameraID+'/'+date_tgt)\n",
    "            if not os.path.exists(add_date_dir):\n",
    "                os.makedirs(add_date_dir)\n",
    "            #\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_look_ornot.pkl', 'wb') as f:\n",
    "                pickle.dump(output_look_ornot, f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allvectors.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allvectors, f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allangles.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allangles, f)\n",
    "  \n",
    "\n",
    "        look_at_other_or_not_merge = output_look_ornot['look_at_other_or_not_merge']\n",
    "        look_at_tube_or_not_merge = output_look_ornot['look_at_tube_or_not_merge']\n",
    "        look_at_lever_or_not_merge = output_look_ornot['look_at_lever_or_not_merge']\n",
    "        # change the unit to second\n",
    "        session_start_time = session_start_times[idate]\n",
    "        look_at_other_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_other_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_lever_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_lever_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_tube_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_tube_or_not_merge['dodson'])[0],1)/fps - session_start_time \n",
    "\n",
    "        # find time point of behavioral events\n",
    "        output_time_points_socialgaze ,output_time_points_levertube = bhv_events_timepoint_singlecam(bhv_data,look_at_other_or_not_merge,look_at_lever_or_not_merge,look_at_tube_or_not_merge)\n",
    "        time_point_pull1 = output_time_points_socialgaze['time_point_pull1']\n",
    "        time_point_pull2 = output_time_points_socialgaze['time_point_pull2']\n",
    "        oneway_gaze1 = output_time_points_socialgaze['oneway_gaze1']\n",
    "        oneway_gaze2 = output_time_points_socialgaze['oneway_gaze2']\n",
    "        mutual_gaze1 = output_time_points_socialgaze['mutual_gaze1']\n",
    "        mutual_gaze2 = output_time_points_socialgaze['mutual_gaze2']\n",
    "            \n",
    "                \n",
    "        # # plot behavioral events\n",
    "        if np.isin(animal1,animal1_fixedorder):\n",
    "                plot_bhv_events(date_tgt,animal1, animal2, session_start_time, 600, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "        else:\n",
    "                plot_bhv_events(date_tgt,animal2, animal1, session_start_time, 600, time_point_pull2, time_point_pull1, oneway_gaze2, oneway_gaze1, mutual_gaze2, mutual_gaze1)\n",
    "        #\n",
    "        # save behavioral events plot\n",
    "        if 0:\n",
    "            current_dir = data_saved_folder+'/bhv_events_singlecam_wholebody/'+animal1_fixedorder[0]+animal2_fixedorder[0]\n",
    "            add_date_dir = os.path.join(current_dir,cameraID+'/'+date_tgt)\n",
    "            if not os.path.exists(add_date_dir):\n",
    "                os.makedirs(add_date_dir)\n",
    "            plt.savefig(data_saved_folder+\"/bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/'+date_tgt+\"_\"+cameraID_short+\".pdf\")\n",
    "\n",
    "        #\n",
    "        owgaze1_num_all_dates[idate] = np.shape(oneway_gaze1)[0]\n",
    "        owgaze2_num_all_dates[idate] = np.shape(oneway_gaze2)[0]\n",
    "        mtgaze1_num_all_dates[idate] = np.shape(mutual_gaze1)[0]\n",
    "        mtgaze2_num_all_dates[idate] = np.shape(mutual_gaze2)[0]\n",
    "\n",
    "        # analyze the events interval, especially for the pull to other and other to pull interval\n",
    "        # could be used for define time bin for DBN\n",
    "        if 1:\n",
    "            _,_,_,pullTOother_itv, otherTOpull_itv = bhv_events_interval(totalsess_time, session_start_time, time_point_pull1, time_point_pull2, \n",
    "                                                                         oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "            #\n",
    "            pull_other_pool_itv = np.concatenate((pullTOother_itv,otherTOpull_itv))\n",
    "            bhv_intv_all_dates[date_tgt] = {'pull_to_other':pullTOother_itv,'other_to_pull':otherTOpull_itv,\n",
    "                            'pull_other_pooled': pull_other_pool_itv}\n",
    "        \n",
    "        # plot the tracking demo video\n",
    "        if 1: \n",
    "            tracking_video_singlecam_wholebody_demo(bodyparts_locs_camI,output_look_ornot,output_allvectors,output_allangles,\n",
    "                                              lever_locs_camI,tube_locs_camI,time_point_pull1,time_point_pull2,\n",
    "                                              animalnames_videotrack,bodypartnames_videotrack,date_tgt,\n",
    "                                              animal1_filename,animal2_filename,session_start_time,fps,nframes,cameraID,\n",
    "                                              video_file_original,sqr_thres_tubelever,sqr_thres_face,sqr_thres_body)         \n",
    "        \n",
    "\n",
    "    # save data\n",
    "    if 0:\n",
    "        \n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "        if not os.path.exists(data_saved_subfolder):\n",
    "            os.makedirs(data_saved_subfolder)\n",
    "                \n",
    "        # with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        #     pickle.dump(DBN_input_data_alltypes, f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/owgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(owgaze1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/owgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(owgaze2_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/mtgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(mtgaze1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/mtgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(mtgaze2_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/pull1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(pull1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/pull2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(pull2_num_all_dates, f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/tasktypes_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(tasktypes_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/coopthres_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(coopthres_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/succ_rate_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(succ_rate_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/interpullintv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(interpullintv_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/trialnum_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(trialnum_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/bhv_intv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(bhv_intv_all_dates, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aada694",
   "metadata": {},
   "source": [
    "#### redefine the tasktype and cooperation threshold to merge them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d0e6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100: self; 3: 3s coop; 2: 2s coop; 1.5: 1.5s coop; 1: 1s coop; -1: no-vision\n",
    "\n",
    "tasktypes_all_dates[tasktypes_all_dates==5] = -1 # change the task type code for no-vision\n",
    "coopthres_forsort = (tasktypes_all_dates-1)*coopthres_all_dates/2\n",
    "coopthres_forsort[coopthres_forsort==0] = 100 # get the cooperation threshold for sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900d890",
   "metadata": {},
   "source": [
    "### plot behavioral events interval to get a sense about time bin\n",
    "#### only focus on pull_to_other_bhv_interval and other_bhv_to_pull_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7b179dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.25413534 3.93133641 2.72666667 1.04       1.89896907 2.4366548\n",
      " 1.66333333 1.35128205 1.725      0.77234043 1.07867647 1.67349398\n",
      " 0.28072289 1.3358209  0.46603774 0.45117371 0.2602649  0.39724138\n",
      " 0.29331683 0.42712766 0.22762148 1.22994505 2.1195122  1.46363636\n",
      " 1.78122066 2.1475     1.19878788]\n",
      "1.230512249443207\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates': dates_list, 'coopthres': coopthres_forsort.ravel()}, columns=['dates', 'coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['coopthres','dates'], ascending = [False, True])\n",
    "dates_list_sorted = np.array(dates_list)[sorting_df.index]\n",
    "ndates_sorted = np.shape(dates_list_sorted)[0]\n",
    "\n",
    "pull_other_intv_forplots = {}\n",
    "pull_other_intv_mean = np.zeros((1,ndates_sorted))[0]\n",
    "pull_other_intv_ii = []\n",
    "for ii in np.arange(0,ndates_sorted,1):\n",
    "    pull_other_intv_ii = pd.Series(bhv_intv_all_dates[dates_list_sorted[ii]]['pull_other_pooled'])\n",
    "    # remove the interval that is too large\n",
    "    pull_other_intv_ii[pull_other_intv_ii>(np.nanmean(pull_other_intv_ii)+2*np.nanstd(pull_other_intv_ii))]= np.nan    \n",
    "    # pull_other_intv_ii[pull_other_intv_ii>10]= np.nan\n",
    "    pull_other_intv_forplots[ii] = pull_other_intv_ii\n",
    "    pull_other_intv_mean[ii] = np.nanmean(pull_other_intv_ii)\n",
    "    \n",
    "    \n",
    "#\n",
    "pull_other_intv_forplots = pd.DataFrame(pull_other_intv_forplots)\n",
    "\n",
    "#\n",
    "# plot\n",
    "pull_other_intv_forplots.plot(kind = 'box',ax=ax1, positions=np.arange(0,ndates_sorted,1))\n",
    "# plt.boxplot(pull_other_intv_forplots)\n",
    "plt.plot(np.arange(0,ndates_sorted,1),pull_other_intv_mean,'r*',markersize=10)\n",
    "#\n",
    "ax1.set_ylabel(\"bhv event interval(around pulls)\",fontsize=13)\n",
    "ax1.set_ylim([-2,16])\n",
    "#\n",
    "plt.xticks(np.arange(0,ndates_sorted,1),dates_list_sorted, rotation=90,fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "#\n",
    "tasktypes = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','no-vision']\n",
    "taskswitches = np.where(np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)[0]+0.5\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.plot([taskswitch,taskswitch],[-2,15],'k--')\n",
    "taskswitches = np.concatenate(([0],taskswitches))\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.text(taskswitch+0.25,-1,tasktypes[itaskswitch],fontsize=10)\n",
    "ax1.text(taskswitch-5,15,'mean Inteval = '+str(np.nanmean(pull_other_intv_forplots)),fontsize=10)\n",
    "\n",
    "print(pull_other_intv_mean)\n",
    "print(np.nanmean(pull_other_intv_forplots))\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"bhvInterval_hist_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e1548e",
   "metadata": {},
   "source": [
    "### prepare the input data for DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d188541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load social gaze with camera-2 only of 20221122\n",
      "load social gaze with camera-2 only of 20221125\n",
      "load social gaze with camera-2 only of 20221202\n",
      "load social gaze with camera-2 only of 20221206\n",
      "load social gaze with camera-2 only of 20230126\n",
      "load social gaze with camera-2 only of 20230130\n",
      "load social gaze with camera-2 only of 20230201\n",
      "load social gaze with camera-2 only of 20230207\n",
      "load social gaze with camera-2 only of 20230208-1\n",
      "load social gaze with camera-2 only of 20230209\n",
      "load social gaze with camera-2 only of 20230222\n",
      "load social gaze with camera-2 only of 20230223-1\n",
      "load social gaze with camera-2 only of 20230227-1\n",
      "load social gaze with camera-2 only of 20230228-1\n",
      "load social gaze with camera-2 only of 20230302-1\n",
      "load social gaze with camera-2 only of 20230307-2\n",
      "load social gaze with camera-2 only of 20230313\n",
      "load social gaze with camera-2 only of 20230321\n",
      "load social gaze with camera-2 only of 20230322\n",
      "load social gaze with camera-2 only of 20230324\n",
      "load social gaze with camera-2 only of 20230327\n",
      "load social gaze with camera-2 only of 20230328\n",
      "load social gaze with camera-2 only of 20230331\n",
      "load social gaze with camera-2 only of 20230403\n",
      "load social gaze with camera-2 only of 20230404\n",
      "load social gaze with camera-2 only of 20230405\n",
      "load social gaze with camera-2 only of 20230406\n"
     ]
    }
   ],
   "source": [
    "# define DBN related summarizing variables\n",
    "#DBN_group_typenames = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','no-vision']\n",
    "#DBN_group_typeIDs  =  [1,3,3,  3,3,5]\n",
    "#DBN_group_coopthres = [0,3,2,1.5,1,0]\n",
    "DBN_group_typenames = ['self','coop(1s)','no-vision']\n",
    "DBN_group_typeIDs  =  [1,3,5]\n",
    "DBN_group_coopthres = [0,1,0]\n",
    "nDBN_groups = np.shape(DBN_group_typenames)[0]\n",
    "\n",
    "prepare_input_data = 1\n",
    "\n",
    "DBN_input_data_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "\n",
    "# DBN resolutions (make sure they are the same as in the later part of the code)\n",
    "totalsess_time = 600 # total session time in s\n",
    "# temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "ntemp_reses = np.shape(temp_resolus)[0]\n",
    "\n",
    "mergetempRos = 0\n",
    "\n",
    "# # train the dynamic bayesian network - Alec's model \n",
    "#   prepare the multi-session table; one time lag; multi time steps (temporal resolution) as separate files\n",
    "\n",
    "# prepare the DBN input data\n",
    "if prepare_input_data:\n",
    "    \n",
    "    for idate in np.arange(0,ndates,1):\n",
    "        date_tgt = dates_list[idate]\n",
    "        session_start_time = session_start_times[idate]\n",
    "\n",
    "        # load behavioral results\n",
    "        try:\n",
    "            bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "            trial_record_json = glob.glob(bhv_data_path +date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "            bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_bhv_data_\" + \"*.json\")\n",
    "            session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_session_info_\" + \"*.json\")\n",
    "            #\n",
    "            trial_record = pd.read_json(trial_record_json[0])\n",
    "            bhv_data = pd.read_json(bhv_data_json[0])\n",
    "            session_info = pd.read_json(session_info_json[0])\n",
    "        except:\n",
    "            bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "            trial_record_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "            bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_bhv_data_\" + \"*.json\")\n",
    "            session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_session_info_\" + \"*.json\")\n",
    "            #\n",
    "            trial_record = pd.read_json(trial_record_json[0])\n",
    "            bhv_data = pd.read_json(bhv_data_json[0])\n",
    "            session_info = pd.read_json(session_info_json[0])\n",
    "            \n",
    "        # get animal info\n",
    "        animal1 = session_info['lever1_animal'][0].lower()\n",
    "        animal2 = session_info['lever2_animal'][0].lower()\n",
    "        \n",
    "        # clean up the trial_record\n",
    "        warnings.filterwarnings('ignore')\n",
    "        trial_record_clean = pd.DataFrame(columns=trial_record.columns)\n",
    "        for itrial in np.arange(0,np.max(trial_record['trial_number']),1):\n",
    "            # trial_record_clean.loc[itrial] = trial_record[trial_record['trial_number']==itrial+1].iloc[[0]]\n",
    "            trial_record_clean = trial_record_clean.append(trial_record[trial_record['trial_number']==itrial+1].iloc[[0]])\n",
    "        trial_record_clean = trial_record_clean.reset_index(drop = True)\n",
    "\n",
    "        # change bhv_data time to the absolute time\n",
    "        time_points_new = pd.DataFrame(np.zeros(np.shape(bhv_data)[0]),columns=[\"time_points_new\"])\n",
    "        for itrial in np.arange(0,np.max(trial_record_clean['trial_number']),1):\n",
    "            ind = bhv_data[\"trial_number\"]==itrial+1\n",
    "            new_time_itrial = bhv_data[ind][\"time_points\"] + trial_record_clean[\"trial_starttime\"].iloc[itrial]\n",
    "            time_points_new[\"time_points_new\"][ind] = new_time_itrial\n",
    "        bhv_data[\"time_points\"] = time_points_new[\"time_points_new\"]\n",
    "        bhv_data = bhv_data[bhv_data[\"time_points\"] != 0]\n",
    "            \n",
    "        # get task type and cooperation threshold\n",
    "        try:\n",
    "            coop_thres = session_info[\"pulltime_thres\"][0]\n",
    "            tasktype = session_info[\"task_type\"][0]\n",
    "        except:\n",
    "            coop_thres = 0\n",
    "            tasktype = 1\n",
    "\n",
    "        # load behavioral event results\n",
    "        print('load social gaze with '+cameraID+' only of '+date_tgt)\n",
    "        with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_look_ornot.pkl', 'rb') as f:\n",
    "            output_look_ornot = pickle.load(f)\n",
    "        with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allvectors.pkl', 'rb') as f:\n",
    "            output_allvectors = pickle.load(f)\n",
    "        with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allangles.pkl', 'rb') as f:\n",
    "            output_allangles = pickle.load(f)  \n",
    "        #\n",
    "        look_at_other_or_not_merge = output_look_ornot['look_at_other_or_not_merge']\n",
    "        look_at_tube_or_not_merge = output_look_ornot['look_at_tube_or_not_merge']\n",
    "        look_at_lever_or_not_merge = output_look_ornot['look_at_lever_or_not_merge']\n",
    "        # change the unit to second\n",
    "        session_start_time = session_start_times[idate]\n",
    "        look_at_other_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_other_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_lever_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_lever_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_tube_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_tube_or_not_merge['dodson'])[0],1)/fps - session_start_time \n",
    "\n",
    "        # find time point of behavioral events\n",
    "        output_time_points_socialgaze ,output_time_points_levertube = bhv_events_timepoint_singlecam(bhv_data,look_at_other_or_not_merge,look_at_lever_or_not_merge,look_at_tube_or_not_merge)\n",
    "        time_point_pull1 = output_time_points_socialgaze['time_point_pull1']\n",
    "        time_point_pull2 = output_time_points_socialgaze['time_point_pull2']\n",
    "        oneway_gaze1 = output_time_points_socialgaze['oneway_gaze1']\n",
    "        oneway_gaze2 = output_time_points_socialgaze['oneway_gaze2']\n",
    "        mutual_gaze1 = output_time_points_socialgaze['mutual_gaze1']\n",
    "        mutual_gaze2 = output_time_points_socialgaze['mutual_gaze2']   \n",
    "        lever_gaze1 = output_time_points_levertube['time_point_lookatlever1']\n",
    "        lever_gaze2 = output_time_points_levertube['time_point_lookatlever2']\n",
    "        tube_gaze1 = output_time_points_levertube['time_point_lookattube1']\n",
    "        tube_gaze2 = output_time_points_levertube['time_point_lookattube2']\n",
    "\n",
    "\n",
    "        if mergetempRos:\n",
    "            temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "            # use bhv event to decide temporal resolution\n",
    "            #\n",
    "            #low_lim,up_lim,_ = bhv_events_interval(totalsess_time, session_start_time, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "            #temp_resolus = temp_resolus = np.arange(low_lim,up_lim,0.1)\n",
    "\n",
    "        ntemp_reses = np.shape(temp_resolus)[0]           \n",
    "\n",
    "        # try different temporal resolutions\n",
    "        for temp_resolu in temp_resolus:\n",
    "            bhv_df = []\n",
    "\n",
    "            if np.isin(animal1,animal1_fixedorder):\n",
    "                bhv_df_itr,_,_ = train_DBN_multiLag_create_df_only(totalsess_time,session_start_time,temp_resolu,time_point_pull1,time_point_pull2,oneway_gaze1,oneway_gaze2,mutual_gaze1,mutual_gaze2,lever_gaze1,lever_gaze2,tube_gaze1,tube_gaze2)\n",
    "            else:\n",
    "                bhv_df_itr,_,_ = train_DBN_multiLag_create_df_only(totalsess_time,session_start_time,temp_resolu,time_point_pull2,time_point_pull1,oneway_gaze2,oneway_gaze1,mutual_gaze2,mutual_gaze1,lever_gaze2,lever_gaze1,tube_gaze2,tube_gaze1)     \n",
    "\n",
    "            if len(bhv_df)==0:\n",
    "                bhv_df = bhv_df_itr\n",
    "            else:\n",
    "                bhv_df = pd.concat([bhv_df,bhv_df_itr])                   \n",
    "                bhv_df = bhv_df.reset_index(drop=True)        \n",
    "\n",
    "            # merge sessions from the same condition\n",
    "            for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "                iDBN_group_typename = DBN_group_typenames[iDBN_group] \n",
    "                iDBN_group_typeID =  DBN_group_typeIDs[iDBN_group] \n",
    "                iDBN_group_cothres = DBN_group_coopthres[iDBN_group] \n",
    "\n",
    "                # merge sessions \n",
    "                if (tasktype!=3):\n",
    "                    if (tasktype==iDBN_group_typeID):\n",
    "                        if (len(DBN_input_data_alltypes[iDBN_group_typename])==0):\n",
    "                            DBN_input_data_alltypes[iDBN_group_typename] = bhv_df\n",
    "                        else:\n",
    "                            DBN_input_data_alltypes[iDBN_group_typename] = pd.concat([DBN_input_data_alltypes[iDBN_group_typename],bhv_df])\n",
    "                else:\n",
    "                    if (coop_thres==iDBN_group_cothres):\n",
    "                        if (len(DBN_input_data_alltypes[iDBN_group_typename])==0):\n",
    "                            DBN_input_data_alltypes[iDBN_group_typename] = bhv_df\n",
    "                        else:\n",
    "                            DBN_input_data_alltypes[iDBN_group_typename] = pd.concat([DBN_input_data_alltypes[iDBN_group_typename],bhv_df])\n",
    "\n",
    "    # save data\n",
    "    if 1:\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_morebhv_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "        if not os.path.exists(data_saved_subfolder):\n",
    "            os.makedirs(data_saved_subfolder)\n",
    "        if not mergetempRos:\n",
    "            with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'sReSo.pkl', 'wb') as f:\n",
    "                pickle.dump(DBN_input_data_alltypes, f)\n",
    "        else:\n",
    "            with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_mergeTempsReSo.pkl', 'wb') as f:\n",
    "                pickle.dump(DBN_input_data_alltypes, f)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "545c4f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1160, 24)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(DBN_input_data_alltypes['self'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a722ca91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a743731",
   "metadata": {},
   "source": [
    "### run the DBN model on the combined session data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d7d323",
   "metadata": {},
   "source": [
    "#### a test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68d13d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run DBN on the large table with merged sessions\n",
    "\n",
    "mergetempRos = 0 # 1: merge different time bins\n",
    "\n",
    "moreSampSize = 0 # 1: use more sample size (more than just minimal row number and max row number)\n",
    "\n",
    "num_starting_points = 1 # number of random starting points/graphs\n",
    "nbootstraps = 1\n",
    "\n",
    "if 0:\n",
    "\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        samplingsizes = np.arange(1100,3000,100)\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "        nsamplings = np.shape(samplingsizes)[0]\n",
    "\n",
    "    weighted_graphs_diffTempRo_diffSampSize = {}\n",
    "    weighted_graphs_shuffled_diffTempRo_diffSampSize = {}\n",
    "    sig_edges_diffTempRo_diffSampSize = {}\n",
    "    DAGscores_diffTempRo_diffSampSize = {}\n",
    "    DAGscores_shuffled_diffTempRo_diffSampSize = {}\n",
    "\n",
    "    totalsess_time = 600 # total session time in s\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "\n",
    "    # try different temporal resolutions, remember to use the same settings as in the previous ones\n",
    "    for temp_resolu in temp_resolus:\n",
    "\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_morebhv_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "        if not mergetempRos:\n",
    "            with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "                DBN_input_data_alltypes = pickle.load(f)\n",
    "        else:\n",
    "            with open(data_saved_subfolder+'//DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "                DBN_input_data_alltypes = pickle.load(f)\n",
    "\n",
    "                \n",
    "        # only try two sample sizes - minimal row number (require data downsample) and maximal row number (require data upsample)\n",
    "       \n",
    "        if not moreSampSize:\n",
    "            key_to_value_lengths = {k:len(v) for k, v in DBN_input_data_alltypes.items()}\n",
    "            key_to_value_lengths_array = np.fromiter(key_to_value_lengths.values(),dtype=float)\n",
    "            key_to_value_lengths_array[key_to_value_lengths_array==0]=np.nan\n",
    "            min_samplesize = np.nanmin(key_to_value_lengths_array)\n",
    "            min_samplesize = int(min_samplesize/100)*100\n",
    "            max_samplesize = np.nanmax(key_to_value_lengths_array)\n",
    "            max_samplesize = int(max_samplesize/100)*100\n",
    "            samplingsizes = [min_samplesize,max_samplesize]\n",
    "            samplingsizes_name = ['min_row_number','max_row_number']   \n",
    "            nsamplings = np.shape(samplingsizes)[0]\n",
    "            print(samplingsizes)\n",
    "                \n",
    "        # try different down/re-sampling size\n",
    "        # for jj in np.arange(0,nsamplings,1):\n",
    "        for jj in np.arange(0,1,1):\n",
    "            \n",
    "            isamplingsize = samplingsizes[jj]\n",
    "            \n",
    "            DAGs_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            DAGs_shuffle_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            DAGs_scores_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            DAGs_shuffle_scores_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "\n",
    "            weighted_graphs_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            weighted_graphs_shuffled_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "            sig_edges_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "\n",
    "            # different session conditions (aka DBN groups)\n",
    "            # for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "            for iDBN_group in np.arange(0,1,1):\n",
    "                iDBN_group_typename = DBN_group_typenames[iDBN_group] \n",
    "                iDBN_group_typeID =  DBN_group_typeIDs[iDBN_group] \n",
    "                iDBN_group_cothres = DBN_group_coopthres[iDBN_group] \n",
    "\n",
    "                try:\n",
    "                    bhv_df_all = DBN_input_data_alltypes[iDBN_group_typename]\n",
    "                    # bhv_df = bhv_df_all.sample(30*100,replace = True, random_state = round(time())) # take the subset for DBN training\n",
    "\n",
    "                    #Anirban(Alec) shuffle, slow\n",
    "                    # bhv_df_shuffle, df_shufflekeys = EfficientShuffle(bhv_df,round(time()))\n",
    "\n",
    "\n",
    "                    # define DBN graph structures; make sure they are the same as in the train_DBN_multiLag\n",
    "                    colnames = list(bhv_df_all.columns)\n",
    "                    eventnames = [\"pull1\",\"pull2\",\"owgaze1\",\"owgaze2\",\"tbgaze1\",\"tbgaze2\"]\n",
    "                    nevents = np.size(eventnames)\n",
    "\n",
    "                    all_pops = list(bhv_df_all.columns)\n",
    "                    from_pops = [pop for pop in all_pops if not pop.endswith('t3')]\n",
    "                    to_pops = [pop for pop in all_pops if pop.endswith('t3')]\n",
    "                    causal_whitelist = [(from_pop,to_pop) for from_pop in from_pops for to_pop in to_pops]\n",
    "\n",
    "                    nFromNodes = np.shape(from_pops)[0]\n",
    "                    nToNodes = np.shape(to_pops)[0]\n",
    "\n",
    "                    DAGs_randstart = np.zeros((num_starting_points, nFromNodes, nToNodes))\n",
    "                    DAGs_randstart_shuffle = np.zeros((num_starting_points, nFromNodes, nToNodes))\n",
    "                    score_randstart = np.zeros((num_starting_points))\n",
    "                    score_randstart_shuffle = np.zeros((num_starting_points))\n",
    "\n",
    "                    # step 1: randomize the starting point for num_starting_points times\n",
    "                    for istarting_points in np.arange(0,num_starting_points,1):\n",
    "\n",
    "                        # try different down/re-sampling size\n",
    "                        bhv_df = bhv_df_all.sample(isamplingsize,replace = True, random_state = istarting_points) # take the subset for DBN training\n",
    "                        aic = AicScore(bhv_df)\n",
    "\n",
    "                        #Anirban(Alec) shuffle, slow\n",
    "                        bhv_df_shuffle, df_shufflekeys = EfficientShuffle(bhv_df,round(time()))\n",
    "                        aic_shuffle = AicScore(bhv_df_shuffle)\n",
    "\n",
    "                        np.random.seed(istarting_points)\n",
    "                        random.seed(istarting_points)\n",
    "                        starting_edges = random.sample(causal_whitelist, np.random.randint(1,len(causal_whitelist)))\n",
    "                        starting_graph = DAG()\n",
    "                        starting_graph.add_nodes_from(nodes=all_pops)\n",
    "                        starting_graph.add_edges_from(ebunch=starting_edges)\n",
    "\n",
    "                        best_model,edges,DAGs = train_DBN_multiLag_training_only(bhv_df,starting_graph,colnames,eventnames,from_pops,to_pops)           \n",
    "                        DAGs[0][np.isnan(DAGs[0])]=0\n",
    "\n",
    "                        DAGs_randstart[istarting_points,:,:] = DAGs[0]\n",
    "                        score_randstart[istarting_points] = aic.score(best_model)\n",
    "\n",
    "                        # step 2: add the shffled data results\n",
    "                        # shuffled bhv_df\n",
    "                        best_model,edges,DAGs = train_DBN_multiLag_training_only(bhv_df_shuffle,starting_graph,colnames,eventnames,from_pops,to_pops)           \n",
    "                        DAGs[0][np.isnan(DAGs[0])]=0\n",
    "\n",
    "                        DAGs_randstart_shuffle[istarting_points,:,:] = DAGs[0]\n",
    "                        score_randstart_shuffle[istarting_points] = aic_shuffle.score(best_model)\n",
    "\n",
    "                    DAGs_alltypes[iDBN_group_typename] = DAGs_randstart \n",
    "                    DAGs_shuffle_alltypes[iDBN_group_typename] = DAGs_randstart_shuffle\n",
    "\n",
    "                    DAGs_scores_alltypes[iDBN_group_typename] = score_randstart\n",
    "                    DAGs_shuffle_scores_alltypes[iDBN_group_typename] = score_randstart_shuffle\n",
    "\n",
    "                    weighted_graphs = get_weighted_dags(DAGs_alltypes[iDBN_group_typename],nbootstraps)\n",
    "                    weighted_graphs_shuffled = get_weighted_dags(DAGs_shuffle_alltypes[iDBN_group_typename],nbootstraps)\n",
    "                    sig_edges = get_significant_edges(weighted_graphs,weighted_graphs_shuffled)\n",
    "\n",
    "                    weighted_graphs_alltypes[iDBN_group_typename] = weighted_graphs\n",
    "                    weighted_graphs_shuffled_alltypes[iDBN_group_typename] = weighted_graphs_shuffled\n",
    "                    sig_edges_alltypes[iDBN_group_typename] = sig_edges\n",
    "                    \n",
    "                except:\n",
    "                    DAGs_alltypes[iDBN_group_typename] = [] \n",
    "                    DAGs_shuffle_alltypes[iDBN_group_typename] = []\n",
    "\n",
    "                    DAGs_scores_alltypes[iDBN_group_typename] = []\n",
    "                    DAGs_shuffle_scores_alltypes[iDBN_group_typename] = []\n",
    "\n",
    "                    weighted_graphs_alltypes[iDBN_group_typename] = []\n",
    "                    weighted_graphs_shuffled_alltypes[iDBN_group_typename] = []\n",
    "                    sig_edges_alltypes[iDBN_group_typename] = []\n",
    "                \n",
    "            DAGscores_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = DAGs_scores_alltypes\n",
    "            DAGscores_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = DAGs_shuffle_scores_alltypes\n",
    "\n",
    "            weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = weighted_graphs_alltypes\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = weighted_graphs_shuffled_alltypes\n",
    "            sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = sig_edges_alltypes\n",
    "\n",
    "    print(weighted_graphs_diffTempRo_diffSampSize)\n",
    "            \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d647783a",
   "metadata": {},
   "source": [
    "#### run on the entire population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cafbb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run DBN on the large table with merged sessions\n",
    "\n",
    "mergetempRos = 0 # 1: merge different time bins\n",
    "\n",
    "moreSampSize = 0 # 1: use more sample size (more than just minimal row number and max row number)\n",
    "\n",
    "num_starting_points = 100 # number of random starting points/graphs\n",
    "nbootstraps = 95\n",
    "\n",
    "try:\n",
    "    # dumpy\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_morebhv_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(data_saved_subfolder):\n",
    "        os.makedirs(data_saved_subfolder)\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/DAGscores_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_self_moreSampSize.pkl', 'rb') as f:\n",
    "            DAGscores_diffTempRo_diffSampSize = pickle.load(f) \n",
    "        with open(data_saved_subfolder+'/DAGscores_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_self_moreSampSize.pkl', 'rb') as f:\n",
    "            DAGscores_shuffled_diffTempRo_diffSampSize = pickle.load(f) \n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_self_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_self_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_self_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/DAGscores_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_self.pkl', 'rb') as f:\n",
    "            DAGscores_diffTempRo_diffSampSize = pickle.load(f) \n",
    "        with open(data_saved_subfolder+'/DAGscores_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_self.pkl', 'rb') as f:\n",
    "            DAGscores_shuffled_diffTempRo_diffSampSize = pickle.load(f) \n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_self.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_self.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_self.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "except:\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        samplingsizes = np.arange(1100,3000,100)\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "        nsamplings = np.shape(samplingsizes)[0]\n",
    "\n",
    "    weighted_graphs_diffTempRo_diffSampSize = {}\n",
    "    weighted_graphs_shuffled_diffTempRo_diffSampSize = {}\n",
    "    sig_edges_diffTempRo_diffSampSize = {}\n",
    "    DAGscores_diffTempRo_diffSampSize = {}\n",
    "    DAGscores_shuffled_diffTempRo_diffSampSize = {}\n",
    "\n",
    "    totalsess_time = 600 # total session time in s\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_morebhv_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not mergetempRos:\n",
    "        with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "            DBN_input_data_alltypes = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'//DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "            DBN_input_data_alltypes = pickle.load(f)\n",
    "     \n",
    "    #\n",
    "    DAGs_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "    DAGs_shuffle_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "    DAGs_scores_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "    DAGs_shuffle_scores_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "\n",
    "    weighted_graphs_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "    weighted_graphs_shuffled_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "    sig_edges_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "\n",
    "    # different session conditions (aka DBN groups)\n",
    "    for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "        iDBN_group_typename = DBN_group_typenames[iDBN_group] \n",
    "        iDBN_group_typeID =  DBN_group_typeIDs[iDBN_group] \n",
    "        iDBN_group_cothres = DBN_group_coopthres[iDBN_group] \n",
    "                \n",
    "        # try different temporal resolutions, remember to use the same settings as in the previous ones\n",
    "        for temp_resolu in temp_resolus:\n",
    "\n",
    "            # only try two sample sizes - minimal row number (require data downsample) and maximal row number (require data upsample)\n",
    "\n",
    "            if not moreSampSize:\n",
    "                key_to_value_lengths = {k:len(v) for k, v in DBN_input_data_alltypes.items()}\n",
    "                key_to_value_lengths_array = np.fromiter(key_to_value_lengths.values(),dtype=float)\n",
    "                key_to_value_lengths_array[key_to_value_lengths_array==0]=np.nan\n",
    "                min_samplesize = np.nanmin(key_to_value_lengths_array)\n",
    "                min_samplesize = int(min_samplesize/100)*100\n",
    "                max_samplesize = np.nanmax(key_to_value_lengths_array)\n",
    "                max_samplesize = int(max_samplesize/100)*100\n",
    "                samplingsizes = [min_samplesize,max_samplesize]\n",
    "                samplingsizes_name = ['min_row_number','max_row_number']   \n",
    "                nsamplings = np.shape(samplingsizes)[0]\n",
    "                print(samplingsizes)\n",
    "\n",
    "            # try different down/re-sampling size\n",
    "            for jj in np.arange(0,nsamplings,1):\n",
    "\n",
    "                isamplingsize = samplingsizes[jj]\n",
    "\n",
    "                try:\n",
    "                    bhv_df_all = DBN_input_data_alltypes[iDBN_group_typename]\n",
    "                    # bhv_df = bhv_df_all.sample(30*100,replace = True, random_state = round(time())) # take the subset for DBN training\n",
    "\n",
    "                    #Anirban(Alec) shuffle, slow\n",
    "                    # bhv_df_shuffle, df_shufflekeys = EfficientShuffle(bhv_df,round(time()))\n",
    "\n",
    "\n",
    "                    # define DBN graph structures; make sure they are the same as in the train_DBN_multiLag\n",
    "                    colnames = list(bhv_df_all.columns)\n",
    "                    eventnames = [\"pull1\",\"pull2\",\"owgaze1\",\"owgaze2\",\"tbgaze1\",\"tbgaze2\"]\n",
    "                    nevents = np.size(eventnames)\n",
    "\n",
    "                    all_pops = list(bhv_df_all.columns)\n",
    "                    from_pops = [pop for pop in all_pops if not pop.endswith('t3')]\n",
    "                    to_pops = [pop for pop in all_pops if pop.endswith('t3')]\n",
    "                    causal_whitelist = [(from_pop,to_pop) for from_pop in from_pops for to_pop in to_pops]\n",
    "\n",
    "                    nFromNodes = np.shape(from_pops)[0]\n",
    "                    nToNodes = np.shape(to_pops)[0]\n",
    "\n",
    "                    DAGs_randstart = np.zeros((num_starting_points, nFromNodes, nToNodes))\n",
    "                    DAGs_randstart_shuffle = np.zeros((num_starting_points, nFromNodes, nToNodes))\n",
    "                    score_randstart = np.zeros((num_starting_points))\n",
    "                    score_randstart_shuffle = np.zeros((num_starting_points))\n",
    "\n",
    "                    # step 1: randomize the starting point for num_starting_points times\n",
    "                    for istarting_points in np.arange(0,num_starting_points,1):\n",
    "\n",
    "                        # try different down/re-sampling size\n",
    "                        bhv_df = bhv_df_all.sample(isamplingsize,replace = True, random_state = istarting_points) # take the subset for DBN training\n",
    "                        aic = AicScore(bhv_df)\n",
    "\n",
    "                        #Anirban(Alec) shuffle, slow\n",
    "                        bhv_df_shuffle, df_shufflekeys = EfficientShuffle(bhv_df,round(time()))\n",
    "                        aic_shuffle = AicScore(bhv_df_shuffle)\n",
    "\n",
    "                        np.random.seed(istarting_points)\n",
    "                        random.seed(istarting_points)\n",
    "                        starting_edges = random.sample(causal_whitelist, np.random.randint(1,len(causal_whitelist)))\n",
    "                        starting_graph = DAG()\n",
    "                        starting_graph.add_nodes_from(nodes=all_pops)\n",
    "                        starting_graph.add_edges_from(ebunch=starting_edges)\n",
    "\n",
    "                        best_model,edges,DAGs = train_DBN_multiLag_training_only(bhv_df,starting_graph,colnames,eventnames,from_pops,to_pops)           \n",
    "                        DAGs[0][np.isnan(DAGs[0])]=0\n",
    "\n",
    "                        DAGs_randstart[istarting_points,:,:] = DAGs[0]\n",
    "                        score_randstart[istarting_points] = aic.score(best_model)\n",
    "\n",
    "                        # step 2: add the shffled data results\n",
    "                        # shuffled bhv_df\n",
    "                        best_model,edges,DAGs = train_DBN_multiLag_training_only(bhv_df_shuffle,starting_graph,colnames,eventnames,from_pops,to_pops)           \n",
    "                        DAGs[0][np.isnan(DAGs[0])]=0\n",
    "\n",
    "                        DAGs_randstart_shuffle[istarting_points,:,:] = DAGs[0]\n",
    "                        score_randstart_shuffle[istarting_points] = aic_shuffle.score(best_model)\n",
    "\n",
    "                    DAGs_alltypes[iDBN_group_typename] = DAGs_randstart \n",
    "                    DAGs_shuffle_alltypes[iDBN_group_typename] = DAGs_randstart_shuffle\n",
    "\n",
    "                    DAGs_scores_alltypes[iDBN_group_typename] = score_randstart\n",
    "                    DAGs_shuffle_scores_alltypes[iDBN_group_typename] = score_randstart_shuffle\n",
    "\n",
    "                    weighted_graphs = get_weighted_dags(DAGs_alltypes[iDBN_group_typename],nbootstraps)\n",
    "                    weighted_graphs_shuffled = get_weighted_dags(DAGs_shuffle_alltypes[iDBN_group_typename],nbootstraps)\n",
    "                    sig_edges = get_significant_edges(weighted_graphs,weighted_graphs_shuffled)\n",
    "\n",
    "                    weighted_graphs_alltypes[iDBN_group_typename] = weighted_graphs\n",
    "                    weighted_graphs_shuffled_alltypes[iDBN_group_typename] = weighted_graphs_shuffled\n",
    "                    sig_edges_alltypes[iDBN_group_typename] = sig_edges\n",
    "                    \n",
    "                except:\n",
    "                    DAGs_alltypes[iDBN_group_typename] = [] \n",
    "                    DAGs_shuffle_alltypes[iDBN_group_typename] = []\n",
    "\n",
    "                    DAGs_scores_alltypes[iDBN_group_typename] = []\n",
    "                    DAGs_shuffle_scores_alltypes[iDBN_group_typename] = []\n",
    "\n",
    "                    weighted_graphs_alltypes[iDBN_group_typename] = []\n",
    "                    weighted_graphs_shuffled_alltypes[iDBN_group_typename] = []\n",
    "                    sig_edges_alltypes[iDBN_group_typename] = []\n",
    "                \n",
    "            DAGscores_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = DAGs_scores_alltypes\n",
    "            DAGscores_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = DAGs_shuffle_scores_alltypes\n",
    "\n",
    "            weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = weighted_graphs_alltypes\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = weighted_graphs_shuffled_alltypes\n",
    "            sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),samplingsizes_name[jj])] = sig_edges_alltypes\n",
    "\n",
    "            \n",
    "        # save data\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_morebhv_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "        if not os.path.exists(data_saved_subfolder):\n",
    "            os.makedirs(data_saved_subfolder)\n",
    "        if moreSampSize:  \n",
    "            with open(data_saved_subfolder+'/DAGscores_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+iDBN_group_typename+'moreSampSize.pkl', 'wb') as f:\n",
    "                pickle.dump(DAGscores_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/DAGscores_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+iDBN_group_typename+'_moreSampSize.pkl', 'wb') as f:\n",
    "                pickle.dump(DAGscores_shuffled_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+iDBN_group_typename+'_moreSampSize.pkl', 'wb') as f:\n",
    "                pickle.dump(weighted_graphs_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+iDBN_group_typename+'_moreSampSize.pkl', 'wb') as f:\n",
    "                pickle.dump(weighted_graphs_shuffled_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+iDBN_group_typename+'_moreSampSize.pkl', 'wb') as f:\n",
    "                pickle.dump(sig_edges_diffTempRo_diffSampSize, f)\n",
    "\n",
    "        else:\n",
    "            with open(data_saved_subfolder+'/DAGscores_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+iDBN_group_typename+'.pkl', 'wb') as f:\n",
    "                pickle.dump(DAGscores_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/DAGscores_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+iDBN_group_typename+'.pkl', 'wb') as f:\n",
    "                pickle.dump(DAGscores_shuffled_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+iDBN_group_typename+'.pkl', 'wb') as f:\n",
    "                pickle.dump(weighted_graphs_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+iDBN_group_typename+'.pkl', 'wb') as f:\n",
    "                pickle.dump(weighted_graphs_shuffled_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+iDBN_group_typename+'.pkl', 'wb') as f:\n",
    "                pickle.dump(sig_edges_diffTempRo_diffSampSize, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf1eea",
   "metadata": {},
   "source": [
    "### plot graphs - show the edge with arrows; show the best time bin and row number; show the three time lag separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FOR PLOT!! \n",
    "# define DBN related summarizing variables\n",
    "DBN_group_typenames = ['self','coop(1s)','no-vision']\n",
    "DBN_group_typeIDs  =  [1,3,5]\n",
    "DBN_group_coopthres = [0,1,0]\n",
    "nDBN_groups = np.shape(DBN_group_typenames)[0]\n",
    "\n",
    "\n",
    "# make sure these variables are the same as in the previous steps\n",
    "# temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "ntemp_reses = np.shape(temp_resolus)[0]\n",
    "#\n",
    "if moreSampSize:\n",
    "    # different data (down/re)sampling numbers\n",
    "    # samplingsizes = np.arange(1100,3000,100)\n",
    "    samplingsizes = [1100]\n",
    "    # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "    # samplingsizes = [100,500]\n",
    "    # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "    samplingsizes_name = list(map(str, samplingsizes))\n",
    "else:\n",
    "    samplingsizes_name = ['min_row_number']   \n",
    "nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "# make sure these variables are consistent with the train_DBN_alec.py settings\n",
    "# eventnames = [\"pull1\",\"pull2\",\"gaze1\",\"gaze2\"]\n",
    "eventnames = [\"M1pull\",\"M2pull\",\"M1gaze\",\"M2gaze\"]\n",
    "eventnode_locations = [[0,1],[1,1],[0,0],[1,0]]\n",
    "eventname_locations = [[-0.5,1.0],[1.2,1],[-0.6,0],[1.2,0]]\n",
    "# indicate where edge starts\n",
    "# for the self edge, it's the center of the self loop\n",
    "nodearrow_locations = [[[0.00,1.25],[0.25,1.10],[-.10,0.75],[0.15,0.65]],\n",
    "                       [[0.75,1.00],[1.00,1.25],[0.85,0.65],[1.10,0.75]],\n",
    "                       [[0.00,0.25],[0.25,0.35],[0.00,-.25],[0.25,-.10]],\n",
    "                       [[0.75,0.35],[1.00,0.25],[0.75,0.00],[1.00,-.25]]]\n",
    "# indicate where edge goes\n",
    "# for the self edge, it's the theta1 and theta2 (with fixed radius)\n",
    "nodearrow_directions = [[[ -45,-180],[0.50,0.00],[0.00,-.50],[0.50,-.50]],\n",
    "                        [[-.50,0.00],[ -45,-180],[-.50,-.50],[0.00,-.50]],\n",
    "                        [[0.00,0.50],[0.50,0.50],[ 180,  45],[0.50,0.00]],\n",
    "                        [[-.50,0.50],[0.00,0.50],[-.50,0.00],[ 180,  45]]]\n",
    "\n",
    "nevents = np.size(eventnames)\n",
    "# eventnodes_color = ['b','r','y','g']\n",
    "eventnodes_color = ['#BF3EFF','#FF7F00','#BF3EFF','#FF7F00']\n",
    "eventnodes_shape = [\"o\",\"o\",\"^\",\"^\"]\n",
    "    \n",
    "savefigs = 1\n",
    "\n",
    "# different session conditions (aka DBN groups)\n",
    "# different time lags (t_-3, t_-2 and t_-1)\n",
    "fig, axs = plt.subplots(6,nDBN_groups)\n",
    "fig.set_figheight(48)\n",
    "fig.set_figwidth(8*nDBN_groups)\n",
    "\n",
    "time_lags = ['t_-3','t_-2','t_-1']\n",
    "fromRowIDs =[[0,1,2,3],[4,5,6,7],[8,9,10,11]]\n",
    "ntime_lags = np.shape(time_lags)[0]\n",
    "\n",
    "temp_resolu = temp_resolus[0]\n",
    "j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "for ilag in np.arange(0,ntime_lags,1):\n",
    "    \n",
    "    time_lag_name = time_lags[ilag]\n",
    "    fromRowID = fromRowIDs[ilag]\n",
    "    \n",
    "    for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "\n",
    "        try:\n",
    "\n",
    "            iDBN_group_typename = DBN_group_typenames[iDBN_group]\n",
    "\n",
    "            weighted_graphs_tgt = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            weighted_graphs_shuffled_tgt = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            # sig_edges_tgt = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            sig_edges_tgt = get_significant_edges(weighted_graphs_tgt,weighted_graphs_shuffled_tgt)\n",
    "           \n",
    "            #sig_edges_tgt = sig_edges_tgt*((weighted_graphs_tgt.mean(axis=0)>0.5)*1)\n",
    "            \n",
    "            sig_avg_dags = weighted_graphs_tgt.mean(axis = 0) * sig_edges_tgt\n",
    "            sig_avg_dags = sig_avg_dags[fromRowID,:]\n",
    "\n",
    "            # plot\n",
    "            axs[ilag*2+0,iDBN_group].set_title(iDBN_group_typename,fontsize=18)\n",
    "            axs[ilag*2+0,iDBN_group].set_xlim([-0.5,1.5])\n",
    "            axs[ilag*2+0,iDBN_group].set_ylim([-0.5,1.5])\n",
    "            axs[ilag*2+0,iDBN_group].set_xticks([])\n",
    "            axs[ilag*2+0,iDBN_group].set_xticklabels([])\n",
    "            axs[ilag*2+0,iDBN_group].set_yticks([])\n",
    "            axs[ilag*2+0,iDBN_group].set_yticklabels([])\n",
    "            axs[ilag*2+0,iDBN_group].spines['top'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['right'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['bottom'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['left'].set_visible(False)\n",
    "            # axs[ilag*2+0,iDBN_group].axis('equal')\n",
    "\n",
    "            \n",
    "            for ieventnode in np.arange(0,nevents,1):\n",
    "                # plot the event nodes\n",
    "                axs[ilag*2+0,iDBN_group].plot(eventnode_locations[ieventnode][0],eventnode_locations[ieventnode][1],\n",
    "                                              eventnodes_shape[ieventnode],markersize=60,markerfacecolor=eventnodes_color[ieventnode],\n",
    "                                              markeredgecolor='none')              \n",
    "                #axs[ilag*2+0,iDBN_group].text(eventname_locations[ieventnode][0],eventname_locations[ieventnode][1],\n",
    "                #                       eventnames[ieventnode],fontsize=15)\n",
    "                \n",
    "                clmap = mpl.cm.get_cmap('Greens')\n",
    "                \n",
    "                # plot the event edges\n",
    "                for ifromNode in np.arange(0,nevents,1):\n",
    "                    for itoNode in np.arange(0,nevents,1):\n",
    "                        edge_weight_tgt = sig_avg_dags[ifromNode,itoNode]\n",
    "                        if edge_weight_tgt>0:\n",
    "                            if not ifromNode == itoNode:\n",
    "                                #axs[ilag*2+0,iDBN_group].plot(eventnode_locations[ifromNode],eventnode_locations[itoNode],'k-',linewidth=edge_weight_tgt*3)\n",
    "                                axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0],\n",
    "                                                        nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                        nodearrow_directions[ifromNode][itoNode][0],\n",
    "                                                        nodearrow_directions[ifromNode][itoNode][1],\n",
    "                                                        # head_width=0.08*abs(edge_weight_tgt),\n",
    "                                                        # width=0.04*abs(edge_weight_tgt),\n",
    "                                                        head_width=0.08,\n",
    "                                                        width=0.04,   \n",
    "                                                        color = clmap(edge_weight_tgt))\n",
    "                            if ifromNode == itoNode:\n",
    "                                ring = mpatches.Wedge(nodearrow_locations[ifromNode][itoNode],\n",
    "                                                      .1, nodearrow_directions[ifromNode][itoNode][0],\n",
    "                                                      nodearrow_directions[ifromNode][itoNode][1], \n",
    "                                                      # 0.04*abs(edge_weight_tgt),\n",
    "                                                      0.04,\n",
    "                                                      color = clmap(edge_weight_tgt))\n",
    "                                p = PatchCollection(\n",
    "                                    [ring], \n",
    "                                    facecolor=clmap(edge_weight_tgt), \n",
    "                                    edgecolor=clmap(edge_weight_tgt)\n",
    "                                )\n",
    "                                axs[ilag*2+0,iDBN_group].add_collection(p)\n",
    "                                # add arrow head\n",
    "                                if ifromNode < 2:\n",
    "                                    axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0]-0.1+0.02*edge_weight_tgt,\n",
    "                                                            nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                            0,-0.05,color=clmap(edge_weight_tgt),\n",
    "                                                            # head_width=0.08*edge_weight_tgt,width=0.04*edge_weight_tgt\n",
    "                                                            head_width=0.08,width=0.04      \n",
    "                                                            )\n",
    "                                else:\n",
    "                                    axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0]-0.1+0.02*edge_weight_tgt,\n",
    "                                                            nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                            0,0.02,color=clmap(edge_weight_tgt),\n",
    "                                                            # head_width=0.08*edge_weight_tgt,width=0.04*edge_weight_tgt\n",
    "                                                            head_width=0.08,width=0.04      \n",
    "                                                            )\n",
    "\n",
    "            # heatmap for the weights\n",
    "            sig_avg_dags_df = pd.DataFrame(sig_avg_dags)\n",
    "            sig_avg_dags_df.columns = eventnames\n",
    "            sig_avg_dags_df.index = eventnames\n",
    "            vmin,vmax = 0,1\n",
    "            import matplotlib as mpl\n",
    "            norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "            im = axs[ilag*2+1,iDBN_group].pcolormesh(sig_avg_dags_df,cmap=\"Greens\",norm=norm)\n",
    "            #\n",
    "            if iDBN_group == nDBN_groups-1:\n",
    "                cax = axs[ilag*2+1,iDBN_group].inset_axes([1.04, 0.2, 0.05, 0.8])\n",
    "                fig.colorbar(im, ax=axs[ilag*2+1,iDBN_group], cax=cax,label='edge confidence')\n",
    "\n",
    "            axs[ilag*2+1,iDBN_group].axis('equal')\n",
    "            axs[ilag*2+1,iDBN_group].set_xlabel('to Node',fontsize=14)\n",
    "            axs[ilag*2+1,iDBN_group].set_xticks(np.arange(0.5,4.5,1))\n",
    "            axs[ilag*2+1,iDBN_group].set_xticklabels(eventnames)\n",
    "            if iDBN_group == 0:\n",
    "                axs[ilag*2+1,iDBN_group].set_ylabel('from Node',fontsize=14)\n",
    "                axs[ilag*2+1,iDBN_group].set_yticks(np.arange(0.5,4.5,1))\n",
    "                axs[ilag*2+1,iDBN_group].set_yticklabels(eventnames)\n",
    "                axs[ilag*2+1,iDBN_group].text(-1.5,1,time_lag_name+' time lag',rotation=90,fontsize=20)\n",
    "                axs[ilag*2+0,iDBN_group].text(-1.25,0,time_lag_name+' time lag',rotation=90,fontsize=20)\n",
    "            else:\n",
    "                axs[ilag*2+1,iDBN_group].set_yticks([])\n",
    "                axs[ilag*2+1,iDBN_group].set_yticklabels([])\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    if moreSampSize:\n",
    "        plt.savefig(figsavefolder+\"threeTimeLag_DAGs_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows.pdf')\n",
    "    else:  \n",
    "        plt.savefig(figsavefolder+\"threeTimeLag_DAGs_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'_'+j_sampsize_name+'.pdf')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34546be",
   "metadata": {},
   "source": [
    "### plot graphs - show the edge differences, use one condition as the base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FOR PLOT!! \n",
    "# define DBN related summarizing variables\n",
    "DBN_group_typenames = ['self','coop(1s)','no-vision']\n",
    "DBN_group_typeIDs  =  [1,3,5]\n",
    "DBN_group_coopthres = [0,1,0]\n",
    "nDBN_groups = np.shape(DBN_group_typenames)[0]\n",
    "\n",
    "# make sure these variables are the same as in the previous steps\n",
    "# temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "ntemp_reses = np.shape(temp_resolus)[0]\n",
    "#\n",
    "if moreSampSize:\n",
    "    # different data (down/re)sampling numbers\n",
    "    # samplingsizes = np.arange(1100,3000,100)\n",
    "    samplingsizes = [1100]\n",
    "    # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "    # samplingsizes = [100,500]\n",
    "    # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "    samplingsizes_name = list(map(str, samplingsizes))\n",
    "else:\n",
    "    samplingsizes_name = ['min_row_number']   \n",
    "nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "basecondition = 'coop(1s)'\n",
    "\n",
    "# make sure these variables are consistent with the train_DBN_alec.py settings\n",
    "# eventnames = [\"pull1\",\"pull2\",\"gaze1\",\"gaze2\"]\n",
    "eventnames = [\"M1pull\",\"M2pull\",\"M1gaze\",\"M2gaze\"]\n",
    "eventnode_locations = [[0,1],[1,1],[0,0],[1,0]]\n",
    "eventname_locations = [[-0.5,1.0],[1.2,1],[-0.6,0],[1.2,0]]\n",
    "# indicate where edge starts\n",
    "# for the self edge, it's the center of the self loop\n",
    "nodearrow_locations = [[[0.00,1.25],[0.25,1.10],[-.10,0.75],[0.15,0.65]],\n",
    "                       [[0.75,1.00],[1.00,1.25],[0.85,0.65],[1.10,0.75]],\n",
    "                       [[0.00,0.25],[0.25,0.35],[0.00,-.25],[0.25,-.10]],\n",
    "                       [[0.75,0.35],[1.00,0.25],[0.75,0.00],[1.00,-.25]]]\n",
    "# indicate where edge goes\n",
    "# for the self edge, it's the theta1 and theta2 (with fixed radius)\n",
    "nodearrow_directions = [[[ -45,-180],[0.50,0.00],[0.00,-.50],[0.50,-.50]],\n",
    "                        [[-.50,0.00],[ -45,-180],[-.50,-.50],[0.00,-.50]],\n",
    "                        [[0.00,0.50],[0.50,0.50],[ 180,  45],[0.50,0.00]],\n",
    "                        [[-.50,0.50],[0.00,0.50],[-.50,0.00],[ 180,  45]]]\n",
    "\n",
    "nevents = np.size(eventnames)\n",
    "# eventnodes_color = ['b','r','y','g']\n",
    "eventnodes_color = ['#BF3EFF','#FF7F00','#BF3EFF','#FF7F00']\n",
    "eventnodes_shape = [\"o\",\"o\",\"^\",\"^\"]\n",
    "\n",
    "nFromNodes = nevents\n",
    "nToNodes = nevents\n",
    "    \n",
    "savefigs = 1\n",
    "\n",
    "# different session conditions (aka DBN groups)\n",
    "# different time lags (t_-3, t_-2 and t_-1)\n",
    "fig, axs = plt.subplots(6,nDBN_groups)\n",
    "fig.set_figheight(48)\n",
    "fig.set_figwidth(8*nDBN_groups)\n",
    "\n",
    "time_lags = ['t_-3','t_-2','t_-1']\n",
    "fromRowIDs =[[0,1,2,3],[4,5,6,7],[8,9,10,11]]\n",
    "ntime_lags = np.shape(time_lags)[0]\n",
    "\n",
    "temp_resolu = temp_resolus[0]\n",
    "j_sampsize_name = samplingsizes_name[0]    \n",
    "    \n",
    "weighted_graphs_tgt = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][basecondition]\n",
    "weighted_graphs_shuffled_tgt = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][basecondition]\n",
    "#sig_edges_tgt = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][basecondition]\n",
    "sig_edges_tgt = get_significant_edges(weighted_graphs_tgt,weighted_graphs_shuffled_tgt)\n",
    "           \n",
    "# sig_edges_tgt = sig_edges_tgt*((weighted_graphs_tgt.mean(axis=0)>0.5)*1)\n",
    "\n",
    "weighted_graphs_base = weighted_graphs_tgt\n",
    "\n",
    "sig_edges_base = sig_edges_tgt\n",
    "\n",
    "sig_avg_dags_base =  weighted_graphs_base.mean(axis = 0) * sig_edges_base\n",
    "    \n",
    "    \n",
    "for ilag in np.arange(0,ntime_lags,1):\n",
    "    \n",
    "    time_lag_name = time_lags[ilag]\n",
    "    fromRowID = fromRowIDs[ilag]\n",
    "    \n",
    "       \n",
    "    for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "\n",
    "        try:\n",
    "\n",
    "            iDBN_group_typename = DBN_group_typenames[iDBN_group]\n",
    "\n",
    "\n",
    "            weighted_graphs_tgt = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            weighted_graphs_shuffled_tgt = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            # sig_edges_tgt = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            sig_edges_tgt = get_significant_edges(weighted_graphs_tgt,weighted_graphs_shuffled_tgt)\n",
    "           \n",
    "            #sig_edges_tgt = sig_edges_tgt*((weighted_graphs_tgt.mean(axis=0)>0.5)*1)\n",
    "            \n",
    "            if 0:\n",
    "                weighted_graphs_delta = (weighted_graphs_tgt-weighted_graphs_base)\n",
    "                weighted_graphs_delta = weighted_graphs_delta.mean(axis=0)\n",
    "                #\n",
    "                sig_edges_delta = ((sig_edges_tgt+sig_edges_base)>0)*1\n",
    "            else:\n",
    "                weighted_graphs_delta,sig_edges_delta = Modulation_Index(weighted_graphs_base, weighted_graphs_tgt,\n",
    "                                                                         sig_edges_base, sig_edges_tgt, 8000)\n",
    "                weighted_graphs_delta = weighted_graphs_delta.mean(axis=0)\n",
    "                \n",
    "            sig_avg_dags = weighted_graphs_delta * sig_edges_delta\n",
    "            sig_avg_dags = sig_avg_dags[fromRowID,:]\n",
    "\n",
    "            # plot\n",
    "            axs[ilag*2+0,iDBN_group].set_title(iDBN_group_typename,fontsize=18)\n",
    "            axs[ilag*2+0,iDBN_group].set_xlim([-0.5,1.5])\n",
    "            axs[ilag*2+0,iDBN_group].set_ylim([-0.5,1.5])\n",
    "            axs[ilag*2+0,iDBN_group].set_xticks([])\n",
    "            axs[ilag*2+0,iDBN_group].set_xticklabels([])\n",
    "            axs[ilag*2+0,iDBN_group].set_yticks([])\n",
    "            axs[ilag*2+0,iDBN_group].set_yticklabels([])\n",
    "            axs[ilag*2+0,iDBN_group].spines['top'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['right'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['bottom'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['left'].set_visible(False)\n",
    "            # axs[ilag*2+0,iDBN_group].axis('equal')\n",
    "\n",
    "            for ieventnode in np.arange(0,nevents,1):\n",
    "                # plot the event nodes\n",
    "                axs[ilag*2+0,iDBN_group].plot(eventnode_locations[ieventnode][0],eventnode_locations[ieventnode][1],\n",
    "                                              eventnodes_shape[ieventnode],markersize=60,markerfacecolor=eventnodes_color[ieventnode],\n",
    "                                              markeredgecolor='none')              \n",
    "                \n",
    "                #axs[ilag*2+0,iDBN_group].text(eventname_locations[ieventnode][0],eventname_locations[ieventnode][1],\n",
    "                #                       eventnames[ieventnode],fontsize=10)\n",
    "                \n",
    "                clmap = mpl.cm.get_cmap('bwr')\n",
    "                \n",
    "                # plot the event edges\n",
    "                for ifromNode in np.arange(0,nevents,1):\n",
    "                    for itoNode in np.arange(0,nevents,1):\n",
    "                        edge_weight_tgt = sig_avg_dags[ifromNode,itoNode]\n",
    "                        if edge_weight_tgt!=0:\n",
    "                            if not ifromNode == itoNode:\n",
    "                                #axs[ilag*2+0,iDBN_group].plot(eventnode_locations[ifromNode],eventnode_locations[itoNode],'k-',linewidth=edge_weight_tgt*3)\n",
    "                                axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0],\n",
    "                                                        nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                        nodearrow_directions[ifromNode][itoNode][0],\n",
    "                                                        nodearrow_directions[ifromNode][itoNode][1],\n",
    "                                                        # head_width=0.08*abs(edge_weight_tgt),\n",
    "                                                        # width=0.04*abs(edge_weight_tgt),\n",
    "                                                        head_width=0.08,\n",
    "                                                        width=0.04,       \n",
    "                                                        color = clmap((1+edge_weight_tgt)/2))\n",
    "                            if ifromNode == itoNode:\n",
    "                                ring = mpatches.Wedge(nodearrow_locations[ifromNode][itoNode],\n",
    "                                                      .1, nodearrow_directions[ifromNode][itoNode][0],\n",
    "                                                      nodearrow_directions[ifromNode][itoNode][1], \n",
    "                                                      # 0.04*abs(edge_weight_tgt)\n",
    "                                                      0.04\n",
    "                                                     )\n",
    "                                p = PatchCollection(\n",
    "                                    [ring], \n",
    "                                    facecolor=clmap((1+edge_weight_tgt)/2), \n",
    "                                    edgecolor=clmap((1+edge_weight_tgt)/2)\n",
    "                                )\n",
    "                                axs[ilag*2+0,iDBN_group].add_collection(p)\n",
    "                                # add arrow head\n",
    "                                if ifromNode < 2:\n",
    "                                    axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0]-0.1+0.02*edge_weight_tgt,\n",
    "                                                            nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                            0,-0.05,color=clmap((1+edge_weight_tgt)/2),\n",
    "                                                            # head_width=0.08*edge_weight_tgt,width=0.04*edge_weight_tgt\n",
    "                                                            head_width=0.08,width=0.04      \n",
    "                                                            )\n",
    "                                else:\n",
    "                                    axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0]-0.1+0.02*edge_weight_tgt,\n",
    "                                                            nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                            0,0.02,color=clmap((1+edge_weight_tgt)/2),\n",
    "                                                            # head_width=0.08*edge_weight_tgt,width=0.04*edge_weight_tgt\n",
    "                                                            head_width=0.08,width=0.04      \n",
    "                                                            )\n",
    "\n",
    "            # heatmap for the weights\n",
    "            sig_avg_dags_df = pd.DataFrame(sig_avg_dags)\n",
    "            sig_avg_dags_df.columns = eventnames\n",
    "            sig_avg_dags_df.index = eventnames\n",
    "            vmin,vmax = -1,1\n",
    "            norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "            im = axs[ilag*2+1,iDBN_group].pcolormesh(sig_avg_dags_df,cmap=\"bwr\",norm=norm)\n",
    "            #-\n",
    "            if iDBN_group == nDBN_groups-1:\n",
    "                cax = axs[ilag*2+1,iDBN_group].inset_axes([1.04, 0.2, 0.05, 0.8])\n",
    "                fig.colorbar(im, ax=axs[ilag*2+1,iDBN_group], cax=cax,label='edge confidence')\n",
    "\n",
    "            axs[ilag*2+1,iDBN_group].axis('equal')\n",
    "            axs[ilag*2+1,iDBN_group].set_xlabel('to Node',fontsize=14)\n",
    "            axs[ilag*2+1,iDBN_group].set_xticks(np.arange(0.5,4.5,1))\n",
    "            axs[ilag*2+1,iDBN_group].set_xticklabels(eventnames)\n",
    "            if iDBN_group == 0:\n",
    "                axs[ilag*2+1,iDBN_group].set_ylabel('from Node',fontsize=14)\n",
    "                axs[ilag*2+1,iDBN_group].set_yticks(np.arange(0.5,4.5,1))\n",
    "                axs[ilag*2+1,iDBN_group].set_yticklabels(eventnames)\n",
    "                axs[ilag*2+1,iDBN_group].text(-1.5,1,time_lag_name+' time lag',rotation=90,fontsize=20)\n",
    "                axs[ilag*2+0,iDBN_group].text(-1.25,0,time_lag_name+' time lag',rotation=90,fontsize=20)\n",
    "            else:\n",
    "                axs[ilag*2+1,iDBN_group].set_yticks([])\n",
    "                axs[ilag*2+1,iDBN_group].set_yticklabels([])\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    if moreSampSize:\n",
    "        plt.savefig(figsavefolder+\"threeTimeLag_DAGs_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_EdgeFifferenceFrom_'+basecondition+'AsBase.pdf')\n",
    "    else:\n",
    "        plt.savefig(figsavefolder+\"threeTimeLag_DAGs_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'_'+j_sampsize_name+'_EdgeFifferenceFrom_'+basecondition+'AsBase.pdf')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed62ef",
   "metadata": {},
   "source": [
    "## Plots that include all pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bbfff1",
   "metadata": {},
   "source": [
    "### VERSION 1: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis show the time lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32fb524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "#\n",
    "fig, axs = plt.subplots(2,nanimalpairs)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(5*nanimalpairs)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    if 0:\n",
    "        MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "        MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    else:\n",
    "        MI_coop_self,_ = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 8000)\n",
    "        MI_coop_self = MI_coop_self.mean(axis = 0)\n",
    "        MI_nov_coop,_  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 8000)\n",
    "        MI_nov_coop = MI_nov_coop.mean(axis = 0)\n",
    "        \n",
    "    #\n",
    "    t3MI_coop_self = MI_coop_self[[0,1,2,3],:]\n",
    "    t2MI_coop_self = MI_coop_self[[4,5,6,7],:]\n",
    "    t1MI_coop_self = MI_coop_self[[8,9,10,11],:]\n",
    "    t3MI_nov_coop = MI_nov_coop[[0,1,2,3],:]\n",
    "    t2MI_nov_coop = MI_nov_coop[[4,5,6,7],:]\n",
    "    t1MI_nov_coop = MI_nov_coop[[8,9,10,11],:]\n",
    "    #\n",
    "    pull_pull_fromNodes = [0,1]\n",
    "    pull_pull_toNodes = [1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes = [2,3]\n",
    "    gaze_gaze_toNodes = [3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes = [0,1,2,3]\n",
    "    within_pullgaze_toNodes = [2,3,0,1]\n",
    "    #\n",
    "    across_pullgaze_fromNodes = [0,1,2,3]\n",
    "    across_pullgaze_toNodes = [3,2,1,0]\n",
    "\n",
    "    \n",
    "    # plot coop self modulation\n",
    "    # pull-pull\n",
    "    xxx1 = [np.mean(t3MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t2MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t1MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes])]\n",
    "    line1 = axs[0,ianimalpair].plot(xxx1,'*--',markersize = 13,label='pull<->pull')\n",
    "    # gaze-gaze\n",
    "    xxx2 = [np.mean(t3MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes])]\n",
    "    line2 = axs[0,ianimalpair].plot(xxx2,'o--',markersize = 13,label='gaze<->gaze')\n",
    "    # within animal pullgaze\n",
    "    xxx3 = [np.mean(t3MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes])]\n",
    "    line3 = axs[0,ianimalpair].plot(xxx3,'v--',markersize = 13,label='within animal pull<->gaze')\n",
    "    # across animal pullgaze\n",
    "    xxx4 = [np.mean(t3MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes])]\n",
    "    line4 = axs[0,ianimalpair].plot(xxx4,'^--',markersize = 13,label='across animal pull<->gaze')\n",
    "    #\n",
    "    axs[0,ianimalpair].set_ylim([-1.05,1.05])\n",
    "    axs[0,ianimalpair].set_xticks([0,1,2])\n",
    "    axs[0,ianimalpair].set_xticklabels([])\n",
    "    axs[0,ianimalpair].set_yticks([-1,-0.5,0,0.5,1])\n",
    "    if ianimalpair == 0:\n",
    "        axs[0,ianimalpair].tick_params(axis='y', labelsize=13)\n",
    "        axs[0,ianimalpair].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "    else:\n",
    "        axs[0,ianimalpair].set_yticklabels([])\n",
    "    axs[0,ianimalpair].set_title('pair:'+animal1_fixedorder+'-'+animal2_fixedorder,fontsize = 16)\n",
    "\n",
    "\n",
    "    # plot novision coop modulation\n",
    "    # pull-pull\n",
    "    xxx1 = [np.mean(t3MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes])]\n",
    "    line1 = axs[1,ianimalpair].plot(xxx1,'*--',markersize = 13,label='pull<->pull')\n",
    "    # gaze-gaze\n",
    "    xxx2 = [np.mean(t3MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes])]\n",
    "    line2 = axs[1,ianimalpair].plot(xxx2,'o--',markersize = 13,label='gaze<->gaze')\n",
    "    # within animal pullgaze\n",
    "    xxx3 = [np.mean(t3MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes])]\n",
    "    line3 = axs[1,ianimalpair].plot(xxx3,'v--',markersize = 13,label='within animal pull<->gaze')\n",
    "    # across animal pullgaze\n",
    "    xxx4 = [np.mean(t3MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes])]\n",
    "    line4 = axs[1,ianimalpair].plot(xxx4,'^--',markersize = 13,label='across animal pull<->gaze')\n",
    "    #\n",
    "    axs[1,ianimalpair].set_ylim([-1.05,1.05])\n",
    "    axs[1,ianimalpair].set_xticks([0,1,2])\n",
    "    axs[1,ianimalpair].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "    axs[1,ianimalpair].set_xlabel('time lag',fontsize=15)\n",
    "    axs[1,ianimalpair].set_yticks([-1,-0.5,0,0.5,1])\n",
    "    if ianimalpair == 0:\n",
    "        axs[1,ianimalpair].tick_params(axis='y', labelsize=13)\n",
    "        axs[1,ianimalpair].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "        axs[1,ianimalpair].legend()\n",
    "    else:\n",
    "        axs[1,ianimalpair].set_yticklabels([])\n",
    "    axs[1,ianimalpair].set_title('pair:'+animal1_fixedorder+'-'+animal2_fixedorder,fontsize = 16)\n",
    "    \n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_summary_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_summary_'+str(temp_resolu)+'_'+j_sampsize_name+'.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33085d8b",
   "metadata": {},
   "source": [
    "### VERSION 2: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis show the time lag; combined into four edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga']\n",
    "animalpairs_datashapes = ['o','v','^']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(2,4)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(5*4)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "        MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    else:\n",
    "        MI_coop_self,_ = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 8000)\n",
    "        MI_coop_self = MI_coop_self.mean(axis = 0)\n",
    "        MI_nov_coop,_  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 8000)\n",
    "        MI_nov_coop = MI_nov_coop.mean(axis = 0)\n",
    "    #\n",
    "    t3MI_coop_self = MI_coop_self[[0,1,2,3],:]\n",
    "    t2MI_coop_self = MI_coop_self[[4,5,6,7],:]\n",
    "    t1MI_coop_self = MI_coop_self[[8,9,10,11],:]\n",
    "    t3MI_nov_coop = MI_nov_coop[[0,1,2,3],:]\n",
    "    t2MI_nov_coop = MI_nov_coop[[4,5,6,7],:]\n",
    "    t1MI_nov_coop = MI_nov_coop[[8,9,10,11],:]\n",
    "    #\n",
    "    pull_pull_fromNodes = [0,1]\n",
    "    pull_pull_toNodes = [1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes = [2,3]\n",
    "    gaze_gaze_toNodes = [3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes = [0,1,2,3]\n",
    "    within_pullgaze_toNodes = [2,3,0,1]\n",
    "    #\n",
    "    across_pullgaze_fromNodes = [0,1,2,3]\n",
    "    across_pullgaze_toNodes = [3,2,1,0]\n",
    "\n",
    "    \n",
    "    # plot coop self modulation\n",
    "    # pull-pull\n",
    "    xxx1 = [np.mean(t3MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t2MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t1MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes])]\n",
    "    line1 = axs[0,0].plot(xxx1,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='r')\n",
    "    # gaze-gaze\n",
    "    xxx2 = [np.mean(t3MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes])]\n",
    "    line2 = axs[0,1].plot(xxx2,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='b')\n",
    "    # within animal pullgaze\n",
    "    xxx3 = [np.mean(t3MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes])]\n",
    "    line3 = axs[0,2].plot(xxx3,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='g')\n",
    "    # across animal pullgaze\n",
    "    xxx4 = [np.mean(t3MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes])]\n",
    "    line4 = axs[0,3].plot(xxx4,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='y')\n",
    "    #\n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze','within animal pull<->gaze','across animal pull<->gaze']\n",
    "    for iplot in np.arange(0,4,1):\n",
    "        axs[0,iplot].set_xlim([-0.1,2.1])\n",
    "        axs[0,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[0,iplot].set_xticks([0,1,2])\n",
    "        axs[0,iplot].set_xticklabels([])\n",
    "        axs[0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        #\n",
    "        if iplot == 0:\n",
    "            axs[0,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[0,iplot].set_yticklabels([])\n",
    "        axs[0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[0,iplot].plot([-1,3],[0,0],'k--')\n",
    "\n",
    "    # plot novision coop modulation\n",
    "    # pull-pull\n",
    "    xxx1 = [np.mean(t3MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes])]\n",
    "    line1 = axs[1,0].plot(xxx1,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='r')\n",
    "    # gaze-gaze\n",
    "    xxx2 = [np.mean(t3MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes])]\n",
    "    line2 = axs[1,1].plot(xxx2,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='b')\n",
    "    # within animal pullgaze\n",
    "    xxx3 = [np.mean(t3MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes])]\n",
    "    line3 = axs[1,2].plot(xxx3,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='g')\n",
    "    # across animal pullgaze\n",
    "    xxx4 = [np.mean(t3MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes])]\n",
    "    line4 = axs[1,3].plot(xxx4,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='y')\n",
    "     #\n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze','within animal pull<->gaze','across animal pull<->gaze']\n",
    "    for iplot in np.arange(0,4,1):\n",
    "        axs[1,iplot].set_xlim([-0.1,2.1])\n",
    "        axs[1,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[1,iplot].set_xticks([0,1,2])\n",
    "        axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "        axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "        axs[1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        if iplot == 0:\n",
    "            axs[1,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[1,iplot].set_yticklabels([])\n",
    "        axs[1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[1,iplot].plot([-1,3],[0,0],'k--')\n",
    "        \n",
    "    axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "                     'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "                     'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "    \n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_summary_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_v2.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_summary_'+str(temp_resolu)+'_'+j_sampsize_name+'_v2.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8cd65a",
   "metadata": {},
   "source": [
    "### VERSION 3: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis show the time lag; combined into six edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga']\n",
    "animalpairs_datashapes = ['o','v','^']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(2,6)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(5*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    if 0:\n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 8000)\n",
    "        MI_coop_self = MI_coop_self.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 8000)\n",
    "        MI_nov_coop = MI_nov_coop.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop   \n",
    "    \n",
    "    #\n",
    "    t3MI_coop_self = MI_coop_self[[0,1,2,3],:]\n",
    "    t2MI_coop_self = MI_coop_self[[4,5,6,7],:]\n",
    "    t1MI_coop_self = MI_coop_self[[8,9,10,11],:]\n",
    "    t3MI_nov_coop = MI_nov_coop[[0,1,2,3],:]\n",
    "    t2MI_nov_coop = MI_nov_coop[[4,5,6,7],:]\n",
    "    t1MI_nov_coop = MI_nov_coop[[8,9,10,11],:]\n",
    "    #\n",
    "    pull_pull_fromNodes = [0,1]\n",
    "    pull_pull_toNodes = [1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes = [2,3]\n",
    "    gaze_gaze_toNodes = [3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes = [0,1]\n",
    "    within_pullgaze_toNodes = [2,3]\n",
    "    #\n",
    "    across_pullgaze_fromNodes = [0,1]\n",
    "    across_pullgaze_toNodes = [3,2]\n",
    "    #\n",
    "    within_gazepull_fromNodes = [2,3]\n",
    "    within_gazepull_toNodes = [0,1]\n",
    "    #\n",
    "    across_gazepull_fromNodes = [2,3]\n",
    "    across_gazepull_toNodes = [1,0]\n",
    "\n",
    "    \n",
    "    # plot coop self modulation\n",
    "    # pull-pull\n",
    "    xxx1 = [np.mean(t3MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t2MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t1MI_coop_self[pull_pull_fromNodes,pull_pull_toNodes])]\n",
    "    line1 = axs[0,0].plot(xxx1,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='r')\n",
    "    # gaze-gaze\n",
    "    xxx2 = [np.mean(t3MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[gaze_gaze_fromNodes,gaze_gaze_toNodes])]\n",
    "    line2 = axs[0,1].plot(xxx2,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='b')\n",
    "    # within animal pullgaze\n",
    "    xxx3 = [np.mean(t3MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[within_pullgaze_fromNodes,within_pullgaze_toNodes])]\n",
    "    line3 = axs[0,2].plot(xxx3,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#008080')\n",
    "    # across animal pullgaze\n",
    "    xxx4 = [np.mean(t3MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_coop_self[across_pullgaze_fromNodes,across_pullgaze_toNodes])]\n",
    "    line4 = axs[0,3].plot(xxx4,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#D1B26F')\n",
    "    # within animal gazepull\n",
    "    xxx5 = [np.mean(t3MI_coop_self[within_gazepull_fromNodes,within_gazepull_toNodes]),\n",
    "            np.mean(t2MI_coop_self[within_gazepull_fromNodes,within_gazepull_toNodes]),\n",
    "            np.mean(t1MI_coop_self[within_gazepull_fromNodes,within_gazepull_toNodes])]\n",
    "    line5 = axs[0,4].plot(xxx5,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#7FFF00')\n",
    "    # across animal gazepull\n",
    "    xxx6 = [np.mean(t3MI_coop_self[across_gazepull_fromNodes,across_gazepull_toNodes]),\n",
    "            np.mean(t2MI_coop_self[across_gazepull_fromNodes,across_gazepull_toNodes]),\n",
    "            np.mean(t1MI_coop_self[across_gazepull_fromNodes,across_gazepull_toNodes])]\n",
    "    line6 = axs[0,5].plot(xxx6,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#FAC205')\n",
    "    #\n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[0,iplot].set_xlim([-0.1,2.1])\n",
    "        axs[0,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[0,iplot].set_xticks([0,1,2])\n",
    "        axs[0,iplot].set_xticklabels([])\n",
    "        axs[0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        #\n",
    "        if iplot == 0:\n",
    "            axs[0,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[0,iplot].set_yticklabels([])\n",
    "        axs[0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[0,iplot].plot([-1,3],[0,0],'k--')\n",
    "\n",
    "    # plot novision coop modulation\n",
    "    # pull-pull\n",
    "    xxx1 = [np.mean(t3MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[pull_pull_fromNodes,pull_pull_toNodes])]\n",
    "    line1 = axs[1,0].plot(xxx1,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='r')\n",
    "    # gaze-gaze\n",
    "    xxx2 = [np.mean(t3MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[gaze_gaze_fromNodes,gaze_gaze_toNodes])]\n",
    "    line2 = axs[1,1].plot(xxx2,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='b')\n",
    "    # within animal pullgaze\n",
    "    xxx3 = [np.mean(t3MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[within_pullgaze_fromNodes,within_pullgaze_toNodes])]\n",
    "    line3 = axs[1,2].plot(xxx3,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#008080')\n",
    "    # across animal pullgaze\n",
    "    xxx4 = [np.mean(t3MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[across_pullgaze_fromNodes,across_pullgaze_toNodes])]\n",
    "    line4 = axs[1,3].plot(xxx4,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#D1B26F')\n",
    "    # within animal gazepull\n",
    "    xxx5 = [np.mean(t3MI_nov_coop[within_gazepull_fromNodes,within_gazepull_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[within_gazepull_fromNodes,within_gazepull_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[within_gazepull_fromNodes,within_gazepull_toNodes])]\n",
    "    line5 = axs[1,4].plot(xxx5,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#7FFF00')\n",
    "    # across animal gazepull\n",
    "    xxx6 = [np.mean(t3MI_nov_coop[across_gazepull_fromNodes,across_gazepull_toNodes]),\n",
    "            np.mean(t2MI_nov_coop[across_gazepull_fromNodes,across_gazepull_toNodes]),\n",
    "            np.mean(t1MI_nov_coop[across_gazepull_fromNodes,across_gazepull_toNodes])]\n",
    "    line6 = axs[1,5].plot(xxx6,animalpairs_datashapes[ianimalpair]+'--',markersize = 13,color='#FAC205')\n",
    "    #\n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[1,iplot].set_xlim([-0.1,2.1])\n",
    "        axs[1,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[1,iplot].set_xticks([0,1,2])\n",
    "        axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "        axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "        axs[1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        if iplot == 0:\n",
    "            axs[1,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[1,iplot].set_yticklabels([])\n",
    "        axs[1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[1,iplot].plot([-1,3],[0,0],'k--')\n",
    "        \n",
    "    axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "                     'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "                     'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "    \n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_detailed_summary_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_v2.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_detailed_summary_'+str(temp_resolu)+'_'+j_sampsize_name+'_v2.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee15a992",
   "metadata": {},
   "source": [
    "### VERSION 4: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis shows the pairs. y axis averaged the MI among time lag and show CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a5da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga']\n",
    "animalpairs_datashapes = ['o','v','^']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(2,6)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(5*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 8000)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 8000)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    pull_pull_fromNodes_all = [0,1,4,5,8,9]\n",
    "    pull_pull_toNodes_all = [1,0,1,0,1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes_all = [2,3,6,7,10,11]\n",
    "    gaze_gaze_toNodes_all = [3,2,3,2,3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes_all = [0,1,4,5,8,9]\n",
    "    within_pullgaze_toNodes_all = [2,3,2,3,2,3]\n",
    "    #\n",
    "    across_pullgaze_fromNodes_all = [0,1,4,5,8,9]\n",
    "    across_pullgaze_toNodes_all = [3,2,3,2,3,2]\n",
    "    #\n",
    "    within_gazepull_fromNodes_all = [2,3,6,7,10,11]\n",
    "    within_gazepull_toNodes_all = [0,1,0,1,0,1]\n",
    "    #\n",
    "    across_gazepull_fromNodes_all = [2,3,6,7,10,11]\n",
    "    across_gazepull_toNodes_all = [1,0,1,0,1,0]\n",
    "\n",
    "    \n",
    "    # plot coop self modulation\n",
    "    \n",
    "    # pull-pull\n",
    "    xxx1 = np.mean(MI_coop_self_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all])\n",
    "    # err1 = np.std(MI_coop_self_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all])\n",
    "    err1 = st.sem(MI_coop_self_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all].flatten())\n",
    "    axs[0,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 5)\n",
    "    line1 = axs[0,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # gaze-gaze\n",
    "    xxx2 = np.mean(MI_coop_self_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all])\n",
    "    # err2 = np.std(MI_coop_self_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all])\n",
    "    err2 = st.sem(MI_coop_self_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all].flatten())\n",
    "    axs[0,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 5)\n",
    "    line2 = axs[0,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal gazepull\n",
    "    xxx3 = np.mean(MI_coop_self_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all])\n",
    "    # err3 = np.std(MI_coop_self_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all])\n",
    "    err3 = st.sem(MI_coop_self_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all].flatten())\n",
    "    axs[0,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 5)\n",
    "    line3 = axs[0,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal gazepull\n",
    "    xxx4 = np.mean(MI_coop_self_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all])\n",
    "    # err4 = np.std(MI_coop_self_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all])\n",
    "    err4 = st.sem(MI_coop_self_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all].flatten())\n",
    "    axs[0,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 5)\n",
    "    line4 = axs[0,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal pullgaze\n",
    "    xxx5 = np.mean(MI_coop_self_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all])\n",
    "    #err5 = np.std(MI_coop_self_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all])\n",
    "    err5 = st.sem(MI_coop_self_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all].flatten())\n",
    "    axs[0,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 5)\n",
    "    line5 = axs[0,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal pullgaze\n",
    "    xxx6 = np.mean(MI_coop_self_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all])\n",
    "    # err6 = np.std(MI_coop_self_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all])\n",
    "    err6 = st.sem(MI_coop_self_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all].flatten())\n",
    "    axs[0,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 5)\n",
    "    line6 = axs[0,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    \n",
    "    #\n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 ]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[0,iplot].set_xlim([-0.1,2.1])\n",
    "        axs[0,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[0,iplot].set_xticks([0,1,2])\n",
    "        axs[0,iplot].set_xticklabels([])\n",
    "        axs[0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        #\n",
    "        if iplot == 0:\n",
    "            axs[0,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[0,iplot].set_yticklabels([])\n",
    "        axs[0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[0,iplot].plot([-1,3],[0,0],'k--')\n",
    "\n",
    "    # plot novision coop modulation\n",
    "    # pull-pull\n",
    "    xxx1 = np.mean(MI_nov_coop_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all])\n",
    "    # err1 = np.std(MI_nov_coop_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all])\n",
    "    err1 = st.sem(MI_nov_coop_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all].flatten())\n",
    "    axs[1,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 5)\n",
    "    line1 = axs[1,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # gaze-gaze\n",
    "    xxx2 = np.mean(MI_nov_coop_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all])\n",
    "    # err2 = np.std(MI_nov_coop_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all])\n",
    "    err2 = st.sem(MI_nov_coop_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all].flatten())\n",
    "    axs[1,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 5)\n",
    "    line2 = axs[1,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal gazepull\n",
    "    xxx3 = np.mean(MI_nov_coop_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all])\n",
    "    # err3 = np.std(MI_nov_coop_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all])\n",
    "    err3 = st.sem(MI_nov_coop_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all].flatten())\n",
    "    axs[1,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 5)\n",
    "    line3 = axs[1,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal gazepull\n",
    "    xxx4 = np.mean(MI_nov_coop_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all])\n",
    "    # err4 = np.std(MI_nov_coop_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all])\n",
    "    err4 = st.sem(MI_nov_coop_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all].flatten())\n",
    "    axs[1,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 5)\n",
    "    line4 = axs[1,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal pullgaze\n",
    "    xxx5 = np.mean(MI_nov_coop_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all])\n",
    "    #err5 = np.std(MI_nov_coop_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all])\n",
    "    err5 = st.sem(MI_nov_coop_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all].flatten())\n",
    "    axs[1,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 5)\n",
    "    line5 = axs[1,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal pullgaze\n",
    "    xxx6 = np.mean(MI_nov_coop_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all])\n",
    "    # err6 = np.std(MI_nov_coop_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all])\n",
    "    err6 = st.sem(MI_nov_coop_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all].flatten())\n",
    "    axs[1,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 5)\n",
    "    line6 = axs[1,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    \n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 ]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[1,iplot].set_xlim([-0.1,2.1])\n",
    "        axs[1,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[1,iplot].set_xticks([0,1,2])\n",
    "        #axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "        axs[1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA'],fontsize = 13)\n",
    "        #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "        axs[1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        if iplot == 0:\n",
    "            axs[1,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[1,iplot].set_yticklabels([])\n",
    "        axs[1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[1,iplot].plot([-1,3],[0,0],'k--')\n",
    "        \n",
    "    #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "    #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "    #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "    \n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_mergedLag_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_meanSEM.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_mergedLag_'+str(temp_resolu)+'_'+j_sampsize_name+'_meanSEM.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8346193d",
   "metadata": {},
   "source": [
    "### version 5: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis shows the pairs. y axis averaged the MI only for 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72961be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga']\n",
    "animalpairs_datashapes = ['o','o','o']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(2,6)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(5*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 8000)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 8000)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    pull_pull_fromNodes_all = [8,9]\n",
    "    pull_pull_toNodes_all = [1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes_all = [10,11]\n",
    "    gaze_gaze_toNodes_all = [3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes_all = [8,9]\n",
    "    within_pullgaze_toNodes_all = [2,3]\n",
    "    #\n",
    "    across_pullgaze_fromNodes_all = [8,9]\n",
    "    across_pullgaze_toNodes_all = [3,2]\n",
    "    #\n",
    "    within_gazepull_fromNodes_all = [10,11]\n",
    "    within_gazepull_toNodes_all = [0,1]\n",
    "    #\n",
    "    across_gazepull_fromNodes_all = [10,11]\n",
    "    across_gazepull_toNodes_all = [1,0]\n",
    "\n",
    "    \n",
    "    # plot coop self modulation\n",
    "    \n",
    "    # pull-pull\n",
    "    a = MI_coop_self_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all].flatten()\n",
    "    xxx1 = np.mean(a)\n",
    "    err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "    line1 = axs[0,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # gaze-gaze\n",
    "    a = (MI_coop_self_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all]).flatten()\n",
    "    xxx2 = np.mean(a)\n",
    "    err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "    line2 = axs[0,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal gazepull\n",
    "    a = (MI_coop_self_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all]).flatten()\n",
    "    xxx3 = np.mean(a)\n",
    "    err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "    line3 = axs[0,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal gazepull\n",
    "    a = (MI_coop_self_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all]).flatten()\n",
    "    xxx4 = np.mean(a)\n",
    "    err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "    line4 = axs[0,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal pullgaze\n",
    "    a = (MI_coop_self_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all]).flatten()\n",
    "    xxx5 = np.mean(a)\n",
    "    err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "    line5 = axs[0,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal pullgaze\n",
    "    a = (MI_coop_self_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all]).flatten()\n",
    "    xxx6 = np.mean(a)\n",
    "    err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "    line6 = axs[0,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    \n",
    "    #\n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 ]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[0,iplot].set_xlim([-0.3,2.3])\n",
    "        axs[0,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[0,iplot].set_xticks([0,1,2])\n",
    "        axs[0,iplot].set_xticklabels([])\n",
    "        axs[0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        #\n",
    "        if iplot == 0:\n",
    "            axs[0,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[0,iplot].set_yticklabels([])\n",
    "        axs[0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[0,iplot].plot([-1,3],[0,0],'k--')\n",
    "\n",
    "    # plot novision coop modulation\n",
    "    # pull-pull\n",
    "    a = MI_nov_coop_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all].flatten()\n",
    "    xxx1 = np.mean(a)\n",
    "    err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "    line1 = axs[1,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # gaze-gaze\n",
    "    a = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all]).flatten()\n",
    "    xxx2 = np.mean(a)\n",
    "    err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "    line2 = axs[1,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal gazepull\n",
    "    a = (MI_nov_coop_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all]).flatten()\n",
    "    xxx3 = np.mean(a)\n",
    "    err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "    line3 = axs[1,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal gazepull\n",
    "    a = (MI_nov_coop_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all]).flatten()\n",
    "    xxx4 = np.mean(a)\n",
    "    err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "    line4 = axs[1,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal pullgaze\n",
    "    a = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all]).flatten()\n",
    "    xxx5 = np.mean(a)\n",
    "    err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "    line5 = axs[1,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal pullgaze\n",
    "    a = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all]).flatten()\n",
    "    xxx6 = np.mean(a)\n",
    "    err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "    line6 = axs[1,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    \n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 ]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[1,iplot].set_xlim([-0.3,2.3])\n",
    "        axs[1,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[1,iplot].set_xticks([0,1,2])\n",
    "        #axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "        axs[1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA'],fontsize = 13)\n",
    "        #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "        axs[1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        if iplot == 0:\n",
    "            axs[1,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[1,iplot].set_yticklabels([])\n",
    "        axs[1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[1,iplot].plot([-1,3],[0,0],'k--')\n",
    "        \n",
    "    #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "    #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "    #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "    \n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_1secondLag_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_mean95CI.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_1secondLag_'+str(temp_resolu)+'_'+j_sampsize_name+'_mean95CI.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e72e3",
   "metadata": {},
   "source": [
    "### version 6: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis shows the pairs. y axis showed the MI; separate animal 1 and 2; merge time lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da12c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga']\n",
    "animalpairs_datashapes = ['o','o','o']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(4,6)\n",
    "fig.set_figheight(8*4)\n",
    "fig.set_figwidth(8*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 8000)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 8000)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    \n",
    "    #\n",
    "    pull_pull_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "    pull_pull_toNodes_all = [[1,1,1],[0,0,0]]\n",
    "    #\n",
    "    gaze_gaze_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "    gaze_gaze_toNodes_all = [[3,3,3],[2,2,2]]\n",
    "    #\n",
    "    within_pullgaze_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "    within_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "    #\n",
    "    across_pullgaze_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "    across_pullgaze_toNodes_all = [[3,3,3],[2,2,2]]\n",
    "    #\n",
    "    within_gazepull_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "    within_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "    #\n",
    "    across_gazepull_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "    across_gazepull_toNodes_all = [[1,1,1],[0,0,0]]\n",
    "    \n",
    "    animalshortnames = ['A1','A2']\n",
    "\n",
    "    \n",
    "    for ianimal in np.arange(0,2,1):\n",
    "        \n",
    "        anishortname = animalshortnames[ianimal]\n",
    "        \n",
    "        \n",
    "        # plot coop self modulation\n",
    "\n",
    "        # pull-pull\n",
    "        a = MI_coop_self_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[2*ianimal+0,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_coop_self_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[2*ianimal+0,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_coop_self_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[2*ianimal+0,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_coop_self_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[2*ianimal+0,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_coop_self_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[2*ianimal+0,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_coop_self_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[2*ianimal+0,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        #\n",
    "        plottypes = ['from '+anishortname+' across animal pull<->pull','from '+anishortname+' across animal gaze<->gaze',\n",
    "                     'from '+anishortname+' within animal gaze->pull','from '+anishortname+' across animal gaze->pull',\n",
    "                     'from '+anishortname+' within animal pull->gaze','from '+anishortname+' across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[2*ianimal+0,iplot].set_xlim([-0.3,2.3])\n",
    "            axs[2*ianimal+0,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[2*ianimal+0,iplot].set_xticks([0,1,2])\n",
    "            axs[2*ianimal+0,iplot].set_xticklabels([])\n",
    "            axs[2*ianimal+0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            #\n",
    "            if iplot == 0:\n",
    "                axs[2*ianimal+0,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[2*ianimal+0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "            else:\n",
    "                axs[2*ianimal+0,iplot].set_yticklabels([])\n",
    "            axs[2*ianimal+0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[2*ianimal+0,iplot].plot([-1,3],[0,0],'k--')\n",
    "\n",
    "        # plot novision coop modulation\n",
    "        # pull-pull\n",
    "        a = MI_nov_coop_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[2*ianimal+1,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[2*ianimal+1,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_nov_coop_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[2*ianimal+1,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_nov_coop_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[2*ianimal+1,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[2*ianimal+1,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[2*ianimal+1,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        plottypes = ['from '+anishortname+' across animal pull<->pull','from '+anishortname+' across animal gaze<->gaze',\n",
    "                     'from '+anishortname+' within animal gaze->pull','from '+anishortname+' across animal gaze->pull',\n",
    "                     'from '+anishortname+' within animal pull->gaze','from '+anishortname+' across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[2*ianimal+1,iplot].set_xlim([-0.3,2.3])\n",
    "            axs[2*ianimal+1,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[2*ianimal+1,iplot].set_xticks([0,1,2])\n",
    "            #axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "            axs[2*ianimal+1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA'],fontsize = 13)\n",
    "            #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "            axs[2*ianimal+1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            if iplot == 0:\n",
    "                axs[2*ianimal+1,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[2*ianimal+1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "            else:\n",
    "                axs[1,iplot].set_yticklabels([])\n",
    "            axs[2*ianimal+1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[2*ianimal+1,iplot].plot([-1,3],[0,0],'k--')\n",
    "\n",
    "        #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "\n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_mergedLag_IndiAnimal_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_mean95CI.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_mergedLag_IndiAnimal_'+str(temp_resolu)+'_'+j_sampsize_name+'_mean95CI.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b2cdfe",
   "metadata": {},
   "source": [
    "### version 7: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis shows the pairs. y axis showed the MI; separate animal 1 and 2; only for 1s time lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7466a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga']\n",
    "animalpairs_datashapes = ['o','o','o']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(4,6)\n",
    "fig.set_figheight(8*4)\n",
    "fig.set_figwidth(8*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 8000)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 8000)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    pull_pull_fromNodes_all = [8,9]\n",
    "    pull_pull_toNodes_all = [1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes_all = [10,11]\n",
    "    gaze_gaze_toNodes_all = [3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes_all = [8,9]\n",
    "    within_pullgaze_toNodes_all = [2,3]\n",
    "    #\n",
    "    across_pullgaze_fromNodes_all = [8,9]\n",
    "    across_pullgaze_toNodes_all = [3,2]\n",
    "    #\n",
    "    within_gazepull_fromNodes_all = [10,11]\n",
    "    within_gazepull_toNodes_all = [0,1]\n",
    "    #\n",
    "    across_gazepull_fromNodes_all = [10,11]\n",
    "    across_gazepull_toNodes_all = [1,0]\n",
    "\n",
    "    animalshortnames = ['A1','A2']\n",
    "    \n",
    "    for ianimal in np.arange(0,2,1):\n",
    "        \n",
    "        anishortname = animalshortnames[ianimal]\n",
    "        \n",
    "        # plot coop self modulation\n",
    "\n",
    "        # pull-pull\n",
    "        a = MI_coop_self_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[2*ianimal+0,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_coop_self_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[2*ianimal+0,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_coop_self_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[2*ianimal+0,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_coop_self_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[2*ianimal+0,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_coop_self_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[2*ianimal+0,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_coop_self_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[2*ianimal+0,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        #\n",
    "        plottypes = ['from '+anishortname+' across animal pull<->pull','from '+anishortname+' across animal gaze<->gaze',\n",
    "                     'from '+anishortname+' within animal gaze->pull','from '+anishortname+' across animal gaze->pull',\n",
    "                     'from '+anishortname+' within animal pull->gaze','from '+anishortname+' across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[2*ianimal+0,iplot].set_xlim([-0.3,2.3])\n",
    "            axs[2*ianimal+0,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[2*ianimal+0,iplot].set_xticks([0,1,2])\n",
    "            axs[2*ianimal+0,iplot].set_xticklabels([])\n",
    "            axs[2*ianimal+0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            #\n",
    "            if iplot == 0:\n",
    "                axs[2*ianimal+0,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[2*ianimal+0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "            else:\n",
    "                axs[2*ianimal+0,iplot].set_yticklabels([])\n",
    "            axs[2*ianimal+0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[2*ianimal+0,iplot].plot([-1,3],[0,0],'k--')\n",
    "\n",
    "        # plot novision coop modulation\n",
    "        # pull-pull\n",
    "        a = MI_nov_coop_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[2*ianimal+1,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[2*ianimal+1,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_nov_coop_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[2*ianimal+1,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_nov_coop_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[2*ianimal+1,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[2*ianimal+1,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[2*ianimal+1,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        plottypes = ['from '+anishortname+' across animal pull<->pull','from '+anishortname+' across animal gaze<->gaze',\n",
    "                     'from '+anishortname+' within animal gaze->pull','from '+anishortname+' across animal gaze->pull',\n",
    "                     'from '+anishortname+' within animal pull->gaze','from '+anishortname+' across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[2*ianimal+1,iplot].set_xlim([-0.3,2.3])\n",
    "            axs[2*ianimal+1,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[2*ianimal+1,iplot].set_xticks([0,1,2])\n",
    "            #axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "            axs[2*ianimal+1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA'],fontsize = 13)\n",
    "            #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "            axs[2*ianimal+1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            if iplot == 0:\n",
    "                axs[2*ianimal+1,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[2*ianimal+1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "            else:\n",
    "                axs[2*ianimal+1,iplot].set_yticklabels([])\n",
    "            axs[2*ianimal+1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[2*ianimal+1,iplot].plot([-1,3],[0,0],'k--')\n",
    "\n",
    "        #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "\n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_1secondLag_IndiAnimal_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_mean95CI.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_morebhv_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_1secondLag_IndiAnimal_'+str(temp_resolu)+'_'+j_sampsize_name+'_mean95CI.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b3fa68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ff85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca400451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da044d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5145a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa155b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72257eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
