{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca6246b",
   "metadata": {},
   "source": [
    "### In this script, DBN is run on the individual dates\n",
    "### In this script, DBN is run with 1s time bin, 3 time lag \n",
    "### In this script, the animal tracking is done with only one camera - camera 2 (middle) \n",
    "### This script analyze the autolever sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd279dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "import sklearn\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import string\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.models import DynamicBayesianNetwork as DBN\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.estimators import HillClimbSearch,BicScore\n",
    "from pgmpy.base import DAG\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee0ed4",
   "metadata": {},
   "source": [
    "### function - get body part location for each pair of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.body_part_locs_eachpair import body_part_locs_eachpair\n",
    "from ana_functions.body_part_locs_singlecam import body_part_locs_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ae6f98",
   "metadata": {},
   "source": [
    "### function - align the two cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b03438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_align import camera_align       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494356c2",
   "metadata": {},
   "source": [
    "### function - merge the two pairs of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_merge import camera_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc7f6a",
   "metadata": {},
   "source": [
    "### function - find social gaze time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f6ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.find_socialgaze_timepoint import find_socialgaze_timepoint\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam import find_socialgaze_timepoint_singlecam\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam_wholebody import find_socialgaze_timepoint_singlecam_wholebody\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam_wholebody_2 import find_socialgaze_timepoint_singlecam_wholebody_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7e75b",
   "metadata": {},
   "source": [
    "### function - define time point of behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_timepoint import bhv_events_timepoint\n",
    "from ana_functions.bhv_events_timepoint_singlecam import bhv_events_timepoint_singlecam\n",
    "from ana_functions.bhv_events_timepoint_singlecam_otherlever import bhv_events_timepoint_singlecam_otherlever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4ab8c",
   "metadata": {},
   "source": [
    "### function - plot behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ba678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.plot_bhv_events import plot_bhv_events\n",
    "from ana_functions.plot_bhv_events_levertube import plot_bhv_events_levertube\n",
    "from ana_functions.draw_self_loop import draw_self_loop\n",
    "import matplotlib.patches as mpatches \n",
    "from matplotlib.collections import PatchCollection\n",
    "from ana_functions.plot_gaze_along_phase_of_continuous_bhv_var_singlecam import plot_gaze_along_phase_of_continuous_bhv_var_singlecam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d535a6",
   "metadata": {},
   "source": [
    "### function - make demo videos with skeleton and inportant vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4de83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.tracking_video_singlecam_demo import tracking_video_singlecam_demo\n",
    "from ana_functions.tracking_video_singlecam_wholebody_demo import tracking_video_singlecam_wholebody_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69920a6a",
   "metadata": {},
   "source": [
    "### function - interval between all behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a804dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_interval import bhv_events_interval\n",
    "from ana_functions.bhv_events_interval import bhv_events_interval_certainEdges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c0b97",
   "metadata": {},
   "source": [
    "### function - train the dynamic bayesian network - multi time lag (3 lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.train_DBN_multiLag_autolever import train_DBN_multiLag\n",
    "from ana_functions.train_DBN_multiLag_autolever import train_DBN_multiLag_create_df_only\n",
    "from ana_functions.train_DBN_multiLag_autolever import train_DBN_multiLag_training_only\n",
    "from ana_functions.train_DBN_multiLag_autolever import graph_to_matrix\n",
    "from ana_functions.train_DBN_multiLag_autolever import get_weighted_dags\n",
    "from ana_functions.train_DBN_multiLag_autolever import get_significant_edges\n",
    "from ana_functions.train_DBN_multiLag_autolever import threshold_edges\n",
    "from ana_functions.train_DBN_multiLag_autolever import Modulation_Index\n",
    "from ana_functions.EfficientTimeShuffling import EfficientShuffle\n",
    "from ana_functions.AicScore import AicScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819c438",
   "metadata": {},
   "source": [
    "## Analyze each session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e84fc",
   "metadata": {},
   "source": [
    "### prepare the basic behavioral data (especially the time stamps for each bhv events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc05cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instead of using gaze angle threshold, use the target rectagon to deside gaze info\n",
    "# ...need to update\n",
    "sqr_thres_tubelever = 75 # draw the square around tube and lever\n",
    "sqr_thres_face = 1.15 # a ratio for defining face boundary\n",
    "sqr_thres_body = 4 # how many times to enlongate the face box boundry to the body\n",
    "\n",
    "\n",
    "# get the fps of the analyzed video\n",
    "fps = 30\n",
    "\n",
    "# frame number of the demo video\n",
    "# nframes = 0.5*30 # second*30fps\n",
    "nframes = 2*30 # second*30fps\n",
    "\n",
    "# re-analyze the video or not\n",
    "reanalyze_video = 0\n",
    "redo_anystep = 0\n",
    "\n",
    "# only analyze the best (five) sessions for each conditions\n",
    "do_bestsession = 1\n",
    "if do_bestsession:\n",
    "    savefile_sufix = '_bestsessions_autolever'\n",
    "else:\n",
    "    savefile_sufix = '_autolever'\n",
    "    \n",
    "# all the videos (no misaligned ones)\n",
    "# aligned with the audio\n",
    "# get the session start time from \"videosound_bhv_sync.py/.ipynb\"\n",
    "# currently the session_start_time will be manually typed in. It can be updated after a better method is used\n",
    "\n",
    "# dodson scorch\n",
    "if 1:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [                      \n",
    "                     ]\n",
    "        session_start_times = [                                \n",
    "                              ] # in second\n",
    "    elif do_bestsession:\n",
    "        # pick only five sessions for each conditions\n",
    "        dates_list = [        \n",
    "                       \"20220915\",\"20220920\",\"20221010\",\"20230208\",\n",
    "            \n",
    "                       \"20221205\",\"20221206\",\"20221209\",\"20221214\",\"20230112\",\n",
    "                      \n",
    "                      \"20230327\",\"20230328\",\"20230331\",\"20230403\",\"20230404\",\n",
    "                      \"20230405\",\"20230406\",\n",
    "                     ]\n",
    "        session_start_times = [                 \n",
    "                                 0.00,33.03, 6.50, 0.00, \n",
    "            \n",
    "                                 0.00, 0.00, 21.7, 17.0, 14.2, \n",
    "            \n",
    "                                 30.0, 34.8, 29.2, 27.0, 28.0,\n",
    "                                 26.5, 23.0,                                \n",
    "                              ] # in second\n",
    "    \n",
    "    animal1_fixedorder = ['dodson']\n",
    "    animal2_fixedorder = ['scorch']\n",
    "\n",
    "    animal1_filename = \"Dodson\"\n",
    "    animal2_filename = \"Scorch\"\n",
    "    \n",
    "# eddie sparkle\n",
    "if 0:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [                                            \n",
    "                   ]\n",
    "        session_start_times = [                                                                 \n",
    "                              ] # in second\n",
    "    elif do_bestsession:   \n",
    "        dates_list = [\n",
    "                      \"20221122\",  \"20221125\",  \n",
    "                      \n",
    "                      \"20230321\",  \"20230322\",  \"20230324\",  \"20230327\",  \"20230328\",\n",
    "            \n",
    "                      \"20230524\",  \"20230526\",  \"20230529\",  \"20230531\",  \"20230605\", \n",
    "                      \"20230606\",  \"20230608\",  \"20230609\",  \"20230613\",  \"20230615\",\n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                  8.00,  38.00, \n",
    "                                  \n",
    "                                  7.00,   7.50,  5.50, 11.00,  9.00,\n",
    "                            \n",
    "                                  25.0,   34.0,  29.0,  12.8,  26.0,  \n",
    "                                  24.1,   21.0,  23.0,  29.0,  24.5,\n",
    "                              ] # in second\n",
    "    \n",
    "    animal1_fixedorder = ['eddie']\n",
    "    animal2_fixedorder = ['sparkle']\n",
    "\n",
    "    animal1_filename = \"Eddie\"\n",
    "    animal2_filename = \"Sparkle\"\n",
    "    \n",
    "# ginger kanga\n",
    "if 0:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [                     \n",
    "                   ]\n",
    "        session_start_times = [                            \n",
    "                              ] # in second \n",
    "    elif do_bestsession:   \n",
    "        dates_list = [\n",
    "                      \"20230214\",\"20230216\",\n",
    "\n",
    "                      \"20230412\",\"20230413\",\"20230517\",\n",
    "            \n",
    "                      \"20230616\",\"20230620\",\"20230621\",\"20230622\",\"20230623\",\n",
    "                      \"20230626\",\"20230627\",\"20230629\",\"20230703\",                    \n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                 0.00, 48.00, \n",
    "\n",
    "                                 0.00,  0.00,  0.00,  \n",
    "            \n",
    "                                58.20, 60.20, 26.80, 43.50, 40.00,\n",
    "                                53.00, 51.00, 27.20, 32.20,\n",
    "                                \n",
    "                              ] # in second \n",
    "    \n",
    "    animal1_fixedorder = ['ginger']\n",
    "    animal2_fixedorder = ['kanga']\n",
    "\n",
    "    animal1_filename = \"Ginger\"\n",
    "    animal2_filename = \"Kanga\"\n",
    "\n",
    "    \n",
    "# dannon kanga\n",
    "if 0:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [\n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                              ] # in second \n",
    "    elif do_bestsession:   \n",
    "        dates_list = [\n",
    "                      \"20230718\",\"20230720\",\"20230914\",\n",
    "            \n",
    "                      \"20230907\",\"20230915\",\"20230918\",\"20230926\",\"20230928\",\n",
    "                      \"20231002\",\"20231010\",\n",
    "            \n",
    "                      \"20240201\",\"20240212\",\"20240214\",\"20240215\",\"20240222\",\n",
    "                      \"20240223\",\"20240226\",\n",
    "            \n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                    0,     0,     0, \n",
    "            \n",
    "                                    0,     0,     0,     0,     0,     \n",
    "                                    0,     0,\n",
    "            \n",
    "                                    21.00, 45.50, 19.00, 22.20, 28.20,\n",
    "                                    25.50, 16.10,\n",
    "                              ] # in second \n",
    "    \n",
    "    animal1_fixedorder = ['dannon']\n",
    "    animal2_fixedorder = ['kanga']\n",
    "\n",
    "    animal1_filename = \"Dannon\"\n",
    "    animal2_filename = \"Kanga\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#    \n",
    "# dates_list = [\"20230718\"]\n",
    "# session_start_times = [0.00] # in second\n",
    "\n",
    "ndates = np.shape(dates_list)[0]\n",
    "\n",
    "session_start_frames = session_start_times * fps # fps is 30Hz\n",
    "\n",
    "totalsess_time = 600\n",
    "\n",
    "# video tracking results info\n",
    "animalnames_videotrack = ['dodson','scorch'] # does not really mean dodson and scorch, instead, indicate animal1 and animal2\n",
    "bodypartnames_videotrack = ['rightTuft','whiteBlaze','leftTuft','rightEye','leftEye','mouth']\n",
    "\n",
    "\n",
    "# which camera to analyzed\n",
    "cameraID = 'camera-2'\n",
    "cameraID_short = 'cam2'\n",
    "\n",
    "\n",
    "# location of levers and tubes for camera 2\n",
    "# get this information using DLC animal tracking GUI, the results are stored: \n",
    "# /home/ws523/marmoset_tracking_DLCv2/marmoset_tracking_with_lever_tube-weikang-2023-04-13/labeled-data/\n",
    "considerlevertube = 1\n",
    "considertubeonly = 0\n",
    "# # camera 1\n",
    "# lever_locs_camI = {'dodson':np.array([645,600]),'scorch':np.array([425,435])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1350,630]),'scorch':np.array([555,345])}\n",
    "# # camera 2\n",
    "lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "tube_locs_camI  = {'dodson':np.array([1550,515]),'scorch':np.array([350,515])}\n",
    "# # lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "# # tube_locs_camI  = {'dodson':np.array([1650,490]),'scorch':np.array([250,490])}\n",
    "# # camera 3\n",
    "# lever_locs_camI = {'dodson':np.array([1580,440]),'scorch':np.array([1296,540])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1470,375]),'scorch':np.array([805,475])}\n",
    "\n",
    "\n",
    "if np.shape(session_start_times)[0] != np.shape(dates_list)[0]:\n",
    "    exit()\n",
    "\n",
    "    \n",
    "# define bhv events summarizing variables     \n",
    "tasktypes_all_dates = np.zeros((ndates,1))\n",
    "coopthres_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "succ_rate_all_dates = np.zeros((ndates,1))\n",
    "interpullintv_all_dates = np.zeros((ndates,1))\n",
    "trialnum_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "owgaze1_num_all_dates = np.zeros((ndates,1))\n",
    "owgaze2_num_all_dates = np.zeros((ndates,1))\n",
    "mtgaze1_num_all_dates = np.zeros((ndates,1))\n",
    "mtgaze2_num_all_dates = np.zeros((ndates,1))\n",
    "pull1_num_all_dates = np.zeros((ndates,1))\n",
    "pull2_num_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "gazelever1_num_all_dates = np.zeros((ndates,1))\n",
    "gazelever2_num_all_dates = np.zeros((ndates,1))\n",
    "gazetube1_num_all_dates = np.zeros((ndates,1))\n",
    "gazetube2_num_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "gazeotherlever1_num_all_dates = np.zeros((ndates,1))\n",
    "gazeotherlever2_num_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "session_recordtime_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "bhv_intv_all_dates = dict.fromkeys(dates_list, [])\n",
    "pull_edges_intv_all_dates = dict.fromkeys(dates_list, [])\n",
    "\n",
    "gazeDist_phaseof_contbhvvar_all_dates = dict.fromkeys(dates_list, [])\n",
    "\n",
    "# where to save the summarizing data\n",
    "data_saved_folder = '/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/3d_recontruction_analysis_self_and_coop_task_data_saved/'\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic behavior analysis (define time stamps for each bhv events, etc)\n",
    "\n",
    "try:\n",
    "    if redo_anystep:\n",
    "        dummy\n",
    "    \n",
    "    # load saved data\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    \n",
    "    with open(data_saved_subfolder+'/owgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        owgaze1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/owgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        owgaze2_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/mtgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        mtgaze1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/mtgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        mtgaze2_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/pull1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        pull1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/pull2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        pull2_num_all_dates = pickle.load(f)\n",
    "        \n",
    "    with open(data_saved_subfolder+'/gazelever1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        gazelever1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/gazelever2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        gazelever2_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/gazetube1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        gazetube1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/gazetube2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        gazetube2_num_all_dates = pickle.load(f)\n",
    "    \n",
    "    with open(data_saved_subfolder+'/gazeotherlever1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        gazeotherlever1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/gazeotherlever2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        gazeotherlever2_num_all_dates = pickle.load(f)\n",
    "    \n",
    "    with open(data_saved_subfolder+'/session_recordtime_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        session_recordtime_all_dates = pickle.load(f)\n",
    "\n",
    "    with open(data_saved_subfolder+'/tasktypes_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        tasktypes_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/coopthres_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        coopthres_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/succ_rate_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        succ_rate_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/interpullintv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        interpullintv_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/trialnum_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        trialnum_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/bhv_intv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        bhv_intv_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/pull_edges_intv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        pull_edges_intv_all_dates = pickle.load(f)\n",
    "\n",
    "    with open(data_saved_subfolder+'/gazeDist_phaseof_contbhvvar_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        gazeDist_phaseof_contbhvvar_all_dates = pickle.load(f)   \n",
    "\n",
    "    print('all data from all dates are loaded')\n",
    "\n",
    "except:\n",
    "\n",
    "    print('analyze all dates')\n",
    "\n",
    "    for idate in np.arange(0,ndates,1):\n",
    "        date_tgt = dates_list[idate]\n",
    "        session_start_time = session_start_times[idate]\n",
    "\n",
    "        # folder and file path\n",
    "        camera12_analyzed_path = \"/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/test_video_cooperative_task_3d/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera12/\"\n",
    "        camera23_analyzed_path = \"/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/test_video_cooperative_task_3d/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera23/\"\n",
    "        \n",
    "        singlecam_ana_type = \"DLC_dlcrnetms5_marmoset_tracking_with_middle_cameraSep1shuffle1_150000\"\n",
    "        try: \n",
    "            bodyparts_camI_camIJ = camera12_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "            # get the bodypart data from files\n",
    "            bodyparts_locs_camI = body_part_locs_singlecam(bodyparts_camI_camIJ,singlecam_ana_type,animalnames_videotrack,bodypartnames_videotrack,date_tgt)\n",
    "            video_file_original = camera12_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+\".mp4\"\n",
    "        except:\n",
    "            bodyparts_camI_camIJ = camera23_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "            # get the bodypart data from files\n",
    "            bodyparts_locs_camI = body_part_locs_singlecam(bodyparts_camI_camIJ,singlecam_ana_type,animalnames_videotrack,bodypartnames_videotrack,date_tgt)\n",
    "            video_file_original = camera23_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+\".mp4\"        \n",
    "        \n",
    "        #\n",
    "        recordedtime = np.shape(bodyparts_locs_camI[('dodson','rightTuft')])[0]/fps # - session_start_time\n",
    "        session_recordtime_all_dates[idate] = recordedtime\n",
    "        \n",
    "        \n",
    "        # load behavioral results\n",
    "        try:\n",
    "            try:\n",
    "                bhv_data_path = \"/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                trial_record_json = glob.glob(bhv_data_path +date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_session_info_\" + \"*.json\")\n",
    "                #\n",
    "                trial_record = pd.read_json(trial_record_json[0])\n",
    "                bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                session_info = pd.read_json(session_info_json[0])\n",
    "            except:\n",
    "                bhv_data_path = \"/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                trial_record_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_session_info_\" + \"*.json\")\n",
    "                #\n",
    "                trial_record = pd.read_json(trial_record_json[0])\n",
    "                bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                session_info = pd.read_json(session_info_json[0])\n",
    "        except:\n",
    "            try:\n",
    "                bhv_data_path = \"/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/marmoset_tracking_bhv_data_forceManipulation_task/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                trial_record_json = glob.glob(bhv_data_path +date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_session_info_\" + \"*.json\")\n",
    "                #\n",
    "                trial_record = pd.read_json(trial_record_json[0])\n",
    "                bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                session_info = pd.read_json(session_info_json[0])\n",
    "            except:\n",
    "                bhv_data_path = \"/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/marmoset_tracking_bhv_data_forceManipulation_task/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                trial_record_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_session_info_\" + \"*.json\")\n",
    "                #\n",
    "                trial_record = pd.read_json(trial_record_json[0])\n",
    "                bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                session_info = pd.read_json(session_info_json[0])\n",
    "\n",
    "        # get animal info from the session information\n",
    "        animal1 = session_info['lever1_animal'][0].lower()\n",
    "        animal2 = session_info['lever2_animal'][0].lower()\n",
    "\n",
    "        \n",
    "        # get task type and cooperation threshold\n",
    "        try:\n",
    "            coop_thres = session_info[\"pulltime_thres\"][0]\n",
    "            tasktype = session_info[\"task_type\"][0]\n",
    "        except:\n",
    "            coop_thres = 0\n",
    "            tasktype = 1\n",
    "        tasktypes_all_dates[idate] = tasktype\n",
    "        coopthres_all_dates[idate] = coop_thres   \n",
    "\n",
    "        # clean up the trial_record\n",
    "        warnings.filterwarnings('ignore')\n",
    "        trial_record_clean = pd.DataFrame(columns=trial_record.columns)\n",
    "        for itrial in np.arange(0,np.max(trial_record['trial_number']),1):\n",
    "            # trial_record_clean.loc[itrial] = trial_record[trial_record['trial_number']==itrial+1].iloc[[0]]\n",
    "            trial_record_clean = trial_record_clean.append(trial_record[trial_record['trial_number']==itrial+1].iloc[[0]])\n",
    "        trial_record_clean = trial_record_clean.reset_index(drop = True)\n",
    "\n",
    "        # change bhv_data time to the absolute time\n",
    "        time_points_new = pd.DataFrame(np.zeros(np.shape(bhv_data)[0]),columns=[\"time_points_new\"])\n",
    "        for itrial in np.arange(0,np.max(trial_record_clean['trial_number']),1):\n",
    "            ind = bhv_data[\"trial_number\"]==itrial+1\n",
    "            new_time_itrial = bhv_data[ind][\"time_points\"] + trial_record_clean[\"trial_starttime\"].iloc[itrial]\n",
    "            time_points_new[\"time_points_new\"][ind] = new_time_itrial\n",
    "        bhv_data[\"time_points\"] = time_points_new[\"time_points_new\"]\n",
    "        bhv_data = bhv_data[bhv_data[\"time_points\"] != 0]\n",
    "\n",
    "\n",
    "        # analyze behavior results\n",
    "        # succ_rate_all_dates[idate] = np.sum(trial_record_clean[\"rewarded\"]>0)/np.shape(trial_record_clean)[0]\n",
    "        succ_rate_all_dates[idate] = np.sum((bhv_data['behavior_events']==3)|(bhv_data['behavior_events']==4))/np.sum((bhv_data['behavior_events']==1)|(bhv_data['behavior_events']==2))\n",
    "        trialnum_all_dates[idate] = np.shape(trial_record_clean)[0]\n",
    "        #\n",
    "        pullid = np.array(bhv_data[(bhv_data['behavior_events']==1) | (bhv_data['behavior_events']==2)][\"behavior_events\"])\n",
    "        pulltime = np.array(bhv_data[(bhv_data['behavior_events']==1) | (bhv_data['behavior_events']==2)][\"time_points\"])\n",
    "        pullid_diff = np.abs(pullid[1:] - pullid[0:-1])\n",
    "        pulltime_diff = pulltime[1:] - pulltime[0:-1]\n",
    "        interpull_intv = pulltime_diff[pullid_diff==1]\n",
    "        interpull_intv = interpull_intv[interpull_intv<10]\n",
    "        mean_interpull_intv = np.nanmean(interpull_intv)\n",
    "        std_interpull_intv = np.nanstd(interpull_intv)\n",
    "        #\n",
    "        interpullintv_all_dates[idate] = mean_interpull_intv\n",
    "        # \n",
    "        if np.isin(animal1,animal1_fixedorder):\n",
    "            pull1_num_all_dates[idate] = np.sum(bhv_data['behavior_events']==1) \n",
    "            pull2_num_all_dates[idate] = np.sum(bhv_data['behavior_events']==2)\n",
    "        else:\n",
    "            pull1_num_all_dates[idate] = np.sum(bhv_data['behavior_events']==2) \n",
    "            pull2_num_all_dates[idate] = np.sum(bhv_data['behavior_events']==1)\n",
    "\n",
    "        \n",
    "        # load behavioral event results\n",
    "        try:\n",
    "            # dummy\n",
    "            print('load social gaze with '+cameraID+' only of '+date_tgt)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_look_ornot.pkl', 'rb') as f:\n",
    "                output_look_ornot = pickle.load(f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allvectors.pkl', 'rb') as f:\n",
    "                output_allvectors = pickle.load(f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allangles.pkl', 'rb') as f:\n",
    "                output_allangles = pickle.load(f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_key_locations.pkl', 'rb') as f:\n",
    "                output_key_locations = pickle.load(f)\n",
    "        except:   \n",
    "            print('analyze social gaze with '+cameraID+' only of '+date_tgt)\n",
    "            # get social gaze information \n",
    "            output_look_ornot, output_allvectors, output_allangles = find_socialgaze_timepoint_singlecam_wholebody(bodyparts_locs_camI,lever_locs_camI,tube_locs_camI,\n",
    "                                                                                                                   considerlevertube,considertubeonly,sqr_thres_tubelever,\n",
    "                                                                                                                   sqr_thres_face,sqr_thres_body)\n",
    "            output_key_locations = find_socialgaze_timepoint_singlecam_wholebody_2(bodyparts_locs_camI,lever_locs_camI,tube_locs_camI,considerlevertube)\n",
    "            \n",
    "            # save data\n",
    "            current_dir = data_saved_folder+'/bhv_events_singlecam_wholebody/'+animal1_fixedorder[0]+animal2_fixedorder[0]\n",
    "            add_date_dir = os.path.join(current_dir,cameraID+'/'+date_tgt)\n",
    "            if not os.path.exists(add_date_dir):\n",
    "                os.makedirs(add_date_dir)\n",
    "            #\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_look_ornot.pkl', 'wb') as f:\n",
    "                pickle.dump(output_look_ornot, f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allvectors.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allvectors, f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allangles.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allangles, f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_key_locations.pkl', 'wb') as f:\n",
    "                pickle.dump(output_key_locations, f)\n",
    "  \n",
    "\n",
    "        look_at_other_or_not_merge = output_look_ornot['look_at_other_or_not_merge']\n",
    "        look_at_tube_or_not_merge = output_look_ornot['look_at_tube_or_not_merge']\n",
    "        look_at_lever_or_not_merge = output_look_ornot['look_at_lever_or_not_merge']\n",
    "        look_at_otherlever_or_not_merge = output_look_ornot['look_at_otherlever_or_not_merge']\n",
    "        look_at_otherface_or_not_merge = output_look_ornot['look_at_otherface_or_not_merge']\n",
    "        \n",
    "        # change the unit to second\n",
    "        session_start_time = session_start_times[idate]\n",
    "        look_at_other_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_other_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_lever_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_lever_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_tube_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_tube_or_not_merge['dodson'])[0],1)/fps - session_start_time \n",
    "        look_at_otherlever_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_otherlever_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_otherface_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_otherface_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "\n",
    "        \n",
    "        # find time point of behavioral events\n",
    "        # output_time_points_socialgaze ,output_time_points_levertube = bhv_events_timepoint_singlecam(bhv_data,look_at_other_or_not_merge,look_at_lever_or_not_merge,look_at_tube_or_not_merge)\n",
    "        output_time_points_socialgaze ,output_time_points_levertube = bhv_events_timepoint_singlecam(bhv_data,look_at_otherface_or_not_merge,look_at_lever_or_not_merge,look_at_tube_or_not_merge)\n",
    "        time_point_pull1 = output_time_points_socialgaze['time_point_pull1']\n",
    "        time_point_pull2 = output_time_points_socialgaze['time_point_pull2']\n",
    "        oneway_gaze1 = output_time_points_socialgaze['oneway_gaze1']\n",
    "        oneway_gaze2 = output_time_points_socialgaze['oneway_gaze2']\n",
    "        mutual_gaze1 = output_time_points_socialgaze['mutual_gaze1']\n",
    "        mutual_gaze2 = output_time_points_socialgaze['mutual_gaze2']\n",
    "        time_point_lever1 = output_time_points_levertube['time_point_lookatlever1']\n",
    "        time_point_lever2 = output_time_points_levertube['time_point_lookatlever2']\n",
    "        time_point_tube1 = output_time_points_levertube['time_point_lookattube1']\n",
    "        time_point_tube2 = output_time_points_levertube['time_point_lookattube2']\n",
    "            \n",
    "        output_time_points_otherlever = bhv_events_timepoint_singlecam_otherlever(bhv_data, look_at_otherlever_or_not_merge)\n",
    "        time_point_otherlever1 = output_time_points_otherlever['time_point_lookatotherlever1']\n",
    "        time_point_otherlever2 = output_time_points_otherlever['time_point_lookatotherlever2']\n",
    "        \n",
    "        \n",
    "            \n",
    "        #\n",
    "        if np.isin(animal1,animal1_fixedorder):\n",
    "            owgaze1_num_all_dates[idate] = np.shape(oneway_gaze1)[0]#/(min_length/fps)\n",
    "            owgaze2_num_all_dates[idate] = np.shape(oneway_gaze2)[0]#/(min_length/fps)\n",
    "            mtgaze1_num_all_dates[idate] = np.shape(mutual_gaze1)[0]#/(min_length/fps)\n",
    "            mtgaze2_num_all_dates[idate] = np.shape(mutual_gaze2)[0]#/(min_length/fps)\n",
    "            gazelever1_num_all_dates[idate] = np.shape(time_point_lever1)[0]\n",
    "            gazelever2_num_all_dates[idate] = np.shape(time_point_lever2)[0]\n",
    "            gazetube1_num_all_dates[idate] = np.shape(time_point_tube1)[0]\n",
    "            gazetube2_num_all_dates[idate] = np.shape(time_point_tube2)[0]\n",
    "            \n",
    "            gazeotherlever1_num_all_dates[idate] = np.shape(time_point_otherlever1)[0]\n",
    "            gazeotherlever2_num_all_dates[idate] = np.shape(time_point_otherlever2)[0]\n",
    "        else:\n",
    "            owgaze1_num_all_dates[idate] = np.shape(oneway_gaze2)[0]#/(min_length/fps)\n",
    "            owgaze2_num_all_dates[idate] = np.shape(oneway_gaze1)[0]#/(min_length/fps)\n",
    "            mtgaze1_num_all_dates[idate] = np.shape(mutual_gaze2)[0]#/(min_length/fps)\n",
    "            mtgaze2_num_all_dates[idate] = np.shape(mutual_gaze1)[0]#/(min_length/fps)\n",
    "            gazelever1_num_all_dates[idate] = np.shape(time_point_lever2)[0]\n",
    "            gazelever2_num_all_dates[idate] = np.shape(time_point_lever1)[0]\n",
    "            gazetube1_num_all_dates[idate] = np.shape(time_point_tube2)[0]\n",
    "            gazetube2_num_all_dates[idate] = np.shape(time_point_tube1)[0]\n",
    "            \n",
    "            gazeotherlever1_num_all_dates[idate] = np.shape(time_point_otherlever2)[0]\n",
    "            gazeotherlever2_num_all_dates[idate] = np.shape(time_point_otherlever1)[0]\n",
    "\n",
    "        \n",
    "        # plot and analyze the gaze distribution along the phase of continous behavioral variables\n",
    "        if 1:\n",
    "            fig_savepath = data_saved_folder+'/\tbhv_events_continuous_variables_singlecam_wholebody/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'+cameraID+'/'+date_tgt+'/'   \n",
    "            if not os.path.exists(fig_savepath):\n",
    "                os.makedirs(fig_savepath)\n",
    "            fig_savepath = fig_savepath + date_tgt\n",
    "\n",
    "            doActvePeri = 1\n",
    "            doGazeStart = 1\n",
    "            savefig = 1\n",
    "            #\n",
    "            gazeDist_phaseof_contbhvvar_summary = plot_gaze_along_phase_of_continuous_bhv_var_singlecam(fig_savepath, savefig, animal1, animal2, session_start_time, \n",
    "                                                                            time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, \n",
    "                                                                            mutual_gaze1, mutual_gaze2, animalnames_videotrack, output_look_ornot, \n",
    "                                                                            output_allvectors, output_allangles, output_key_locations, doActvePeri, doGazeStart)\n",
    "            #\n",
    "            gazeDist_phaseof_contbhvvar_all_dates[date_tgt] = gazeDist_phaseof_contbhvvar_summary\n",
    "\n",
    "        \n",
    "        # analyze the events interval, especially for the pull to other and other to pull interval\n",
    "        # could be used for define time bin for DBN\n",
    "        if np.isin(animal1,animal1_fixedorder):\n",
    "            _,_,_,pullTOother_itv, otherTOpull_itv = bhv_events_interval(totalsess_time, session_start_time, time_point_pull1, time_point_pull2, \n",
    "                                                                         oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "            #\n",
    "            pull_other_pool_itv = np.concatenate((pullTOother_itv,otherTOpull_itv))\n",
    "            bhv_intv_all_dates[date_tgt] = {'pull_to_other':pullTOother_itv,'other_to_pull':otherTOpull_itv,\n",
    "                            'pull_other_pooled': pull_other_pool_itv}\n",
    "            \n",
    "            all_pull_edges_intervals = bhv_events_interval_certainEdges(totalsess_time, session_start_time, time_point_pull1, time_point_pull2, \n",
    "                                                                        oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "            pull_edges_intv_all_dates[date_tgt] = all_pull_edges_intervals\n",
    "        else:\n",
    "            _,_,_,pullTOother_itv, otherTOpull_itv = bhv_events_interval(totalsess_time, session_start_time, time_point_pull2, time_point_pull1, \n",
    "                                                                         oneway_gaze2, oneway_gaze1, mutual_gaze2, mutual_gaze1)\n",
    "            #\n",
    "            pull_other_pool_itv = np.concatenate((pullTOother_itv,otherTOpull_itv))\n",
    "            bhv_intv_all_dates[date_tgt] = {'pull_to_other':pullTOother_itv,'other_to_pull':otherTOpull_itv,\n",
    "                            'pull_other_pooled': pull_other_pool_itv}\n",
    "            \n",
    "            all_pull_edges_intervals = bhv_events_interval_certainEdges(totalsess_time, session_start_time, time_point_pull2, time_point_pull1, \n",
    "                                                                        oneway_gaze2, oneway_gaze1, mutual_gaze2, mutual_gaze1)\n",
    "            pull_edges_intv_all_dates[date_tgt] = all_pull_edges_intervals\n",
    "   \n",
    "        \n",
    "        \n",
    "\n",
    "    # save data\n",
    "    if 1:\n",
    "        \n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "        if not os.path.exists(data_saved_subfolder):\n",
    "            os.makedirs(data_saved_subfolder)\n",
    "                \n",
    "        # with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        #     pickle.dump(DBN_input_data_alltypes, f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/owgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(owgaze1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/owgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(owgaze2_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/mtgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(mtgaze1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/mtgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(mtgaze2_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/pull1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(pull1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/pull2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(pull2_num_all_dates, f)\n",
    "            \n",
    "        with open(data_saved_subfolder+'/gazelever1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(gazelever1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/gazelever2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(gazelever2_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/gazetube1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(gazetube1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/gazetube2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(gazetube2_num_all_dates, f)\n",
    "         \n",
    "        with open(data_saved_subfolder+'/session_recordtime_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(session_recordtime_all_dates, f)\n",
    "        \n",
    "        with open(data_saved_subfolder+'/gazeotherlever1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(gazeotherlever1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/gazeotherlever2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(gazeotherlever2_num_all_dates, f)\n",
    "        \n",
    "\n",
    "        with open(data_saved_subfolder+'/tasktypes_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(tasktypes_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/coopthres_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(coopthres_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/succ_rate_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(succ_rate_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/interpullintv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(interpullintv_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/trialnum_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(trialnum_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/bhv_intv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(bhv_intv_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/pull_edges_intv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(pull_edges_intv_all_dates, f)\n",
    "    \n",
    "        with open(data_saved_subfolder+'/gazeDist_phaseof_contbhvvar_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(gazeDist_phaseof_contbhvvar_all_dates, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86c9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    minframe = 5000\n",
    "    maxframe = 7000\n",
    "    \n",
    "    gaze_thresold = 0.25\n",
    "    \n",
    "    # get the discrete behavioral events\n",
    "    # aligned to the start of the video recording\n",
    "    time_point_pull1_frames = (np.array(time_point_pull1)+session_start_time)*fps \n",
    "    time_point_pull2_frames = (np.array(time_point_pull2)+session_start_time)*fps \n",
    "\n",
    "    # define gazes are all gaze entry\n",
    "    #\n",
    "    # oneway_gaze1_frames = (np.sort(np.concatenate((oneway_gaze1,mutual_gaze1)))+session_start_time)*fps \n",
    "    # oneway_gaze2_frames = (np.sort(np.concatenate((oneway_gaze2,mutual_gaze2)))+session_start_time)*fps \n",
    "\n",
    "    # define gaze as the flash gaze and gaze start\n",
    "    # get the gaze start and stop\n",
    "    #animal1_gaze = np.concatenate([oneway_gaze1, mutual_gaze1])\n",
    "    animal1_gaze = np.sort(np.concatenate((oneway_gaze1,mutual_gaze1)))\n",
    "    animal1_gaze = np.sort(np.unique(animal1_gaze))\n",
    "    animal1_gaze_stop = animal1_gaze[np.concatenate(((animal1_gaze[1:]-animal1_gaze[0:-1]>gaze_thresold)*1,[1]))==1]\n",
    "    animal1_gaze_start = np.concatenate(([animal1_gaze[0]],animal1_gaze[np.where(animal1_gaze[1:]-animal1_gaze[0:-1]>gaze_thresold)[0]+1]))\n",
    "    animal1_gaze_flash = np.intersect1d(animal1_gaze_start, animal1_gaze_stop)\n",
    "    animal1_gaze_start = animal1_gaze_start[~np.isin(animal1_gaze_start,animal1_gaze_flash)]\n",
    "    animal1_gaze_stop = animal1_gaze_stop[~np.isin(animal1_gaze_stop,animal1_gaze_flash)]\n",
    "    #\n",
    "    #animal2_gaze = np.concatenate([oneway_gaze2, mutual_gaze2])\n",
    "    animal2_gaze = np.sort(np.concatenate((oneway_gaze2,mutual_gaze2)))\n",
    "    animal2_gaze = np.sort(np.unique(animal2_gaze))\n",
    "    animal2_gaze_stop = animal2_gaze[np.concatenate(((animal2_gaze[1:]-animal2_gaze[0:-1]>gaze_thresold)*1,[1]))==1]\n",
    "    animal2_gaze_start = np.concatenate(([animal2_gaze[0]],animal2_gaze[np.where(animal2_gaze[1:]-animal2_gaze[0:-1]>gaze_thresold)[0]+1]))\n",
    "    animal2_gaze_flash = np.intersect1d(animal2_gaze_start, animal2_gaze_stop)\n",
    "    animal2_gaze_start = animal2_gaze_start[~np.isin(animal2_gaze_start,animal2_gaze_flash)]\n",
    "    animal2_gaze_stop = animal2_gaze_stop[~np.isin(animal2_gaze_stop,animal2_gaze_flash)] \n",
    "    #\n",
    "    oneway_gaze1_frames = (np.sort(np.concatenate((animal1_gaze_start,animal1_gaze_flash)))+session_start_time)*fps \n",
    "    oneway_gaze2_frames = (np.sort(np.concatenate((animal2_gaze_start,animal2_gaze_flash)))+session_start_time)*fps \n",
    "\n",
    "    a = output_key_locations['lever_loc_all_merge']['dodson'].transpose()\n",
    "    b = output_key_locations['meaneye_loc_all_merge']['dodson'].transpose()\n",
    "    a_min_b = a - b\n",
    "    otherani_otherlever_dist = np.sqrt(np.einsum('ij,ij->j', a_min_b, a_min_b))\n",
    "    otherani_otherlever_dist = scipy.ndimage.gaussian_filter1d(otherani_otherlever_dist,3)\n",
    "\n",
    "    otherani_otherlever_dist = (otherani_otherlever_dist-np.nanmin(otherani_otherlever_dist))/(np.nanmax(otherani_otherlever_dist)-np.nanmin(otherani_otherlever_dist))\n",
    "\n",
    "    oneway_gaze1_frames_forplot = oneway_gaze1_frames[(oneway_gaze1_frames<maxframe)&(oneway_gaze1_frames>minframe)]\n",
    "    oneway_gaze2_frames_forplot = oneway_gaze2_frames[(oneway_gaze2_frames<maxframe)&(oneway_gaze2_frames>minframe)]\n",
    "\n",
    "    pull1_frames_forplot = time_point_pull1_frames[(time_point_pull1_frames<maxframe)&(time_point_pull1_frames>minframe)]\n",
    "    pull2_frames_forplot = time_point_pull2_frames[(time_point_pull2_frames<maxframe)&(time_point_pull2_frames>minframe)]\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    for igaze in oneway_gaze2_frames_forplot:\n",
    "        ax1.plot([igaze,igaze],[0,1],color='#7c7c7c')\n",
    "\n",
    "    for ipull in pull1_frames_forplot:\n",
    "        ax1.plot([ipull,ipull],[0,1],color='r')\n",
    "\n",
    "    for ipull in pull2_frames_forplot:\n",
    "        ax1.plot([ipull,ipull],[0,1],color='b')\n",
    "\n",
    "    ax1.plot(np.arange(minframe,maxframe,1),otherani_otherlever_dist[minframe:maxframe])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51126bf7",
   "metadata": {},
   "source": [
    "### prepare the input data for DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae4662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define DBN related summarizing variables\n",
    "DBN_input_data_alltypes = dict.fromkeys(dates_list, [])\n",
    "\n",
    "doBhvitv_timebin = 0 # 1: if use the mean bhv event interval for time bin\n",
    "\n",
    "prepare_input_data = 0\n",
    "\n",
    "# DBN resolutions (make sure they are the same as in the later part of the code)\n",
    "# totalsess_time = 600 # total session time in s\n",
    "# temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "ntemp_reses = np.shape(temp_resolus)[0]\n",
    "\n",
    "mergetempRos = 0\n",
    "\n",
    "# # train the dynamic bayesian network - Alec's model \n",
    "#   prepare the multi-session table; one time lag; multi time steps (temporal resolution) as separate files\n",
    "\n",
    "# prepare the DBN input data\n",
    "if prepare_input_data:\n",
    "    \n",
    "    for idate in np.arange(0,ndates,1):\n",
    "        date_tgt = dates_list[idate]\n",
    "        session_start_time = session_start_times[idate]\n",
    "        session_recordtime_all = session_recordtime_all_dates[idate]\n",
    "        \n",
    "        totalsess_time = np.ceil(session_recordtime_all-session_start_time)\n",
    "        \n",
    "\n",
    "        # load behavioral results\n",
    "        try:\n",
    "            try:\n",
    "                bhv_data_path = \"/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                trial_record_json = glob.glob(bhv_data_path +date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_session_info_\" + \"*.json\")\n",
    "                #\n",
    "                trial_record = pd.read_json(trial_record_json[0])\n",
    "                bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                session_info = pd.read_json(session_info_json[0])\n",
    "            except:\n",
    "                bhv_data_path = \"/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                trial_record_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_session_info_\" + \"*.json\")\n",
    "                #\n",
    "                trial_record = pd.read_json(trial_record_json[0])\n",
    "                bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                session_info = pd.read_json(session_info_json[0])\n",
    "        except:    \n",
    "            try:\n",
    "                bhv_data_path = \"/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/marmoset_tracking_bhv_data_forceManipulation_task/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                trial_record_json = glob.glob(bhv_data_path +date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_session_info_\" + \"*.json\")\n",
    "                #\n",
    "                trial_record = pd.read_json(trial_record_json[0])\n",
    "                bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                session_info = pd.read_json(session_info_json[0])\n",
    "            except:\n",
    "                bhv_data_path = \"/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/marmoset_tracking_bhv_data_forceManipulation_task/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                trial_record_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_session_info_\" + \"*.json\")\n",
    "                #\n",
    "                trial_record = pd.read_json(trial_record_json[0])\n",
    "                bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                session_info = pd.read_json(session_info_json[0])\n",
    "            \n",
    "        # get animal info\n",
    "        animal1 = session_info['lever1_animal'][0].lower()\n",
    "        animal2 = session_info['lever2_animal'][0].lower()\n",
    "        \n",
    "        # clean up the trial_record\n",
    "        warnings.filterwarnings('ignore')\n",
    "        trial_record_clean = pd.DataFrame(columns=trial_record.columns)\n",
    "        for itrial in np.arange(0,np.max(trial_record['trial_number']),1):\n",
    "            # trial_record_clean.loc[itrial] = trial_record[trial_record['trial_number']==itrial+1].iloc[[0]]\n",
    "            trial_record_clean = trial_record_clean.append(trial_record[trial_record['trial_number']==itrial+1].iloc[[0]])\n",
    "        trial_record_clean = trial_record_clean.reset_index(drop = True)\n",
    "\n",
    "        # change bhv_data time to the absolute time\n",
    "        time_points_new = pd.DataFrame(np.zeros(np.shape(bhv_data)[0]),columns=[\"time_points_new\"])\n",
    "        for itrial in np.arange(0,np.max(trial_record_clean['trial_number']),1):\n",
    "            ind = bhv_data[\"trial_number\"]==itrial+1\n",
    "            new_time_itrial = bhv_data[ind][\"time_points\"] + trial_record_clean[\"trial_starttime\"].iloc[itrial]\n",
    "            time_points_new[\"time_points_new\"][ind] = new_time_itrial\n",
    "        bhv_data[\"time_points\"] = time_points_new[\"time_points_new\"]\n",
    "        bhv_data = bhv_data[bhv_data[\"time_points\"] != 0]\n",
    "            \n",
    "        # get task type and cooperation threshold\n",
    "        try:\n",
    "            coop_thres = session_info[\"pulltime_thres\"][0]\n",
    "            tasktype = session_info[\"task_type\"][0]\n",
    "        except:\n",
    "            coop_thres = 0\n",
    "            tasktype = 1\n",
    "\n",
    "        # load behavioral event results\n",
    "        print('load social gaze with '+cameraID+' only of '+date_tgt)\n",
    "        with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_look_ornot.pkl', 'rb') as f:\n",
    "            output_look_ornot = pickle.load(f)\n",
    "        with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allvectors.pkl', 'rb') as f:\n",
    "            output_allvectors = pickle.load(f)\n",
    "        with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allangles.pkl', 'rb') as f:\n",
    "            output_allangles = pickle.load(f)  \n",
    "        #\n",
    "        look_at_other_or_not_merge = output_look_ornot['look_at_other_or_not_merge']\n",
    "        look_at_tube_or_not_merge = output_look_ornot['look_at_tube_or_not_merge']\n",
    "        look_at_lever_or_not_merge = output_look_ornot['look_at_lever_or_not_merge']\n",
    "        look_at_otherlever_or_not_merge = output_look_ornot['look_at_otherlever_or_not_merge']\n",
    "        look_at_otherface_or_not_merge = output_look_ornot['look_at_otherface_or_not_merge']\n",
    "        \n",
    "        # change the unit to second\n",
    "        session_start_time = session_start_times[idate]\n",
    "        look_at_other_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_other_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_lever_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_lever_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_tube_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_tube_or_not_merge['dodson'])[0],1)/fps - session_start_time \n",
    "        look_at_otherlever_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_otherlever_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_otherface_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_otherface_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        \n",
    "        # find time point of behavioral events\n",
    "        # output_time_points_socialgaze ,output_time_points_levertube = bhv_events_timepoint_singlecam(bhv_data,look_at_other_or_not_merge,look_at_lever_or_not_merge,look_at_tube_or_not_merge)\n",
    "        output_time_points_socialgaze ,output_time_points_levertube = bhv_events_timepoint_singlecam(bhv_data,look_at_otherface_or_not_merge,look_at_lever_or_not_merge,look_at_tube_or_not_merge)\n",
    "        time_point_pull1 = output_time_points_socialgaze['time_point_pull1']\n",
    "        time_point_pull2 = output_time_points_socialgaze['time_point_pull2']\n",
    "        oneway_gaze1 = output_time_points_socialgaze['oneway_gaze1']\n",
    "        oneway_gaze2 = output_time_points_socialgaze['oneway_gaze2']\n",
    "        mutual_gaze1 = output_time_points_socialgaze['mutual_gaze1']\n",
    "        mutual_gaze2 = output_time_points_socialgaze['mutual_gaze2']   \n",
    "        time_point_lever1 = output_time_points_levertube['time_point_lookatlever1']\n",
    "        time_point_lever2 = output_time_points_levertube['time_point_lookatlever2']\n",
    "        time_point_tube1 = output_time_points_levertube['time_point_lookattube1']\n",
    "        time_point_tube2 = output_time_points_levertube['time_point_lookattube2']\n",
    "            \n",
    "        output_time_points_otherlever = bhv_events_timepoint_singlecam_otherlever(bhv_data, look_at_otherlever_or_not_merge)\n",
    "        time_point_otherlever1 = output_time_points_otherlever['time_point_lookatotherlever1']\n",
    "        time_point_otherlever2 = output_time_points_otherlever['time_point_lookatotherlever2']\n",
    "\n",
    "        \n",
    "        if mergetempRos:\n",
    "            temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "            # use bhv event to decide temporal resolution\n",
    "            #\n",
    "            #low_lim,up_lim,_ = bhv_events_interval(totalsess_time, session_start_time, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "            #temp_resolus = temp_resolus = np.arange(low_lim,up_lim,0.1)\n",
    "        #\n",
    "        if doBhvitv_timebin:\n",
    "            pull_other_intv_ii = pd.Series(bhv_intv_all_dates[date_tgt]['pull_other_pooled'])\n",
    "            # remove the interval that is too large\n",
    "            pull_other_intv_ii[pull_other_intv_ii>(np.nanmean(pull_other_intv_ii)+2*np.nanstd(pull_other_intv_ii))]= np.nan    \n",
    "            # pull_other_intv_ii[pull_other_intv_ii>10]= np.nan\n",
    "            temp_resolus = [np.nanmean(pull_other_intv_ii)]          \n",
    "        #\n",
    "        ntemp_reses = np.shape(temp_resolus)[0]           \n",
    "\n",
    "        \n",
    "        # try different temporal resolutions\n",
    "        for temp_resolu in temp_resolus:\n",
    "            bhv_df = []\n",
    "\n",
    "            if np.isin(animal1,animal1_fixedorder):\n",
    "                bhv_df_itr,_,_ = train_DBN_multiLag_create_df_only(totalsess_time, session_start_time, temp_resolu, \n",
    "                                                                   time_point_pull1, time_point_pull2, \n",
    "                                                                   oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2,\n",
    "                                                                   time_point_otherlever1, time_point_otherlever2)\n",
    "            else:\n",
    "                bhv_df_itr,_,_ = train_DBN_multiLag_create_df_only(totalsess_time, session_start_time, temp_resolu, \n",
    "                                                                   time_point_pull2, time_point_pull1, \n",
    "                                                                   oneway_gaze2, oneway_gaze1, mutual_gaze2, mutual_gaze1,\n",
    "                                                                   time_point_otherlever2, time_point_otherlever1)     \n",
    "\n",
    "            if len(bhv_df)==0:\n",
    "                bhv_df = bhv_df_itr\n",
    "            else:\n",
    "                bhv_df = pd.concat([bhv_df,bhv_df_itr])                   \n",
    "                bhv_df = bhv_df.reset_index(drop=True)        \n",
    "\n",
    "            DBN_input_data_alltypes[date_tgt] = bhv_df\n",
    "            \n",
    "    # save data\n",
    "    if 1:\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_allsessions'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "        if not os.path.exists(data_saved_subfolder):\n",
    "            os.makedirs(data_saved_subfolder)\n",
    "        if not mergetempRos:\n",
    "            if doBhvitv_timebin:\n",
    "                with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'bhvItvTempReSo.pkl', 'wb') as f:\n",
    "                    pickle.dump(DBN_input_data_alltypes, f)\n",
    "            else:\n",
    "                with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'sReSo.pkl', 'wb') as f:\n",
    "                    pickle.dump(DBN_input_data_alltypes, f)\n",
    "        else:\n",
    "            with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_mergeTempsReSo.pkl', 'wb') as f:\n",
    "                pickle.dump(DBN_input_data_alltypes, f)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fa3049",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBN_input_data_alltypes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aada694",
   "metadata": {},
   "source": [
    "#### redefine the tasktype and cooperation threshold to merge them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100: self; 3: 3s coop; 2: 2s coop; 1.5: 1.5s coop; 1: 1s coop; -1: no-vision; 3.5:animal1 autolever, 4:animal2_autolever\n",
    "\n",
    "tasktypes_all_dates[tasktypes_all_dates==5] = -1 # change the task type code for no-vision\n",
    "coopthres_forsort = (tasktypes_all_dates-1)*coopthres_all_dates/2\n",
    "coopthres_forsort[coopthres_forsort==0] = 0 # get the cooperation threshold for sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900d890",
   "metadata": {},
   "source": [
    "### plot behavioral events interval to get a sense about time bin\n",
    "#### only focus on pull_to_other_bhv_interval and other_bhv_to_pull_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b179dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates': dates_list, 'coopthres': coopthres_forsort.ravel()}, columns=['dates', 'coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['coopthres','dates'], ascending = [True, True])\n",
    "dates_list_sorted = np.array(dates_list)[sorting_df.index]\n",
    "ndates_sorted = np.shape(dates_list_sorted)[0]\n",
    "\n",
    "pull_other_intv_forplots = {}\n",
    "pull_other_intv_mean = np.zeros((1,ndates_sorted))[0]\n",
    "pull_other_intv_ii = []\n",
    "for ii in np.arange(0,ndates_sorted,1):\n",
    "    pull_other_intv_ii = pd.Series(bhv_intv_all_dates[dates_list_sorted[ii]]['pull_other_pooled'])\n",
    "    # remove the interval that is too large\n",
    "    pull_other_intv_ii[pull_other_intv_ii>(np.nanmean(pull_other_intv_ii)+2*np.nanstd(pull_other_intv_ii))]= np.nan    \n",
    "    # pull_other_intv_ii[pull_other_intv_ii>10]= np.nan\n",
    "    pull_other_intv_forplots[ii] = pull_other_intv_ii\n",
    "    pull_other_intv_mean[ii] = np.nanmean(pull_other_intv_ii)\n",
    "    \n",
    "    \n",
    "#\n",
    "pull_other_intv_forplots = pd.DataFrame(pull_other_intv_forplots)\n",
    "\n",
    "#\n",
    "# plot\n",
    "pull_other_intv_forplots.plot(kind = 'box',ax=ax1, positions=np.arange(0,ndates_sorted,1))\n",
    "# plt.boxplot(pull_other_intv_forplots)\n",
    "plt.plot(np.arange(0,ndates_sorted,1),pull_other_intv_mean,'r*',markersize=10)\n",
    "#\n",
    "ax1.set_ylabel(\"bhv event interval(around pulls)\",fontsize=13)\n",
    "ax1.set_ylim([-2,16])\n",
    "#\n",
    "plt.xticks(np.arange(0,ndates_sorted,1),dates_list_sorted, rotation=90,fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "#\n",
    "tasktypes = ['self','coop(1s)','animal1_autolever','animal2_autolever']\n",
    "taskswitches = np.where(np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)[0]+0.5\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.plot([taskswitch,taskswitch],[-2,15],'k--')\n",
    "taskswitches = np.concatenate(([0],taskswitches))\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.text(taskswitch+0.25,-1,tasktypes[itaskswitch],fontsize=10)\n",
    "ax1.text(taskswitch-5,15,'mean Inteval = '+str(np.nanmean(pull_other_intv_forplots)),fontsize=10)\n",
    "\n",
    "print(pull_other_intv_mean)\n",
    "print(np.nanmean(pull_other_intv_forplots))\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_autolever/'+savefile_sufix+'/'+cameraID+'/autolever/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"bhvInterval_hist_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3831554",
   "metadata": {},
   "source": [
    "### plot some other basis behavioral measures\n",
    "#### successful rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates': dates_list, 'coopthres': coopthres_forsort.ravel()}, columns=['dates', 'coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['coopthres','dates'], ascending = [True, True])\n",
    "dates_list_sorted = np.array(dates_list)[sorting_df.index]\n",
    "ndates_sorted = np.shape(dates_list_sorted)[0]\n",
    "\n",
    "\n",
    "ax1.plot(np.arange(0,ndates_sorted,1),succ_rate_all_dates[sorting_df.index],'o',markersize=10)\n",
    "#\n",
    "ax1.set_ylabel(\"successful rate\",fontsize=13)\n",
    "ax1.set_ylim([-0.1,1.1])\n",
    "ax1.set_xlim([-0.5,ndates_sorted-0.5])\n",
    "#\n",
    "plt.xticks(np.arange(0,ndates_sorted,1),dates_list_sorted, rotation=90,fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "#\n",
    "tasktypes = ['self','coop(1s)','animal1_autolever','animal2_autolever']\n",
    "taskswitches = np.where(np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)[0]+0.5\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.plot([taskswitch,taskswitch],[-0.1,1.1],'k--')\n",
    "taskswitches = np.concatenate(([0],taskswitches))\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.text(taskswitch+0.25,-0.05,tasktypes[itaskswitch],fontsize=10)\n",
    "    \n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_autolever/'+savefile_sufix+'/'+cameraID+'/autolever/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"successfulrate_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15978aac",
   "metadata": {},
   "source": [
    "#### animal pull numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b937f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates': dates_list, 'coopthres': coopthres_forsort.ravel()}, columns=['dates', 'coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['coopthres','dates'], ascending = [True, True])\n",
    "dates_list_sorted = np.array(dates_list)[sorting_df.index]\n",
    "ndates_sorted = np.shape(dates_list_sorted)[0]\n",
    "\n",
    "pullmean_num_all_dates = (pull1_num_all_dates+pull2_num_all_dates)/2\n",
    "ax1.plot(np.arange(0,ndates_sorted,1),\n",
    "         pull1_num_all_dates[sorting_df.index]/session_recordtime_all_dates[sorting_df.index],\n",
    "         'bv',markersize=5,label='animal1 pull #')\n",
    "ax1.plot(np.arange(0,ndates_sorted,1),\n",
    "         pull2_num_all_dates[sorting_df.index]/session_recordtime_all_dates[sorting_df.index],\n",
    "         'rv',markersize=5,label='animal2 pull #')\n",
    "ax1.plot(np.arange(0,ndates_sorted,1),\n",
    "         pullmean_num_all_dates[sorting_df.index]/session_recordtime_all_dates[sorting_df.index],\n",
    "         'kv',markersize=8,label='mean pull #')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "#\n",
    "ax1.set_ylabel(\"pull numbers per second\",fontsize=13)\n",
    "ax1.set_ylim([-0.1,0.4])\n",
    "ax1.set_xlim([-0.5,ndates_sorted-0.5])\n",
    "\n",
    "#\n",
    "plt.xticks(np.arange(0,ndates_sorted,1),dates_list_sorted, rotation=90,fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "#\n",
    "tasktypes = ['self','coop(1s)','animal1_autolever','animal2_autolever']\n",
    "taskswitches = np.where(np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)[0]+0.5\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.plot([taskswitch,taskswitch],[-20,540],'k--')\n",
    "taskswitches = np.concatenate(([0],taskswitches))\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.text(taskswitch+0.25,-0.05,tasktypes[itaskswitch],fontsize=10)\n",
    "    \n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_autolever/'+savefile_sufix+'/'+cameraID+'/autolever/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"pullnumbers_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a5cfe5",
   "metadata": {},
   "source": [
    "#### gaze number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5915c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gaze1_num_all_dates = owgaze1_num_all_dates + mtgaze1_num_all_dates\n",
    "gaze2_num_all_dates = owgaze2_num_all_dates + mtgaze2_num_all_dates\n",
    "gazemean_num_all_dates = (gaze1_num_all_dates+gaze2_num_all_dates)/2\n",
    "\n",
    "print(np.nanmax(gaze1_num_all_dates))\n",
    "print(np.nanmax(gaze2_num_all_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52cccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates': dates_list, 'coopthres': coopthres_forsort.ravel()}, columns=['dates', 'coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['coopthres','dates'], ascending = [True, True])\n",
    "dates_list_sorted = np.array(dates_list)[sorting_df.index]\n",
    "ndates_sorted = np.shape(dates_list_sorted)[0]\n",
    "\n",
    "\n",
    "\n",
    "ax1.plot(np.arange(0,ndates_sorted,1),\n",
    "         gaze1_num_all_dates[sorting_df.index]/session_recordtime_all_dates[sorting_df.index],\n",
    "         'b^',markersize=5,label='animal1 gaze #')\n",
    "ax1.plot(np.arange(0,ndates_sorted,1),\n",
    "         gaze2_num_all_dates[sorting_df.index]/session_recordtime_all_dates[sorting_df.index],\n",
    "         'r^',markersize=5,label='animal2 gaze #')\n",
    "ax1.plot(np.arange(0,ndates_sorted,1),\n",
    "         gazemean_num_all_dates[sorting_df.index]/session_recordtime_all_dates[sorting_df.index],\n",
    "         'k^',markersize=8,label='mean gaze #')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "#\n",
    "ax1.set_ylabel(\"social gaze number per second\",fontsize=13)\n",
    "ax1.set_ylim([-0.1,3])\n",
    "ax1.set_xlim([-0.5,ndates_sorted-0.5])\n",
    "\n",
    "#\n",
    "plt.xticks(np.arange(0,ndates_sorted,1),dates_list_sorted, rotation=90,fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "#\n",
    "tasktypes = ['self','coop(1s)','animal1_autolever','animal2_autolever']\n",
    "taskswitches = np.where(np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)[0]+0.5\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.plot([taskswitch,taskswitch],[-20,4500],'k--')\n",
    "taskswitches = np.concatenate(([0],taskswitches))\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.text(taskswitch+0.25,-0.05,tasktypes[itaskswitch],fontsize=10)\n",
    "    \n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_autolever/'+savefile_sufix+'/'+cameraID+'/autolever/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"gazenumbers_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc98eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "gazeotherlever_mean_all_dates = (gazeotherlever1_num_all_dates+gazeotherlever2_num_all_dates)/2\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates': dates_list, 'coopthres': coopthres_forsort.ravel()}, columns=['dates', 'coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['coopthres','dates'], ascending = [True, True])\n",
    "dates_list_sorted = np.array(dates_list)[sorting_df.index]\n",
    "ndates_sorted = np.shape(dates_list_sorted)[0]\n",
    "\n",
    "\n",
    "\n",
    "ax1.plot(np.arange(0,ndates_sorted,1),\n",
    "         gazeotherlever1_num_all_dates[sorting_df.index]/session_recordtime_all_dates[sorting_df.index],\n",
    "         'b^',markersize=5,label='animal1 gaze #')\n",
    "ax1.plot(np.arange(0,ndates_sorted,1),\n",
    "         gazeotherlever2_num_all_dates[sorting_df.index]/session_recordtime_all_dates[sorting_df.index],\n",
    "         'r^',markersize=5,label='animal2 gaze #')\n",
    "ax1.plot(np.arange(0,ndates_sorted,1),\n",
    "         gazeotherlever_mean_all_dates[sorting_df.index]/session_recordtime_all_dates[sorting_df.index],\n",
    "         'k^',markersize=8,label='mean gaze #')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "#\n",
    "ax1.set_ylabel(\"gaze other lever number per second\",fontsize=13)\n",
    "ax1.set_ylim([-0.1,3])\n",
    "ax1.set_xlim([-0.5,ndates_sorted-0.5])\n",
    "\n",
    "#\n",
    "plt.xticks(np.arange(0,ndates_sorted,1),dates_list_sorted, rotation=90,fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "#\n",
    "tasktypes = ['self','coop(1s)','animal1_autolever','animal2_autolever']\n",
    "taskswitches = np.where(np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)[0]+0.5\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.plot([taskswitch,taskswitch],[-20,4500],'k--')\n",
    "taskswitches = np.concatenate(([0],taskswitches))\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.text(taskswitch+0.25,-0.05,tasktypes[itaskswitch],fontsize=10)\n",
    "    \n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_autolever/'+savefile_sufix+'/'+cameraID+'/autolever/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"gazeotherlevernumbers_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c82e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_numbers = (owgaze1_num_all_dates+owgaze2_num_all_dates+mtgaze1_num_all_dates+mtgaze2_num_all_dates)/session_recordtime_all_dates\n",
    "gaze_pull_ratios = (owgaze1_num_all_dates+owgaze2_num_all_dates+mtgaze1_num_all_dates+mtgaze2_num_all_dates)/(pull1_num_all_dates+pull2_num_all_dates)\n",
    "\n",
    "gazeotherlever_numbers = (gazeotherlever1_num_all_dates+gazeotherlever2_num_all_dates)/session_recordtime_all_dates\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "grouptypes = ['self','coop(1s)','animal1_autolever','animal2_autolever']\n",
    "\n",
    "gaze_numbers_groups = [np.transpose(gaze_numbers[np.transpose(coopthres_forsort==0)[0]])[0],\n",
    "                       np.transpose(gaze_numbers[np.transpose(coopthres_forsort==1)[0]])[0],\n",
    "                       np.transpose(gaze_numbers[np.transpose(coopthres_forsort==3.5)[0]])[0],\n",
    "                       np.transpose(gaze_numbers[np.transpose(coopthres_forsort==4)[0]])[0],]\n",
    "\n",
    "gazeotherlever_numbers_groups = [np.transpose(gazeotherlever_numbers[np.transpose(coopthres_forsort==0)[0]])[0],\n",
    "                                 np.transpose(gazeotherlever_numbers[np.transpose(coopthres_forsort==1)[0]])[0],\n",
    "                                 np.transpose(gazeotherlever_numbers[np.transpose(coopthres_forsort==3.5)[0]])[0],\n",
    "                                 np.transpose(gazeotherlever_numbers[np.transpose(coopthres_forsort==4)[0]])[0],]\n",
    "\n",
    "gaze_numbers_plot = plt.boxplot(gaze_numbers_groups)\n",
    "plt.boxplot(gazeotherlever_numbers_groups)\n",
    "\n",
    "plt.xticks(np.arange(1, len(grouptypes)+1, 1), grouptypes, fontsize = 12);\n",
    "ax1.set_ylim([-0.1,4])\n",
    "ax1.set_ylabel(\"average social gaze number per second\",fontsize=13)\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_autolever/'+savefile_sufix+'/'+cameraID+'/autolever/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"averaged_gazenumbers_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c7d69",
   "metadata": {},
   "source": [
    "### plot the gaze distribution along the continuous variables\n",
    "#### only focus on \"otherani_otherlever_dist\", plot the ratio of number of 'decrasing' phase vs 'increasing' phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f55719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2,1)\n",
    "# fig.set_figheight(10)\n",
    "# fig.set_figwidth(10*2)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "type_tgt = 'otherani_otherlever_dist'\n",
    "\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates': dates_list, 'coopthres': coopthres_forsort.ravel()}, columns=['dates', 'coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['coopthres','dates'], ascending = [False, True])\n",
    "dates_list_sorted = np.array(dates_list)[sorting_df.index]\n",
    "ndates_sorted = np.shape(dates_list_sorted)[0]\n",
    "\n",
    "gazeDist_ratios_forplot_animal1 = np.ones(np.shape(dates_list_sorted))*np.nan\n",
    "gazeDist_ratios_forplot_animal2 = np.ones(np.shape(dates_list_sorted))*np.nan\n",
    "\n",
    "for idate in np.arange(0,ndates_sorted,1):\n",
    "    \n",
    "    date_i = dates_list_sorted[idate]\n",
    "    \n",
    "    # for animal 1\n",
    "    gazeDist_tgt = gazeDist_phaseof_contbhvvar_all_dates[date_i][animal1_fixedorder[0]][type_tgt]\n",
    "    gateDist_ratio_tgt = np.sum(gazeDist_tgt['phase']=='decreasing')/np.sum(gazeDist_tgt['phase']=='increasing')\n",
    "    gazeDist_ratios_forplot_animal1[idate] = gateDist_ratio_tgt\n",
    "    \n",
    "    # for animal 2\n",
    "    gazeDist_tgt = gazeDist_phaseof_contbhvvar_all_dates[date_i][animal2_fixedorder[0]][type_tgt]\n",
    "    gateDist_ratio_tgt = np.sum(gazeDist_tgt['phase']=='decreasing')/np.sum(gazeDist_tgt['phase']=='increasing')\n",
    "    gazeDist_ratios_forplot_animal2[idate] = gateDist_ratio_tgt\n",
    "    \n",
    "\n",
    "ax1.plot(np.arange(0,ndates_sorted,1),gazeDist_ratios_forplot_animal1,'b^',markersize=5,label=animal1_fixedorder[0])\n",
    "ax1.plot(np.arange(0,ndates_sorted,1),gazeDist_ratios_forplot_animal2,'r^',markersize=5,label=animal2_fixedorder[0])\n",
    "ax1.plot([-0.5,ndates_sorted-0.5],[1,1],'k--')\n",
    "ax1.legend()\n",
    "\n",
    "#\n",
    "ax1.set_ylabel('ratio',fontsize=13)\n",
    "ax1.set_title(\"social gaze on the decreasing phase / inecreasing phase of \"+type_tgt)\n",
    "# ax1.set_ylim([-20,1500])\n",
    "ax1.set_ylim([0,2])\n",
    "ax1.set_xlim([-0.5,ndates_sorted-0.5])\n",
    "\n",
    "#\n",
    "plt.xticks(np.arange(0,ndates_sorted,1),dates_list_sorted, rotation=90,fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "#\n",
    "tasktypes = ['self','coop(1s)','animal1_autolever','animal2_autolever']\n",
    "taskswitches = np.where(np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)[0]+0.5\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    # ax1.plot([taskswitch,taskswitch],[-20,1500],'k--')\n",
    "    ax1.plot([taskswitch,taskswitch],[0,2],'k--')\n",
    "taskswitches = np.concatenate(([0],taskswitches))\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.text(taskswitch+0.25,0.5,tasktypes[itaskswitch],fontsize=10)\n",
    "    \n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_autolever/'+savefile_sufix+'/'+cameraID+'/autolever/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"gazenumberratio_decreasingphaseVSincreasingphase\"+type_tgt+\"_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239f11d",
   "metadata": {},
   "source": [
    "## plot that includes all the animals - final summarizing plot\n",
    "#### plot the gaze numbers for all individuals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# animal1_fixedorders = ['eddie','dodson','dannon','ginger']\n",
    "# animal2_fixedorders = ['sparkle','scorch','kanga_1','kanga_2']\n",
    "animal1_fixedorders = ['eddie','dodson','ginger']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga_2']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "# grouptypes = ['self reward','1s threshold','animal1 autolever','animal2_autolever']\n",
    "grouptypes = ['self reward','1s threshold','self autolever','other autolever']\n",
    "coopthres_IDs = [0, 1, 3.5, 4]\n",
    "ngrouptypes = np.shape(grouptypes)[0]\n",
    "\n",
    "gazenum_foreachgroup_foreachAni = dict.fromkeys(grouptypes,[])\n",
    "gazenum_foreachgroup_all = dict.fromkeys(grouptypes,[])\n",
    "#\n",
    "gazeothernum_foreachgroup_foreachAni = dict.fromkeys(grouptypes,[])\n",
    "gazeothernum_foreachgroup_all = dict.fromkeys(grouptypes,[])\n",
    "\n",
    "#\n",
    "# malenames = ['eddie','dodson','dannon',]\n",
    "# femalenames = ['sparkle','scorch','kanga_1','kanga_2','ginger',]\n",
    "malenames = ['eddie','dodson',]\n",
    "femalenames = ['sparkle','scorch','kanga_2','ginger',]\n",
    "gazenum_foreachgroup_male = dict.fromkeys(grouptypes,[])\n",
    "gazenum_foreachgroup_female = dict.fromkeys(grouptypes,[])\n",
    "#\n",
    "gazeothernum_foreachgroup_male = dict.fromkeys(grouptypes,[])\n",
    "gazeothernum_foreachgroup_female = dict.fromkeys(grouptypes,[])\n",
    "\n",
    "#\n",
    "# subnames = ['eddie','dodson','dannon','ginger',]\n",
    "# domnames = ['sparkle','scorch','kanga_1','kanga_2',]\n",
    "subnames = ['eddie','dodson','ginger',]\n",
    "domnames = ['sparkle','scorch','kanga_2',]\n",
    "gazenum_foreachgroup_sub = dict.fromkeys(grouptypes,[])\n",
    "gazenum_foreachgroup_dom = dict.fromkeys(grouptypes,[])\n",
    "#\n",
    "gazeothernum_foreachgroup_sub = dict.fromkeys(grouptypes,[])\n",
    "gazeothernum_foreachgroup_dom = dict.fromkeys(grouptypes,[])\n",
    "\n",
    "#\n",
    "for igrouptype in np.arange(0,ngrouptypes,1):\n",
    "    \n",
    "    grouptype = grouptypes[igrouptype]\n",
    "    coopthres_ID = coopthres_IDs[igrouptype]\n",
    "    \n",
    "    gazenum_foreachgroup_foreachAni[grouptype] = dict.fromkeys(animal1_fixedorders+animal2_fixedorders,[])\n",
    "    gazeothernum_foreachgroup_foreachAni[grouptype] = dict.fromkeys(animal1_fixedorders+animal2_fixedorders,[])\n",
    "    \n",
    "\n",
    "    #\n",
    "    for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "        animal1 = animal1_fixedorders[ianimalpair]\n",
    "        animal2 = animal2_fixedorders[ianimalpair]\n",
    "        \n",
    "        if (animal2 == 'kanga_1') | (animal2 == 'kanga_2'):\n",
    "            animal2_filename = 'kanga'\n",
    "        else:\n",
    "            animal2_filename = animal2\n",
    "\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1+animal2_filename+'/'\n",
    "\n",
    "        with open(data_saved_subfolder+'/owgaze1_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            owgaze1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/owgaze2_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            owgaze2_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/mtgaze1_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            mtgaze1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/mtgaze2_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            mtgaze2_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/pull1_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            pull1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/pull2_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            pull2_num_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/gazelever1_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            gazelever1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/gazelever2_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            gazelever2_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/gazetube1_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            gazetube1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/gazetube2_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            gazetube2_num_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/gazeotherlever1_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            gazeotherlever1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/gazeotherlever2_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            gazeotherlever2_num_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/session_recordtime_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            session_recordtime_all_dates = pickle.load(f)\n",
    "        \n",
    "        with open(data_saved_subfolder+'/tasktypes_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            tasktypes_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/coopthres_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            coopthres_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/succ_rate_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            succ_rate_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/interpullintv_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            interpullintv_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/trialnum_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            trialnum_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/bhv_intv_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            bhv_intv_all_dates = pickle.load(f)\n",
    "\n",
    "        # combine owgaze and mtgaze\n",
    "        gaze1_num_all_dates = (owgaze1_num_all_dates + mtgaze1_num_all_dates)/session_recordtime_all_dates\n",
    "        gaze2_num_all_dates = (owgaze2_num_all_dates + mtgaze2_num_all_dates)/session_recordtime_all_dates\n",
    "        #\n",
    "        gazeotherlever1_num_all_dates = gazeotherlever1_num_all_dates/session_recordtime_all_dates\n",
    "        gazeotherlever2_num_all_dates = gazeotherlever2_num_all_dates/session_recordtime_all_dates\n",
    "        \n",
    "        #\n",
    "        # 100: self; 3: 3s coop; 2: 2s coop; 1.5: 1.5s coop; 1: 1s coop; -1: no-vision\n",
    "        tasktypes_all_dates[tasktypes_all_dates==5] = -1 # change the task type code for no-vision\n",
    "        coopthres_forsort = (tasktypes_all_dates-1)*coopthres_all_dates/2\n",
    "        coopthres_forsort[coopthres_forsort==0] = 0 # get the cooperation threshold for sorting\n",
    "\n",
    "        if grouptype == 'self autolever':\n",
    "            # \n",
    "            gazenum_foreachgroup_foreachAni[grouptype][animal1] = gaze1_num_all_dates[coopthres_forsort==3.5]\n",
    "            gazenum_foreachgroup_foreachAni[grouptype][animal2] = gaze2_num_all_dates[coopthres_forsort==4]\n",
    "            #\n",
    "            gazeothernum_foreachgroup_foreachAni[grouptype][animal1] = gazeotherlever1_num_all_dates[coopthres_forsort==3.5]\n",
    "            gazeothernum_foreachgroup_foreachAni[grouptype][animal2] = gazeotherlever2_num_all_dates[coopthres_forsort==4]\n",
    "        #\n",
    "        elif grouptype == 'other autolever':\n",
    "            # \n",
    "            gazenum_foreachgroup_foreachAni[grouptype][animal1] = gaze1_num_all_dates[coopthres_forsort==4]\n",
    "            gazenum_foreachgroup_foreachAni[grouptype][animal2] = gaze2_num_all_dates[coopthres_forsort==3.5]\n",
    "            #\n",
    "            gazeothernum_foreachgroup_foreachAni[grouptype][animal1] = gazeotherlever1_num_all_dates[coopthres_forsort==4]\n",
    "            gazeothernum_foreachgroup_foreachAni[grouptype][animal2] = gazeotherlever2_num_all_dates[coopthres_forsort==3.5]\n",
    "        #\n",
    "        else:\n",
    "            # \n",
    "            gazenum_foreachgroup_foreachAni[grouptype][animal1] = gaze1_num_all_dates[coopthres_forsort==coopthres_ID]\n",
    "            gazenum_foreachgroup_foreachAni[grouptype][animal2] = gaze2_num_all_dates[coopthres_forsort==coopthres_ID]\n",
    "            #\n",
    "            gazeothernum_foreachgroup_foreachAni[grouptype][animal1] = gazeotherlever1_num_all_dates[coopthres_forsort==coopthres_ID]\n",
    "            gazeothernum_foreachgroup_foreachAni[grouptype][animal2] = gazeotherlever2_num_all_dates[coopthres_forsort==coopthres_ID]\n",
    "    \n",
    "    \n",
    "    # combine across all animals\n",
    "    gazenum_foreachgroup_all[grouptype] = np.hstack(list(gazenum_foreachgroup_foreachAni[grouptype].values()))\n",
    "    gazeothernum_foreachgroup_all[grouptype] = np.hstack(list(gazeothernum_foreachgroup_foreachAni[grouptype].values()))\n",
    "    \n",
    "    # combine across male and female\n",
    "    df = pd.DataFrame.from_dict(gazenum_foreachgroup_foreachAni[grouptype],orient='index')\n",
    "    df = df.transpose()[malenames]\n",
    "    gazenum_foreachgroup_male[grouptype] = df.values.ravel()\n",
    "    #\n",
    "    df = pd.DataFrame.from_dict(gazeothernum_foreachgroup_foreachAni[grouptype],orient='index')\n",
    "    df = df.transpose()[malenames]\n",
    "    gazeothernum_foreachgroup_male[grouptype] = df.values.ravel()\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(gazenum_foreachgroup_foreachAni[grouptype],orient='index')\n",
    "    df = df.transpose()[femalenames]\n",
    "    gazenum_foreachgroup_female[grouptype] = df.values.ravel()\n",
    "    #\n",
    "    df = pd.DataFrame.from_dict(gazeothernum_foreachgroup_foreachAni[grouptype],orient='index')\n",
    "    df = df.transpose()[femalenames]\n",
    "    gazeothernum_foreachgroup_female[grouptype] = df.values.ravel()\n",
    "    \n",
    "    # combine across sub and dom\n",
    "    df = pd.DataFrame.from_dict(gazenum_foreachgroup_foreachAni[grouptype],orient='index')\n",
    "    df = df.transpose()[subnames]\n",
    "    gazenum_foreachgroup_sub[grouptype] = df.values.ravel()\n",
    "    #\n",
    "    df = pd.DataFrame.from_dict(gazenum_foreachgroup_foreachAni[grouptype],orient='index')\n",
    "    df = df.transpose()[domnames]\n",
    "    gazenum_foreachgroup_dom[grouptype] = df.values.ravel()\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(gazeothernum_foreachgroup_foreachAni[grouptype],orient='index')\n",
    "    df = df.transpose()[subnames]\n",
    "    gazeothernum_foreachgroup_sub[grouptype] = df.values.ravel()\n",
    "    #\n",
    "    df = pd.DataFrame.from_dict(gazeothernum_foreachgroup_foreachAni[grouptype],orient='index')\n",
    "    df = df.transpose()[domnames]\n",
    "    gazeothernum_foreachgroup_dom[grouptype] = df.values.ravel()\n",
    "    \n",
    "    \n",
    "        \n",
    "# box plot \n",
    "fig, axs = plt.subplots(4,1)\n",
    "fig.set_figheight(5*4)\n",
    "fig.set_figwidth(3*2)\n",
    "\n",
    "# subplot 1 - all animals\n",
    "gazenum_foreachgroup_all_df = pd.DataFrame.from_dict(gazenum_foreachgroup_all,orient='index')\n",
    "gazenum_foreachgroup_all_df = gazenum_foreachgroup_all_df.transpose()\n",
    "gazenum_foreachgroup_all_df['type'] = 'all social gaze'\n",
    "gazeothernum_foreachgroup_all_df = pd.DataFrame.from_dict(gazeothernum_foreachgroup_all,orient='index')\n",
    "gazeothernum_foreachgroup_all_df = gazeothernum_foreachgroup_all_df.transpose()\n",
    "gazeothernum_foreachgroup_all_df['type'] = 'all other lever gaze'\n",
    "#\n",
    "df_long=pd.concat([gazenum_foreachgroup_all_df, gazeothernum_foreachgroup_all_df])\n",
    "df_long2 = df_long.melt(id_vars=['type'], value_vars=grouptypes,var_name='condition', value_name='value')\n",
    "# \n",
    "# barplot ans swarmplot\n",
    "seaborn.boxplot(ax=axs[0],data=df_long2,x='condition',y='value',hue='type')\n",
    "# seaborn.swarmplot(ax=axs[0],data=df_long2,x='condition',y='value',hue='type',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs[0].set_xlabel('')\n",
    "axs[0].set_xticklabels('')\n",
    "axs[0].xaxis.set_tick_params(labelsize=15)\n",
    "axs[0].set_ylabel(\"gaze number per second\",fontsize=15)\n",
    "axs[0].set_title('all animals' ,fontsize=24)\n",
    "axs[0].set_ylim([-0.1,1.7])\n",
    "axs[0].legend(fontsize=18, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# subplot 2 - all animals other lever gaze to social gaze ratio\n",
    "gazenum_foreachgroup_all_df = pd.DataFrame.from_dict(gazenum_foreachgroup_all,orient='index')\n",
    "gazenum_foreachgroup_all_df = gazenum_foreachgroup_all_df.transpose()\n",
    "gazeothernum_foreachgroup_all_df = pd.DataFrame.from_dict(gazeothernum_foreachgroup_all,orient='index')\n",
    "gazeothernum_foreachgroup_all_df = gazeothernum_foreachgroup_all_df.transpose()\n",
    "socialtoleverratio_foreachgroup_all_df = gazeothernum_foreachgroup_all_df/gazenum_foreachgroup_all_df\n",
    "socialtoleverratio_foreachgroup_all_df['type'] = 'lever gaze to social gaze ratio'\n",
    "#\n",
    "df_long=pd.concat([socialtoleverratio_foreachgroup_all_df])\n",
    "df_long2 = df_long.melt(id_vars=['type'], value_vars=grouptypes,var_name='condition', value_name='value')\n",
    "# \n",
    "# barplot ans swarmplot\n",
    "# seaborn.boxplot(ax=axs[1],data=df_long2,x='condition',y='value',hue='type')\n",
    "seaborn.violinplot(ax=axs[1],data=df_long2,x='condition',y='value',hue='type')\n",
    "# seaborn.swarmplot(ax=axs[1],data=df_long2,x='condition',y='value',hue='type',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs[1].set_xlabel('')\n",
    "axs[1].set_xticklabels('')\n",
    "axs[1].xaxis.set_tick_params(labelsize=15)\n",
    "axs[1].set_ylabel(\"lever gaze to social gaze ratio\",fontsize=15)\n",
    "axs[1].set_title('all animals' ,fontsize=24)\n",
    "axs[1].set_ylim([-0.1,5])\n",
    "axs[1].legend(fontsize=18, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "# subplot 3 - male and female animals\n",
    "gazenum_foreachgroup_male_df = pd.DataFrame.from_dict(gazenum_foreachgroup_male,orient='index')\n",
    "gazenum_foreachgroup_male_df = gazenum_foreachgroup_male_df.transpose()\n",
    "gazenum_foreachgroup_female_df = pd.DataFrame.from_dict(gazenum_foreachgroup_female,orient='index')\n",
    "gazenum_foreachgroup_female_df = gazenum_foreachgroup_female_df.transpose()\n",
    "#\n",
    "gazeothernum_foreachgroup_male_df = pd.DataFrame.from_dict(gazeothernum_foreachgroup_male,orient='index')\n",
    "gazeothernum_foreachgroup_male_df = gazeothernum_foreachgroup_male_df.transpose()\n",
    "gazeothernum_foreachgroup_female_df = pd.DataFrame.from_dict(gazeothernum_foreachgroup_female,orient='index')\n",
    "gazeothernum_foreachgroup_female_df = gazeothernum_foreachgroup_female_df.transpose()\n",
    "# \n",
    "socialtoleverratio_foreachgroup_male_df = gazeothernum_foreachgroup_male_df/gazenum_foreachgroup_male_df\n",
    "socialtoleverratio_foreachgroup_male_df['type'] = 'male lever gaze to social gaze ratio'\n",
    "socialtoleverratio_foreachgroup_female_df = gazeothernum_foreachgroup_female_df/gazenum_foreachgroup_female_df\n",
    "socialtoleverratio_foreachgroup_female_df['type'] = 'female lever gaze to social gaze ratio'\n",
    "#\n",
    "gazenum_foreachgroup_male_df['type'] = 'male social gaze'\n",
    "gazenum_foreachgroup_female_df['type'] = 'female social gaze'\n",
    "gazeothernum_foreachgroup_male_df['type'] = 'male other lever gaze'\n",
    "gazeothernum_foreachgroup_female_df['type'] = 'female other lever gaze'\n",
    "#\n",
    "# df_long=pd.concat([gazenum_foreachgroup_male_df,gazenum_foreachgroup_female_df,\n",
    "#                    gazeothernum_foreachgroup_male_df,gazeothernum_foreachgroup_female_df])\n",
    "df_long=pd.concat([socialtoleverratio_foreachgroup_male_df,\n",
    "                   socialtoleverratio_foreachgroup_female_df,\n",
    "                   ])\n",
    "df_long2 = df_long.melt(id_vars=['type'], value_vars=grouptypes,var_name='condition', value_name='value')\n",
    "# \n",
    "# barplot ans swarmplot\n",
    "seaborn.violinplot(ax=axs[2],data=df_long2,x='condition',y='value',hue='type')\n",
    "# seaborn.swarmplot(ax=axs[2],data=df_long2,x='condition',y='value',hue='type',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs[2].set_xlabel('')\n",
    "axs[2].set_xticklabels('')\n",
    "axs[2].xaxis.set_tick_params(labelsize=15)\n",
    "axs[2].set_ylabel(\"gaze number per second\",fontsize=15)\n",
    "axs[2].set_title('male and female' ,fontsize=24)\n",
    "axs[2].set_ylim([-0.1,5])\n",
    "axs[2].legend(fontsize=18, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# subplot 4 - dom and sub animals\n",
    "gazenum_foreachgroup_sub_df = pd.DataFrame.from_dict(gazenum_foreachgroup_sub,orient='index')\n",
    "gazenum_foreachgroup_sub_df = gazenum_foreachgroup_sub_df.transpose()\n",
    "gazenum_foreachgroup_dom_df = pd.DataFrame.from_dict(gazenum_foreachgroup_dom,orient='index')\n",
    "gazenum_foreachgroup_dom_df = gazenum_foreachgroup_dom_df.transpose()\n",
    "#\n",
    "gazeothernum_foreachgroup_sub_df = pd.DataFrame.from_dict(gazeothernum_foreachgroup_sub,orient='index')\n",
    "gazeothernum_foreachgroup_sub_df = gazeothernum_foreachgroup_sub_df.transpose()\n",
    "gazeothernum_foreachgroup_dom_df = pd.DataFrame.from_dict(gazeothernum_foreachgroup_dom,orient='index')\n",
    "gazeothernum_foreachgroup_dom_df = gazeothernum_foreachgroup_dom_df.transpose()\n",
    "#\n",
    "socialtoleverratio_foreachgroup_sub_df = gazeothernum_foreachgroup_sub_df/gazenum_foreachgroup_sub_df\n",
    "socialtoleverratio_foreachgroup_sub_df['type'] = 'sub lever gaze to social gaze ratio'\n",
    "socialtoleverratio_foreachgroup_dom_df = gazeothernum_foreachgroup_dom_df/gazenum_foreachgroup_dom_df\n",
    "socialtoleverratio_foreachgroup_dom_df['type'] = 'dom lever gaze to social gaze ratio'\n",
    "#\n",
    "gazenum_foreachgroup_sub_df['type'] = 'sub social gaze'\n",
    "gazenum_foreachgroup_dom_df['type'] = 'dom social gaze'\n",
    "gazeothernum_foreachgroup_sub_df['type'] = 'sub other lever gaze'\n",
    "gazeothernum_foreachgroup_dom_df['type'] = 'dom other lever gaze'\n",
    "#\n",
    "# df_long=pd.concat([gazenum_foreachgroup_sub_df,gazenum_foreachgroup_dom_df,\n",
    "#                    gazeothernum_foreachgroup_sub_df,gazeothernum_foreachgroup_dom_df,])\n",
    "df_long=pd.concat([socialtoleverratio_foreachgroup_sub_df,\n",
    "                   socialtoleverratio_foreachgroup_dom_df,\n",
    "                   ])\n",
    "df_long2 = df_long.melt(id_vars=['type'], value_vars=grouptypes,var_name='condition', value_name='value')\n",
    "# \n",
    "# barplot ans swarmplot\n",
    "seaborn.violinplot(ax=axs[3],data=df_long2,x='condition',y='value',hue='type')\n",
    "# seaborn.swarmplot(ax=axs[3],data=df_long2,x='condition',y='value',hue='type',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs[3].set_xlabel('')\n",
    "axs[3].set_xticklabels(axs[3].get_xticklabels(),rotation=45)\n",
    "axs[3].xaxis.set_tick_params(labelsize=15)\n",
    "axs[3].set_ylabel(\"gaze number per second\",fontsize=15)\n",
    "axs[3].set_title('sub and dom' ,fontsize=24)\n",
    "axs[3].set_ylim([-0.1,5.7])\n",
    "axs[3].legend(fontsize=18, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "        \n",
    "savefigs = 0\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_autolever/'+savefile_sufix+'/'+cameraID+'/autolever/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+'averaged_gazenumbers_andotherlevernumbers_acrossAllAnimals.pdf')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a3112",
   "metadata": {},
   "source": [
    "#### significance check using anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gazenum_foreachgroup_all_df = pd.DataFrame.from_dict(gazenum_foreachgroup_all,orient='index')\n",
    "gazenum_foreachgroup_all_df = gazenum_foreachgroup_all_df.transpose()\n",
    "gazeothernum_foreachgroup_all_df = pd.DataFrame.from_dict(gazeothernum_foreachgroup_all,orient='index')\n",
    "gazeothernum_foreachgroup_all_df = gazeothernum_foreachgroup_all_df.transpose()\n",
    "socialtoleverratio_foreachgroup_all_df = gazeothernum_foreachgroup_all_df/gazenum_foreachgroup_all_df\n",
    "gazenum_foreachgroup_all_df['type'] = 'all social gaze'\n",
    "gazeothernum_foreachgroup_all_df['type'] = 'all other lever gaze'\n",
    "socialtoleverratio_foreachgroup_all_df['type'] = 'lever gaze to social gaze ratio'\n",
    "#\n",
    "df_long=pd.concat([gazenum_foreachgroup_all_df, gazeothernum_foreachgroup_all_df,\n",
    "                   socialtoleverratio_foreachgroup_all_df])\n",
    "df_long2 = df_long.melt(id_vars=['type'], value_vars=grouptypes,var_name='condition', value_name='value')\n",
    "df_long2 = df_long2[~np.isnan(df_long2['value'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07cf688",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = np.array(df_long[df_long['type']=='lever gaze to social gaze ratio']['1s threshold'])\n",
    "xxx = xxx[~np.isnan(xxx)]\n",
    "yyy = np.array(df_long[df_long['type']=='lever gaze to social gaze ratio']['other autolever'])\n",
    "yyy = yyy[~np.isnan(yyy)]\n",
    "\n",
    "st.ttest_ind(xxx, yyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = np.array(df_long[df_long['type']=='all social gaze']['self reward'])\n",
    "xxx = xxx[~np.isnan(xxx)]\n",
    "yyy = np.array(df_long[df_long['type']=='all social gaze']['1s threshold'])\n",
    "yyy = yyy[~np.isnan(yyy)]\n",
    "\n",
    "st.ttest_ind(xxx, yyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbce12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = np.array(df_long[df_long['type']=='all social gaze']['other autolever'])\n",
    "xxx = xxx[~np.isnan(xxx)]\n",
    "yyy = np.array(df_long[df_long['type']=='all other lever gaze']['other autolever'])\n",
    "yyy = yyy[~np.isnan(yyy)]\n",
    "\n",
    "st.ttest_ind(xxx, yyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06acb0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# anova\n",
    "cw_lm=ols('value ~ type + condition + type:condition', data=df_long2).fit() #Specify C for Categorical\n",
    "print(sm.stats.anova_lm(cw_lm, typ=2))\n",
    "# post hoc test \n",
    "tukey = pairwise_tukeyhsd(endog=df_long2['value'], groups=df_long2['type']+df_long2['condition'], alpha=0.05)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaab88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gazenum_foreachgroup_male_df = pd.DataFrame.from_dict(gazenum_foreachgroup_male,orient='index')\n",
    "gazenum_foreachgroup_male_df = gazenum_foreachgroup_male_df.transpose()\n",
    "gazenum_foreachgroup_male_df['type'] = 'social gaze'\n",
    "gazenum_foreachgroup_male_df['sex'] = 'male'\n",
    "\n",
    "gazenum_foreachgroup_female_df = pd.DataFrame.from_dict(gazenum_foreachgroup_female,orient='index')\n",
    "gazenum_foreachgroup_female_df = gazenum_foreachgroup_female_df.transpose()\n",
    "gazenum_foreachgroup_female_df['type'] = 'social gaze'\n",
    "gazenum_foreachgroup_female_df['sex'] = 'female'\n",
    "\n",
    "gazeothernum_foreachgroup_male_df = pd.DataFrame.from_dict(gazeothernum_foreachgroup_male,orient='index')\n",
    "gazeothernum_foreachgroup_male_df = gazeothernum_foreachgroup_male_df.transpose()\n",
    "gazeothernum_foreachgroup_male_df['type'] = 'other lever gaze'\n",
    "gazeothernum_foreachgroup_male_df['sex'] = 'male'\n",
    "\n",
    "gazeothernum_foreachgroup_female_df = pd.DataFrame.from_dict(gazeothernum_foreachgroup_female,orient='index')\n",
    "gazeothernum_foreachgroup_female_df = gazeothernum_foreachgroup_female_df.transpose()\n",
    "gazeothernum_foreachgroup_female_df['type'] = 'other lever gaze'\n",
    "gazeothernum_foreachgroup_female_df['sex'] = 'female'\n",
    "\n",
    "#\n",
    "df_long=pd.concat([gazenum_foreachgroup_male_df,gazenum_foreachgroup_female_df,\n",
    "                   gazeothernum_foreachgroup_male_df,gazeothernum_foreachgroup_female_df])\n",
    "df_long2 = df_long.melt(id_vars=['type','sex'], value_vars=grouptypes,var_name='condition', value_name='value')\n",
    "df_long2 = df_long2[~np.isnan(df_long2['value'])]\n",
    "\n",
    "# perform the anova on male and female\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# anova\n",
    "cw_lm=ols('value ~ type + sex + condition', data=df_long2).fit() #Specify C for Categorical\n",
    "print(sm.stats.anova_lm(cw_lm, typ=2))\n",
    "# post hoc test \n",
    "tukey = pairwise_tukeyhsd(endog=df_long2['value'], groups=df_long2['type']+df_long2['sex']+df_long2['condition'], alpha=0.05)\n",
    "print(tukey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb46dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "gazenum_foreachgroup_all_df = pd.DataFrame.from_dict(gazenum_foreachgroup_all,orient='index')\n",
    "gazenum_foreachgroup_all_df = gazenum_foreachgroup_all_df.transpose()\n",
    "gazeothernum_foreachgroup_all_df = pd.DataFrame.from_dict(gazeothernum_foreachgroup_all,orient='index')\n",
    "gazeothernum_foreachgroup_all_df = gazeothernum_foreachgroup_all_df.transpose()\n",
    "socialtoleverratio_foreachgroup_all_df = gazeothernum_foreachgroup_all_df/gazenum_foreachgroup_all_df\n",
    "socialtoleverratio_foreachgroup_all_df['type'] = 'lever gaze to social gaze ratio'\n",
    "#\n",
    "df_long=pd.concat([socialtoleverratio_foreachgroup_all_df])\n",
    "df_long2 = df_long.melt(id_vars=['type'], value_vars=grouptypes,var_name='condition', value_name='value')\n",
    "#\n",
    "df_long2 = df_long2[~np.isnan(df_long2['value'])]\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "#\n",
    "# anova\n",
    "cw_lm=ols('value ~ condition', data=df_long2).fit() #Specify C for Categorical\n",
    "print(sm.stats.anova_lm(cw_lm, typ=2))\n",
    "# post hoc test \n",
    "tukey = pairwise_tukeyhsd(endog=df_long2['value'], groups=df_long2['condition'], alpha=0.05)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b93bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# male female\n",
    "#df_long=pd.concat([socialtoleverratio_foreachgroup_male_df,\n",
    "#                    socialtoleverratio_foreachgroup_female_df,\n",
    "#                   ])\n",
    "df_long=pd.concat([socialtoleverratio_foreachgroup_sub_df,\n",
    "                   socialtoleverratio_foreachgroup_dom_df,\n",
    "                   ])\n",
    "df_long2 = df_long.melt(id_vars=['type'], value_vars=grouptypes,var_name='condition', value_name='value')\n",
    "#\n",
    "df_long2 = df_long2[~np.isnan(df_long2['value'])]\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "#\n",
    "# anova\n",
    "cw_lm=ols('value ~ condition+type', data=df_long2).fit() #Specify C for Categorical\n",
    "print(sm.stats.anova_lm(cw_lm, typ=2))\n",
    "# post hoc test \n",
    "tukey = pairwise_tukeyhsd(endog=df_long2['value'], groups=df_long2['condition']+df_long2['type'], alpha=0.05)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = np.array(df_long[df_long['type']=='male lever gaze to social gaze ratio']['other autolever'])\n",
    "# data2 = np.array(df_long[df_long['type']=='female lever gaze to social gaze ratio']['other autolever'])\n",
    "data1 = np.array(df_long[df_long['type']=='sub lever gaze to social gaze ratio']['other autolever'])\n",
    "data2 = np.array(df_long[df_long['type']=='dom lever gaze to social gaze ratio']['other autolever'])\n",
    "data1=data1[~np.isnan(data1)]\n",
    "data2=data2[~np.isnan(data2)]\n",
    "\n",
    "st.mannwhitneyu(data1,data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28bf1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bbc07f",
   "metadata": {},
   "source": [
    "### similar plot as the previous one comparing gaze to other's lever vs face\n",
    "### compare the ratio of each conditions vs. MC (MC ratio as the baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f68ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal1_fixedorders = ['eddie','dodson','dannon','ginger']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga_1','kanga_2']\n",
    "# animal1_fixedorders = ['eddie','dodson','ginger']\n",
    "# animal2_fixedorders = ['sparkle','scorch','kanga_2']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "# grouptypes = ['self reward','1s threshold','animal1 autolever','animal2_autolever']\n",
    "grouptypes = ['self reward','1s threshold','self autolever','other autolever']\n",
    "coopthres_IDs = [0, 1, 3.5, 4]\n",
    "ngrouptypes = np.shape(grouptypes)[0]\n",
    "\n",
    "gazenum_gazeothernum_summary = pd.DataFrame(columns=['IDs','act_animal','conditions','gazenum','gazeothernum'])\n",
    "#\n",
    "malenames = ['eddie','dodson','dannon',]\n",
    "femalenames = ['sparkle','scorch','kanga_1','kanga_2','ginger',]\n",
    "#\n",
    "subnames = ['eddie','dodson','dannon','ginger',]\n",
    "domnames = ['sparkle','scorch','kanga_1','kanga_2',]\n",
    "\n",
    "#\n",
    "for igrouptype in np.arange(0,ngrouptypes,1):\n",
    "    \n",
    "    grouptype = grouptypes[igrouptype]\n",
    "    coopthres_ID = coopthres_IDs[igrouptype]\n",
    "    \n",
    "    \n",
    "    #\n",
    "    for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "        animal1 = animal1_fixedorders[ianimalpair]\n",
    "        animal2 = animal2_fixedorders[ianimalpair]\n",
    "        \n",
    "        if (animal2 == 'kanga_1') | (animal2 == 'kanga_2'):\n",
    "            animal2_filename = 'kanga'\n",
    "        else:\n",
    "            animal2_filename = animal2\n",
    "\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1+animal2_filename+'/'\n",
    "\n",
    "        with open(data_saved_subfolder+'/owgaze1_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            owgaze1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/owgaze2_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            owgaze2_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/mtgaze1_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            mtgaze1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/mtgaze2_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            mtgaze2_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/pull1_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            pull1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/pull2_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            pull2_num_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/gazelever1_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            gazelever1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/gazelever2_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            gazelever2_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/gazetube1_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            gazetube1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/gazetube2_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            gazetube2_num_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/gazeotherlever1_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            gazeotherlever1_num_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/gazeotherlever2_num_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            gazeotherlever2_num_all_dates = pickle.load(f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/session_recordtime_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            session_recordtime_all_dates = pickle.load(f)\n",
    "        \n",
    "        with open(data_saved_subfolder+'/tasktypes_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            tasktypes_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/coopthres_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            coopthres_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/succ_rate_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            succ_rate_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/interpullintv_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            interpullintv_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/trialnum_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            trialnum_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/bhv_intv_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            bhv_intv_all_dates = pickle.load(f)\n",
    "\n",
    "        # combine owgaze and mtgaze\n",
    "        gaze1_num_all_dates = (owgaze1_num_all_dates + mtgaze1_num_all_dates)/session_recordtime_all_dates\n",
    "        gaze2_num_all_dates = (owgaze2_num_all_dates + mtgaze2_num_all_dates)/session_recordtime_all_dates\n",
    "        #\n",
    "        gazeotherlever1_num_all_dates = gazeotherlever1_num_all_dates/session_recordtime_all_dates\n",
    "        gazeotherlever2_num_all_dates = gazeotherlever2_num_all_dates/session_recordtime_all_dates\n",
    "        \n",
    "        #\n",
    "        # 100: self; 3: 3s coop; 2: 2s coop; 1.5: 1.5s coop; 1: 1s coop; -1: no-vision\n",
    "        tasktypes_all_dates[tasktypes_all_dates==5] = -1 # change the task type code for no-vision\n",
    "        coopthres_forsort = (tasktypes_all_dates-1)*coopthres_all_dates/2\n",
    "        coopthres_forsort[coopthres_forsort==0] = 0 # get the cooperation threshold for sorting\n",
    "\n",
    "        if grouptype == 'self autolever':\n",
    "            # \n",
    "            gazenum_foreachgroup_foreachAni_animal1 = gaze1_num_all_dates[coopthres_forsort==3.5]\n",
    "            gazenum_foreachgroup_foreachAni_animal2 = gaze2_num_all_dates[coopthres_forsort==4]\n",
    "            #\n",
    "            gazeothernum_foreachgroup_foreachAni_animal1 = gazeotherlever1_num_all_dates[coopthres_forsort==3.5]\n",
    "            gazeothernum_foreachgroup_foreachAni_animal2 = gazeotherlever2_num_all_dates[coopthres_forsort==4]\n",
    "        #\n",
    "        elif grouptype == 'other autolever':\n",
    "            # \n",
    "            gazenum_foreachgroup_foreachAni_animal1 = gaze1_num_all_dates[coopthres_forsort==4]\n",
    "            gazenum_foreachgroup_foreachAni_animal2 = gaze2_num_all_dates[coopthres_forsort==3.5]\n",
    "            #\n",
    "            gazeothernum_foreachgroup_foreachAni_animal1 = gazeotherlever1_num_all_dates[coopthres_forsort==4]\n",
    "            gazeothernum_foreachgroup_foreachAni_animal2 = gazeotherlever2_num_all_dates[coopthres_forsort==3.5]\n",
    "        #\n",
    "        else:\n",
    "            # \n",
    "            gazenum_foreachgroup_foreachAni_animal1 = gaze1_num_all_dates[coopthres_forsort==coopthres_ID]\n",
    "            gazenum_foreachgroup_foreachAni_animal2 = gaze2_num_all_dates[coopthres_forsort==coopthres_ID]\n",
    "            #\n",
    "            gazeothernum_foreachgroup_foreachAni_animal1 = gazeotherlever1_num_all_dates[coopthres_forsort==coopthres_ID]\n",
    "            gazeothernum_foreachgroup_foreachAni_animal2 = gazeotherlever2_num_all_dates[coopthres_forsort==coopthres_ID]\n",
    "    \n",
    "        # put data in the combined pd\n",
    "        nentry_animal1 = np.shape(gazenum_foreachgroup_foreachAni_animal1)[0]\n",
    "        for ientry in np.arange(0,nentry_animal1,1):\n",
    "            gazenum_gazeothernum_summary = gazenum_gazeothernum_summary.append({'IDs':ientry,\n",
    "                                                                                'act_animal':animal1,\n",
    "                                                                                'conditions':grouptype,\n",
    "                                                                                'gazenum':gazenum_foreachgroup_foreachAni_animal1[ientry],\n",
    "                                                                                'gazeothernum':gazeothernum_foreachgroup_foreachAni_animal1[ientry],},\n",
    "                                                                                 ignore_index=True)\n",
    "        nentry_animal2 = np.shape(gazenum_foreachgroup_foreachAni_animal2)[0]\n",
    "        for ientry in np.arange(0,nentry_animal2,1):\n",
    "            gazenum_gazeothernum_summary = gazenum_gazeothernum_summary.append({'IDs':ientry,\n",
    "                                                                                'act_animal':animal2,\n",
    "                                                                                'conditions':grouptype,\n",
    "                                                                                'gazenum':gazenum_foreachgroup_foreachAni_animal2[ientry],\n",
    "                                                                                'gazeothernum':gazeothernum_foreachgroup_foreachAni_animal2[ientry],},\n",
    "                                                                                 ignore_index=True)\n",
    "    \n",
    "gazenum_gazeothernum_summary['sex'] = np.nan\n",
    "gazenum_gazeothernum_summary['hierarchy'] = np.nan\n",
    "\n",
    "gazenum_gazeothernum_summary['levertofaceratio'] = gazenum_gazeothernum_summary['gazeothernum']/gazenum_gazeothernum_summary['gazenum']\n",
    "   \n",
    "gazenum_gazeothernum_summary['ratio_vs_MC'] = np.nan\n",
    "    \n",
    "# box plot \n",
    "fig, axs = plt.subplots(4,1)\n",
    "fig.set_figheight(3*4)\n",
    "fig.set_figwidth(3*2)\n",
    "\n",
    "# subplot 1 - all animals\n",
    "seaborn.violinplot(ax=axs[0],data=gazenum_gazeothernum_summary,x='conditions',y='levertofaceratio')\n",
    "axs[0].set_ylabel(\"lever gaze to social gaze ratio\")\n",
    "axs[0].set_title('all animals')\n",
    "axs[0].set_ylim([-0.1,5])\n",
    "axs[0].legend(fontsize=18, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# subplot 2 - all animals, minus MC mean\n",
    "actanimals = np.unique(gazenum_gazeothernum_summary['act_animal'])\n",
    "for actanimal in actanimals:\n",
    "    ind = gazenum_gazeothernum_summary['act_animal'] == actanimal\n",
    "    gazenum_gazeothernum_ianimal = gazenum_gazeothernum_summary[ind].copy()\n",
    "    #\n",
    "    MCmean = np.nanmean(gazenum_gazeothernum_ianimal[gazenum_gazeothernum_ianimal['conditions']=='1s threshold']['levertofaceratio'])\n",
    "    #\n",
    "    gazenum_gazeothernum_summary.loc[ind,'ratio_vs_MC'] = gazenum_gazeothernum_ianimal['levertofaceratio']-MCmean\n",
    "#\n",
    "seaborn.violinplot(ax=axs[1],data=gazenum_gazeothernum_summary,x='conditions',y='ratio_vs_MC')\n",
    "axs[1].plot([-0.5,3.5],[0,0],'k--')\n",
    "axs[1].set_ylabel(\"ratio; compared with MC mean\")\n",
    "axs[1].set_title('all animals')\n",
    "axs[1].set_ylim([-3,3])\n",
    "axs[1].legend(fontsize=18, bbox_to_anchor=(1.05, 1), loc='upper left')    \n",
    "\n",
    "# subplot 3 - male female, minus MC mean\n",
    "actanimals = np.unique(gazenum_gazeothernum_summary['act_animal'])\n",
    "for actanimal in actanimals:\n",
    "    ind = gazenum_gazeothernum_summary['act_animal'] == actanimal\n",
    "    #\n",
    "    if np.isin(actanimal,malenames):\n",
    "        gazenum_gazeothernum_summary.loc[ind,'sex'] = 'male'\n",
    "    else:\n",
    "        gazenum_gazeothernum_summary.loc[ind,'sex'] = 'female'\n",
    "#\n",
    "seaborn.violinplot(ax=axs[2],data=gazenum_gazeothernum_summary,x='conditions',y='ratio_vs_MC',hue='sex')\n",
    "axs[2].plot([-0.5,3.5],[0,0],'k--')\n",
    "axs[2].set_ylabel(\"ratio; compared with MC mean\")\n",
    "axs[2].set_title('male female')\n",
    "axs[2].set_ylim([-3,3])\n",
    "axs[2].legend(fontsize=18, bbox_to_anchor=(1.05, 1), loc='upper left')  \n",
    "\n",
    "# subplot 4 - sub dom, minus MC mean\n",
    "actanimals = np.unique(gazenum_gazeothernum_summary['act_animal'])\n",
    "for actanimal in actanimals:\n",
    "    ind = gazenum_gazeothernum_summary['act_animal'] == actanimal\n",
    "    #\n",
    "    if np.isin(actanimal,subnames):\n",
    "        gazenum_gazeothernum_summary.loc[ind,'hierarchy'] = 'sub'\n",
    "    else:\n",
    "        gazenum_gazeothernum_summary.loc[ind,'hierarchy'] = 'dom'\n",
    "#\n",
    "seaborn.violinplot(ax=axs[3],data=gazenum_gazeothernum_summary,x='conditions',y='ratio_vs_MC',hue='hierarchy')\n",
    "axs[3].plot([-0.5,3.5],[0,0],'k--')\n",
    "axs[3].set_ylabel(\"ratio; compared with MC mean\")\n",
    "axs[3].set_title('sub dom')\n",
    "axs[3].set_ylim([-3,3])\n",
    "axs[3].legend(fontsize=18, bbox_to_anchor=(1.05, 1), loc='upper left')  \n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "        \n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_autolever/'+savefile_sufix+'/'+cameraID+'/autolever/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+'averaged_gazenumbers_andotherlevernumbers_comparedwithMC_acrossAllAnimals.pdf')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba06952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.wilcoxon(gazenum_gazeothernum_summary[gazenum_gazeothernum_summary['conditions']=='other autolever']['ratio_vs_MC'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f40f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1=(gazenum_gazeothernum_summary['conditions']=='other autolever')&(gazenum_gazeothernum_summary['sex']=='male')\n",
    "data1 = gazenum_gazeothernum_summary[ind1]['ratio_vs_MC']\n",
    "ind2=(gazenum_gazeothernum_summary['conditions']=='other autolever')&(gazenum_gazeothernum_summary['sex']=='female')\n",
    "data2 = gazenum_gazeothernum_summary[ind2]['ratio_vs_MC']\n",
    "\n",
    "st.mannwhitneyu(data1,data2)\n",
    "# st.ttest_ind(data1,data2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ff8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1=(gazenum_gazeothernum_summary['conditions']=='other autolever')&(gazenum_gazeothernum_summary['hierarchy']=='sub')\n",
    "data1 = gazenum_gazeothernum_summary[ind1]['ratio_vs_MC']\n",
    "ind2=(gazenum_gazeothernum_summary['conditions']=='other autolever')&(gazenum_gazeothernum_summary['hierarchy']=='dom')\n",
    "data2 = gazenum_gazeothernum_summary[ind2]['ratio_vs_MC']\n",
    "\n",
    "st.mannwhitneyu(data1,data2)\n",
    "# st.ttest_ind(data1,data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ebfe5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0b9191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91814277",
   "metadata": {},
   "source": [
    "#### plot the gaze distribution around pulls, analysis is based on the DBN_input_data all session format\n",
    "#### similar plot was in \"3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_allsessions_basicEvents\" looking at the difference between successful and failed pulls\n",
    "#### pool across all animals, compared self reward, 3s to 1s cooperation and no vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedc7acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "mergetempRos = 0 # 1: merge different time bins\n",
    "minmaxfullSampSize = 1 # 1: use the  min row number and max row number, or the full row for each session\n",
    "moreSampSize = 0 # 1: use more sample size (more than just minimal row number and max row number)\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','dannon','ginger',]\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga_1','kanga_2',]\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "temp_resolu = 1\n",
    "dist_twin_range = 5\n",
    "\n",
    "grouptypes = ['self reward','1s threshold','animal1 autolever','animal2 autolever']\n",
    "# grouptypes = ['self reward','1s threshold','self autolever','other autolever']\n",
    "coopthres_IDs = [0, 1, 3.5, 4]\n",
    "ngrouptypes = np.shape(grouptypes)[0]\n",
    "\n",
    "# initiate the final data set\n",
    "SameAnimal_gazeDist_mean_forEachAni = dict.fromkeys(grouptypes,[])\n",
    "AcroAnimal_gazeDist_mean_forEachAni = dict.fromkeys(grouptypes,[])\n",
    "# shuffle both the pull and gaze time stamp\n",
    "SameAnimal_gazeDist_shuffle_forEachAni = dict.fromkeys(grouptypes,[])\n",
    "AcroAnimal_gazeDist_shuffle_forEachAni = dict.fromkeys(grouptypes,[])\n",
    "#\n",
    "SameAnimal_gazeDist_mean_all = dict.fromkeys(grouptypes,[])\n",
    "AcroAnimal_gazeDist_mean_all = dict.fromkeys(grouptypes,[])\n",
    "# shuffle both the pull and gaze time stamp\n",
    "SameAnimal_gazeDist_shuffle_all = dict.fromkeys(grouptypes,[])\n",
    "AcroAnimal_gazeDist_shuffle_all = dict.fromkeys(grouptypes,[])\n",
    "#\n",
    "malenames = ['eddie','dodson','dannon',]\n",
    "femalenames = ['sparkle','scorch','kanga_1','kanga_2','ginger',]\n",
    "SameAnimal_gazeDist_mean_male = dict.fromkeys(grouptypes,[])\n",
    "AcroAnimal_gazeDist_mean_male = dict.fromkeys(grouptypes,[])\n",
    "SameAnimal_gazeDist_mean_female = dict.fromkeys(grouptypes,[])\n",
    "AcroAnimal_gazeDist_mean_female = dict.fromkeys(grouptypes,[])\n",
    "#\n",
    "subnames = ['eddie','dodson','dannon','ginger']\n",
    "domnames = ['sparkle','scorch','kanga_1','kanga_2']\n",
    "SameAnimal_gazeDist_mean_sub = dict.fromkeys(grouptypes,[])\n",
    "AcroAnimal_gazeDist_mean_sub = dict.fromkeys(grouptypes,[])\n",
    "SameAnimal_gazeDist_mean_dom = dict.fromkeys(grouptypes,[])\n",
    "AcroAnimal_gazeDist_mean_dom = dict.fromkeys(grouptypes,[])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "for igrouptype in np.arange(0,ngrouptypes,1):\n",
    "    \n",
    "    grouptype = grouptypes[igrouptype]\n",
    "    coopthres_ID = coopthres_IDs[igrouptype]\n",
    "    \n",
    "    SameAnimal_gazeDist_mean_forEachAni[grouptype] = dict.fromkeys(animal1_fixedorders+animal2_fixedorders,[])\n",
    "    AcroAnimal_gazeDist_mean_forEachAni[grouptype] = dict.fromkeys(animal1_fixedorders+animal2_fixedorders,[])\n",
    "    SameAnimal_gazeDist_shuffle_forEachAni[grouptype] = dict.fromkeys(animal1_fixedorders+animal2_fixedorders,[])\n",
    "    AcroAnimal_gazeDist_shuffle_forEachAni[grouptype] = dict.fromkeys(animal1_fixedorders+animal2_fixedorders,[])   \n",
    "    \n",
    "    for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "        animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "        animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "\n",
    "        if (animal2_fixedorder == 'kanga_1') | (animal2_fixedorder == 'kanga_2'):\n",
    "            animal2_filename = 'kanga'\n",
    "        else:\n",
    "            animal2_filename = animal2_fixedorder\n",
    "            \n",
    "        # load the basic behavioral measures\n",
    "        # load saved data\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder+animal2_filename+'/'\n",
    "        #\n",
    "        with open(data_saved_subfolder+'/tasktypes_all_dates_'+animal1_fixedorder+animal2_filename+'.pkl', 'rb') as f:\n",
    "            tasktypes_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/coopthres_all_dates_'+animal1_fixedorder+animal2_filename+'.pkl', 'rb') as f:\n",
    "            coopthres_all_dates = pickle.load(f)\n",
    "\n",
    "        #     \n",
    "        # load the DBN related analysis\n",
    "        # load data\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_allsessions'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_filename+'/'\n",
    "        #\n",
    "        if not mergetempRos:\n",
    "            with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder+animal2_filename+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "                DBN_input_data_alltypes = pickle.load(f)\n",
    "        else:\n",
    "            with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder+animal2_filename+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "                DBN_input_data_alltypes = pickle.load(f)\n",
    "\n",
    "        #\n",
    "        # re-organize the target dates\n",
    "        # 100: self; 3: 3s coop; 2: 2s coop; 1.5: 1.5s coop; 1: 1s coop; -1: no-vision\n",
    "        tasktypes_all_dates[tasktypes_all_dates==5] = -1 # change the task type code for no-vision\n",
    "        coopthres_forsort = (tasktypes_all_dates-1)*coopthres_all_dates/2\n",
    "        coopthres_forsort[coopthres_forsort==0] = 0 # get the cooperation threshold for sorting\n",
    "\n",
    "\n",
    "        #\n",
    "        # sort the data based on task type and dates\n",
    "        dates_list = list(DBN_input_data_alltypes.keys())\n",
    "        sorting_df = pd.DataFrame({'dates': dates_list, 'coopthres': coopthres_forsort.ravel()}, columns=['dates', 'coopthres'])\n",
    "        sorting_df = sorting_df.sort_values(by=['coopthres','dates'], ascending = [False, True])\n",
    "        #\n",
    "        # only select the targeted dates\n",
    "        sorting_tgt_df = sorting_df[(sorting_df['coopthres']==coopthres_ID)]\n",
    "        dates_list_tgt = sorting_tgt_df['dates']\n",
    "        dates_list_tgt = np.array(dates_list_tgt)\n",
    "        #\n",
    "        ndates_tgt = np.shape(dates_list_tgt)[0]\n",
    "\n",
    "        #\n",
    "        # initiate the final data set\n",
    "        SameAnimal_gazeDist_mean_forEachAni[grouptype][animal1_fixedorder] = dict.fromkeys(dates_list_tgt,[])\n",
    "        SameAnimal_gazeDist_mean_forEachAni[grouptype][animal2_fixedorder] = dict.fromkeys(dates_list_tgt,[])\n",
    "        AcroAnimal_gazeDist_mean_forEachAni[grouptype][animal1_fixedorder] = dict.fromkeys(dates_list_tgt,[])\n",
    "        AcroAnimal_gazeDist_mean_forEachAni[grouptype][animal2_fixedorder] = dict.fromkeys(dates_list_tgt,[])\n",
    "        #\n",
    "        SameAnimal_gazeDist_shuffle_forEachAni[grouptype][animal1_fixedorder] = dict.fromkeys(dates_list_tgt,[])\n",
    "        SameAnimal_gazeDist_shuffle_forEachAni[grouptype][animal2_fixedorder] = dict.fromkeys(dates_list_tgt,[])\n",
    "        AcroAnimal_gazeDist_shuffle_forEachAni[grouptype][animal1_fixedorder] = dict.fromkeys(dates_list_tgt,[])\n",
    "        AcroAnimal_gazeDist_shuffle_forEachAni[grouptype][animal2_fixedorder] = dict.fromkeys(dates_list_tgt,[])\n",
    "\n",
    "        # \n",
    "        for idate in np.arange(0,ndates_tgt,1):\n",
    "            idate_name = dates_list_tgt[idate]\n",
    "\n",
    "            DBN_input_data_idate = DBN_input_data_alltypes[idate_name]\n",
    "            \n",
    "            # pull1_t0 and gaze1_t0\n",
    "            xxx1 = (np.array(DBN_input_data_idate['pull1_t0'])==1)*1\n",
    "            xxx2 = (np.array(DBN_input_data_idate['lvgaze1_t0'])==1)*1\n",
    "            # xxx2 = (np.array(DBN_input_data_idate['owgaze1_t0'])==1)*1\n",
    "            xxx1_shuffle = xxx1.copy()\n",
    "            np.random.shuffle(xxx1_shuffle)\n",
    "            xxx2_shuffle = xxx2.copy()\n",
    "            np.random.shuffle(xxx2_shuffle)\n",
    "            # pad the two sides\n",
    "            xxx1 = np.hstack([np.zeros((1,dist_twin_range))[0],xxx1,np.zeros((1,dist_twin_range))[0]])\n",
    "            xxx2 = np.hstack([np.zeros((1,dist_twin_range))[0],xxx2,np.zeros((1,dist_twin_range))[0]])\n",
    "            xxx1_shuffle = np.hstack([np.zeros((1,dist_twin_range))[0],xxx1_shuffle,np.zeros((1,dist_twin_range))[0]])\n",
    "            xxx2_shuffle = np.hstack([np.zeros((1,dist_twin_range))[0],xxx2_shuffle,np.zeros((1,dist_twin_range))[0]])\n",
    "            # \n",
    "            npulls = int(np.nansum(xxx1))\n",
    "            pullIDs = np.where(xxx1 == 1)[0]\n",
    "            gazenum_dist_temp = np.zeros((npulls,2*dist_twin_range+1))\n",
    "            #\n",
    "            for ipull in np.arange(0,npulls,1):\n",
    "                pullID = pullIDs[ipull]\n",
    "                gazenum_dist_temp[ipull,:] = xxx2[np.arange(pullID-dist_twin_range,pullID+dist_twin_range+1,1)]\n",
    "            SameAnimal_gazeDist_mean_forEachAni[grouptype][animal1_fixedorder][idate_name]=np.nanmean(gazenum_dist_temp,axis=0)/(np.sum(xxx2)/np.sum(xxx1))\n",
    "            # SameAnimal_gazeDist_mean_forEachAni[grouptype][animal1_fixedorder][idate_name]=np.nansum(gazenum_dist_temp,axis=0)# /(np.sum(xxx2))\n",
    "            if npulls == 0:\n",
    "                SameAnimal_gazeDist_mean_forEachAni[grouptype][animal1_fixedorder][idate_name]=np.ones((1,2*dist_twin_range+1))[0]*np.nan        \n",
    "            # shuffle\n",
    "            npulls = int(np.nansum(xxx1_shuffle))\n",
    "            pullIDs = np.where(xxx1_shuffle == 1)[0]\n",
    "            gazenum_dist_temp = np.zeros((npulls,2*dist_twin_range+1))\n",
    "            #\n",
    "            for ipull in np.arange(0,npulls,1):\n",
    "                pullID = pullIDs[ipull]\n",
    "                gazenum_dist_temp[ipull,:] = xxx2_shuffle[np.arange(pullID-dist_twin_range,pullID+dist_twin_range+1,1)]\n",
    "            SameAnimal_gazeDist_shuffle_forEachAni[grouptype][animal1_fixedorder][idate_name]=np.nanmean(gazenum_dist_temp,axis=0)/(np.sum(xxx2)/np.sum(xxx1))\n",
    "            # SameAnimal_gazeDist_shuffle_forEachAni[grouptype][animal1_fixedorder][idate_name]=np.nansum(gazenum_dist_temp,axis=0)# /(np.sum(xxx2))           \n",
    "            if npulls == 0:\n",
    "                SameAnimal_gazeDist_shuffle_forEachAni[grouptype][animal1_fixedorder][idate_name]=np.ones((1,2*dist_twin_range+1))[0]*np.nan        \n",
    "                \n",
    "            # pull2_t0 and gaze2_t0\n",
    "            xxx1 = (np.array(DBN_input_data_idate['pull2_t0'])==1)*1\n",
    "            xxx2 = (np.array(DBN_input_data_idate['lvgaze2_t0'])==1)*1\n",
    "            # xxx2 = (np.array(DBN_input_data_idate['owgaze2_t0'])==1)*1\n",
    "            xxx1_shuffle = xxx1.copy()\n",
    "            np.random.shuffle(xxx1_shuffle)\n",
    "            xxx2_shuffle = xxx2.copy()\n",
    "            np.random.shuffle(xxx2_shuffle)\n",
    "            # pad the two sides\n",
    "            xxx1 = np.hstack([np.zeros((1,dist_twin_range))[0],xxx1,np.zeros((1,dist_twin_range))[0]])\n",
    "            xxx2 = np.hstack([np.zeros((1,dist_twin_range))[0],xxx2,np.zeros((1,dist_twin_range))[0]])\n",
    "            xxx1_shuffle = np.hstack([np.zeros((1,dist_twin_range))[0],xxx1_shuffle,np.zeros((1,dist_twin_range))[0]])\n",
    "            xxx2_shuffle = np.hstack([np.zeros((1,dist_twin_range))[0],xxx2_shuffle,np.zeros((1,dist_twin_range))[0]])\n",
    "            # \n",
    "            npulls = int(np.nansum(xxx1))\n",
    "            pullIDs = np.where(xxx1 == 1)[0]\n",
    "            gazenum_dist_temp = np.zeros((npulls,2*dist_twin_range+1))\n",
    "            #\n",
    "            for ipull in np.arange(0,npulls,1):\n",
    "                pullID = pullIDs[ipull]\n",
    "                gazenum_dist_temp[ipull,:] = xxx2[np.arange(pullID-dist_twin_range,pullID+dist_twin_range+1,1)]\n",
    "            SameAnimal_gazeDist_mean_forEachAni[grouptype][animal2_fixedorder][idate_name]=np.nanmean(gazenum_dist_temp,axis=0)/(np.sum(xxx2)/np.sum(xxx1))\n",
    "            # SameAnimal_gazeDist_mean_forEachAni[grouptype][animal2_fixedorder][idate_name]=np.nansum(gazenum_dist_temp,axis=0)# /(np.sum(xxx2))            \n",
    "            if npulls == 0:\n",
    "                SameAnimal_gazeDist_mean_forEachAni[grouptype][animal2_fixedorder][idate_name]=np.ones((1,2*dist_twin_range+1))[0]*np.nan \n",
    "            # shuffle\n",
    "            npulls = int(np.nansum(xxx1_shuffle))\n",
    "            pullIDs = np.where(xxx1_shuffle == 1)[0]\n",
    "            gazenum_dist_temp = np.zeros((npulls,2*dist_twin_range+1))\n",
    "            #\n",
    "            for ipull in np.arange(0,npulls,1):\n",
    "                pullID = pullIDs[ipull]\n",
    "                gazenum_dist_temp[ipull,:] = xxx2_shuffle[np.arange(pullID-dist_twin_range,pullID+dist_twin_range+1,1)]\n",
    "            SameAnimal_gazeDist_shuffle_forEachAni[grouptype][animal2_fixedorder][idate_name]=np.nanmean(gazenum_dist_temp,axis=0)/(np.sum(xxx2)/np.sum(xxx1))\n",
    "            # SameAnimal_gazeDist_shuffle_forEachAni[grouptype][animal2_fixedorder][idate_name]=np.nansum(gazenum_dist_temp,axis=0)# /(np.sum(xxx2))\n",
    "            if npulls == 0:\n",
    "                SameAnimal_gazeDist_shuffle_forEachAni[grouptype][animal2_fixedorder][idate_name]=np.ones((1,2*dist_twin_range+1))[0]*np.nan \n",
    "                \n",
    "            # pull1_t0 and gaze2_t0\n",
    "            xxx1 = (np.array(DBN_input_data_idate['pull1_t0'])==1)*1\n",
    "            xxx2 = (np.array(DBN_input_data_idate['lvgaze2_t0'])==1)*1\n",
    "            # xxx2 = (np.array(DBN_input_data_idate['owgaze2_t0'])==1)*1\n",
    "            xxx1_shuffle = xxx1.copy()\n",
    "            np.random.shuffle(xxx1_shuffle)\n",
    "            xxx2_shuffle = xxx2.copy()\n",
    "            np.random.shuffle(xxx2_shuffle)\n",
    "            # pad the two sides\n",
    "            xxx1 = np.hstack([np.zeros((1,dist_twin_range))[0],xxx1,np.zeros((1,dist_twin_range))[0]])\n",
    "            xxx2 = np.hstack([np.zeros((1,dist_twin_range))[0],xxx2,np.zeros((1,dist_twin_range))[0]])\n",
    "            xxx1_shuffle = np.hstack([np.zeros((1,dist_twin_range))[0],xxx1_shuffle,np.zeros((1,dist_twin_range))[0]])\n",
    "            xxx2_shuffle = np.hstack([np.zeros((1,dist_twin_range))[0],xxx2_shuffle,np.zeros((1,dist_twin_range))[0]])\n",
    "            # \n",
    "            npulls = int(np.nansum(xxx1))\n",
    "            pullIDs = np.where(xxx1 == 1)[0]\n",
    "            gazenum_dist_temp = np.zeros((npulls,2*dist_twin_range+1))\n",
    "            #\n",
    "            for ipull in np.arange(0,npulls,1):\n",
    "                pullID = pullIDs[ipull]\n",
    "                gazenum_dist_temp[ipull,:] = xxx2[np.arange(pullID-dist_twin_range,pullID+dist_twin_range+1,1)]\n",
    "            AcroAnimal_gazeDist_mean_forEachAni[grouptype][animal2_fixedorder][idate_name]=np.nanmean(gazenum_dist_temp,axis=0)/(np.sum(xxx2)/np.sum(xxx1))\n",
    "            # AcroAnimal_gazeDist_mean_forEachAni[grouptype][animal2_fixedorder][idate_name]=np.nansum(gazenum_dist_temp,axis=0)# /(np.sum(xxx2))\n",
    "            if npulls == 0:\n",
    "                AcroAnimal_gazeDist_mean_forEachAni[grouptype][animal2_fixedorder][idate_name]=np.ones((1,2*dist_twin_range+1))[0]*np.nan \n",
    "            # shuffle\n",
    "            npulls = int(np.nansum(xxx1_shuffle))\n",
    "            pullIDs = np.where(xxx1_shuffle == 1)[0]\n",
    "            gazenum_dist_temp = np.zeros((npulls,2*dist_twin_range+1))\n",
    "            #\n",
    "            for ipull in np.arange(0,npulls,1):\n",
    "                pullID = pullIDs[ipull]\n",
    "                gazenum_dist_temp[ipull,:] = xxx2_shuffle[np.arange(pullID-dist_twin_range,pullID+dist_twin_range+1,1)]\n",
    "            AcroAnimal_gazeDist_shuffle_forEachAni[grouptype][animal2_fixedorder][idate_name]=np.nanmean(gazenum_dist_temp,axis=0)/(np.sum(xxx2)/np.sum(xxx1))\n",
    "            # AcroAnimal_gazeDist_shuffle_forEachAni[grouptype][animal2_fixedorder][idate_name]=np.nansum(gazenum_dist_temp,axis=0)# /(np.sum(xxx2))\n",
    "            if npulls == 0:\n",
    "                AcroAnimal_gazeDist_shuffle_forEachAni[grouptype][animal2_fixedorder][idate_name]=np.ones((1,2*dist_twin_range+1))[0]*np.nan \n",
    "    \n",
    "            # pull2_t0 and gaze1_t0\n",
    "            xxx1 = (np.array(DBN_input_data_idate['pull2_t0'])==1)*1\n",
    "            xxx2 = (np.array(DBN_input_data_idate['lvgaze1_t0'])==1)*1\n",
    "            # xxx2 = (np.array(DBN_input_data_idate['owgaze1_t0'])==1)*1\n",
    "            xxx1_shuffle = xxx1.copy()\n",
    "            np.random.shuffle(xxx1_shuffle)\n",
    "            xxx2_shuffle = xxx2.copy()\n",
    "            np.random.shuffle(xxx2_shuffle)\n",
    "            # pad the two sides\n",
    "            xxx1 = np.hstack([np.zeros((1,dist_twin_range))[0],xxx1,np.zeros((1,dist_twin_range))[0]])\n",
    "            xxx2 = np.hstack([np.zeros((1,dist_twin_range))[0],xxx2,np.zeros((1,dist_twin_range))[0]])\n",
    "            xxx1_shuffle = np.hstack([np.zeros((1,dist_twin_range))[0],xxx1_shuffle,np.zeros((1,dist_twin_range))[0]])\n",
    "            xxx2_shuffle = np.hstack([np.zeros((1,dist_twin_range))[0],xxx2_shuffle,np.zeros((1,dist_twin_range))[0]])\n",
    "            # \n",
    "            npulls = int(np.nansum(xxx1))\n",
    "            pullIDs = np.where(xxx1 == 1)[0]\n",
    "            gazenum_dist_temp = np.zeros((npulls,2*dist_twin_range+1))\n",
    "            #\n",
    "            for ipull in np.arange(0,npulls,1):\n",
    "                pullID = pullIDs[ipull]\n",
    "                gazenum_dist_temp[ipull,:] = xxx2[np.arange(pullID-dist_twin_range,pullID+dist_twin_range+1,1)]\n",
    "            AcroAnimal_gazeDist_mean_forEachAni[grouptype][animal1_fixedorder][idate_name]=np.nanmean(gazenum_dist_temp,axis=0)/(np.sum(xxx2)/np.sum(xxx1))\n",
    "            # AcroAnimal_gazeDist_mean_forEachAni[grouptype][animal1_fixedorder][idate_name]=np.nansum(gazenum_dist_temp,axis=0)# /(np.sum(xxx2))\n",
    "            if npulls == 0:\n",
    "                AcroAnimal_gazeDist_mean_forEachAni[grouptype][animal1_fixedorder][idate_name]=np.ones((1,2*dist_twin_range+1))[0]*np.nan \n",
    "            # shuffle\n",
    "            npulls = int(np.nansum(xxx1_shuffle))\n",
    "            pullIDs = np.where(xxx1_shuffle == 1)[0]\n",
    "            gazenum_dist_temp = np.zeros((npulls,2*dist_twin_range+1))\n",
    "            #\n",
    "            for ipull in np.arange(0,npulls,1):\n",
    "                pullID = pullIDs[ipull]\n",
    "                gazenum_dist_temp[ipull,:] = xxx2_shuffle[np.arange(pullID-dist_twin_range,pullID+dist_twin_range+1,1)]\n",
    "            AcroAnimal_gazeDist_shuffle_forEachAni[grouptype][animal1_fixedorder][idate_name]=np.nanmean(gazenum_dist_temp,axis=0)/(np.sum(xxx2)/np.sum(xxx1))\n",
    "            # AcroAnimal_gazeDist_shuffle_forEachAni[grouptype][animal1_fixedorder][idate_name]=np.nansum(gazenum_dist_temp,axis=0)# /(np.sum(xxx2))\n",
    "            if npulls == 0:\n",
    "                AcroAnimal_gazeDist_shuffle_forEachAni[grouptype][animal1_fixedorder][idate_name]=np.ones((1,2*dist_twin_range+1))[0]*np.nan \n",
    "\n",
    "    \n",
    "    # combine across all animals\n",
    "    df = pd.DataFrame([SameAnimal_gazeDist_mean_forEachAni[grouptype][name] for name in animal1_fixedorders+animal2_fixedorders])\n",
    "    SameAnimal_gazeDist_mean_all[grouptype] = np.vstack(df.stack().values)\n",
    "    df = pd.DataFrame([AcroAnimal_gazeDist_mean_forEachAni[grouptype][name] for name in animal1_fixedorders+animal2_fixedorders])\n",
    "    AcroAnimal_gazeDist_mean_all[grouptype] = np.vstack(df.stack().values)\n",
    "    \n",
    "    # combine across al animals for shuffle\n",
    "    df = pd.DataFrame([SameAnimal_gazeDist_shuffle_forEachAni[grouptype][name] for name in animal1_fixedorders+animal2_fixedorders])\n",
    "    SameAnimal_gazeDist_shuffle_all[grouptype] = np.vstack(df.stack().values)\n",
    "    df = pd.DataFrame([AcroAnimal_gazeDist_shuffle_forEachAni[grouptype][name] for name in animal1_fixedorders+animal2_fixedorders])\n",
    "    AcroAnimal_gazeDist_shuffle_all[grouptype] = np.vstack(df.stack().values)\n",
    "    \n",
    "    # combine across male and female\n",
    "    df = pd.DataFrame([SameAnimal_gazeDist_mean_forEachAni[grouptype][name] for name in malenames])\n",
    "    SameAnimal_gazeDist_mean_male[grouptype] = np.vstack(df.stack().values)\n",
    "    df = pd.DataFrame([AcroAnimal_gazeDist_mean_forEachAni[grouptype][name] for name in malenames])\n",
    "    AcroAnimal_gazeDist_mean_male[grouptype] = np.vstack(df.stack().values)\n",
    "    df = pd.DataFrame([SameAnimal_gazeDist_mean_forEachAni[grouptype][name] for name in femalenames])\n",
    "    SameAnimal_gazeDist_mean_female[grouptype] = np.vstack(df.stack().values)\n",
    "    df = pd.DataFrame([AcroAnimal_gazeDist_mean_forEachAni[grouptype][name] for name in femalenames])\n",
    "    AcroAnimal_gazeDist_mean_female[grouptype] = np.vstack(df.stack().values)\n",
    "    \n",
    "    # combine across sub and dom\n",
    "    df = pd.DataFrame([SameAnimal_gazeDist_mean_forEachAni[grouptype][name] for name in subnames])\n",
    "    SameAnimal_gazeDist_mean_sub[grouptype] = np.vstack(df.stack().values)\n",
    "    df = pd.DataFrame([AcroAnimal_gazeDist_mean_forEachAni[grouptype][name] for name in subnames])\n",
    "    AcroAnimal_gazeDist_mean_sub[grouptype] = np.vstack(df.stack().values)\n",
    "    df = pd.DataFrame([SameAnimal_gazeDist_mean_forEachAni[grouptype][name] for name in domnames])\n",
    "    SameAnimal_gazeDist_mean_dom[grouptype] = np.vstack(df.stack().values)\n",
    "    df = pd.DataFrame([AcroAnimal_gazeDist_mean_forEachAni[grouptype][name] for name in domnames])\n",
    "    AcroAnimal_gazeDist_mean_dom[grouptype] = np.vstack(df.stack().values)\n",
    "\n",
    "    \n",
    "# add the self autolever and other autolever\n",
    "SameAnimal_gazeDist_mean_forEachAni['self autolever'] = {\n",
    "                     'eddie':SameAnimal_gazeDist_mean_forEachAni['animal1 autolever']['eddie'],\n",
    "                     'dodson':SameAnimal_gazeDist_mean_forEachAni['animal1 autolever']['dodson'],\n",
    "                     'dannon':SameAnimal_gazeDist_mean_forEachAni['animal1 autolever']['dannon'],\n",
    "                     'ginger':SameAnimal_gazeDist_mean_forEachAni['animal1 autolever']['ginger'],\n",
    "                     'sparkle':SameAnimal_gazeDist_mean_forEachAni['animal2 autolever']['sparkle'],\n",
    "                     'scorch':SameAnimal_gazeDist_mean_forEachAni['animal2 autolever']['scorch'],\n",
    "                     'kanga_1':SameAnimal_gazeDist_mean_forEachAni['animal2 autolever']['kanga_1'],\n",
    "                     'kanga_2':SameAnimal_gazeDist_mean_forEachAni['animal2 autolever']['kanga_2'],\n",
    "                    }\n",
    "df = pd.DataFrame([SameAnimal_gazeDist_mean_forEachAni['self autolever'][name] for name in animal1_fixedorders+animal2_fixedorders])\n",
    "SameAnimal_gazeDist_mean_all['self autolever'] = np.vstack(df.stack().values)\n",
    "#\n",
    "SameAnimal_gazeDist_mean_forEachAni['other autolever'] = {\n",
    "                     'eddie':SameAnimal_gazeDist_mean_forEachAni['animal2 autolever']['eddie'],\n",
    "                     'dodson':SameAnimal_gazeDist_mean_forEachAni['animal2 autolever']['dodson'],\n",
    "                     'dannon':SameAnimal_gazeDist_mean_forEachAni['animal2 autolever']['dannon'],\n",
    "                     'ginger':SameAnimal_gazeDist_mean_forEachAni['animal2 autolever']['ginger'],\n",
    "                     'sparkle':SameAnimal_gazeDist_mean_forEachAni['animal1 autolever']['sparkle'],\n",
    "                     'scorch':SameAnimal_gazeDist_mean_forEachAni['animal1 autolever']['scorch'],\n",
    "                     'kanga_1':SameAnimal_gazeDist_mean_forEachAni['animal1 autolever']['kanga_1'],\n",
    "                     'kanga_2':SameAnimal_gazeDist_mean_forEachAni['animal1 autolever']['kanga_2'],\n",
    "                    }\n",
    "df = pd.DataFrame([SameAnimal_gazeDist_mean_forEachAni['other autolever'][name] for name in animal1_fixedorders+animal2_fixedorders])\n",
    "SameAnimal_gazeDist_mean_all['other autolever'] = np.vstack(df.stack().values)\n",
    "#\n",
    "AcroAnimal_gazeDist_mean_forEachAni['self autolever'] = {\n",
    "                     'eddie':AcroAnimal_gazeDist_mean_forEachAni['animal1 autolever']['eddie'],\n",
    "                     'dodson':AcroAnimal_gazeDist_mean_forEachAni['animal1 autolever']['dodson'],\n",
    "                     'dannon':AcroAnimal_gazeDist_mean_forEachAni['animal1 autolever']['dannon'],\n",
    "                     'ginger':AcroAnimal_gazeDist_mean_forEachAni['animal1 autolever']['ginger'],\n",
    "                     'sparkle':AcroAnimal_gazeDist_mean_forEachAni['animal2 autolever']['sparkle'],\n",
    "                     'scorch':AcroAnimal_gazeDist_mean_forEachAni['animal2 autolever']['scorch'],\n",
    "                     'kanga_1':AcroAnimal_gazeDist_mean_forEachAni['animal2 autolever']['kanga_1'],\n",
    "                     'kanga_2':AcroAnimal_gazeDist_mean_forEachAni['animal2 autolever']['kanga_2'],\n",
    "                    }\n",
    "df = pd.DataFrame([AcroAnimal_gazeDist_mean_forEachAni['self autolever'][name] for name in animal1_fixedorders+animal2_fixedorders])\n",
    "AcroAnimal_gazeDist_mean_all['self autolever'] = np.vstack(df.stack().values)\n",
    "#\n",
    "AcroAnimal_gazeDist_mean_forEachAni['other autolever'] = {\n",
    "                     'eddie':AcroAnimal_gazeDist_mean_forEachAni['animal2 autolever']['eddie'],\n",
    "                     'dodson':AcroAnimal_gazeDist_mean_forEachAni['animal2 autolever']['dodson'],\n",
    "                     'dannon':AcroAnimal_gazeDist_mean_forEachAni['animal2 autolever']['dannon'],\n",
    "                     'ginger':AcroAnimal_gazeDist_mean_forEachAni['animal2 autolever']['ginger'],\n",
    "                     'sparkle':AcroAnimal_gazeDist_mean_forEachAni['animal1 autolever']['sparkle'],\n",
    "                     'scorch':AcroAnimal_gazeDist_mean_forEachAni['animal1 autolever']['scorch'],\n",
    "                     'kanga_1':AcroAnimal_gazeDist_mean_forEachAni['animal1 autolever']['kanga_1'],\n",
    "                     'kanga_2':AcroAnimal_gazeDist_mean_forEachAni['animal1 autolever']['kanga_2'],\n",
    "                    }\n",
    "df = pd.DataFrame([AcroAnimal_gazeDist_mean_forEachAni['other autolever'][name] for name in animal1_fixedorders+animal2_fixedorders])\n",
    "AcroAnimal_gazeDist_mean_all['other autolever'] = np.vstack(df.stack().values)\n",
    "#   \n",
    "SameAnimal_gazeDist_shuffle_forEachAni['self autolever'] = {\n",
    "                     'eddie':SameAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['eddie'],\n",
    "                     'dodson':SameAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['dodson'],\n",
    "                     'dannon':SameAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['dannon'],\n",
    "                     'ginger':SameAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['ginger'],\n",
    "                     'sparkle':SameAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['sparkle'],\n",
    "                     'scorch':SameAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['scorch'],\n",
    "                     'kanga_1':SameAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['kanga_1'],\n",
    "                     'kanga_2':SameAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['kanga_2'],\n",
    "                    }\n",
    "df = pd.DataFrame([SameAnimal_gazeDist_shuffle_forEachAni['self autolever'][name] for name in animal1_fixedorders+animal2_fixedorders])\n",
    "SameAnimal_gazeDist_shuffle_all['self autolever'] = np.vstack(df.stack().values)\n",
    "#\n",
    "SameAnimal_gazeDist_shuffle_forEachAni['other autolever'] = {\n",
    "                     'eddie':SameAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['eddie'],\n",
    "                     'dodson':SameAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['dodson'],\n",
    "                     'dannon':SameAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['dannon'],\n",
    "                     'ginger':SameAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['ginger'],\n",
    "                     'sparkle':SameAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['sparkle'],\n",
    "                     'scorch':SameAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['scorch'],\n",
    "                     'kanga_1':SameAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['kanga_1'],\n",
    "                     'kanga_2':SameAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['kanga_2'],\n",
    "                    }\n",
    "df = pd.DataFrame([SameAnimal_gazeDist_shuffle_forEachAni['other autolever'][name] for name in animal1_fixedorders+animal2_fixedorders])\n",
    "SameAnimal_gazeDist_shuffle_all['other autolever'] = np.vstack(df.stack().values)\n",
    "#\n",
    "AcroAnimal_gazeDist_shuffle_forEachAni['self autolever'] = {\n",
    "                     'eddie':AcroAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['eddie'],\n",
    "                     'dodson':AcroAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['dodson'],\n",
    "                     'dannon':AcroAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['dannon'],\n",
    "                     'ginger':AcroAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['ginger'],\n",
    "                     'sparkle':AcroAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['sparkle'],\n",
    "                     'scorch':AcroAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['scorch'],\n",
    "                     'kanga_1':AcroAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['kanga_1'],\n",
    "                     'kanga_2':AcroAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['kanga_2'],\n",
    "                    }\n",
    "df = pd.DataFrame([AcroAnimal_gazeDist_shuffle_forEachAni['self autolever'][name] for name in animal1_fixedorders+animal2_fixedorders])\n",
    "AcroAnimal_gazeDist_shuffle_all['self autolever'] = np.vstack(df.stack().values)\n",
    "#\n",
    "AcroAnimal_gazeDist_shuffle_forEachAni['other autolever'] = {\n",
    "                     'eddie':AcroAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['eddie'],\n",
    "                     'dodson':AcroAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['dodson'],\n",
    "                     'dannon':AcroAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['dannon'],\n",
    "                     'ginger':AcroAnimal_gazeDist_shuffle_forEachAni['animal2 autolever']['ginger'],\n",
    "                     'sparkle':AcroAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['sparkle'],\n",
    "                     'scorch':AcroAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['scorch'],\n",
    "                     'kanga_1':AcroAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['kanga_1'],\n",
    "                     'kanga_2':AcroAnimal_gazeDist_shuffle_forEachAni['animal1 autolever']['kanga_2'],\n",
    "                    }\n",
    "df = pd.DataFrame([AcroAnimal_gazeDist_shuffle_forEachAni['other autolever'][name] for name in animal1_fixedorders+animal2_fixedorders])\n",
    "AcroAnimal_gazeDist_shuffle_all['other autolever'] = np.vstack(df.stack().values)    \n",
    "    \n",
    "    \n",
    "#\n",
    "if 1:\n",
    "    \n",
    "    xxx = np.arange(-dist_twin_range,dist_twin_range+1,1)\n",
    "    \n",
    "    fig, axs = plt.subplots(3, 2)\n",
    "    fig.set_figheight(5*3)\n",
    "    fig.set_figwidth(7*2)   \n",
    "    \n",
    "    # plot the summarizing figure\n",
    "    # plot the within animal and across animal distribution\n",
    "    \n",
    "    for iplottype in np.arange(0,2,1):\n",
    "        # \n",
    "        # plot, all animals\n",
    "        # conds_forplot = ['self reward','1s threshold','animal1 autolever','animal2 autolever']\n",
    "        conds_forplot = ['self reward','1s threshold','self autolever','other autolever']\n",
    "        # conds_forplot = ['self reward','3s threshold','2s threshold','1.5s threshold','1s threshold','novision']\n",
    "        gazeDist_average_forplot = dict.fromkeys(conds_forplot,[])\n",
    "        gazeDist_std_forplot = dict.fromkeys(conds_forplot,[])\n",
    "        gazeDist_average_shf_forplot = dict.fromkeys(conds_forplot,[])\n",
    "        gazeDist_std_shf_forplot = dict.fromkeys(conds_forplot,[])\n",
    "        for cond_forplot in conds_forplot:\n",
    "            if iplottype == 0:\n",
    "                gazeDist_average_forplot[cond_forplot] = np.nanmean(SameAnimal_gazeDist_mean_all[cond_forplot],axis=0)\n",
    "                gazeDist_std_forplot[cond_forplot] = np.nanstd(SameAnimal_gazeDist_mean_all[cond_forplot],axis=0)/np.sqrt(np.shape(SameAnimal_gazeDist_mean_all[cond_forplot])[0])\n",
    "                #\n",
    "                gazeDist_average_shf_forplot[cond_forplot] = np.nanmean(SameAnimal_gazeDist_shuffle_all[cond_forplot],axis=0)\n",
    "                gazeDist_std_shf_forplot[cond_forplot] = np.nanstd(SameAnimal_gazeDist_shuffle_all[cond_forplot],axis=0)/np.sqrt(np.shape(SameAnimal_gazeDist_shuffle_all[cond_forplot])[0])\n",
    "            elif iplottype == 1:\n",
    "                gazeDist_average_forplot[cond_forplot] = np.nanmean(AcroAnimal_gazeDist_mean_all[cond_forplot],axis=0)\n",
    "                gazeDist_std_forplot[cond_forplot] = np.nanstd(AcroAnimal_gazeDist_mean_all[cond_forplot],axis=0)/np.sqrt(np.shape(AcroAnimal_gazeDist_mean_all[cond_forplot])[0])\n",
    "                #\n",
    "                gazeDist_average_shf_forplot[cond_forplot] = np.nanmean(AcroAnimal_gazeDist_shuffle_all[cond_forplot],axis=0)\n",
    "                gazeDist_std_shf_forplot[cond_forplot] = np.nanstd(AcroAnimal_gazeDist_shuffle_all[cond_forplot],axis=0)/np.sqrt(np.shape(AcroAnimal_gazeDist_shuffle_all[cond_forplot])[0])\n",
    "            #\n",
    "            axs[0,iplottype].errorbar(xxx,gazeDist_average_forplot[cond_forplot],\n",
    "                            gazeDist_std_forplot[cond_forplot],label=cond_forplot)\n",
    "            # axs[0,iplottype].errorbar(xxx,gazeDist_average_shf_forplot[cond_forplot],\n",
    "            #                 gazeDist_std_shf_forplot[cond_forplot],label=\"shuffled \"+cond_forplot)\n",
    "        axs[0,iplottype].plot([0,0],[0,1],'--',color='0.5')\n",
    "        axs[0,iplottype].set_xlim(-dist_twin_range-0.75,dist_twin_range+0.75)\n",
    "        axs[0,iplottype].set_ylim(0,0.3)\n",
    "        # axs[0,iplottype].set_xlabel('time (s)',fontsize=15)\n",
    "        axs[0,iplottype].set_ylabel('other lever gaze distribution',fontsize=15)\n",
    "        axs[0,iplottype].legend()   \n",
    "        if iplottype == 0:\n",
    "            axs[0,iplottype].set_title('within animal: all animals',fontsize=16)   \n",
    "        elif iplottype == 1:\n",
    "            axs[0,iplottype].set_title('across animal: all animals',fontsize=16)\n",
    "\n",
    "        # plot, male and female\n",
    "        conds_forplot = ['1s threshold']\n",
    "        gazeDist_average_male_forplot = dict.fromkeys(conds_forplot,[])\n",
    "        gazeDist_std_male_forplot = dict.fromkeys(conds_forplot,[])\n",
    "        gazeDist_average_female_forplot = dict.fromkeys(conds_forplot,[])\n",
    "        gazeDist_std_female_forplot = dict.fromkeys(conds_forplot,[])\n",
    "        for cond_forplot in conds_forplot:\n",
    "            if iplottype == 0:\n",
    "                gazeDist_average_male_forplot[cond_forplot] = np.nanmean(SameAnimal_gazeDist_mean_male[cond_forplot],axis=0)\n",
    "                gazeDist_std_male_forplot[cond_forplot] = np.nanstd(SameAnimal_gazeDist_mean_male[cond_forplot],axis=0)/np.sqrt(np.shape(SameAnimal_gazeDist_mean_male[cond_forplot])[0])\n",
    "                #\n",
    "                gazeDist_average_female_forplot[cond_forplot] = np.nanmean(SameAnimal_gazeDist_mean_female[cond_forplot],axis=0)\n",
    "                gazeDist_std_female_forplot[cond_forplot] = np.nanstd(SameAnimal_gazeDist_mean_female[cond_forplot],axis=0)/np.sqrt(np.shape(SameAnimal_gazeDist_mean_female[cond_forplot])[0])\n",
    "            elif iplottype == 1:\n",
    "                gazeDist_average_male_forplot[cond_forplot] = np.nanmean(AcroAnimal_gazeDist_mean_male[cond_forplot],axis=0)\n",
    "                gazeDist_std_male_forplot[cond_forplot] = np.nanstd(AcroAnimal_gazeDist_mean_male[cond_forplot],axis=0)/np.sqrt(np.shape(AcroAnimal_gazeDist_mean_male[cond_forplot])[0])\n",
    "                #\n",
    "                gazeDist_average_female_forplot[cond_forplot] = np.nanmean(AcroAnimal_gazeDist_mean_female[cond_forplot],axis=0)\n",
    "                gazeDist_std_female_forplot[cond_forplot] = np.nanstd(AcroAnimal_gazeDist_mean_female[cond_forplot],axis=0)/np.sqrt(np.shape(AcroAnimal_gazeDist_mean_female[cond_forplot])[0])\n",
    "            #\n",
    "            axs[1,iplottype].errorbar(xxx,gazeDist_average_male_forplot[cond_forplot],\n",
    "                            gazeDist_std_male_forplot[cond_forplot],label='male '+cond_forplot)\n",
    "            axs[1,iplottype].errorbar(xxx,gazeDist_average_female_forplot[cond_forplot],\n",
    "                            gazeDist_std_female_forplot[cond_forplot],label='female '+cond_forplot)\n",
    "        axs[1,iplottype].plot([0,0],[0,1],'--',color='0.5')\n",
    "        axs[1,iplottype].set_xlim(-dist_twin_range-0.75,dist_twin_range+0.75)\n",
    "        axs[1,iplottype].set_ylim(0,0.3)\n",
    "        # axs[1,iplottype].set_xlabel('time (s)',fontsize=15)\n",
    "        axs[1,iplottype].set_ylabel('other lever gaze distribution',fontsize=15)\n",
    "        axs[1,iplottype].legend()   \n",
    "        if iplottype == 0:\n",
    "            axs[1,iplottype].set_title('within animal: male and female',fontsize=16) \n",
    "        elif iplottype == 1:\n",
    "            axs[1,iplottype].set_title('across animal: male and female',fontsize=16) \n",
    "\n",
    "        # plot, sub and dom\n",
    "        conds_forplot = ['1s threshold']\n",
    "        gazeDist_average_dom_forplot = dict.fromkeys(conds_forplot,[])\n",
    "        gazeDist_std_dom_forplot = dict.fromkeys(conds_forplot,[])\n",
    "        gazeDist_average_sub_forplot = dict.fromkeys(conds_forplot,[])\n",
    "        gazeDist_std_sub_forplot = dict.fromkeys(conds_forplot,[])\n",
    "        for cond_forplot in conds_forplot:\n",
    "            if iplottype == 0:\n",
    "                gazeDist_average_sub_forplot[cond_forplot] = np.nanmean(SameAnimal_gazeDist_mean_sub[cond_forplot],axis=0)\n",
    "                gazeDist_std_sub_forplot[cond_forplot] = np.nanstd(SameAnimal_gazeDist_mean_sub[cond_forplot],axis=0)/np.sqrt(np.shape(SameAnimal_gazeDist_mean_sub[cond_forplot])[0]) \n",
    "                #\n",
    "                gazeDist_average_dom_forplot[cond_forplot] = np.nanmean(SameAnimal_gazeDist_mean_dom[cond_forplot],axis=0)\n",
    "                gazeDist_std_dom_forplot[cond_forplot] = np.nanstd(SameAnimal_gazeDist_mean_dom[cond_forplot],axis=0)/np.sqrt(np.shape(SameAnimal_gazeDist_mean_dom[cond_forplot])[0])\n",
    "            elif iplottype == 1:\n",
    "                gazeDist_average_sub_forplot[cond_forplot] = np.nanmean(AcroAnimal_gazeDist_mean_sub[cond_forplot],axis=0)\n",
    "                gazeDist_std_sub_forplot[cond_forplot] = np.nanstd(AcroAnimal_gazeDist_mean_sub[cond_forplot],axis=0)/np.sqrt(np.shape(AcroAnimal_gazeDist_mean_sub[cond_forplot])[0]) \n",
    "                #\n",
    "                gazeDist_average_dom_forplot[cond_forplot] = np.nanmean(AcroAnimal_gazeDist_mean_dom[cond_forplot],axis=0)\n",
    "                gazeDist_std_dom_forplot[cond_forplot] = np.nanstd(AcroAnimal_gazeDist_mean_dom[cond_forplot],axis=0)/np.sqrt(np.shape(AcroAnimal_gazeDist_mean_dom[cond_forplot])[0])\n",
    "            #\n",
    "            axs[2,iplottype].errorbar(xxx,gazeDist_average_sub_forplot[cond_forplot],\n",
    "                            gazeDist_std_sub_forplot[cond_forplot],label='sub '+cond_forplot)\n",
    "            axs[2,iplottype].errorbar(xxx,gazeDist_average_dom_forplot[cond_forplot],\n",
    "                            gazeDist_std_dom_forplot[cond_forplot],label='dom '+cond_forplot)\n",
    "        axs[2,iplottype].plot([0,0],[0,1],'--',color='0.5')\n",
    "        axs[2,iplottype].set_xlim(-dist_twin_range-0.75,dist_twin_range+0.75)\n",
    "        axs[2,iplottype].set_ylim(0,0.3)\n",
    "        axs[2,iplottype].set_xlabel('time (s)',fontsize=15)\n",
    "        axs[2,iplottype].set_ylabel('other lever gaze distribution',fontsize=15)\n",
    "        axs[2,iplottype].legend()   \n",
    "        if iplottype == 0:\n",
    "            axs[2,iplottype].set_title('within animal: subordinate and dominant',fontsize=16) \n",
    "        elif iplottype == 1:\n",
    "            axs[2,iplottype].set_title('across animal: subordinate and dominant',fontsize=16) \n",
    "\n",
    "    savefigs = 1\n",
    "    if savefigs:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_autolever/'+savefile_sufix+'/'+cameraID+'/autolever/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "\n",
    "        plt.savefig(figsavefolder+\"socialgaze_distribution_summaryplot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b6925",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8524df",
   "metadata": {},
   "outputs": [],
   "source": [
    "coopthres_forsort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c38f8d7",
   "metadata": {},
   "source": [
    "#### get the half (max - min) width for selected conditions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a203f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import splrep, sproot, splev\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.optimize import curve_fit \n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "class MultiplePeaks(Exception): pass\n",
    "class NoPeaksFound(Exception): pass\n",
    "\n",
    "def fwhm(x, y, k=10):\n",
    "    \"\"\"\n",
    "    Determine full-with-half-maximum of a peaked set of points, x and y.\n",
    "\n",
    "    Assumes that there is only one peak present in the datasset.  The function\n",
    "    uses a spline interpolation of order k.\n",
    "    \"\"\"\n",
    "    \n",
    "    maxtimepoint = x[y==np.nanmax(y)][0]\n",
    "    \n",
    "    half_max = max(y)/2.0\n",
    "    # half_max = y[round(np.shape(y)[0]/2)-1]\n",
    "    s = splrep(x, y - half_max, k=k)\n",
    "    roots = sproot(s)\n",
    "\n",
    "    if len(roots) > 2:\n",
    "    #     raise MultiplePeaks(\"The dataset appears to have multiple peaks, and \"\n",
    "    #             \"thus the FWHM can't be determined.\")\n",
    "        # return np.nan\n",
    "        return abs(roots[1] - roots[0]), maxtimepoint\n",
    "    elif len(roots) < 2:\n",
    "    #     raise NoPeaksFound(\"No proper peaks were found in the data set; likely \"\n",
    "    #             \"the dataset is flat (e.g. all zeros).\")\n",
    "        # return np.max(x)-np.min(x)\n",
    "        return np.nan, np.nan\n",
    "    else:\n",
    "        return abs(roots[1] - roots[0]), maxtimepoint\n",
    "        \n",
    "        \n",
    "#\n",
    "# Define the Gaussian function \n",
    "def Gauss(x, A, B): \n",
    "    y = A*np.exp(-1*B*x**2) \n",
    "    return y \n",
    "\n",
    "# Define the Gaussian function\n",
    "def gaussian(x, A, B, C):\n",
    "    y = A*np.exp(-1*B*(x-C)**2) \n",
    "    return y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f808828",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  np.arange(-dist_twin_range,dist_twin_range+1,1)\n",
    "\n",
    "# conditions = list(AcroAnimal_gazeDist_mean_all.keys())\n",
    "conditions = ['self reward','1s threshold','self autolever','other autolever']\n",
    "nconds = np.shape(conditions)[0]\n",
    "\n",
    "halfwidth_all = dict.fromkeys(conditions)\n",
    "maxtimepoint_all = dict.fromkeys(conditions)\n",
    "\n",
    "for icond in np.arange(0,nconds,1):\n",
    "\n",
    "    condname = conditions[icond]\n",
    "    \n",
    "    y_allsess = AcroAnimal_gazeDist_mean_all[condname]\n",
    "    nsess = np.shape(y_allsess)[0]\n",
    "    \n",
    "    halfwidth_all[condname] = np.ones((1,nsess))[0]*np.nan\n",
    "    maxtimepoint_all[condname] = np.ones((1,nsess))[0]*np.nan\n",
    "    \n",
    "    for isess in np.arange(0,nsess,1):\n",
    "    \n",
    "        try:\n",
    "            y =  y_allsess[isess]\n",
    "            y = (y-np.nanmin(y))/(np.nanmax(y)-np.nanmin(y))     \n",
    "            \n",
    "            # y = gaussian_filter1d(y, 4)\n",
    "\n",
    "            maxtimepoint_all[condname][isess] = x[y==np.nanmax(y)][0]\n",
    "            \n",
    "            parameters, covariance = curve_fit(Gauss, x, y) \n",
    "            # parameters, covariance = curve_fit(gaussian, x, y) \n",
    "            #\n",
    "            fit_A = parameters[0] \n",
    "            fit_B = parameters[1] \n",
    "            # fit_C = parameters[2] \n",
    "            #\n",
    "            fit_y = Gauss(x, fit_A, fit_B) \n",
    "            # fit_y = gaussian(x,fit_A,fit_B,fit_C)\n",
    "            y = (fit_y-np.nanmin(fit_y))/(np.nanmax(fit_y)-np.nanmin(fit_y)) \n",
    "            \n",
    "\n",
    "            halfwidth_all[condname][isess], _ = fwhm(x, y, k=3)\n",
    "            # halfwidth_all[condname][isess], maxtimepoint_all[condname][isess] = fwhm(x, y, k=3)\n",
    "            \n",
    "        except:\n",
    "            halfwidth_all[condname][isess] = np.nan\n",
    "            # maxtimepoint_all[condname][isess] = np.nan\n",
    "        \n",
    "# box plot \n",
    "fig, axs = plt.subplots(1,2)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(5*2)\n",
    "\n",
    "# subplot 1 - half max width - all animals\n",
    "halfwidth_all_df = pd.DataFrame.from_dict(halfwidth_all,orient='index')\n",
    "halfwidth_all_df = halfwidth_all_df.transpose()\n",
    "halfwidth_all_df['type'] = 'all'\n",
    "#\n",
    "df_long=pd.concat([halfwidth_all_df])\n",
    "df_long2 = df_long.melt(id_vars=['type'], value_vars=conditions,var_name='condition', value_name='value')\n",
    "# \n",
    "# barplot ans swarmplot\n",
    "seaborn.boxplot(ax=axs[0],data=df_long2,x='condition',y='value',hue='type')\n",
    "# seaborn.swarmplot(ax=axs[0],data=df_long2,x='condition',y='value',hue='type',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs[0].set_xlabel('')\n",
    "axs[0].set_xticklabels(conditions)\n",
    "axs[0].xaxis.set_tick_params(labelsize=15,rotation=45)\n",
    "axs[0].set_ylabel(\"half max width\",fontsize=15)\n",
    "axs[0].set_title('all animals' ,fontsize=24)\n",
    "axs[0].set_ylim([0,10])\n",
    "axs[0].legend(fontsize=18)\n",
    "\n",
    "\n",
    "# subplot 2 - max time point - all animals\n",
    "maxtimepoint_all_df = pd.DataFrame.from_dict(maxtimepoint_all,orient='index')\n",
    "maxtimepoint_all_df = maxtimepoint_all_df.transpose()\n",
    "maxtimepoint_all_df['type'] = 'all'\n",
    "#\n",
    "df_long=pd.concat([maxtimepoint_all_df])\n",
    "df_long2 = df_long.melt(id_vars=['type'], value_vars=conditions,var_name='condition', value_name='value')\n",
    "# \n",
    "# barplot ans swarmplot\n",
    "seaborn.boxplot(ax=axs[1],data=df_long2,x='condition',y='value',hue='type')\n",
    "# seaborn.swarmplot(ax=axs[1],data=df_long2,x='condition',y='value',hue='type',\n",
    "#                   alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs[1].set_xlabel('')\n",
    "axs[1].set_xticklabels(conditions)\n",
    "axs[1].xaxis.set_tick_params(labelsize=15,rotation=45)\n",
    "axs[1].set_ylabel(\"max time point\",fontsize=15)\n",
    "axs[1].set_title('all animals' ,fontsize=24)\n",
    "axs[1].set_ylim([-4,4])\n",
    "axs[1].legend(fontsize=18)\n",
    "\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_autolever/'+savefile_sufix+'/'+cameraID+'/autolever/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "\n",
    "    plt.savefig(figsavefolder+\"socialgaze_distribution_summaryplot_halfmaxWitdh.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f722573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "halfwidth_all_df = pd.DataFrame.from_dict(halfwidth_all,orient='index')\n",
    "halfwidth_all_df = halfwidth_all_df.transpose()\n",
    "halfwidth_all_df['type'] = 'all'\n",
    "#\n",
    "df_long=pd.concat([halfwidth_all_df])\n",
    "df_long2 = df_long.melt(id_vars=['type'], value_vars=conditions,var_name='condition', value_name='value')\n",
    "df_long2 = df_long2[~np.isnan(df_long2['value'])]    \n",
    "#    \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "#\n",
    "# anova\n",
    "cw_lm=ols('value ~ condition', data=df_long2).fit() #Specify C for Categorical\n",
    "print(sm.stats.anova_lm(cw_lm, typ=2))\n",
    "# post hoc test \n",
    "tukey = pairwise_tukeyhsd(endog=df_long2['value'], groups=df_long2['condition'], alpha=0.05)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7825b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxtimepoint_all_df = pd.DataFrame.from_dict(maxtimepoint_all,orient='index')\n",
    "maxtimepoint_all_df = maxtimepoint_all_df.transpose()\n",
    "maxtimepoint_all_df['type'] = 'all'\n",
    "#\n",
    "df_long=pd.concat([maxtimepoint_all_df])\n",
    "df_long2 = df_long.melt(id_vars=['type'], value_vars=conditions,var_name='condition', value_name='value')\n",
    "df_long2 = df_long2[~np.isnan(df_long2['value'])]    \n",
    "#    \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "#\n",
    "# anova\n",
    "cw_lm=ols('value ~ condition', data=df_long2).fit() #Specify C for Categorical\n",
    "print(sm.stats.anova_lm(cw_lm, typ=2))\n",
    "# post hoc test \n",
    "tukey = pairwise_tukeyhsd(endog=df_long2['value'], groups=df_long2['condition'], alpha=0.05)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27762b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b75672b",
   "metadata": {},
   "source": [
    "####  plot the gaze distribution along the continuous variables - pool across animals  and sesisons\n",
    "#### only focus on \"otherani_otherlever_dist\", plot the ratio of number of 'decrasing' phase vs 'increasing' phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b357703",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal1_fixedorders = ['eddie','dodson','dannon','ginger',]\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga_1','kanga_2',]\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "type_tgt = 'otherani_otherlever_dist'\n",
    "# type_tgt = 'animal_lever_dist'\n",
    "# type_tgt = 'animal_animal_dist'\n",
    "\n",
    "# grouptypes = ['self reward','1s threshold','animal1 autolever','animal2_autolever']\n",
    "grouptypes = ['self reward','1s threshold','self autolever','other autolever']\n",
    "coopthres_IDs = [0, 1, 3.5, 4]\n",
    "ngrouptypes = np.shape(grouptypes)[0]\n",
    "\n",
    "gazeDist_foreachgroup_foreachAni = dict.fromkeys(grouptypes,[])\n",
    "gazeDist_foreachgroup_all = dict.fromkeys(grouptypes,[])\n",
    "\n",
    "malenames = ['eddie','dodson','dannon',]\n",
    "femalenames = ['sparkle','scorch','kanga_1','kanga_2','ginger',]\n",
    "gazeDist_foreachgroup_male = dict.fromkeys(grouptypes,[])\n",
    "gazeDist_foreachgroup_female = dict.fromkeys(grouptypes,[])\n",
    "\n",
    "subnames = ['eddie','dodson','dannon','ginger',]\n",
    "domnames = ['sparkle','scorch','kanga_1','kanga_2',]\n",
    "gazeDist_foreachgroup_sub = dict.fromkeys(grouptypes,[])\n",
    "gazeDist_foreachgroup_dom = dict.fromkeys(grouptypes,[])\n",
    "\n",
    "#\n",
    "for igrouptype in np.arange(0,ngrouptypes,1):\n",
    "    \n",
    "    grouptype = grouptypes[igrouptype]\n",
    "    coopthres_ID = coopthres_IDs[igrouptype]\n",
    "    \n",
    "    gazeDist_foreachgroup_foreachAni[grouptype] = dict.fromkeys(animal1_fixedorders+animal2_fixedorders,[])\n",
    "    \n",
    "    #\n",
    "    for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "        animal1 = animal1_fixedorders[ianimalpair]\n",
    "        animal2 = animal2_fixedorders[ianimalpair]\n",
    "        \n",
    "        if (animal2 == 'kanga_1') | (animal2 == 'kanga_2'):\n",
    "            animal2_filename = 'kanga'\n",
    "        else:\n",
    "            animal2_filename = animal2\n",
    "\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1+animal2_filename+'/'\n",
    "        \n",
    "        with open(data_saved_subfolder+'/tasktypes_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            tasktypes_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/coopthres_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            coopthres_all_dates = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/gazeDist_phaseof_contbhvvar_all_dates_'+animal1+animal2_filename+'.pkl', 'rb') as f:\n",
    "            gazeDist_phaseof_contbhvvar_all_dates = pickle.load(f) \n",
    "            \n",
    "        #\n",
    "        # 100: self; 3: 3s coop; 2: 2s coop; 1.5: 1.5s coop; 1: 1s coop; -1: no-vision\n",
    "        tasktypes_all_dates[tasktypes_all_dates==5] = -1 # change the task type code for no-vision\n",
    "        coopthres_forsort = (tasktypes_all_dates-1)*coopthres_all_dates/2\n",
    "        coopthres_forsort[coopthres_forsort==0] = 0 # get the cooperation threshold for sorting\n",
    "        \n",
    "        # reorganize to separate the session into self autolever and other autolever\n",
    "        if grouptype == 'self autolever':\n",
    "             \n",
    "            # for animal 1\n",
    "            dates_all_dates = np.array(list(gazeDist_phaseof_contbhvvar_all_dates.keys()))\n",
    "            dates_igrouptype = dates_all_dates[coopthres_forsort.transpose()[0]==3.5]\n",
    "            ndates = np.shape(dates_igrouptype)[0]\n",
    "            #\n",
    "            gazeDist_ratios_animal1 = np.ones(np.shape(dates_igrouptype))*np.nan\n",
    "\n",
    "            for idate in np.arange(0,ndates,1):     \n",
    "                #\n",
    "                gazeDist_idate = gazeDist_phaseof_contbhvvar_all_dates[dates_igrouptype[idate]][animal1][type_tgt]\n",
    "                gateDist_ratio_idate = np.sum(gazeDist_idate['phase']=='decreasing')/np.sum(gazeDist_idate['phase']=='increasing')\n",
    "                gazeDist_ratios_animal1[idate] = gateDist_ratio_idate\n",
    "            # \n",
    "            gazeDist_foreachgroup_foreachAni[grouptype][animal1] = gazeDist_ratios_animal1\n",
    "\n",
    "            # for animal 2\n",
    "            dates_all_dates = np.array(list(gazeDist_phaseof_contbhvvar_all_dates.keys()))\n",
    "            dates_igrouptype = dates_all_dates[coopthres_forsort.transpose()[0]==4]\n",
    "            ndates = np.shape(dates_igrouptype)[0]\n",
    "            #\n",
    "            gazeDist_ratios_animal2 = np.ones(np.shape(dates_igrouptype))*np.nan\n",
    "\n",
    "            for idate in np.arange(0,ndates,1):     \n",
    "                #\n",
    "                gazeDist_idate = gazeDist_phaseof_contbhvvar_all_dates[dates_igrouptype[idate]][animal2_filename][type_tgt]\n",
    "                gateDist_ratio_idate = np.sum(gazeDist_idate['phase']=='decreasing')/np.sum(gazeDist_idate['phase']=='increasing')\n",
    "                gazeDist_ratios_animal2[idate] = gateDist_ratio_idate\n",
    "            # \n",
    "            gazeDist_foreachgroup_foreachAni[grouptype][animal2] = gazeDist_ratios_animal2\n",
    "        \n",
    "        elif grouptype == 'other autolever':\n",
    "            \n",
    "            # for animal 1\n",
    "            dates_all_dates = np.array(list(gazeDist_phaseof_contbhvvar_all_dates.keys()))\n",
    "            dates_igrouptype = dates_all_dates[coopthres_forsort.transpose()[0]==4]\n",
    "            ndates = np.shape(dates_igrouptype)[0]\n",
    "            #\n",
    "            gazeDist_ratios_animal1 = np.ones(np.shape(dates_igrouptype))*np.nan\n",
    "\n",
    "            for idate in np.arange(0,ndates,1):     \n",
    "                #\n",
    "                gazeDist_idate = gazeDist_phaseof_contbhvvar_all_dates[dates_igrouptype[idate]][animal1][type_tgt]\n",
    "                gateDist_ratio_idate = np.sum(gazeDist_idate['phase']=='decreasing')/np.sum(gazeDist_idate['phase']=='increasing')\n",
    "                gazeDist_ratios_animal1[idate] = gateDist_ratio_idate\n",
    "            # \n",
    "            gazeDist_foreachgroup_foreachAni[grouptype][animal1] = gazeDist_ratios_animal1\n",
    "\n",
    "            # for animal 2\n",
    "            dates_all_dates = np.array(list(gazeDist_phaseof_contbhvvar_all_dates.keys()))\n",
    "            dates_igrouptype = dates_all_dates[coopthres_forsort.transpose()[0]==3.5]\n",
    "            ndates = np.shape(dates_igrouptype)[0]\n",
    "            #\n",
    "            gazeDist_ratios_animal2 = np.ones(np.shape(dates_igrouptype))*np.nan\n",
    "\n",
    "            for idate in np.arange(0,ndates,1):     \n",
    "                #\n",
    "                gazeDist_idate = gazeDist_phaseof_contbhvvar_all_dates[dates_igrouptype[idate]][animal2_filename][type_tgt]\n",
    "                gateDist_ratio_idate = np.sum(gazeDist_idate['phase']=='decreasing')/np.sum(gazeDist_idate['phase']=='increasing')\n",
    "                gazeDist_ratios_animal2[idate] = gateDist_ratio_idate\n",
    "            # \n",
    "            gazeDist_foreachgroup_foreachAni[grouptype][animal2] = gazeDist_ratios_animal2\n",
    "            \n",
    "        else:\n",
    "            dates_all_dates = np.array(list(gazeDist_phaseof_contbhvvar_all_dates.keys()))\n",
    "            dates_igrouptype = dates_all_dates[coopthres_forsort.transpose()[0]==coopthres_ID]\n",
    "            ndates = np.shape(dates_igrouptype)[0]\n",
    "            #\n",
    "            gazeDist_ratios_animal1 = np.ones(np.shape(dates_igrouptype))*np.nan\n",
    "            gazeDist_ratios_animal2 = np.ones(np.shape(dates_igrouptype))*np.nan\n",
    "\n",
    "            for idate in np.arange(0,ndates,1):     \n",
    "                # \n",
    "                # for animal 1\n",
    "                gazeDist_idate = gazeDist_phaseof_contbhvvar_all_dates[dates_igrouptype[idate]][animal1][type_tgt]\n",
    "                gateDist_ratio_idate = np.sum(gazeDist_idate['phase']=='decreasing')/np.sum(gazeDist_idate['phase']=='increasing')\n",
    "                gazeDist_ratios_animal1[idate] = gateDist_ratio_idate\n",
    "                # for animal 2\n",
    "                gazeDist_idate = gazeDist_phaseof_contbhvvar_all_dates[dates_igrouptype[idate]][animal2_filename][type_tgt]\n",
    "                gateDist_ratio_idate = np.sum(gazeDist_idate['phase']=='decreasing')/np.sum(gazeDist_idate['phase']=='increasing')\n",
    "                gazeDist_ratios_animal2[idate] = gateDist_ratio_idate\n",
    "            # \n",
    "            gazeDist_foreachgroup_foreachAni[grouptype][animal1] = gazeDist_ratios_animal1\n",
    "            gazeDist_foreachgroup_foreachAni[grouptype][animal2] = gazeDist_ratios_animal2\n",
    "            \n",
    "            \n",
    "    # combine across all animals\n",
    "    gazeDist_foreachgroup_all[grouptype] = np.hstack(list(gazeDist_foreachgroup_foreachAni[grouptype].values()))\n",
    "    \n",
    "    # combine across male and female\n",
    "    df = pd.DataFrame.from_dict(gazeDist_foreachgroup_foreachAni[grouptype],orient='index')\n",
    "    df = df.transpose()[malenames]\n",
    "    gazeDist_foreachgroup_male[grouptype] = df.values.ravel()\n",
    "    #\n",
    "    df = pd.DataFrame.from_dict(gazeDist_foreachgroup_foreachAni[grouptype],orient='index')\n",
    "    df = df.transpose()[femalenames]\n",
    "    gazeDist_foreachgroup_female[grouptype] = df.values.ravel()\n",
    "    \n",
    "    # combine across sub and dom\n",
    "    df = pd.DataFrame.from_dict(gazeDist_foreachgroup_foreachAni[grouptype],orient='index')\n",
    "    df = df.transpose()[subnames]\n",
    "    gazeDist_foreachgroup_sub[grouptype] = df.values.ravel()\n",
    "    #\n",
    "    df = pd.DataFrame.from_dict(gazeDist_foreachgroup_foreachAni[grouptype],orient='index')\n",
    "    df = df.transpose()[domnames]\n",
    "    gazeDist_foreachgroup_dom[grouptype] = df.values.ravel()\n",
    "    \n",
    "    \n",
    "        \n",
    "# box plot \n",
    "fig, axs = plt.subplots(3,1)\n",
    "fig.set_figheight(5*3)\n",
    "fig.set_figwidth(3*2)\n",
    "\n",
    "# subplot 1 - all animals\n",
    "gazeDist_foreachgroup_all_df = pd.DataFrame.from_dict(gazeDist_foreachgroup_all,orient='index')\n",
    "gazeDist_foreachgroup_all_df = gazeDist_foreachgroup_all_df.transpose()\n",
    "gazeDist_foreachgroup_all_df['type'] = 'all'\n",
    "#\n",
    "df_long=pd.concat([gazeDist_foreachgroup_all_df])\n",
    "df_long2 = df_long.melt(id_vars=['type'], value_vars=grouptypes,var_name='condition', value_name='value')\n",
    "# \n",
    "# barplot ans swarmplot\n",
    "seaborn.boxplot(ax=axs[0],data=df_long2,x='condition',y='value',hue='type')\n",
    "# seaborn.swarmplot(ax=axs[0],data=df_long2,x='condition',y='value',hue='type',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs[0].plot([-0.5,3.5],[1,1],'k--')\n",
    "axs[0].set_xlabel('')\n",
    "axs[0].set_xticklabels('')\n",
    "axs[0].xaxis.set_tick_params(labelsize=15)\n",
    "axs[0].set_ylabel(\"ratio\",fontsize=15)\n",
    "axs[0].set_title(\"social gaze on the decreasing phase / inecreasing phase of \"+type_tgt)\n",
    "axs[0].set_ylim([-0.1,4.7])\n",
    "axs[0].legend(fontsize=18)\n",
    "\n",
    "# subplot 2 - male and female animals\n",
    "gazeDist_foreachgroup_male_df = pd.DataFrame.from_dict(gazeDist_foreachgroup_male,orient='index')\n",
    "gazeDist_foreachgroup_male_df = gazeDist_foreachgroup_male_df.transpose()\n",
    "gazeDist_foreachgroup_male_df['type'] = 'male'\n",
    "gazeDist_foreachgroup_female_df = pd.DataFrame.from_dict(gazeDist_foreachgroup_female,orient='index')\n",
    "gazeDist_foreachgroup_female_df = gazeDist_foreachgroup_female_df.transpose()\n",
    "gazeDist_foreachgroup_female_df['type'] = 'female'\n",
    "#\n",
    "df_long=pd.concat([gazeDist_foreachgroup_male_df,gazeDist_foreachgroup_female_df])\n",
    "df_long2 = df_long.melt(id_vars=['type'], value_vars=grouptypes,var_name='condition', value_name='value')\n",
    "# \n",
    "# barplot ans swarmplot\n",
    "seaborn.boxplot(ax=axs[1],data=df_long2,x='condition',y='value',hue='type')\n",
    "# seaborn.swarmplot(ax=axs[1],data=df_long2,x='condition',y='value',hue='type',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs[1].plot([-0.5,3.5],[1,1],'k--')\n",
    "axs[1].set_xlabel('')\n",
    "axs[1].set_xticklabels('')\n",
    "axs[1].xaxis.set_tick_params(labelsize=15)\n",
    "axs[1].set_ylabel(\"ratio\",fontsize=15)\n",
    "# axs[1].set_title('male and female' ,fontsize=24)\n",
    "axs[1].set_ylim([-0.1,4.7])\n",
    "axs[1].legend(fontsize=18)\n",
    "\n",
    "# subplot 3 - dom and sub animals\n",
    "gazeDist_foreachgroup_sub_df = pd.DataFrame.from_dict(gazeDist_foreachgroup_sub,orient='index')\n",
    "gazeDist_foreachgroup_sub_df = gazeDist_foreachgroup_sub_df.transpose()\n",
    "gazeDist_foreachgroup_sub_df['type'] = 'sub'\n",
    "gazeDist_foreachgroup_dom_df = pd.DataFrame.from_dict(gazeDist_foreachgroup_dom,orient='index')\n",
    "gazeDist_foreachgroup_dom_df = gazeDist_foreachgroup_dom_df.transpose()\n",
    "gazeDist_foreachgroup_dom_df['type'] = 'dom'\n",
    "#\n",
    "df_long=pd.concat([gazeDist_foreachgroup_sub_df,gazeDist_foreachgroup_dom_df])\n",
    "df_long2 = df_long.melt(id_vars=['type'], value_vars=grouptypes,var_name='condition', value_name='value')\n",
    "# \n",
    "# barplot ans swarmplot\n",
    "seaborn.boxplot(ax=axs[2],data=df_long2,x='condition',y='value',hue='type')\n",
    "# seaborn.swarmplot(ax=axs[2],data=df_long2,x='condition',y='value',hue='type',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs[2].plot([-0.5,3.5],[1,1],'k--')\n",
    "axs[2].set_xlabel('')\n",
    "axs[2].set_xticklabels(axs[2].get_xticklabels(),rotation=45)\n",
    "axs[2].xaxis.set_tick_params(labelsize=15)\n",
    "axs[2].set_ylabel(\"ratio\",fontsize=15)\n",
    "# axs[2].set_title('sub and dom' ,fontsize=24)\n",
    "axs[2].set_ylim([-0.1,4.7])\n",
    "axs[2].legend(fontsize=18)\n",
    "\n",
    "        \n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_bhv_singlecam_wholebodylabels_allsessions_basicEvents_autolever/'+savefile_sufix+'/'+cameraID+'/autolever/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"averaged_gazenumberratio_decreasingphaseVSincreasingphase\"+type_tgt+\"_\"+'acrossAllAnimals.pdf')\n",
    "            \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c72cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "xxx = gazeDist_foreachgroup_all_df['1s threshold']\n",
    "# xxx = gazeDist_foreachgroup_dom_df['1s threshold']\n",
    "# xxx = gazeDist_foreachgroup_female_df['1s threshold']\n",
    "xxx_clean = xxx[~np.isnan(xxx) & ~np.isinf(xxx)]\n",
    "\n",
    "st.ttest_1samp(xxx_clean,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7316e1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6373ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cefc48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a5bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ae3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597269f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17682bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daafde47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
