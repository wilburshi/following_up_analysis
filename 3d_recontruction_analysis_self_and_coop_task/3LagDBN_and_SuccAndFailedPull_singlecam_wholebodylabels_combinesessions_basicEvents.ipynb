{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca6246b",
   "metadata": {},
   "source": [
    "### In this script, DBN is run on the combined sessions, combined for each condition\n",
    "### In this script, DBN is run with 1s time bin, 3 time lag \n",
    "### In this script, DBN is run with sucessful and failed pulls seperately\n",
    "### In this script, the animal tracking is done with only one camera - camera 2 (middle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bd279dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "import string\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.models import DynamicBayesianNetwork as DBN\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.estimators import HillClimbSearch,BicScore\n",
    "from pgmpy.base import DAG\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee0ed4",
   "metadata": {},
   "source": [
    "### function - get body part location for each pair of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1724bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.body_part_locs_eachpair import body_part_locs_eachpair\n",
    "from ana_functions.body_part_locs_singlecam import body_part_locs_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ae6f98",
   "metadata": {},
   "source": [
    "### function - align the two cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31b03438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_align import camera_align       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494356c2",
   "metadata": {},
   "source": [
    "### function - merge the two pairs of cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bda6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.camera_merge import camera_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc7f6a",
   "metadata": {},
   "source": [
    "### function - find social gaze time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71f6ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.find_socialgaze_timepoint import find_socialgaze_timepoint\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam import find_socialgaze_timepoint_singlecam\n",
    "from ana_functions.find_socialgaze_timepoint_singlecam_wholebody import find_socialgaze_timepoint_singlecam_wholebody"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7e75b",
   "metadata": {},
   "source": [
    "### function - define time point of behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dfb672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_timepoint import bhv_events_timepoint\n",
    "from ana_functions.bhv_events_timepoint_singlecam import bhv_events_timepoint_singlecam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4ab8c",
   "metadata": {},
   "source": [
    "### function - plot behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb2ba678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.plot_bhv_events import plot_bhv_events\n",
    "from ana_functions.plot_bhv_events_levertube import plot_bhv_events_levertube\n",
    "from ana_functions.draw_self_loop import draw_self_loop\n",
    "import matplotlib.patches as mpatches \n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c724b",
   "metadata": {},
   "source": [
    "### function - plot inter-pull interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9327925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.plot_interpull_interval import plot_interpull_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d535a6",
   "metadata": {},
   "source": [
    "### function - make demo videos with skeleton and inportant vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec4de83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.tracking_video_singlecam_demo import tracking_video_singlecam_demo\n",
    "from ana_functions.tracking_video_singlecam_wholebody_demo import tracking_video_singlecam_wholebody_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69920a6a",
   "metadata": {},
   "source": [
    "### function - interval between all behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a804dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.bhv_events_interval import bhv_events_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c0b97",
   "metadata": {},
   "source": [
    "### function - train the dynamic bayesian network - multi time lag (3 lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "003d7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag\n",
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag_create_df_only\n",
    "from ana_functions.train_DBN_multiLag import train_DBN_multiLag_training_only\n",
    "from ana_functions.train_DBN_multiLag import graph_to_matrix\n",
    "from ana_functions.train_DBN_multiLag import get_weighted_dags\n",
    "from ana_functions.train_DBN_multiLag import get_significant_edges\n",
    "from ana_functions.train_DBN_multiLag import threshold_edges\n",
    "from ana_functions.train_DBN_multiLag import Modulation_Index\n",
    "from ana_functions.EfficientTimeShuffling import EfficientShuffle\n",
    "from ana_functions.AicScore import AicScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819c438",
   "metadata": {},
   "source": [
    "## Analyze each session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e84fc",
   "metadata": {},
   "source": [
    "### prepare the basic behavioral data (especially the time stamps for each bhv events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9dc05cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instead of using gaze angle threshold, use the target rectagon to deside gaze info\n",
    "# ...need to update\n",
    "sqr_thres_tubelever = 75 # draw the square around tube and lever\n",
    "sqr_thres_face = 1.15 # a ratio for defining face boundary\n",
    "sqr_thres_body = 4 # how many times to enlongate the face box boundry to the body\n",
    "\n",
    "\n",
    "# get the fps of the analyzed video\n",
    "fps = 30\n",
    "\n",
    "# frame number of the demo video\n",
    "# nframes = 0.5*30 # second*30fps\n",
    "nframes = 5*30 # second*30fps\n",
    "\n",
    "# re-analyze the video or not\n",
    "reanalyze_video = 0\n",
    "redo_anystep = 0\n",
    "\n",
    "# session list options\n",
    "do_bestsession = 1 # only analyze the best (five) sessions for each conditions during the training phase\n",
    "do_trainedMCs = 1 # the list that only consider trained (1s) MC, together with SR and NV as controls\n",
    "if do_bestsession:\n",
    "    if not do_trainedMCs:\n",
    "        savefile_sufix = '_bestsessions'\n",
    "    elif do_trainedMCs:\n",
    "        savefile_sufix = '_trainedMCsessions'\n",
    "else:\n",
    "    savefile_sufix = ''\n",
    "    \n",
    "# all the videos (no misaligned ones)\n",
    "# aligned with the audio\n",
    "# get the session start time from \"videosound_bhv_sync.py/.ipynb\"\n",
    "# currently the session_start_time will be manually typed in. It can be updated after a better method is used\n",
    "\n",
    "# dodson scorch\n",
    "if 1:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [\n",
    "            \n",
    "                     ]\n",
    "        session_start_times = [ \n",
    "            \n",
    "                              ] # in second\n",
    "    elif do_bestsession:\n",
    "        if not do_trainedMCs:\n",
    "            # pick only five sessions for each conditions during the training phase\n",
    "            dates_list = [\n",
    "                          # \"20220912\",\n",
    "                          \"20220915\",\"20220920\",\"20221010\",\"20230208\",\n",
    "                          \"20221011\",\"20221013\",\"20221015\",\"20221017\",\n",
    "                          \"20221022\",\"20221026\",\"20221028\",\"20221030\",\"20230209\",\n",
    "                          \"20221125\",\"20221128\",\"20221129\",\"20230214\",\"20230215\",                  \n",
    "                          \"20221205\",\"20221206\",\"20221209\",\"20221214\",\"20230112\",\n",
    "                          \"20230117\",\"20230118\",\"20230124\",\n",
    "                          # \"20230126\",\n",
    "                         ]\n",
    "            session_start_times = [ \n",
    "                                    # 18.10, \n",
    "                                     0.00, 33.03,  6.50,  0.00, \n",
    "                                     2.80, 27.80, 27.90, 27.00,  \n",
    "                                    51.90, 21.00, 30.80, 17.50,  0.00,                    \n",
    "                                    26.40, 22.50, 28.50,  0.00, 33.00,                     \n",
    "                                     0.00,  0.00, 21.70, 17.00, 14.20, \n",
    "                                     0.00,  0.00,  0.00, \n",
    "                                     # 0.00,  \n",
    "                                  ] # in second\n",
    "        elif do_trainedMCs:\n",
    "            dates_list = [\n",
    "                          \"20220915\",\"20220920\",\"20221010\",\"20230208\", # SR\n",
    "                          \n",
    "                          \"20230321\",\"20230322\",\"20230323\",\"20230324\",\"20230412\",\"20230413\", # trained MC\n",
    "                          \n",
    "                          \"20230117\",\"20230118\",\"20230124\", # NV \n",
    "                         ]\n",
    "            session_start_times = [ \n",
    "                                     0.00, 33.03,  6.50,  0.00, \n",
    "                                     \n",
    "                                     20.5,  21.4,  21.0,  24.5,  20.5,  26.6,\n",
    "                    \n",
    "                                     0.00,  0.00,  0.00,  \n",
    "                                  ] # in second\n",
    "    \n",
    "    animal1_fixedorder = ['dodson']\n",
    "    animal2_fixedorder = ['scorch']\n",
    "\n",
    "    animal1_filename = \"Dodson\"\n",
    "    animal2_filename = \"Scorch\"\n",
    "    \n",
    "    \n",
    "# eddie sparkle\n",
    "if 0:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [\n",
    "                                    \n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                 \n",
    "                              ] # in second\n",
    "    elif do_bestsession:   \n",
    "        if not do_trainedMCs:\n",
    "            # pick only five sessions for each conditions during the training phase\n",
    "            dates_list = [\n",
    "                          \"20221122\",  \"20221125\",  \n",
    "                          \"20221202\",  \"20221206\",  \"20230126\",  \"20230130\",  \"20230201\",\n",
    "                          \"20230207\",  \"20230208-1\",\"20230209\",  \"20230222\",  \"20230223-1\",\n",
    "                          \"20230227-1\",\"20230228-1\",\"20230302-1\",\"20230307-2\",\"20230313\",\n",
    "                          \"20230321\",  \"20230322\",  \"20230324\",  \"20230327\",  \"20230328\",\n",
    "                          \"20230331\",  \"20230403\",  \"20230404\",  \"20230405\",  \"20230406\"\n",
    "                       ]\n",
    "            session_start_times = [ \n",
    "                                      8.00,  38.00, \n",
    "                                      9.50,   1.00, 38.00,  4.20,  3.80,\n",
    "                                      9.00,   7.50,  8.50, 14.50,  7.80,\n",
    "                                      8.00,   7.50,  8.00,  8.00,  4.00,\n",
    "                                      7.00,   7.50,  5.50, 11.00,  9.00,\n",
    "                                      4.50,   9.30, 25.50, 20.40, 21.30,\n",
    "                                  ] # in second\n",
    "        elif do_trainedMCs:\n",
    "            dates_list = [\n",
    "                          \"20221122\",  \"20221125\",  # sr\n",
    "                \n",
    "                          \"20230410\",  \"20230411\",  \"20230412\",  \"20230413\",  \"20230616\", # trained MC\n",
    "                \n",
    "                          \"20230331\",  \"20230403\",  \"20230404\",  \"20230405\",  \"20230406\", # nv\n",
    "                       ]\n",
    "            session_start_times = [ \n",
    "                                      8.00, 38.00, \n",
    "                \n",
    "                                      23.2,  23.0,  21.2,  25.0,  23.0,   \n",
    "                \n",
    "                                      4.50,  9.30, 25.50, 20.40, 21.30,\n",
    "                \n",
    "                                  ] # in second\n",
    "    animal1_fixedorder = ['eddie']\n",
    "    animal2_fixedorder = ['sparkle']\n",
    "\n",
    "    animal1_filename = \"Eddie\"\n",
    "    animal2_filename = \"Sparkle\"\n",
    "    \n",
    "    \n",
    "# ginger kanga\n",
    "if 0:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [\n",
    "                      \n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                                \n",
    "                              ] # in second \n",
    "    elif do_bestsession:\n",
    "        if not do_trainedMCs:\n",
    "            # pick only five sessions for each conditions during the training phase\n",
    "            dates_list = [\n",
    "                          #\"20230213\",\n",
    "                          \"20230214\",\"20230216\",\n",
    "                          \"20230228\",\"20230302\",\"20230303\",\"20230307\",          \n",
    "                          \"20230314\",\"20230315\",\"20230316\",\"20230317\",\n",
    "                          \"20230301\",\"20230320\",\"20230321\",\"20230322\",\n",
    "                          \"20230323\",\"20230412\",\"20230413\",\"20230517\",\n",
    "                          \"20230522_ws\",\"20230524\",\"20230605_1\",\"20230606\",\"20230607\"\n",
    "                       ]\n",
    "            session_start_times = [ \n",
    "                                    # 0.00, \n",
    "                                     0.00, 48.00, \n",
    "                                    23.00, 28.50, 34.00, 25.50, \n",
    "                                    25.50, 31.50, 28.00, 30.50,\n",
    "                                     0.00,  0.00,  0.00,  0.00, \n",
    "                                     0.00,  0.00,  0.00,  0.00, \n",
    "                                     0.00,  0.00,  0.00,  0.00,  0.00,\n",
    "                                  ] # in second \n",
    "        elif do_trainedMCs:\n",
    "            dates_list = [\n",
    "                          \"20230214\",   \"20230216\",  # SR\n",
    "                          \n",
    "                          \"20230614\",   \"20230615\",  \"20230711\",\"20230712\", # trained MC\n",
    "                \n",
    "                          \"20230522_ws\",\"20230524\",\"20230605_1\",\"20230606\",\"20230607\", # nv  \n",
    "                       ]\n",
    "            session_start_times = [ \n",
    "                                     0.00, 48.00, \n",
    "                                    \n",
    "                                     0.00,  0.00,  54.5,  24.7,\n",
    "                \n",
    "                                     0.00,  0.00,  0.00,  0.00,  0.00,\n",
    "                                  ] # in second \n",
    "    \n",
    "    animal1_fixedorder = ['ginger']\n",
    "    animal2_fixedorder = ['kanga']\n",
    "\n",
    "    animal1_filename = \"Ginger\"\n",
    "    animal2_filename = \"Kanga\"\n",
    "\n",
    "    \n",
    "# dannon kanga\n",
    "if 0:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [\n",
    "                    \n",
    "                   ]\n",
    "        session_start_times = [ \n",
    "                              \n",
    "                              ] # in second \n",
    "    elif do_bestsession: \n",
    "        if not do_trainedMCs:\n",
    "            # pick only five sessions for each conditions during the training phase\n",
    "            dates_list = [\n",
    "                          \"20230718\",\"20230720\",\"20230914\",\"20230726\",\"20230727\",\"20230809\",\n",
    "                          \"20230810\",\"20230811\",\"20230814\",\"20230816\",\"20230829\",\"20230907\",\"20230915\",\n",
    "                          \"20230918\",\"20230926\",\"20230928\",\"20231002\",\"20231010\",\"20231011\",\n",
    "                          \"20231013\",\"20231020\",\"20231024\",\"20231025\",\n",
    "                       ]\n",
    "            session_start_times = [ \n",
    "                                        0,    0,    0, 32.2, 27.2, 37.5,\n",
    "                                     21.0, 21.5, 19.8, 32.0,    0,    0,   0, \n",
    "                                        0,    0,    0,    0,    0,    0,\n",
    "                                        0,    0,    0,    0, \n",
    "                                  ] # in second \n",
    "        elif do_trainedMCs:\n",
    "            dates_list = [\n",
    "                          \"20230718\",\"20230720\",\"20230914\", # sr\n",
    "                \n",
    "                          \"20231030\",\"20231031\",\"20231101\",\"20231102\",\"20240304\",\"20240305\", # trained MC\n",
    "                \n",
    "                          \"20231011\",\"20231013\",\"20231020\",\"20231024\",\"20231025\", # nv\n",
    "                       ]\n",
    "            session_start_times = [ \n",
    "                                       0,    0,    0,\n",
    "                \n",
    "                                    18.2, 14.0, 15.8, 15.2, 16.3, 37.9,\n",
    "                \n",
    "                                       0,    0,    0,    0,    0, \n",
    "                                  ] # in second \n",
    "    \n",
    "    animal1_fixedorder = ['dannon']\n",
    "    animal2_fixedorder = ['kanga']\n",
    "\n",
    "    animal1_filename = \"Dannon\"\n",
    "    animal2_filename = \"Kanga\"\n",
    "\n",
    "# Koala Vermelho\n",
    "if 0:\n",
    "    if not do_bestsession:\n",
    "        dates_list = [\n",
    "                     \n",
    "                     ]\n",
    "        session_start_times = [ \n",
    "                               \n",
    "                              ] # in second\n",
    "    elif do_bestsession:\n",
    "        if not do_trainedMCs:\n",
    "            # pick only five sessions for each conditions during the training phase\n",
    "            dates_list = [\n",
    "                          \"20231222\",\"20231226\",\"20231227\",  \"20231229\",\"20231230\",\n",
    "                          \"20231231\",\"20240102\",\"20240104-2\",\"20240105\",\"20240108\",\n",
    "                          \"20240109\",\"20240115\",\"20240116\",  \"20240117\",\"20240118\",\"20240119\",\n",
    "                          \"20240207\",\"20240208\",\"20240209\",  \"20240212\",\"20240213\",\n",
    "                          \"20240214\",\"20240215\",\"20240216\",  \n",
    "                         ]\n",
    "            session_start_times = [ \n",
    "                                    21.5,  0.00,  0.00,  0.00,  0.00, \n",
    "                                    0.00,  12.2,  0.00,  18.8,  31.2,  \n",
    "                                    32.5,  0.00,  50.0,  0.00,  37.5,  29.5,\n",
    "                                    58.5,  72.0,  0.00,  71.5,  70.5,\n",
    "                                    86.8,  94.0,  65.0, \n",
    "                                  ] # in second\n",
    "        elif do_trainedMCs:\n",
    "            dates_list = [\n",
    "                          \"20231222\",\"20231226\",\"20231227\", # SR\n",
    "                          \n",
    "                          \"20240220\",\"20240222\",\"20240223\",\"20240226\", # trained MC\n",
    "                 \n",
    "                          \"20240214\",\"20240215\",\"20240216\",  # NV\n",
    "                         ]\n",
    "            session_start_times = [ \n",
    "                                    21.5,  0.00,  0.00, \n",
    "                                    \n",
    "                                    68.8,  43.8,  13.2,  47.5,\n",
    "                \n",
    "                                    86.8,  94.0,  65.0, \n",
    "                                  ] # in second\n",
    "\n",
    "    animal1_fixedorder = ['koala']\n",
    "    animal2_fixedorder = ['vermelho']\n",
    "\n",
    "    animal1_filename = \"Koala\"\n",
    "    animal2_filename = \"Vermelho\"\n",
    "    \n",
    "#    \n",
    "#dates_list = [\"20221128\"]\n",
    "#session_start_times = [1.00] # in second\n",
    "ndates = np.shape(dates_list)[0]\n",
    "\n",
    "session_start_frames = session_start_times * fps # fps is 30Hz\n",
    "\n",
    "totalsess_time = 600\n",
    "\n",
    "# video tracking results info\n",
    "animalnames_videotrack = ['dodson','scorch'] # does not really mean dodson and scorch, instead, indicate animal1 and animal2\n",
    "bodypartnames_videotrack = ['rightTuft','whiteBlaze','leftTuft','rightEye','leftEye','mouth']\n",
    "\n",
    "\n",
    "# which camera to analyzed\n",
    "cameraID = 'camera-2'\n",
    "cameraID_short = 'cam2'\n",
    "\n",
    "\n",
    "# location of levers and tubes for camera 2\n",
    "# get this information using DLC animal tracking GUI, the results are stored: \n",
    "# /home/ws523/marmoset_tracking_DLCv2/marmoset_tracking_with_lever_tube-weikang-2023-04-13/labeled-data/\n",
    "considerlevertube = 1\n",
    "considertubeonly = 0\n",
    "# # camera 1\n",
    "# lever_locs_camI = {'dodson':np.array([645,600]),'scorch':np.array([425,435])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1350,630]),'scorch':np.array([555,345])}\n",
    "# # camera 2\n",
    "lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "tube_locs_camI  = {'dodson':np.array([1550,515]),'scorch':np.array([350,515])}\n",
    "# # lever_locs_camI = {'dodson':np.array([1335,715]),'scorch':np.array([550,715])}\n",
    "# # tube_locs_camI  = {'dodson':np.array([1650,490]),'scorch':np.array([250,490])}\n",
    "# # camera 3\n",
    "# lever_locs_camI = {'dodson':np.array([1580,440]),'scorch':np.array([1296,540])}\n",
    "# tube_locs_camI  = {'dodson':np.array([1470,375]),'scorch':np.array([805,475])}\n",
    "\n",
    "\n",
    "if np.shape(session_start_times)[0] != np.shape(dates_list)[0]:\n",
    "    exit()\n",
    "\n",
    "    \n",
    "# define bhv events summarizing variables     \n",
    "tasktypes_all_dates = np.zeros((ndates,1))\n",
    "coopthres_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "succ_rate_all_dates = np.zeros((ndates,1))\n",
    "interpullintv_all_dates = np.zeros((ndates,1))\n",
    "trialnum_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "owgaze1_num_all_dates = np.zeros((ndates,1))\n",
    "owgaze2_num_all_dates = np.zeros((ndates,1))\n",
    "mtgaze1_num_all_dates = np.zeros((ndates,1))\n",
    "mtgaze2_num_all_dates = np.zeros((ndates,1))\n",
    "pull1_num_all_dates = np.zeros((ndates,1))\n",
    "pull2_num_all_dates = np.zeros((ndates,1))\n",
    "\n",
    "bhv_intv_all_dates = dict.fromkeys(dates_list, [])\n",
    "\n",
    "\n",
    "# where to save the summarizing data\n",
    "data_saved_folder = '/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/3d_recontruction_analysis_self_and_coop_task_data_saved/'\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93c7a76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data from all dates are loaded\n"
     ]
    }
   ],
   "source": [
    "# basic behavior analysis (define time stamps for each bhv events, etc)\n",
    "\n",
    "try:\n",
    "    if redo_anystep:\n",
    "        dummy\n",
    "    \n",
    "    # load saved data\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    \n",
    "    with open(data_saved_subfolder+'/owgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        owgaze1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/owgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        owgaze2_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/mtgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        mtgaze1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/mtgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        mtgaze2_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/pull1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        pull1_num_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/pull2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        pull2_num_all_dates = pickle.load(f)\n",
    "\n",
    "    with open(data_saved_subfolder+'/tasktypes_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        tasktypes_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/coopthres_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        coopthres_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/succ_rate_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        succ_rate_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/interpullintv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        interpullintv_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/trialnum_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        trialnum_all_dates = pickle.load(f)\n",
    "    with open(data_saved_subfolder+'/bhv_intv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "        bhv_intv_all_dates = pickle.load(f)\n",
    "\n",
    "    print('all data from all dates are loaded')\n",
    "\n",
    "except:\n",
    "\n",
    "    print('analyze all dates')\n",
    "\n",
    "    for idate in np.arange(0,ndates,1):\n",
    "        date_tgt = dates_list[idate]\n",
    "        session_start_time = session_start_times[idate]\n",
    "\n",
    "        # folder and file path\n",
    "        camera12_analyzed_path = \"/gpfs/gibbs/pi/jadi/VideoTracker_SocialInter/test_video_cooperative_task_3d/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera12/\"\n",
    "        camera23_analyzed_path = \"/gpfs/gibbs/pi/jadi/VideoTracker_SocialInter/test_video_cooperative_task_3d/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_camera23/\"\n",
    "        \n",
    "        singlecam_ana_type = \"DLC_dlcrnetms5_marmoset_tracking_with_middle_cameraSep1shuffle1_150000\"\n",
    "        try: \n",
    "            bodyparts_camI_camIJ = camera12_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "            # get the bodypart data from files\n",
    "            bodyparts_locs_camI = body_part_locs_singlecam(bodyparts_camI_camIJ,singlecam_ana_type,animalnames_videotrack,bodypartnames_videotrack,date_tgt)\n",
    "            video_file_original = camera12_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+\".mp4\"\n",
    "        except:\n",
    "            bodyparts_camI_camIJ = camera23_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "            # get the bodypart data from files\n",
    "            bodyparts_locs_camI = body_part_locs_singlecam(bodyparts_camI_camIJ,singlecam_ana_type,animalnames_videotrack,bodypartnames_videotrack,date_tgt)\n",
    "            video_file_original = camera23_analyzed_path+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_\"+cameraID+\".mp4\"        \n",
    "        \n",
    "        \n",
    "         # load behavioral results\n",
    "        try:\n",
    "            try:\n",
    "                bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                trial_record_json = glob.glob(bhv_data_path +date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_session_info_\" + \"*.json\")\n",
    "                #\n",
    "                trial_record = pd.read_json(trial_record_json[0])\n",
    "                bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                session_info = pd.read_json(session_info_json[0])\n",
    "            except:\n",
    "                bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                trial_record_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_session_info_\" + \"*.json\")\n",
    "                #\n",
    "                trial_record = pd.read_json(trial_record_json[0])\n",
    "                bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                session_info = pd.read_json(session_info_json[0])\n",
    "        except:\n",
    "            try:\n",
    "                bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_forceManipulation_task/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                trial_record_json = glob.glob(bhv_data_path +date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_session_info_\" + \"*.json\")\n",
    "                #\n",
    "                trial_record = pd.read_json(trial_record_json[0])\n",
    "                bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                session_info = pd.read_json(session_info_json[0])\n",
    "            except:\n",
    "                bhv_data_path = \"/home/ws523/marmoset_tracking_bhv_data_forceManipulation_task/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                trial_record_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_session_info_\" + \"*.json\")\n",
    "                #\n",
    "                trial_record = pd.read_json(trial_record_json[0])\n",
    "                bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                session_info = pd.read_json(session_info_json[0])\n",
    "\n",
    "\n",
    "        # get animal info from the session information\n",
    "        animal1 = session_info['lever1_animal'][0].lower()\n",
    "        animal2 = session_info['lever2_animal'][0].lower()\n",
    "\n",
    "        \n",
    "        # get task type and cooperation threshold\n",
    "        try:\n",
    "            coop_thres = session_info[\"pulltime_thres\"][0]\n",
    "            tasktype = session_info[\"task_type\"][0]\n",
    "        except:\n",
    "            coop_thres = 0\n",
    "            tasktype = 1\n",
    "        tasktypes_all_dates[idate] = tasktype\n",
    "        coopthres_all_dates[idate] = coop_thres   \n",
    "\n",
    "        # clean up the trial_record\n",
    "        warnings.filterwarnings('ignore')\n",
    "        trial_record_clean = pd.DataFrame(columns=trial_record.columns)\n",
    "        for itrial in np.arange(0,np.max(trial_record['trial_number']),1):\n",
    "            # trial_record_clean.loc[itrial] = trial_record[trial_record['trial_number']==itrial+1].iloc[[0]]\n",
    "            trial_record_clean = trial_record_clean.append(trial_record[trial_record['trial_number']==itrial+1].iloc[[0]])\n",
    "        trial_record_clean = trial_record_clean.reset_index(drop = True)\n",
    "\n",
    "        # change bhv_data time to the absolute time\n",
    "        time_points_new = pd.DataFrame(np.zeros(np.shape(bhv_data)[0]),columns=[\"time_points_new\"])\n",
    "        for itrial in np.arange(0,np.max(trial_record_clean['trial_number']),1):\n",
    "            ind = bhv_data[\"trial_number\"]==itrial+1\n",
    "            new_time_itrial = bhv_data[ind][\"time_points\"] + trial_record_clean[\"trial_starttime\"].iloc[itrial]\n",
    "            time_points_new[\"time_points_new\"][ind] = new_time_itrial\n",
    "        bhv_data[\"time_points\"] = time_points_new[\"time_points_new\"]\n",
    "        bhv_data = bhv_data[bhv_data[\"time_points\"] != 0]\n",
    "\n",
    "\n",
    "        # analyze behavior results\n",
    "        # succ_rate_all_dates[idate] = np.sum(trial_record_clean[\"rewarded\"]>0)/np.shape(trial_record_clean)[0]\n",
    "        succ_rate_all_dates[idate] = np.sum((bhv_data['behavior_events']==3)|(bhv_data['behavior_events']==4))/np.sum((bhv_data['behavior_events']==1)|(bhv_data['behavior_events']==2))\n",
    "        trialnum_all_dates[idate] = np.shape(trial_record_clean)[0]\n",
    "        #\n",
    "        pullid = np.array(bhv_data[(bhv_data['behavior_events']==1) | (bhv_data['behavior_events']==2)][\"behavior_events\"])\n",
    "        pulltime = np.array(bhv_data[(bhv_data['behavior_events']==1) | (bhv_data['behavior_events']==2)][\"time_points\"])\n",
    "        pullid_diff = np.abs(pullid[1:] - pullid[0:-1])\n",
    "        pulltime_diff = pulltime[1:] - pulltime[0:-1]\n",
    "        interpull_intv = pulltime_diff[pullid_diff==1]\n",
    "        interpull_intv = interpull_intv[interpull_intv<10]\n",
    "        mean_interpull_intv = np.nanmean(interpull_intv)\n",
    "        std_interpull_intv = np.nanstd(interpull_intv)\n",
    "        #\n",
    "        interpullintv_all_dates[idate] = mean_interpull_intv\n",
    "        # \n",
    "        pull1_num_all_dates[idate] = np.sum(bhv_data['behavior_events']==1) \n",
    "        pull2_num_all_dates[idate] = np.sum(bhv_data['behavior_events']==2)\n",
    "\n",
    "        \n",
    "        # load behavioral event results\n",
    "        try:\n",
    "            # dummy\n",
    "            print('load social gaze with '+cameraID+' only of '+date_tgt)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_look_ornot.pkl', 'rb') as f:\n",
    "                output_look_ornot = pickle.load(f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allvectors.pkl', 'rb') as f:\n",
    "                output_allvectors = pickle.load(f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allangles.pkl', 'rb') as f:\n",
    "                output_allangles = pickle.load(f)  \n",
    "        except:   \n",
    "            print('analyze social gaze with '+cameraID+' only of '+date_tgt)\n",
    "            # get social gaze information \n",
    "            output_look_ornot, output_allvectors, output_allangles = find_socialgaze_timepoint_singlecam_wholebody(bodyparts_locs_camI,lever_locs_camI,tube_locs_camI,\n",
    "                                                                                                                   considerlevertube,considertubeonly,sqr_thres_tubelever,\n",
    "                                                                                                                   sqr_thres_face,sqr_thres_body)\n",
    "            # save data\n",
    "            current_dir = data_saved_folder+'/bhv_events_singlecam_wholebody/'+animal1_fixedorder[0]+animal2_fixedorder[0]\n",
    "            add_date_dir = os.path.join(current_dir,cameraID+'/'+date_tgt)\n",
    "            if not os.path.exists(add_date_dir):\n",
    "                os.makedirs(add_date_dir)\n",
    "            #\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_look_ornot.pkl', 'wb') as f:\n",
    "                pickle.dump(output_look_ornot, f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allvectors.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allvectors, f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allangles.pkl', 'wb') as f:\n",
    "                pickle.dump(output_allangles, f)\n",
    "  \n",
    "\n",
    "        look_at_other_or_not_merge = output_look_ornot['look_at_other_or_not_merge']\n",
    "        look_at_tube_or_not_merge = output_look_ornot['look_at_tube_or_not_merge']\n",
    "        look_at_lever_or_not_merge = output_look_ornot['look_at_lever_or_not_merge']\n",
    "        # change the unit to second\n",
    "        session_start_time = session_start_times[idate]\n",
    "        look_at_other_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_other_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_lever_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_lever_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "        look_at_tube_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_tube_or_not_merge['dodson'])[0],1)/fps - session_start_time \n",
    "\n",
    "        # find time point of behavioral events\n",
    "        output_time_points_socialgaze ,output_time_points_levertube = bhv_events_timepoint_singlecam(bhv_data,look_at_other_or_not_merge,look_at_lever_or_not_merge,look_at_tube_or_not_merge)\n",
    "        time_point_pull1 = output_time_points_socialgaze['time_point_pull1']\n",
    "        time_point_pull2 = output_time_points_socialgaze['time_point_pull2']\n",
    "        oneway_gaze1 = output_time_points_socialgaze['oneway_gaze1']\n",
    "        oneway_gaze2 = output_time_points_socialgaze['oneway_gaze2']\n",
    "        mutual_gaze1 = output_time_points_socialgaze['mutual_gaze1']\n",
    "        mutual_gaze2 = output_time_points_socialgaze['mutual_gaze2']\n",
    "            \n",
    "                \n",
    "        # # plot behavioral events\n",
    "        if np.isin(animal1,animal1_fixedorder):\n",
    "                plot_bhv_events(date_tgt,animal1, animal2, session_start_time, 600, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "        else:\n",
    "                plot_bhv_events(date_tgt,animal2, animal1, session_start_time, 600, time_point_pull2, time_point_pull1, oneway_gaze2, oneway_gaze1, mutual_gaze2, mutual_gaze1)\n",
    "        #\n",
    "        # save behavioral events plot\n",
    "        if 0:\n",
    "            current_dir = data_saved_folder+'/bhv_events_singlecam_wholebody/'+animal1_fixedorder[0]+animal2_fixedorder[0]\n",
    "            add_date_dir = os.path.join(current_dir,cameraID+'/'+date_tgt)\n",
    "            if not os.path.exists(add_date_dir):\n",
    "                os.makedirs(add_date_dir)\n",
    "            plt.savefig(data_saved_folder+\"/bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/'+date_tgt+\"_\"+cameraID_short+\".pdf\")\n",
    "\n",
    "        #\n",
    "        owgaze1_num_all_dates[idate] = np.shape(oneway_gaze1)[0]\n",
    "        owgaze2_num_all_dates[idate] = np.shape(oneway_gaze2)[0]\n",
    "        mtgaze1_num_all_dates[idate] = np.shape(mutual_gaze1)[0]\n",
    "        mtgaze2_num_all_dates[idate] = np.shape(mutual_gaze2)[0]\n",
    "\n",
    "        # analyze the events interval, especially for the pull to other and other to pull interval\n",
    "        # could be used for define time bin for DBN\n",
    "        if 1:\n",
    "            _,_,_,pullTOother_itv, otherTOpull_itv = bhv_events_interval(totalsess_time, session_start_time, time_point_pull1, time_point_pull2, \n",
    "                                                                         oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "            #\n",
    "            pull_other_pool_itv = np.concatenate((pullTOother_itv,otherTOpull_itv))\n",
    "            bhv_intv_all_dates[date_tgt] = {'pull_to_other':pullTOother_itv,'other_to_pull':otherTOpull_itv,\n",
    "                            'pull_other_pooled': pull_other_pool_itv}\n",
    "        \n",
    "        # plot the tracking demo video\n",
    "        if 0: \n",
    "            tracking_video_singlecam_wholebody_demo(bodyparts_locs_camI,output_look_ornot,output_allvectors,output_allangles,\n",
    "                                              lever_locs_camI,tube_locs_camI,time_point_pull1,time_point_pull2,\n",
    "                                              animalnames_videotrack,bodypartnames_videotrack,date_tgt,\n",
    "                                              animal1_filename,animal2_filename,session_start_time,fps,nframes,cameraID,\n",
    "                                              video_file_original,sqr_thres_tubelever,sqr_thres_face,sqr_thres_body)         \n",
    "        \n",
    "\n",
    "    # save data\n",
    "    if 0:\n",
    "        \n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "        if not os.path.exists(data_saved_subfolder):\n",
    "            os.makedirs(data_saved_subfolder)\n",
    "                \n",
    "        # with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "        #     pickle.dump(DBN_input_data_alltypes, f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/owgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(owgaze1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/owgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(owgaze2_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/mtgaze1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(mtgaze1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/mtgaze2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(mtgaze2_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/pull1_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(pull1_num_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/pull2_num_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(pull2_num_all_dates, f)\n",
    "\n",
    "        with open(data_saved_subfolder+'/tasktypes_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(tasktypes_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/coopthres_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(coopthres_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/succ_rate_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(succ_rate_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/interpullintv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(interpullintv_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/trialnum_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(trialnum_all_dates, f)\n",
    "        with open(data_saved_subfolder+'/bhv_intv_all_dates_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "            pickle.dump(bhv_intv_all_dates, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ebdc78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aada694",
   "metadata": {},
   "source": [
    "#### redefine the tasktype and cooperation threshold to merge them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d0e6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100: self; 3: 3s coop; 2: 2s coop; 1.5: 1.5s coop; 1: 1s coop; -1: no-vision\n",
    "\n",
    "tasktypes_all_dates[tasktypes_all_dates==5] = -1 # change the task type code for no-vision\n",
    "coopthres_forsort = (tasktypes_all_dates-1)*coopthres_all_dates/2\n",
    "coopthres_forsort[coopthres_forsort==0] = 100 # get the cooperation threshold for sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900d890",
   "metadata": {},
   "source": [
    "### plot behavioral events interval to get a sense about time bin\n",
    "#### only focus on pull_to_other_bhv_interval and other_bhv_to_pull_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7b179dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.75222222 3.639      3.00148148 1.17300275 0.52825203 0.5128866\n",
      " 0.45726872 1.59727273 0.96630728 1.0699115 ]\n",
      "1.1437499999999998\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "#\n",
    "# sort the data based on task type and dates\n",
    "sorting_df = pd.DataFrame({'dates': dates_list, 'coopthres': coopthres_forsort.ravel()}, columns=['dates', 'coopthres'])\n",
    "sorting_df = sorting_df.sort_values(by=['coopthres','dates'], ascending = [False, True])\n",
    "dates_list_sorted = np.array(dates_list)[sorting_df.index]\n",
    "ndates_sorted = np.shape(dates_list_sorted)[0]\n",
    "\n",
    "pull_other_intv_forplots = {}\n",
    "pull_other_intv_mean = np.zeros((1,ndates_sorted))[0]\n",
    "pull_other_intv_ii = []\n",
    "for ii in np.arange(0,ndates_sorted,1):\n",
    "    pull_other_intv_ii = pd.Series(bhv_intv_all_dates[dates_list_sorted[ii]]['pull_other_pooled'])\n",
    "    # remove the interval that is too large\n",
    "    pull_other_intv_ii[pull_other_intv_ii>(np.nanmean(pull_other_intv_ii)+2*np.nanstd(pull_other_intv_ii))]= np.nan    \n",
    "    # pull_other_intv_ii[pull_other_intv_ii>10]= np.nan\n",
    "    pull_other_intv_forplots[ii] = pull_other_intv_ii\n",
    "    pull_other_intv_mean[ii] = np.nanmean(pull_other_intv_ii)\n",
    "    \n",
    "    \n",
    "#\n",
    "pull_other_intv_forplots = pd.DataFrame(pull_other_intv_forplots)\n",
    "\n",
    "#\n",
    "# plot\n",
    "pull_other_intv_forplots.plot(kind = 'box',ax=ax1, positions=np.arange(0,ndates_sorted,1))\n",
    "# plt.boxplot(pull_other_intv_forplots)\n",
    "plt.plot(np.arange(0,ndates_sorted,1),pull_other_intv_mean,'r*',markersize=10)\n",
    "#\n",
    "ax1.set_ylabel(\"bhv event interval(around pulls)\",fontsize=13)\n",
    "ax1.set_ylim([-2,16])\n",
    "#\n",
    "plt.xticks(np.arange(0,ndates_sorted,1),dates_list_sorted, rotation=90,fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "#\n",
    "tasktypes = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','no-vision']\n",
    "taskswitches = np.where(np.array(sorting_df['coopthres'])[1:]-np.array(sorting_df['coopthres'])[:-1]!=0)[0]+0.5\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.plot([taskswitch,taskswitch],[-2,15],'k--')\n",
    "taskswitches = np.concatenate(([0],taskswitches))\n",
    "for itaskswitch in np.arange(0,np.shape(taskswitches)[0],1):\n",
    "    taskswitch = taskswitches[itaskswitch]\n",
    "    ax1.text(taskswitch+0.25,-1,tasktypes[itaskswitch],fontsize=10)\n",
    "ax1.text(taskswitch-5,15,'mean Inteval = '+str(np.nanmean(pull_other_intv_forplots)),fontsize=10)\n",
    "\n",
    "print(pull_other_intv_mean)\n",
    "print(np.nanmean(pull_other_intv_forplots))\n",
    "\n",
    "savefigs = 1\n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    plt.savefig(figsavefolder+\"bhvInterval_hist_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e1548e",
   "metadata": {},
   "source": [
    "### prepare the input data for DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d188541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load social gaze with camera-2 only of 20231222\n",
      "load social gaze with camera-2 only of 20231226\n",
      "load social gaze with camera-2 only of 20231227\n",
      "load social gaze with camera-2 only of 20240220\n",
      "load social gaze with camera-2 only of 20240222\n",
      "load social gaze with camera-2 only of 20240223\n",
      "load social gaze with camera-2 only of 20240226\n",
      "load social gaze with camera-2 only of 20240214\n",
      "load social gaze with camera-2 only of 20240215\n",
      "load social gaze with camera-2 only of 20240216\n",
      "load social gaze with camera-2 only of 20231222\n",
      "load social gaze with camera-2 only of 20231226\n",
      "load social gaze with camera-2 only of 20231227\n",
      "load social gaze with camera-2 only of 20240220\n",
      "load social gaze with camera-2 only of 20240222\n",
      "load social gaze with camera-2 only of 20240223\n",
      "load social gaze with camera-2 only of 20240226\n",
      "load social gaze with camera-2 only of 20240214\n",
      "load social gaze with camera-2 only of 20240215\n",
      "load social gaze with camera-2 only of 20240216\n"
     ]
    }
   ],
   "source": [
    "# define DBN related summarizing variables\n",
    "DBN_group_typenames = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','no-vision']\n",
    "DBN_group_typeIDs  =  [1,3,3,  3,3,5]\n",
    "DBN_group_coopthres = [0,3,2,1.5,1,0]\n",
    "if do_trainedMCs:\n",
    "    DBN_group_typenames = ['self','coop(1s)','no-vision']\n",
    "    DBN_group_typeIDs  =  [1,3,5]\n",
    "    DBN_group_coopthres = [0,1,0]\n",
    "nDBN_groups = np.shape(DBN_group_typenames)[0]\n",
    "\n",
    "pulltypes = ['succpull','failedpull']\n",
    "npulltypes = np.shape(pulltypes)[0]\n",
    "\n",
    "prepare_input_data = 1\n",
    "\n",
    "DBN_input_data_alltypes = dict.fromkeys(pulltypes, [])\n",
    "\n",
    "# DBN resolutions (make sure they are the same as in the later part of the code)\n",
    "totalsess_time = 600 # total session time in s\n",
    "# temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "ntemp_reses = np.shape(temp_resolus)[0]\n",
    "\n",
    "mergetempRos = 0\n",
    "\n",
    "# # train the dynamic bayesian network - Alec's model \n",
    "#   prepare the multi-session table; one time lag; multi time steps (temporal resolution) as separate files\n",
    "\n",
    "# prepare the DBN input data\n",
    "if prepare_input_data:\n",
    "    \n",
    "    for ipulltype in np.arange(0,npulltypes,1):\n",
    "        pulltype = pulltypes[ipulltype]\n",
    "\n",
    "        DBN_input_data_alltypes[pulltype] = dict.fromkeys(DBN_group_typenames, [])\n",
    "            \n",
    "        for idate in np.arange(0,ndates,1):\n",
    "            date_tgt = dates_list[idate]\n",
    "            session_start_time = session_start_times[idate]\n",
    "                 \n",
    "            # load behavioral results\n",
    "            try:\n",
    "                try:\n",
    "                    bhv_data_path = \"/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                    trial_record_json = glob.glob(bhv_data_path +date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                    bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                    session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_session_info_\" + \"*.json\")\n",
    "                    #\n",
    "                    trial_record = pd.read_json(trial_record_json[0])\n",
    "                    bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                    session_info = pd.read_json(session_info_json[0])\n",
    "                except:\n",
    "                    bhv_data_path = \"/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/marmoset_tracking_bhv_data_from_task_code/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                    trial_record_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                    bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                    session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_session_info_\" + \"*.json\")\n",
    "                    #\n",
    "                    trial_record = pd.read_json(trial_record_json[0])\n",
    "                    bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                    session_info = pd.read_json(session_info_json[0])\n",
    "            except:\n",
    "                try:\n",
    "                    bhv_data_path = \"/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/marmoset_tracking_bhv_data_forceManipulation_task/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                    trial_record_json = glob.glob(bhv_data_path +date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                    bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                    session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal2_filename+\"_\"+animal1_filename+\"_session_info_\" + \"*.json\")\n",
    "                    #\n",
    "                    trial_record = pd.read_json(trial_record_json[0])\n",
    "                    bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                    session_info = pd.read_json(session_info_json[0])\n",
    "                except:\n",
    "                    bhv_data_path = \"/gpfs/radev/pi/nandy/jadi_gibbs_data/VideoTracker_SocialInter/marmoset_tracking_bhv_data_forceManipulation_task/\"+date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"/\"\n",
    "                    trial_record_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_TrialRecord_\" + \"*.json\")\n",
    "                    bhv_data_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_bhv_data_\" + \"*.json\")\n",
    "                    session_info_json = glob.glob(bhv_data_path + date_tgt+\"_\"+animal1_filename+\"_\"+animal2_filename+\"_session_info_\" + \"*.json\")\n",
    "                    #\n",
    "                    trial_record = pd.read_json(trial_record_json[0])\n",
    "                    bhv_data = pd.read_json(bhv_data_json[0])\n",
    "                    session_info = pd.read_json(session_info_json[0])\n",
    "\n",
    "                \n",
    "            # separate successful and failed pulls\n",
    "            if pulltype == 'succpull':\n",
    "                trialnum_tgtpull = trial_record[trial_record['rewarded']>0]['trial_number'].reset_index(drop=True)\n",
    "            elif pulltype == 'failedpull':\n",
    "                trialnum_tgtpull = trial_record[trial_record['rewarded']==0]['trial_number'].reset_index(drop=True)\n",
    "            bhv_data = bhv_data[bhv_data['trial_number'].isin(trialnum_tgtpull)]\n",
    "            trial_record = trial_record[trial_record['trial_number'].isin(trialnum_tgtpull)]\n",
    "            bhv_data = bhv_data.reset_index(drop=True)\n",
    "            trial_record = trial_record.reset_index(drop=True)\n",
    "                \n",
    "            # get animal info\n",
    "            animal1 = session_info['lever1_animal'][0].lower()\n",
    "            animal2 = session_info['lever2_animal'][0].lower()\n",
    "\n",
    "            # clean up the trial_record\n",
    "            #try:\n",
    "            warnings.filterwarnings('ignore')\n",
    "            trial_record_clean = pd.DataFrame(columns=trial_record.columns)\n",
    "            for itrial in trial_record['trial_number']:\n",
    "                # trial_record_clean.loc[itrial] = trial_record[trial_record['trial_number']==itrial+1].iloc[[0]]\n",
    "                trial_record_clean = trial_record_clean.append(trial_record[trial_record['trial_number']==itrial].iloc[[0]])\n",
    "            trial_record_clean = trial_record_clean.reset_index(drop = True)\n",
    "\n",
    "            # change bhv_data time to the absolute time\n",
    "            time_points_new = pd.DataFrame(np.zeros(np.shape(bhv_data)[0]),columns=[\"time_points_new\"])\n",
    "            for itrial in trial_record_clean['trial_number']:\n",
    "                ind = bhv_data[\"trial_number\"]==itrial\n",
    "                new_time_itrial = bhv_data[ind][\"time_points\"] + float(trial_record_clean[trial_record_clean['trial_number']==itrial]['trial_starttime'].iloc[0])\n",
    "                time_points_new[\"time_points_new\"][ind] = new_time_itrial\n",
    "            bhv_data[\"time_points\"] = time_points_new[\"time_points_new\"]\n",
    "            bhv_data = bhv_data[bhv_data[\"time_points\"] != 0]\n",
    "            #except:\n",
    "            #    trial_record_clean = trial_record\n",
    "\n",
    "            # get task type and cooperation threshold\n",
    "            try:\n",
    "                coop_thres = session_info[\"pulltime_thres\"][0]\n",
    "                tasktype = session_info[\"task_type\"][0]\n",
    "            except:\n",
    "                coop_thres = 0\n",
    "                tasktype = 1\n",
    "\n",
    "            # load behavioral event results\n",
    "            print('load social gaze with '+cameraID+' only of '+date_tgt)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_look_ornot.pkl', 'rb') as f:\n",
    "                output_look_ornot = pickle.load(f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allvectors.pkl', 'rb') as f:\n",
    "                output_allvectors = pickle.load(f)\n",
    "            with open(data_saved_folder+\"bhv_events_singlecam_wholebody/\"+animal1_fixedorder[0]+animal2_fixedorder[0]+\"/\"+cameraID+'/'+date_tgt+'/output_allangles.pkl', 'rb') as f:\n",
    "                output_allangles = pickle.load(f)  \n",
    "            #\n",
    "            look_at_other_or_not_merge = output_look_ornot['look_at_other_or_not_merge']\n",
    "            look_at_tube_or_not_merge = output_look_ornot['look_at_tube_or_not_merge']\n",
    "            look_at_lever_or_not_merge = output_look_ornot['look_at_lever_or_not_merge']\n",
    "            # change the unit to second\n",
    "            session_start_time = session_start_times[idate]\n",
    "            look_at_other_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_other_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "            look_at_lever_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_lever_or_not_merge['dodson'])[0],1)/fps - session_start_time\n",
    "            look_at_tube_or_not_merge['time_in_second'] = np.arange(0,np.shape(look_at_tube_or_not_merge['dodson'])[0],1)/fps - session_start_time \n",
    "\n",
    "            # redefine the totalsess_time for the length of each recording (NOT! remove the session_start_time)\n",
    "            totalsess_time = int(np.ceil(np.shape(look_at_other_or_not_merge['dodson'])[0]/fps))\n",
    "            \n",
    "            # find time point of behavioral events\n",
    "            output_time_points_socialgaze ,output_time_points_levertube = bhv_events_timepoint_singlecam(bhv_data,look_at_other_or_not_merge,look_at_lever_or_not_merge,look_at_tube_or_not_merge)\n",
    "            time_point_pull1 = output_time_points_socialgaze['time_point_pull1']\n",
    "            time_point_pull2 = output_time_points_socialgaze['time_point_pull2']\n",
    "            oneway_gaze1 = output_time_points_socialgaze['oneway_gaze1']\n",
    "            oneway_gaze2 = output_time_points_socialgaze['oneway_gaze2']\n",
    "            mutual_gaze1 = output_time_points_socialgaze['mutual_gaze1']\n",
    "            mutual_gaze2 = output_time_points_socialgaze['mutual_gaze2']   \n",
    "\n",
    "\n",
    "            if mergetempRos:\n",
    "                temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "                # use bhv event to decide temporal resolution\n",
    "                #\n",
    "                #low_lim,up_lim,_ = bhv_events_interval(totalsess_time, session_start_time, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "                #temp_resolus = temp_resolus = np.arange(low_lim,up_lim,0.1)\n",
    "\n",
    "            ntemp_reses = np.shape(temp_resolus)[0]           \n",
    "\n",
    "            # try different temporal resolutions\n",
    "            for temp_resolu in temp_resolus:\n",
    "                bhv_df = []\n",
    "\n",
    "                if np.isin(animal1,animal1_fixedorder):\n",
    "                    bhv_df_itr,_,_ = train_DBN_multiLag_create_df_only(totalsess_time, session_start_time, temp_resolu, time_point_pull1, time_point_pull2, oneway_gaze1, oneway_gaze2, mutual_gaze1, mutual_gaze2)\n",
    "                else:\n",
    "                    bhv_df_itr,_,_ = train_DBN_multiLag_create_df_only(totalsess_time, session_start_time, temp_resolu, time_point_pull2, time_point_pull1, oneway_gaze2, oneway_gaze1, mutual_gaze2, mutual_gaze1)     \n",
    "\n",
    "                if len(bhv_df)==0:\n",
    "                    bhv_df = bhv_df_itr\n",
    "                else:\n",
    "                    bhv_df = pd.concat([bhv_df,bhv_df_itr])                   \n",
    "                    bhv_df = bhv_df.reset_index(drop=True)        \n",
    "\n",
    "                # merge sessions from the same condition\n",
    "                for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "                    iDBN_group_typename = DBN_group_typenames[iDBN_group] \n",
    "                    iDBN_group_typeID =  DBN_group_typeIDs[iDBN_group] \n",
    "                    iDBN_group_cothres = DBN_group_coopthres[iDBN_group] \n",
    "\n",
    "                    # merge sessions \n",
    "                    if (tasktype!=3):\n",
    "                        if (tasktype==iDBN_group_typeID):\n",
    "                            if (len(DBN_input_data_alltypes[pulltype][iDBN_group_typename])==0):\n",
    "                                DBN_input_data_alltypes[pulltype][iDBN_group_typename] = bhv_df\n",
    "                            else:\n",
    "                                DBN_input_data_alltypes[pulltype][iDBN_group_typename] = pd.concat([DBN_input_data_alltypes[pulltype][iDBN_group_typename],bhv_df])\n",
    "                    else:\n",
    "                        if (coop_thres==iDBN_group_cothres):\n",
    "                            if (len(DBN_input_data_alltypes[pulltype][iDBN_group_typename])==0):\n",
    "                                DBN_input_data_alltypes[pulltype][iDBN_group_typename] = bhv_df\n",
    "                            else:\n",
    "                                DBN_input_data_alltypes[pulltype][iDBN_group_typename] = pd.concat([DBN_input_data_alltypes[pulltype][iDBN_group_typename],bhv_df])\n",
    "\n",
    "    # save data\n",
    "    if 1:\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "        if not os.path.exists(data_saved_subfolder):\n",
    "            os.makedirs(data_saved_subfolder)\n",
    "        if not mergetempRos:\n",
    "            with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'sReSo.pkl', 'wb') as f:\n",
    "                pickle.dump(DBN_input_data_alltypes, f)\n",
    "        else:\n",
    "            with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_mergeTempsReSo.pkl', 'wb') as f:\n",
    "                pickle.dump(DBN_input_data_alltypes, f)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3b62fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x153351c52160>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_resolu = 1\n",
    "data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "if not mergetempRos:\n",
    "    with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "        DBN_input_data_alltypes = pickle.load(f)\n",
    "else:\n",
    "    with open(data_saved_subfolder+'//DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "        DBN_input_data_alltypes = pickle.load(f)\n",
    "plt.plot(DBN_input_data_alltypes['succpull']['coop(1s)']['pull1_t0'].reset_index(drop=True))       \n",
    "plt.plot(DBN_input_data_alltypes['failedpull']['coop(1s)']['pull1_t0'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7080123a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15335ac2d0a0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_resolu = 1\n",
    "data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "if not mergetempRos:\n",
    "    with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "        DBN_input_data_alltypes = pickle.load(f)\n",
    "else:\n",
    "    with open(data_saved_subfolder+'//DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "        DBN_input_data_alltypes = pickle.load(f)\n",
    "plt.plot(DBN_input_data_alltypes['coop(1s)']['pull1_t0'].reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a743731",
   "metadata": {},
   "source": [
    "### run the DBN model on the combined session data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4d56009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define DBN related summarizing variables\n",
    "DBN_group_typenames = ['self','coop(3s)','coop(2s)','coop(1.5s)','coop(1s)','no-vision']\n",
    "DBN_group_typeIDs  =  [1,3,3,  3,3,5]\n",
    "DBN_group_coopthres = [0,3,2,1.5,1,0]\n",
    "nDBN_groups = np.shape(DBN_group_typenames)[0]\n",
    "\n",
    "pulltypes = ['succpull','failedpull']\n",
    "npulltypes = np.shape(pulltypes)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d7d323",
   "metadata": {},
   "source": [
    "#### a test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68d13d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run DBN on the large table with merged sessions\n",
    "\n",
    "mergetempRos = 0 # 1: merge different time bins\n",
    "\n",
    "moreSampSize = 0 # 1: use more sample size (more than just minimal row number and max row number)\n",
    "\n",
    "num_starting_points = 1 # number of random starting points/graphs\n",
    "nbootstraps = 1\n",
    "\n",
    "if 0:\n",
    "\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        samplingsizes = np.arange(1100,3000,100)\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "        nsamplings = np.shape(samplingsizes)[0]\n",
    "\n",
    "    weighted_graphs_diffTempRo_diffSampSize = {}\n",
    "    weighted_graphs_shuffled_diffTempRo_diffSampSize = {}\n",
    "    sig_edges_diffTempRo_diffSampSize = {}\n",
    "    DAGscores_diffTempRo_diffSampSize = {}\n",
    "    DAGscores_shuffled_diffTempRo_diffSampSize = {}\n",
    "\n",
    "    totalsess_time = 600 # total session time in s\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "\n",
    "    # analyze successful pull and failed pull separately\n",
    "    for pulltype in pulltypes:\n",
    "        \n",
    "        # try different temporal resolutions, remember to use the same settings as in the previous ones\n",
    "        for temp_resolu in temp_resolus:\n",
    "\n",
    "            data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "            if not mergetempRos:\n",
    "                with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "                    DBN_input_data_alltypes = pickle.load(f)\n",
    "            else:\n",
    "                with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "                    DBN_input_data_alltypes = pickle.load(f)\n",
    "            \n",
    "            DBN_input_data_alltypes = DBN_input_data_alltypes[pulltype]\n",
    "\n",
    "            # only try two sample sizes - minimal row number (require data downsample) and maximal row number (require data upsample)\n",
    "\n",
    "            if not moreSampSize:\n",
    "                key_to_value_lengths = {k:len(v) for k, v in DBN_input_data_alltypes.items()}\n",
    "                key_to_value_lengths_array = np.fromiter(key_to_value_lengths.values(),dtype=float)\n",
    "                key_to_value_lengths_array[key_to_value_lengths_array==0]=np.nan\n",
    "                min_samplesize = np.nanmin(key_to_value_lengths_array)\n",
    "                min_samplesize = int(min_samplesize/100)*100\n",
    "                max_samplesize = np.nanmax(key_to_value_lengths_array)\n",
    "                max_samplesize = int(max_samplesize/100)*100\n",
    "                samplingsizes = [min_samplesize,max_samplesize]\n",
    "                samplingsizes_name = ['min_row_number','max_row_number']   \n",
    "                nsamplings = np.shape(samplingsizes)[0]\n",
    "                print(samplingsizes)\n",
    "\n",
    "            # try different down/re-sampling size\n",
    "            # for jj in np.arange(0,nsamplings,1):\n",
    "            for jj in np.arange(0,1,1):\n",
    "\n",
    "                isamplingsize = samplingsizes[jj]\n",
    "\n",
    "                DAGs_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "                DAGs_shuffle_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "                DAGs_scores_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "                DAGs_shuffle_scores_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "\n",
    "                weighted_graphs_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "                weighted_graphs_shuffled_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "                sig_edges_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "\n",
    "                # different session conditions (aka DBN groups)\n",
    "                # for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "                for iDBN_group in np.arange(0,1,1):\n",
    "                    iDBN_group_typename = DBN_group_typenames[iDBN_group] \n",
    "                    iDBN_group_typeID =  DBN_group_typeIDs[iDBN_group] \n",
    "                    iDBN_group_cothres = DBN_group_coopthres[iDBN_group] \n",
    "\n",
    "                    try:\n",
    "                        bhv_df_all = DBN_input_data_alltypes[iDBN_group_typename]\n",
    "                        bhv_df_all = bhv_df_all.reset_index(drop=True)\n",
    "                        # bhv_df = bhv_df_all.sample(30*100,replace = True, random_state = round(time())) # take the subset for DBN training\n",
    "\n",
    "                        #Anirban(Alec) shuffle, slow\n",
    "                        # bhv_df_shuffle, df_shufflekeys = EfficientShuffle(bhv_df,round(time()))\n",
    "\n",
    "\n",
    "                        # define DBN graph structures; make sure they are the same as in the train_DBN_multiLag\n",
    "                        colnames = list(bhv_df_all.columns)\n",
    "                        eventnames = [\"pull1\",\"pull2\",\"owgaze1\",\"owgaze2\"]\n",
    "                        nevents = np.size(eventnames)\n",
    "\n",
    "                        all_pops = list(bhv_df_all.columns)\n",
    "                        from_pops = [pop for pop in all_pops if not pop.endswith('t3')]\n",
    "                        to_pops = [pop for pop in all_pops if pop.endswith('t3')]\n",
    "                        causal_whitelist = [(from_pop,to_pop) for from_pop in from_pops for to_pop in to_pops]\n",
    "\n",
    "                        nFromNodes = np.shape(from_pops)[0]\n",
    "                        nToNodes = np.shape(to_pops)[0]\n",
    "\n",
    "                        DAGs_randstart = np.zeros((num_starting_points, nFromNodes, nToNodes))\n",
    "                        DAGs_randstart_shuffle = np.zeros((num_starting_points, nFromNodes, nToNodes))\n",
    "                        score_randstart = np.zeros((num_starting_points))\n",
    "                        score_randstart_shuffle = np.zeros((num_starting_points))\n",
    "\n",
    "                        # step 1: randomize the starting point for num_starting_points times\n",
    "                        for istarting_points in np.arange(0,num_starting_points,1):\n",
    "\n",
    "                            # try different down/re-sampling size\n",
    "                            bhv_df = bhv_df_all.sample(isamplingsize,replace = True, random_state = istarting_points) # take the subset for DBN training\n",
    "                            aic = AicScore(bhv_df)\n",
    "\n",
    "                            #Anirban(Alec) shuffle, slow\n",
    "                            bhv_df_shuffle, df_shufflekeys = EfficientShuffle(bhv_df,round(time()))\n",
    "                            aic_shuffle = AicScore(bhv_df_shuffle)\n",
    "\n",
    "                            np.random.seed(istarting_points)\n",
    "                            random.seed(istarting_points)\n",
    "                            starting_edges = random.sample(causal_whitelist, np.random.randint(1,len(causal_whitelist)))\n",
    "                            starting_graph = DAG()\n",
    "                            starting_graph.add_nodes_from(nodes=all_pops)\n",
    "                            starting_graph.add_edges_from(ebunch=starting_edges)\n",
    "\n",
    "                            best_model,edges,DAGs = train_DBN_multiLag_training_only(bhv_df,starting_graph,colnames,eventnames,from_pops,to_pops)           \n",
    "                            DAGs[0][np.isnan(DAGs[0])]=0\n",
    "\n",
    "                            DAGs_randstart[istarting_points,:,:] = DAGs[0]\n",
    "                            score_randstart[istarting_points] = aic.score(best_model)\n",
    "\n",
    "                            # step 2: add the shffled data results\n",
    "                            # shuffled bhv_df\n",
    "                            best_model,edges,DAGs = train_DBN_multiLag_training_only(bhv_df_shuffle,starting_graph,colnames,eventnames,from_pops,to_pops)           \n",
    "                            DAGs[0][np.isnan(DAGs[0])]=0\n",
    "\n",
    "                            DAGs_randstart_shuffle[istarting_points,:,:] = DAGs[0]\n",
    "                            score_randstart_shuffle[istarting_points] = aic_shuffle.score(best_model)\n",
    "\n",
    "                        DAGs_alltypes[iDBN_group_typename] = DAGs_randstart \n",
    "                        DAGs_shuffle_alltypes[iDBN_group_typename] = DAGs_randstart_shuffle\n",
    "\n",
    "                        DAGs_scores_alltypes[iDBN_group_typename] = score_randstart\n",
    "                        DAGs_shuffle_scores_alltypes[iDBN_group_typename] = score_randstart_shuffle\n",
    "\n",
    "                        weighted_graphs = get_weighted_dags(DAGs_alltypes[iDBN_group_typename],nbootstraps)\n",
    "                        weighted_graphs_shuffled = get_weighted_dags(DAGs_shuffle_alltypes[iDBN_group_typename],nbootstraps)\n",
    "                        sig_edges = get_significant_edges(weighted_graphs,weighted_graphs_shuffled)\n",
    "\n",
    "                        weighted_graphs_alltypes[iDBN_group_typename] = weighted_graphs\n",
    "                        weighted_graphs_shuffled_alltypes[iDBN_group_typename] = weighted_graphs_shuffled\n",
    "                        sig_edges_alltypes[iDBN_group_typename] = sig_edges\n",
    "\n",
    "                    except:\n",
    "                        DAGs_alltypes[iDBN_group_typename] = [] \n",
    "                        DAGs_shuffle_alltypes[iDBN_group_typename] = []\n",
    "\n",
    "                        DAGs_scores_alltypes[iDBN_group_typename] = []\n",
    "                        DAGs_shuffle_scores_alltypes[iDBN_group_typename] = []\n",
    "\n",
    "                        weighted_graphs_alltypes[iDBN_group_typename] = []\n",
    "                        weighted_graphs_shuffled_alltypes[iDBN_group_typename] = []\n",
    "                        sig_edges_alltypes[iDBN_group_typename] = []\n",
    "\n",
    "                DAGscores_diffTempRo_diffSampSize[(pulltype,str(temp_resolu),samplingsizes_name[jj])] = DAGs_scores_alltypes\n",
    "                DAGscores_shuffled_diffTempRo_diffSampSize[(pulltype,str(temp_resolu),samplingsizes_name[jj])] = DAGs_shuffle_scores_alltypes\n",
    "\n",
    "                weighted_graphs_diffTempRo_diffSampSize[(pulltype,str(temp_resolu),samplingsizes_name[jj])] = weighted_graphs_alltypes\n",
    "                weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype,str(temp_resolu),samplingsizes_name[jj])] = weighted_graphs_shuffled_alltypes\n",
    "                sig_edges_diffTempRo_diffSampSize[(pulltype,str(temp_resolu),samplingsizes_name[jj])] = sig_edges_alltypes\n",
    "\n",
    "    print(weighted_graphs_diffTempRo_diffSampSize)\n",
    "            \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d647783a",
   "metadata": {},
   "source": [
    "#### run on the entire population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cafbb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run DBN on the large table with merged sessions\n",
    "\n",
    "mergetempRos = 0 # 1: merge different time bins\n",
    "\n",
    "moreSampSize = 0 # 1: use more sample size (more than just minimal row number and max row number)\n",
    "\n",
    "num_starting_points = 100 # number of random starting points/graphs\n",
    "nbootstraps = 95\n",
    "\n",
    "try:\n",
    "    # dumpy\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(data_saved_subfolder):\n",
    "        os.makedirs(data_saved_subfolder)\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/DAGscores_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'rb') as f:\n",
    "            DAGscores_diffTempRo_diffSampSize = pickle.load(f) \n",
    "        with open(data_saved_subfolder+'/DAGscores_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'rb') as f:\n",
    "            DAGscores_shuffled_diffTempRo_diffSampSize = pickle.load(f) \n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/DAGscores_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "            DAGscores_diffTempRo_diffSampSize = pickle.load(f) \n",
    "        with open(data_saved_subfolder+'/DAGscores_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "            DAGscores_shuffled_diffTempRo_diffSampSize = pickle.load(f) \n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "except:\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        samplingsizes = np.arange(1100,3000,100)\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "        nsamplings = np.shape(samplingsizes)[0]\n",
    "\n",
    "    weighted_graphs_diffTempRo_diffSampSize = {}\n",
    "    weighted_graphs_shuffled_diffTempRo_diffSampSize = {}\n",
    "    sig_edges_diffTempRo_diffSampSize = {}\n",
    "    DAGscores_diffTempRo_diffSampSize = {}\n",
    "    DAGscores_shuffled_diffTempRo_diffSampSize = {}\n",
    "\n",
    "    totalsess_time = 600 # total session time in s\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "\n",
    "     # analyze successful pull and failed pull separately\n",
    "    for pulltype in pulltypes:\n",
    "        \n",
    "        # try different temporal resolutions, remember to use the same settings as in the previous ones\n",
    "        for temp_resolu in temp_resolus:\n",
    "\n",
    "            data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "            if not mergetempRos:\n",
    "                with open(data_saved_subfolder+'/DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'sReSo.pkl', 'rb') as f:\n",
    "                    DBN_input_data_alltypes = pickle.load(f)\n",
    "            else:\n",
    "                with open(data_saved_subfolder+'//DBN_input_data_alltypes_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_mergeTempsReSo.pkl', 'rb') as f:\n",
    "                    DBN_input_data_alltypes = pickle.load(f)\n",
    "            #        \n",
    "            DBN_input_data_alltypes = DBN_input_data_alltypes[pulltype]\n",
    "\n",
    "            # only try two sample sizes - minimal row number (require data downsample) and maximal row number (require data upsample)\n",
    "\n",
    "            if not moreSampSize:\n",
    "                key_to_value_lengths = {k:len(v) for k, v in DBN_input_data_alltypes.items()}\n",
    "                key_to_value_lengths_array = np.fromiter(key_to_value_lengths.values(),dtype=float)\n",
    "                key_to_value_lengths_array[key_to_value_lengths_array==0]=np.nan\n",
    "                min_samplesize = np.nanmin(key_to_value_lengths_array)\n",
    "                min_samplesize = int(min_samplesize/100)*100\n",
    "                max_samplesize = np.nanmax(key_to_value_lengths_array)\n",
    "                max_samplesize = int(max_samplesize/100)*100\n",
    "                # samplingsizes = [min_samplesize,max_samplesize]\n",
    "                samplingsizes = [min_samplesize]\n",
    "                # samplingsizes_name = ['min_row_number','max_row_number'] \n",
    "                samplingsizes_name = ['min_row_number'] \n",
    "                nsamplings = np.shape(samplingsizes)[0]\n",
    "                print(samplingsizes)\n",
    "\n",
    "            # try different down/re-sampling size\n",
    "            for jj in np.arange(0,nsamplings,1):\n",
    "\n",
    "                isamplingsize = samplingsizes[jj]\n",
    "\n",
    "                DAGs_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "                DAGs_shuffle_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "                DAGs_scores_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "                DAGs_shuffle_scores_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "\n",
    "                weighted_graphs_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "                weighted_graphs_shuffled_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "                sig_edges_alltypes = dict.fromkeys(DBN_group_typenames, [])\n",
    "\n",
    "                # different session conditions (aka DBN groups)\n",
    "                for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "                    iDBN_group_typename = DBN_group_typenames[iDBN_group] \n",
    "                    iDBN_group_typeID =  DBN_group_typeIDs[iDBN_group] \n",
    "                    iDBN_group_cothres = DBN_group_coopthres[iDBN_group] \n",
    "\n",
    "                    try:\n",
    "                        bhv_df_all = DBN_input_data_alltypes[iDBN_group_typename]\n",
    "                        bhv_df_all = bhv_df_all.reset_index(drop=True)\n",
    "                        # bhv_df = bhv_df_all.sample(30*100,replace = True, random_state = round(time())) # take the subset for DBN training\n",
    "\n",
    "                        #Anirban(Alec) shuffle, slow\n",
    "                        # bhv_df_shuffle, df_shufflekeys = EfficientShuffle(bhv_df,round(time()))\n",
    "\n",
    "\n",
    "                        # define DBN graph structures; make sure they are the same as in the train_DBN_multiLag\n",
    "                        colnames = list(bhv_df_all.columns)\n",
    "                        eventnames = [\"pull1\",\"pull2\",\"owgaze1\",\"owgaze2\"]\n",
    "                        nevents = np.size(eventnames)\n",
    "\n",
    "                        all_pops = list(bhv_df_all.columns)\n",
    "                        from_pops = [pop for pop in all_pops if not pop.endswith('t3')]\n",
    "                        to_pops = [pop for pop in all_pops if pop.endswith('t3')]\n",
    "                        causal_whitelist = [(from_pop,to_pop) for from_pop in from_pops for to_pop in to_pops]\n",
    "\n",
    "                        nFromNodes = np.shape(from_pops)[0]\n",
    "                        nToNodes = np.shape(to_pops)[0]\n",
    "\n",
    "                        DAGs_randstart = np.zeros((num_starting_points, nFromNodes, nToNodes))\n",
    "                        DAGs_randstart_shuffle = np.zeros((num_starting_points, nFromNodes, nToNodes))\n",
    "                        score_randstart = np.zeros((num_starting_points))\n",
    "                        score_randstart_shuffle = np.zeros((num_starting_points))\n",
    "\n",
    "                        # step 1: randomize the starting point for num_starting_points times\n",
    "                        for istarting_points in np.arange(0,num_starting_points,1):\n",
    "\n",
    "                            # try different down/re-sampling size\n",
    "                            bhv_df = bhv_df_all.sample(isamplingsize,replace = True, random_state = istarting_points) # take the subset for DBN training\n",
    "                            aic = AicScore(bhv_df)\n",
    "\n",
    "                            #Anirban(Alec) shuffle, slow\n",
    "                            bhv_df_shuffle, df_shufflekeys = EfficientShuffle(bhv_df,round(time()))\n",
    "                            aic_shuffle = AicScore(bhv_df_shuffle)\n",
    "\n",
    "                            np.random.seed(istarting_points)\n",
    "                            random.seed(istarting_points)\n",
    "                            starting_edges = random.sample(causal_whitelist, np.random.randint(1,len(causal_whitelist)))\n",
    "                            starting_graph = DAG()\n",
    "                            starting_graph.add_nodes_from(nodes=all_pops)\n",
    "                            starting_graph.add_edges_from(ebunch=starting_edges)\n",
    "\n",
    "                            best_model,edges,DAGs = train_DBN_multiLag_training_only(bhv_df,starting_graph,colnames,eventnames,from_pops,to_pops)           \n",
    "                            DAGs[0][np.isnan(DAGs[0])]=0\n",
    "\n",
    "                            DAGs_randstart[istarting_points,:,:] = DAGs[0]\n",
    "                            score_randstart[istarting_points] = aic.score(best_model)\n",
    "\n",
    "                            # step 2: add the shffled data results\n",
    "                            # shuffled bhv_df\n",
    "                            best_model,edges,DAGs = train_DBN_multiLag_training_only(bhv_df_shuffle,starting_graph,colnames,eventnames,from_pops,to_pops)           \n",
    "                            DAGs[0][np.isnan(DAGs[0])]=0\n",
    "\n",
    "                            DAGs_randstart_shuffle[istarting_points,:,:] = DAGs[0]\n",
    "                            score_randstart_shuffle[istarting_points] = aic_shuffle.score(best_model)\n",
    "\n",
    "                        DAGs_alltypes[iDBN_group_typename] = DAGs_randstart \n",
    "                        DAGs_shuffle_alltypes[iDBN_group_typename] = DAGs_randstart_shuffle\n",
    "\n",
    "                        DAGs_scores_alltypes[iDBN_group_typename] = score_randstart\n",
    "                        DAGs_shuffle_scores_alltypes[iDBN_group_typename] = score_randstart_shuffle\n",
    "\n",
    "                        weighted_graphs = get_weighted_dags(DAGs_alltypes[iDBN_group_typename],nbootstraps)\n",
    "                        weighted_graphs_shuffled = get_weighted_dags(DAGs_shuffle_alltypes[iDBN_group_typename],nbootstraps)\n",
    "                        sig_edges = get_significant_edges(weighted_graphs,weighted_graphs_shuffled)\n",
    "\n",
    "                        weighted_graphs_alltypes[iDBN_group_typename] = weighted_graphs\n",
    "                        weighted_graphs_shuffled_alltypes[iDBN_group_typename] = weighted_graphs_shuffled\n",
    "                        sig_edges_alltypes[iDBN_group_typename] = sig_edges\n",
    "\n",
    "                    except:\n",
    "                        DAGs_alltypes[iDBN_group_typename] = [] \n",
    "                        DAGs_shuffle_alltypes[iDBN_group_typename] = []\n",
    "\n",
    "                        DAGs_scores_alltypes[iDBN_group_typename] = []\n",
    "                        DAGs_shuffle_scores_alltypes[iDBN_group_typename] = []\n",
    "\n",
    "                        weighted_graphs_alltypes[iDBN_group_typename] = []\n",
    "                        weighted_graphs_shuffled_alltypes[iDBN_group_typename] = []\n",
    "                        sig_edges_alltypes[iDBN_group_typename] = []\n",
    "\n",
    "                DAGscores_diffTempRo_diffSampSize[(pulltype,str(temp_resolu),samplingsizes_name[jj])] = DAGs_scores_alltypes\n",
    "                DAGscores_shuffled_diffTempRo_diffSampSize[(pulltype,str(temp_resolu),samplingsizes_name[jj])] = DAGs_shuffle_scores_alltypes\n",
    "\n",
    "                weighted_graphs_diffTempRo_diffSampSize[(pulltype,str(temp_resolu),samplingsizes_name[jj])] = weighted_graphs_alltypes\n",
    "                weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype,str(temp_resolu),samplingsizes_name[jj])] = weighted_graphs_shuffled_alltypes\n",
    "                sig_edges_diffTempRo_diffSampSize[(pulltype,str(temp_resolu),samplingsizes_name[jj])] = sig_edges_alltypes\n",
    "\n",
    "            \n",
    "    # save data\n",
    "    savedata = 1\n",
    "    if savedata:\n",
    "        data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "        if not os.path.exists(data_saved_subfolder):\n",
    "            os.makedirs(data_saved_subfolder)\n",
    "        if moreSampSize:  \n",
    "            with open(data_saved_subfolder+'/DAGscores_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'wb') as f:\n",
    "                pickle.dump(DAGscores_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/DAGscores_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'wb') as f:\n",
    "                pickle.dump(DAGscores_shuffled_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'wb') as f:\n",
    "                pickle.dump(weighted_graphs_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'wb') as f:\n",
    "                pickle.dump(weighted_graphs_shuffled_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'_moreSampSize.pkl', 'wb') as f:\n",
    "                pickle.dump(sig_edges_diffTempRo_diffSampSize, f)\n",
    "\n",
    "        else:\n",
    "            with open(data_saved_subfolder+'/DAGscores_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "                pickle.dump(DAGscores_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/DAGscores_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "                pickle.dump(DAGscores_shuffled_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "                pickle.dump(weighted_graphs_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "                pickle.dump(weighted_graphs_shuffled_diffTempRo_diffSampSize, f)\n",
    "            with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder[0]+animal2_fixedorder[0]+'.pkl', 'wb') as f:\n",
    "                pickle.dump(sig_edges_diffTempRo_diffSampSize, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3077623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for self condition, use the same for failed pull and succ pull\n",
    "# DAGscores_diffTempRo_diffSampSize[('failedpull', '1', 'max_row_number')]['self']=DAGscores_diffTempRo_diffSampSize[('succpull', '1', 'max_row_number')]['self']\n",
    "# DAGscores_shuffled_diffTempRo_diffSampSize[('failedpull', '1', 'max_row_number')]['self']=DAGscores_shuffled_diffTempRo_diffSampSize[('succpull', '1', 'max_row_number')]['self']\n",
    "# weighted_graphs_diffTempRo_diffSampSize[('failedpull', '1', 'max_row_number')]['self']=weighted_graphs_diffTempRo_diffSampSize[('succpull', '1', 'max_row_number')]['self']\n",
    "# weighted_graphs_shuffled_diffTempRo_diffSampSize[('failedpull', '1', 'max_row_number')]['self']=weighted_graphs_shuffled_diffTempRo_diffSampSize[('succpull', '1', 'max_row_number')]['self']\n",
    "# sig_edges_diffTempRo_diffSampSize[('failedpull', '1', 'max_row_number')]['self']=sig_edges_diffTempRo_diffSampSize[('succpull', '1', 'max_row_number')]['self']\n",
    "\n",
    "DAGscores_diffTempRo_diffSampSize[('failedpull', '1', 'min_row_number')]['self']=DAGscores_diffTempRo_diffSampSize[('succpull', '1', 'min_row_number')]['self']\n",
    "DAGscores_shuffled_diffTempRo_diffSampSize[('failedpull', '1', 'min_row_number')]['self']=DAGscores_shuffled_diffTempRo_diffSampSize[('succpull', '1', 'min_row_number')]['self']\n",
    "weighted_graphs_diffTempRo_diffSampSize[('failedpull', '1', 'min_row_number')]['self']=weighted_graphs_diffTempRo_diffSampSize[('succpull', '1', 'min_row_number')]['self']\n",
    "weighted_graphs_shuffled_diffTempRo_diffSampSize[('failedpull', '1', 'min_row_number')]['self']=weighted_graphs_shuffled_diffTempRo_diffSampSize[('succpull', '1', 'min_row_number')]['self']\n",
    "sig_edges_diffTempRo_diffSampSize[('failedpull', '1', 'min_row_number')]['self']=sig_edges_diffTempRo_diffSampSize[('succpull', '1', 'min_row_number')]['self']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf1eea",
   "metadata": {},
   "source": [
    "### plot graphs - show the edge with arrows; show the best time bin and row number; show the three time lag separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FOR PLOT!! \n",
    "# define DBN related summarizing variables\n",
    "DBN_group_typenames = ['self','coop(1s)','no-vision']\n",
    "DBN_group_typeIDs  =  [1,3,5]\n",
    "DBN_group_coopthres = [0,1,0]\n",
    "nDBN_groups = np.shape(DBN_group_typenames)[0]\n",
    "\n",
    "pulltype_forplot = 'succpull' # 'succpull' or 'failedpull'\n",
    "\n",
    "# make sure these variables are the same as in the previous steps\n",
    "# temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "ntemp_reses = np.shape(temp_resolus)[0]\n",
    "#\n",
    "if moreSampSize:\n",
    "    # different data (down/re)sampling numbers\n",
    "    # samplingsizes = np.arange(1100,3000,100)\n",
    "    samplingsizes = [1100]\n",
    "    # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "    # samplingsizes = [100,500]\n",
    "    # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "    samplingsizes_name = list(map(str, samplingsizes))\n",
    "else:\n",
    "    samplingsizes_name = ['min_row_number']   \n",
    "nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "# make sure these variables are consistent with the train_DBN_alec.py settings\n",
    "# eventnames = [\"pull1\",\"pull2\",\"gaze1\",\"gaze2\"]\n",
    "eventnames = [\"M1pull\",\"M2pull\",\"M1gaze\",\"M2gaze\"]\n",
    "eventnode_locations = [[0,1],[1,1],[0,0],[1,0]]\n",
    "eventname_locations = [[-0.5,1.0],[1.2,1],[-0.6,0],[1.2,0]]\n",
    "# indicate where edge starts\n",
    "# for the self edge, it's the center of the self loop\n",
    "nodearrow_locations = [[[0.00,1.25],[0.25,1.10],[-.10,0.75],[0.15,0.65]],\n",
    "                       [[0.75,1.00],[1.00,1.25],[0.85,0.65],[1.10,0.75]],\n",
    "                       [[0.00,0.25],[0.25,0.35],[0.00,-.25],[0.25,-.10]],\n",
    "                       [[0.75,0.35],[1.00,0.25],[0.75,0.00],[1.00,-.25]]]\n",
    "# indicate where edge goes\n",
    "# for the self edge, it's the theta1 and theta2 (with fixed radius)\n",
    "nodearrow_directions = [[[ -45,-180],[0.50,0.00],[0.00,-.50],[0.50,-.50]],\n",
    "                        [[-.50,0.00],[ -45,-180],[-.50,-.50],[0.00,-.50]],\n",
    "                        [[0.00,0.50],[0.50,0.50],[ 180,  45],[0.50,0.00]],\n",
    "                        [[-.50,0.50],[0.00,0.50],[-.50,0.00],[ 180,  45]]]\n",
    "\n",
    "nevents = np.size(eventnames)\n",
    "# eventnodes_color = ['b','r','y','g']\n",
    "eventnodes_color = ['#BF3EFF','#FF7F00','#BF3EFF','#FF7F00']\n",
    "eventnodes_shape = [\"o\",\"o\",\"^\",\"^\"]\n",
    "    \n",
    "savefigs = 1\n",
    "\n",
    "# different session conditions (aka DBN groups)\n",
    "# different time lags (t_-3, t_-2 and t_-1)\n",
    "fig, axs = plt.subplots(6,nDBN_groups)\n",
    "fig.set_figheight(48)\n",
    "fig.set_figwidth(8*nDBN_groups)\n",
    "\n",
    "time_lags = ['t_-3','t_-2','t_-1']\n",
    "fromRowIDs =[[0,1,2,3],[4,5,6,7],[8,9,10,11]]\n",
    "ntime_lags = np.shape(time_lags)[0]\n",
    "\n",
    "temp_resolu = temp_resolus[0]\n",
    "j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "for ilag in np.arange(0,ntime_lags,1):\n",
    "    \n",
    "    time_lag_name = time_lags[ilag]\n",
    "    fromRowID = fromRowIDs[ilag]\n",
    "    \n",
    "    for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "\n",
    "        try:\n",
    "\n",
    "            iDBN_group_typename = DBN_group_typenames[iDBN_group]\n",
    "\n",
    "            weighted_graphs_tgt = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            weighted_graphs_shuffled_tgt = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            # sig_edges_tgt = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            sig_edges_tgt = get_significant_edges(weighted_graphs_tgt,weighted_graphs_shuffled_tgt)\n",
    "           \n",
    "            #sig_edges_tgt = sig_edges_tgt*((weighted_graphs_tgt.mean(axis=0)>0.5)*1)\n",
    "            \n",
    "            sig_avg_dags = weighted_graphs_tgt.mean(axis = 0) * sig_edges_tgt\n",
    "            sig_avg_dags = sig_avg_dags[fromRowID,:]\n",
    "\n",
    "            # plot\n",
    "            axs[ilag*2+0,iDBN_group].set_title(pulltype_forplot+' '+iDBN_group_typename,fontsize=18)\n",
    "            axs[ilag*2+0,iDBN_group].set_xlim([-0.5,1.5])\n",
    "            axs[ilag*2+0,iDBN_group].set_ylim([-0.5,1.5])\n",
    "            axs[ilag*2+0,iDBN_group].set_xticks([])\n",
    "            axs[ilag*2+0,iDBN_group].set_xticklabels([])\n",
    "            axs[ilag*2+0,iDBN_group].set_yticks([])\n",
    "            axs[ilag*2+0,iDBN_group].set_yticklabels([])\n",
    "            axs[ilag*2+0,iDBN_group].spines['top'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['right'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['bottom'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['left'].set_visible(False)\n",
    "            # axs[ilag*2+0,iDBN_group].axis('equal')\n",
    "\n",
    "            \n",
    "            for ieventnode in np.arange(0,nevents,1):\n",
    "                # plot the event nodes\n",
    "                axs[ilag*2+0,iDBN_group].plot(eventnode_locations[ieventnode][0],eventnode_locations[ieventnode][1],\n",
    "                                              eventnodes_shape[ieventnode],markersize=60,markerfacecolor=eventnodes_color[ieventnode],\n",
    "                                              markeredgecolor='none')              \n",
    "                #axs[ilag*2+0,iDBN_group].text(eventname_locations[ieventnode][0],eventname_locations[ieventnode][1],\n",
    "                #                       eventnames[ieventnode],fontsize=15)\n",
    "                \n",
    "                clmap = mpl.cm.get_cmap('Greens')\n",
    "                \n",
    "                # plot the event edges\n",
    "                for ifromNode in np.arange(0,nevents,1):\n",
    "                    for itoNode in np.arange(0,nevents,1):\n",
    "                        edge_weight_tgt = sig_avg_dags[ifromNode,itoNode]\n",
    "                        if edge_weight_tgt>0:\n",
    "                            if not ifromNode == itoNode:\n",
    "                                #axs[ilag*2+0,iDBN_group].plot(eventnode_locations[ifromNode],eventnode_locations[itoNode],'k-',linewidth=edge_weight_tgt*3)\n",
    "                                axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0],\n",
    "                                                        nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                        nodearrow_directions[ifromNode][itoNode][0],\n",
    "                                                        nodearrow_directions[ifromNode][itoNode][1],\n",
    "                                                        # head_width=0.08*abs(edge_weight_tgt),\n",
    "                                                        # width=0.04*abs(edge_weight_tgt),\n",
    "                                                        head_width=0.08,\n",
    "                                                        width=0.04,   \n",
    "                                                        color = clmap(edge_weight_tgt))\n",
    "                            if ifromNode == itoNode:\n",
    "                                ring = mpatches.Wedge(nodearrow_locations[ifromNode][itoNode],\n",
    "                                                      .1, nodearrow_directions[ifromNode][itoNode][0],\n",
    "                                                      nodearrow_directions[ifromNode][itoNode][1], \n",
    "                                                      # 0.04*abs(edge_weight_tgt),\n",
    "                                                      0.04,\n",
    "                                                      color = clmap(edge_weight_tgt))\n",
    "                                p = PatchCollection(\n",
    "                                    [ring], \n",
    "                                    facecolor=clmap(edge_weight_tgt), \n",
    "                                    edgecolor=clmap(edge_weight_tgt)\n",
    "                                )\n",
    "                                axs[ilag*2+0,iDBN_group].add_collection(p)\n",
    "                                # add arrow head\n",
    "                                if ifromNode < 2:\n",
    "                                    axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0]-0.1+0.02*edge_weight_tgt,\n",
    "                                                            nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                            0,-0.05,color=clmap(edge_weight_tgt),\n",
    "                                                            # head_width=0.08*edge_weight_tgt,width=0.04*edge_weight_tgt\n",
    "                                                            head_width=0.08,width=0.04      \n",
    "                                                            )\n",
    "                                else:\n",
    "                                    axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0]-0.1+0.02*edge_weight_tgt,\n",
    "                                                            nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                            0,0.02,color=clmap(edge_weight_tgt),\n",
    "                                                            # head_width=0.08*edge_weight_tgt,width=0.04*edge_weight_tgt\n",
    "                                                            head_width=0.08,width=0.04      \n",
    "                                                            )\n",
    "\n",
    "            # heatmap for the weights\n",
    "            sig_avg_dags_df = pd.DataFrame(sig_avg_dags)\n",
    "            sig_avg_dags_df.columns = eventnames\n",
    "            sig_avg_dags_df.index = eventnames\n",
    "            vmin,vmax = 0,1\n",
    "            import matplotlib as mpl\n",
    "            norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "            im = axs[ilag*2+1,iDBN_group].pcolormesh(sig_avg_dags_df,cmap=\"Greens\",norm=norm)\n",
    "            #\n",
    "            if iDBN_group == nDBN_groups-1:\n",
    "                cax = axs[ilag*2+1,iDBN_group].inset_axes([1.04, 0.2, 0.05, 0.8])\n",
    "                fig.colorbar(im, ax=axs[ilag*2+1,iDBN_group], cax=cax,label='edge confidence')\n",
    "\n",
    "            axs[ilag*2+1,iDBN_group].axis('equal')\n",
    "            axs[ilag*2+1,iDBN_group].set_xlabel('to Node',fontsize=14)\n",
    "            axs[ilag*2+1,iDBN_group].set_xticks(np.arange(0.5,4.5,1))\n",
    "            axs[ilag*2+1,iDBN_group].set_xticklabels(eventnames)\n",
    "            if iDBN_group == 0:\n",
    "                axs[ilag*2+1,iDBN_group].set_ylabel('from Node',fontsize=14)\n",
    "                axs[ilag*2+1,iDBN_group].set_yticks(np.arange(0.5,4.5,1))\n",
    "                axs[ilag*2+1,iDBN_group].set_yticklabels(eventnames)\n",
    "                axs[ilag*2+1,iDBN_group].text(-1.5,1,time_lag_name+' time lag',rotation=90,fontsize=20)\n",
    "                axs[ilag*2+0,iDBN_group].text(-1.25,0,time_lag_name+' time lag',rotation=90,fontsize=20)\n",
    "            else:\n",
    "                axs[ilag*2+1,iDBN_group].set_yticks([])\n",
    "                axs[ilag*2+1,iDBN_group].set_yticklabels([])\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    if moreSampSize:\n",
    "        plt.savefig(figsavefolder+\"threeTimeLag_DAGs_\"+pulltype_forplot+\"_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows.pdf')\n",
    "    else:  \n",
    "        plt.savefig(figsavefolder+\"threeTimeLag_DAGs_\"+pulltype_forplot+\"_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'_'+j_sampsize_name+'.pdf')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34546be",
   "metadata": {},
   "source": [
    "### plot graphs - show the edge differences, use one condition as the base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FOR PLOT!! \n",
    "# define DBN related summarizing variables\n",
    "DBN_group_typenames = ['self','coop(1s)','no-vision']\n",
    "DBN_group_typeIDs  =  [1,3,5]\n",
    "DBN_group_coopthres = [0,1,0]\n",
    "nDBN_groups = np.shape(DBN_group_typenames)[0]\n",
    "\n",
    "pulltype_forplot = 'failedpull' # 'succpull' or 'failedpull'\n",
    "\n",
    "# make sure these variables are the same as in the previous steps\n",
    "# temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "ntemp_reses = np.shape(temp_resolus)[0]\n",
    "#\n",
    "if moreSampSize:\n",
    "    # different data (down/re)sampling numbers\n",
    "    # samplingsizes = np.arange(1100,3000,100)\n",
    "    samplingsizes = [1100]\n",
    "    # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "    # samplingsizes = [100,500]\n",
    "    # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "    samplingsizes_name = list(map(str, samplingsizes))\n",
    "else:\n",
    "    samplingsizes_name = ['min_row_number']   \n",
    "nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "basecondition = 'coop(1s)'\n",
    "\n",
    "# make sure these variables are consistent with the train_DBN_alec.py settings\n",
    "# eventnames = [\"pull1\",\"pull2\",\"gaze1\",\"gaze2\"]\n",
    "eventnames = [\"M1pull\",\"M2pull\",\"M1gaze\",\"M2gaze\"]\n",
    "eventnode_locations = [[0,1],[1,1],[0,0],[1,0]]\n",
    "eventname_locations = [[-0.5,1.0],[1.2,1],[-0.6,0],[1.2,0]]\n",
    "# indicate where edge starts\n",
    "# for the self edge, it's the center of the self loop\n",
    "nodearrow_locations = [[[0.00,1.25],[0.25,1.10],[-.10,0.75],[0.15,0.65]],\n",
    "                       [[0.75,1.00],[1.00,1.25],[0.85,0.65],[1.10,0.75]],\n",
    "                       [[0.00,0.25],[0.25,0.35],[0.00,-.25],[0.25,-.10]],\n",
    "                       [[0.75,0.35],[1.00,0.25],[0.75,0.00],[1.00,-.25]]]\n",
    "# indicate where edge goes\n",
    "# for the self edge, it's the theta1 and theta2 (with fixed radius)\n",
    "nodearrow_directions = [[[ -45,-180],[0.50,0.00],[0.00,-.50],[0.50,-.50]],\n",
    "                        [[-.50,0.00],[ -45,-180],[-.50,-.50],[0.00,-.50]],\n",
    "                        [[0.00,0.50],[0.50,0.50],[ 180,  45],[0.50,0.00]],\n",
    "                        [[-.50,0.50],[0.00,0.50],[-.50,0.00],[ 180,  45]]]\n",
    "\n",
    "nevents = np.size(eventnames)\n",
    "# eventnodes_color = ['b','r','y','g']\n",
    "eventnodes_color = ['#BF3EFF','#FF7F00','#BF3EFF','#FF7F00']\n",
    "eventnodes_shape = [\"o\",\"o\",\"^\",\"^\"]\n",
    "\n",
    "nFromNodes = nevents\n",
    "nToNodes = nevents\n",
    "    \n",
    "savefigs = 1\n",
    "\n",
    "# different session conditions (aka DBN groups)\n",
    "# different time lags (t_-3, t_-2 and t_-1)\n",
    "fig, axs = plt.subplots(6,nDBN_groups)\n",
    "fig.set_figheight(48)\n",
    "fig.set_figwidth(8*nDBN_groups)\n",
    "\n",
    "time_lags = ['t_-3','t_-2','t_-1']\n",
    "fromRowIDs =[[0,1,2,3],[4,5,6,7],[8,9,10,11]]\n",
    "ntime_lags = np.shape(time_lags)[0]\n",
    "\n",
    "temp_resolu = temp_resolus[0]\n",
    "j_sampsize_name = samplingsizes_name[0]    \n",
    "    \n",
    "weighted_graphs_tgt = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)][basecondition]\n",
    "weighted_graphs_shuffled_tgt = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)][basecondition]\n",
    "#sig_edges_tgt = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)][basecondition]\n",
    "sig_edges_tgt = get_significant_edges(weighted_graphs_tgt,weighted_graphs_shuffled_tgt)\n",
    "           \n",
    "# sig_edges_tgt = sig_edges_tgt*((weighted_graphs_tgt.mean(axis=0)>0.5)*1)\n",
    "\n",
    "weighted_graphs_base = weighted_graphs_tgt\n",
    "\n",
    "sig_edges_base = sig_edges_tgt\n",
    "\n",
    "sig_avg_dags_base =  weighted_graphs_base.mean(axis = 0) * sig_edges_base\n",
    "    \n",
    "    \n",
    "for ilag in np.arange(0,ntime_lags,1):\n",
    "    \n",
    "    time_lag_name = time_lags[ilag]\n",
    "    fromRowID = fromRowIDs[ilag]\n",
    "    \n",
    "       \n",
    "    for iDBN_group in np.arange(0,nDBN_groups,1):\n",
    "\n",
    "        try:\n",
    "\n",
    "            iDBN_group_typename = DBN_group_typenames[iDBN_group]\n",
    "\n",
    "\n",
    "            weighted_graphs_tgt = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            weighted_graphs_shuffled_tgt = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            # sig_edges_tgt = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)][iDBN_group_typename]\n",
    "            sig_edges_tgt = get_significant_edges(weighted_graphs_tgt,weighted_graphs_shuffled_tgt)\n",
    "           \n",
    "            #sig_edges_tgt = sig_edges_tgt*((weighted_graphs_tgt.mean(axis=0)>0.5)*1)\n",
    "            \n",
    "            if 0:\n",
    "                weighted_graphs_delta = (weighted_graphs_tgt-weighted_graphs_base)\n",
    "                weighted_graphs_delta = weighted_graphs_delta.mean(axis=0)\n",
    "                #\n",
    "                sig_edges_delta = ((sig_edges_tgt+sig_edges_base)>0)*1\n",
    "            else:\n",
    "                weighted_graphs_delta,sig_edges_delta = Modulation_Index(weighted_graphs_base, weighted_graphs_tgt,\n",
    "                                                                         sig_edges_base, sig_edges_tgt, 8000)\n",
    "                weighted_graphs_delta = weighted_graphs_delta.mean(axis=0)\n",
    "                \n",
    "            sig_avg_dags = weighted_graphs_delta * sig_edges_delta\n",
    "            sig_avg_dags = sig_avg_dags[fromRowID,:]\n",
    "\n",
    "            # plot\n",
    "            axs[ilag*2+0,iDBN_group].set_title(iDBN_group_typename,fontsize=18)\n",
    "            axs[ilag*2+0,iDBN_group].set_xlim([-0.5,1.5])\n",
    "            axs[ilag*2+0,iDBN_group].set_ylim([-0.5,1.5])\n",
    "            axs[ilag*2+0,iDBN_group].set_xticks([])\n",
    "            axs[ilag*2+0,iDBN_group].set_xticklabels([])\n",
    "            axs[ilag*2+0,iDBN_group].set_yticks([])\n",
    "            axs[ilag*2+0,iDBN_group].set_yticklabels([])\n",
    "            axs[ilag*2+0,iDBN_group].spines['top'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['right'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['bottom'].set_visible(False)\n",
    "            axs[ilag*2+0,iDBN_group].spines['left'].set_visible(False)\n",
    "            # axs[ilag*2+0,iDBN_group].axis('equal')\n",
    "\n",
    "            for ieventnode in np.arange(0,nevents,1):\n",
    "                # plot the event nodes\n",
    "                axs[ilag*2+0,iDBN_group].plot(eventnode_locations[ieventnode][0],eventnode_locations[ieventnode][1],\n",
    "                                              eventnodes_shape[ieventnode],markersize=60,markerfacecolor=eventnodes_color[ieventnode],\n",
    "                                              markeredgecolor='none')              \n",
    "                \n",
    "                #axs[ilag*2+0,iDBN_group].text(eventname_locations[ieventnode][0],eventname_locations[ieventnode][1],\n",
    "                #                       eventnames[ieventnode],fontsize=10)\n",
    "                \n",
    "                clmap = mpl.cm.get_cmap('bwr')\n",
    "                \n",
    "                # plot the event edges\n",
    "                for ifromNode in np.arange(0,nevents,1):\n",
    "                    for itoNode in np.arange(0,nevents,1):\n",
    "                        edge_weight_tgt = sig_avg_dags[ifromNode,itoNode]\n",
    "                        if edge_weight_tgt!=0:\n",
    "                            if not ifromNode == itoNode:\n",
    "                                #axs[ilag*2+0,iDBN_group].plot(eventnode_locations[ifromNode],eventnode_locations[itoNode],'k-',linewidth=edge_weight_tgt*3)\n",
    "                                axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0],\n",
    "                                                        nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                        nodearrow_directions[ifromNode][itoNode][0],\n",
    "                                                        nodearrow_directions[ifromNode][itoNode][1],\n",
    "                                                        # head_width=0.08*abs(edge_weight_tgt),\n",
    "                                                        # width=0.04*abs(edge_weight_tgt),\n",
    "                                                        head_width=0.08,\n",
    "                                                        width=0.04,       \n",
    "                                                        color = clmap((1+edge_weight_tgt)/2))\n",
    "                            if ifromNode == itoNode:\n",
    "                                ring = mpatches.Wedge(nodearrow_locations[ifromNode][itoNode],\n",
    "                                                      .1, nodearrow_directions[ifromNode][itoNode][0],\n",
    "                                                      nodearrow_directions[ifromNode][itoNode][1], \n",
    "                                                      # 0.04*abs(edge_weight_tgt)\n",
    "                                                      0.04\n",
    "                                                     )\n",
    "                                p = PatchCollection(\n",
    "                                    [ring], \n",
    "                                    facecolor=clmap((1+edge_weight_tgt)/2), \n",
    "                                    edgecolor=clmap((1+edge_weight_tgt)/2)\n",
    "                                )\n",
    "                                axs[ilag*2+0,iDBN_group].add_collection(p)\n",
    "                                # add arrow head\n",
    "                                if ifromNode < 2:\n",
    "                                    axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0]-0.1+0.02*edge_weight_tgt,\n",
    "                                                            nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                            0,-0.05,color=clmap((1+edge_weight_tgt)/2),\n",
    "                                                            # head_width=0.08*edge_weight_tgt,width=0.04*edge_weight_tgt\n",
    "                                                            head_width=0.08,width=0.04      \n",
    "                                                            )\n",
    "                                else:\n",
    "                                    axs[ilag*2+0,iDBN_group].arrow(nodearrow_locations[ifromNode][itoNode][0]-0.1+0.02*edge_weight_tgt,\n",
    "                                                            nodearrow_locations[ifromNode][itoNode][1],\n",
    "                                                            0,0.02,color=clmap((1+edge_weight_tgt)/2),\n",
    "                                                            # head_width=0.08*edge_weight_tgt,width=0.04*edge_weight_tgt\n",
    "                                                            head_width=0.08,width=0.04      \n",
    "                                                            )\n",
    "\n",
    "            # heatmap for the weights\n",
    "            sig_avg_dags_df = pd.DataFrame(sig_avg_dags)\n",
    "            sig_avg_dags_df.columns = eventnames\n",
    "            sig_avg_dags_df.index = eventnames\n",
    "            vmin,vmax = -1,1\n",
    "            norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "            im = axs[ilag*2+1,iDBN_group].pcolormesh(sig_avg_dags_df,cmap=\"bwr\",norm=norm)\n",
    "            #-\n",
    "            if iDBN_group == nDBN_groups-1:\n",
    "                cax = axs[ilag*2+1,iDBN_group].inset_axes([1.04, 0.2, 0.05, 0.8])\n",
    "                fig.colorbar(im, ax=axs[ilag*2+1,iDBN_group], cax=cax,label='edge confidence')\n",
    "\n",
    "            axs[ilag*2+1,iDBN_group].axis('equal')\n",
    "            axs[ilag*2+1,iDBN_group].set_xlabel('to Node',fontsize=14)\n",
    "            axs[ilag*2+1,iDBN_group].set_xticks(np.arange(0.5,4.5,1))\n",
    "            axs[ilag*2+1,iDBN_group].set_xticklabels(eventnames)\n",
    "            if iDBN_group == 0:\n",
    "                axs[ilag*2+1,iDBN_group].set_ylabel('from Node',fontsize=14)\n",
    "                axs[ilag*2+1,iDBN_group].set_yticks(np.arange(0.5,4.5,1))\n",
    "                axs[ilag*2+1,iDBN_group].set_yticklabels(eventnames)\n",
    "                axs[ilag*2+1,iDBN_group].text(-1.5,1,time_lag_name+' time lag',rotation=90,fontsize=20)\n",
    "                axs[ilag*2+0,iDBN_group].text(-1.25,0,time_lag_name+' time lag',rotation=90,fontsize=20)\n",
    "            else:\n",
    "                axs[ilag*2+1,iDBN_group].set_yticks([])\n",
    "                axs[ilag*2+1,iDBN_group].set_yticklabels([])\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "if savefigs:\n",
    "    figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'+animal1_fixedorder[0]+animal2_fixedorder[0]+'/'\n",
    "    if not os.path.exists(figsavefolder):\n",
    "        os.makedirs(figsavefolder)\n",
    "    if moreSampSize:\n",
    "        plt.savefig(figsavefolder+\"threeTimeLag_DAGs_\"+pulltype_forplot+\"_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_EdgeFifferenceFrom_'+basecondition+'AsBase.pdf')\n",
    "    else:\n",
    "        plt.savefig(figsavefolder+\"threeTimeLag_DAGs_\"+pulltype_forplot+\"_\"+animal1_fixedorder[0]+animal2_fixedorder[0]+'_'+str(temp_resolu)+'_'+j_sampsize_name+'_EdgeFifferenceFrom_'+basecondition+'AsBase.pdf')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed62ef",
   "metadata": {},
   "source": [
    "## Plots that include all pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee15a992",
   "metadata": {},
   "source": [
    "### VERSION 4: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis shows the pairs. y axis averaged the MI among time lag and show CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a5da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animalpairs_datashapes = ['o','v','^','*']\n",
    "#animal1_fixedorders = ['eddie']\n",
    "#animal2_fixedorders = ['sparkle']\n",
    "#animalpairs_datashapes = ['o']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "pulltype_forplot = 'failedpull' # 'succpull' or 'failedpull'\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(2,6)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(5*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 8000)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 8000)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    pull_pull_fromNodes_all = [0,1,4,5,8,9]\n",
    "    pull_pull_toNodes_all = [1,0,1,0,1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes_all = [2,3,6,7,10,11]\n",
    "    gaze_gaze_toNodes_all = [3,2,3,2,3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes_all = [0,1,4,5,8,9]\n",
    "    within_pullgaze_toNodes_all = [2,3,2,3,2,3]\n",
    "    #\n",
    "    across_pullgaze_fromNodes_all = [0,1,4,5,8,9]\n",
    "    across_pullgaze_toNodes_all = [3,2,3,2,3,2]\n",
    "    #\n",
    "    within_gazepull_fromNodes_all = [2,3,6,7,10,11]\n",
    "    within_gazepull_toNodes_all = [0,1,0,1,0,1]\n",
    "    #\n",
    "    across_gazepull_fromNodes_all = [2,3,6,7,10,11]\n",
    "    across_gazepull_toNodes_all = [1,0,1,0,1,0]\n",
    "\n",
    "    \n",
    "    # plot coop self modulation\n",
    "    \n",
    "    # pull-pull\n",
    "    xxx1 = np.mean(MI_coop_self_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all])\n",
    "    # err1 = np.std(MI_coop_self_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all])\n",
    "    err1 = st.sem(MI_coop_self_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all].flatten())\n",
    "    axs[0,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 5)\n",
    "    line1 = axs[0,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # gaze-gaze\n",
    "    xxx2 = np.mean(MI_coop_self_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all])\n",
    "    # err2 = np.std(MI_coop_self_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all])\n",
    "    err2 = st.sem(MI_coop_self_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all].flatten())\n",
    "    axs[0,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 5)\n",
    "    line2 = axs[0,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal gazepull\n",
    "    xxx3 = np.mean(MI_coop_self_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all])\n",
    "    # err3 = np.std(MI_coop_self_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all])\n",
    "    err3 = st.sem(MI_coop_self_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all].flatten())\n",
    "    axs[0,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 5)\n",
    "    line3 = axs[0,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal gazepull\n",
    "    xxx4 = np.mean(MI_coop_self_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all])\n",
    "    # err4 = np.std(MI_coop_self_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all])\n",
    "    err4 = st.sem(MI_coop_self_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all].flatten())\n",
    "    axs[0,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 5)\n",
    "    line4 = axs[0,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal pullgaze\n",
    "    xxx5 = np.mean(MI_coop_self_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all])\n",
    "    #err5 = np.std(MI_coop_self_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all])\n",
    "    err5 = st.sem(MI_coop_self_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all].flatten())\n",
    "    axs[0,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 5)\n",
    "    line5 = axs[0,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal pullgaze\n",
    "    xxx6 = np.mean(MI_coop_self_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all])\n",
    "    # err6 = np.std(MI_coop_self_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all])\n",
    "    err6 = st.sem(MI_coop_self_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all].flatten())\n",
    "    axs[0,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 5)\n",
    "    line6 = axs[0,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    \n",
    "    #\n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 ]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[0,iplot].set_xlim([-0.1,nanimalpairs-0.9])\n",
    "        axs[0,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[0,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "        axs[0,iplot].set_xticklabels([])\n",
    "        axs[0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        #\n",
    "        if iplot == 0:\n",
    "            axs[0,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[0,iplot].set_yticklabels([])\n",
    "        axs[0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[0,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "\n",
    "    # plot novision coop modulation\n",
    "    # pull-pull\n",
    "    xxx1 = np.mean(MI_nov_coop_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all])\n",
    "    # err1 = np.std(MI_nov_coop_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all])\n",
    "    err1 = st.sem(MI_nov_coop_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all].flatten())\n",
    "    axs[1,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 5)\n",
    "    line1 = axs[1,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # gaze-gaze\n",
    "    xxx2 = np.mean(MI_nov_coop_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all])\n",
    "    # err2 = np.std(MI_nov_coop_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all])\n",
    "    err2 = st.sem(MI_nov_coop_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all].flatten())\n",
    "    axs[1,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 5)\n",
    "    line2 = axs[1,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal gazepull\n",
    "    xxx3 = np.mean(MI_nov_coop_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all])\n",
    "    # err3 = np.std(MI_nov_coop_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all])\n",
    "    err3 = st.sem(MI_nov_coop_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all].flatten())\n",
    "    axs[1,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 5)\n",
    "    line3 = axs[1,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal gazepull\n",
    "    xxx4 = np.mean(MI_nov_coop_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all])\n",
    "    # err4 = np.std(MI_nov_coop_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all])\n",
    "    err4 = st.sem(MI_nov_coop_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all].flatten())\n",
    "    axs[1,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 5)\n",
    "    line4 = axs[1,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal pullgaze\n",
    "    xxx5 = np.mean(MI_nov_coop_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all])\n",
    "    #err5 = np.std(MI_nov_coop_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all])\n",
    "    err5 = st.sem(MI_nov_coop_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all].flatten())\n",
    "    axs[1,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 5)\n",
    "    line5 = axs[1,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal pullgaze\n",
    "    xxx6 = np.mean(MI_nov_coop_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all])\n",
    "    # err6 = np.std(MI_nov_coop_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all])\n",
    "    err6 = st.sem(MI_nov_coop_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all].flatten())\n",
    "    axs[1,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 5)\n",
    "    line6 = axs[1,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    \n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 ]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[1,iplot].set_xlim([-0.1,nanimalpairs-0.9])\n",
    "        axs[1,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[1,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "        #axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "        axs[1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA','DA/KA'],fontsize = 13)\n",
    "        #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "        axs[1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        if iplot == 0:\n",
    "            axs[1,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[1,iplot].set_yticklabels([])\n",
    "        axs[1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[1,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "        \n",
    "    #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "    #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "    #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "    \n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_mergedLag_'+pulltype_forplot+'_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_meanSEM.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_mergedLag_'+pulltype_forplot+'_'+str(temp_resolu)+'_'+j_sampsize_name+'_meanSEM.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8346193d",
   "metadata": {},
   "source": [
    "### version 5: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis shows the pairs. y axis averaged the MI only for 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72961be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animalpairs_datashapes = ['o','v','^','*']\n",
    "#animal1_fixedorders = ['eddie']\n",
    "#animal2_fixedorders = ['sparkle']\n",
    "#animalpairs_datashapes = ['o']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "pulltype_forplot = 'failedpull' # 'succpull' or 'failedpull'\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(2,6)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(5*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 8000)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 8000)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    pull_pull_fromNodes_all = [8,9]\n",
    "    pull_pull_toNodes_all = [1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes_all = [10,11]\n",
    "    gaze_gaze_toNodes_all = [3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes_all = [8,9]\n",
    "    within_pullgaze_toNodes_all = [2,3]\n",
    "    #\n",
    "    across_pullgaze_fromNodes_all = [8,9]\n",
    "    across_pullgaze_toNodes_all = [3,2]\n",
    "    #\n",
    "    within_gazepull_fromNodes_all = [10,11]\n",
    "    within_gazepull_toNodes_all = [0,1]\n",
    "    #\n",
    "    across_gazepull_fromNodes_all = [10,11]\n",
    "    across_gazepull_toNodes_all = [1,0]\n",
    "\n",
    "    \n",
    "    # plot coop self modulation\n",
    "    \n",
    "    # pull-pull\n",
    "    a = MI_coop_self_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all].flatten()\n",
    "    xxx1 = np.mean(a)\n",
    "    err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "    line1 = axs[0,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # gaze-gaze\n",
    "    a = (MI_coop_self_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all]).flatten()\n",
    "    xxx2 = np.mean(a)\n",
    "    err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "    line2 = axs[0,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal gazepull\n",
    "    a = (MI_coop_self_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all]).flatten()\n",
    "    xxx3 = np.mean(a)\n",
    "    err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "    line3 = axs[0,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal gazepull\n",
    "    a = (MI_coop_self_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all]).flatten()\n",
    "    xxx4 = np.mean(a)\n",
    "    err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "    line4 = axs[0,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal pullgaze\n",
    "    a = (MI_coop_self_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all]).flatten()\n",
    "    xxx5 = np.mean(a)\n",
    "    err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "    line5 = axs[0,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal pullgaze\n",
    "    a = (MI_coop_self_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all]).flatten()\n",
    "    xxx6 = np.mean(a)\n",
    "    err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[0,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "    line6 = axs[0,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    \n",
    "    #\n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 ]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[0,iplot].set_xlim([-0.3,nanimalpairs-0.7])\n",
    "        axs[0,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[0,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "        axs[0,iplot].set_xticklabels([])\n",
    "        axs[0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        #\n",
    "        if iplot == 0:\n",
    "            axs[0,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[0,iplot].set_yticklabels([])\n",
    "        axs[0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[0,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "\n",
    "    # plot novision coop modulation\n",
    "    # pull-pull\n",
    "    a = MI_nov_coop_all[:,pull_pull_fromNodes_all,pull_pull_toNodes_all].flatten()\n",
    "    xxx1 = np.mean(a)\n",
    "    err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "    line1 = axs[1,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # gaze-gaze\n",
    "    a = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all,gaze_gaze_toNodes_all]).flatten()\n",
    "    xxx2 = np.mean(a)\n",
    "    err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "    line2 = axs[1,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal gazepull\n",
    "    a = (MI_nov_coop_all[:,within_gazepull_fromNodes_all,within_gazepull_toNodes_all]).flatten()\n",
    "    xxx3 = np.mean(a)\n",
    "    err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "    line3 = axs[1,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal gazepull\n",
    "    a = (MI_nov_coop_all[:,across_gazepull_fromNodes_all,across_gazepull_toNodes_all]).flatten()\n",
    "    xxx4 = np.mean(a)\n",
    "    err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "    line4 = axs[1,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # within animal pullgaze\n",
    "    a = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all,within_pullgaze_toNodes_all]).flatten()\n",
    "    xxx5 = np.mean(a)\n",
    "    err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "    line5 = axs[1,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    # across animal pullgaze\n",
    "    a = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all,across_pullgaze_toNodes_all]).flatten()\n",
    "    xxx6 = np.mean(a)\n",
    "    err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "    axs[1,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "    line6 = axs[1,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "    \n",
    "    plottypes = ['across animal pull<->pull','across animal gaze<->gaze',\n",
    "                 'within animal gaze->pull','across animal gaze->pull',\n",
    "                 'within animal pull->gaze','across animal pull->gaze',\n",
    "                 ]\n",
    "    for iplot in np.arange(0,6,1):\n",
    "        axs[1,iplot].set_xlim([-0.3,nanimalpairs-0.7])\n",
    "        axs[1,iplot].set_ylim([-1.05,1.05])\n",
    "        axs[1,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "        #axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "        axs[1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA','DA/KA'],fontsize = 13)\n",
    "        #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "        axs[1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "        if iplot == 0:\n",
    "            axs[1,iplot].tick_params(axis='y', labelsize=13)\n",
    "            axs[1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "        else:\n",
    "            axs[1,iplot].set_yticklabels([])\n",
    "        axs[1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "        #\n",
    "        if ianimalpair == nanimalpairs-1:\n",
    "            axs[1,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "        \n",
    "    #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "    #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "    #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "    \n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_1secondLag_'+pulltype_forplot+'_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_mean95CI.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_1secondLag_'+pulltype_forplot+'_'+str(temp_resolu)+'_'+j_sampsize_name+'_mean95CI.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e72e3",
   "metadata": {},
   "source": [
    "### version 6: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis shows the pairs. y axis showed the MI; separate animal 1 and 2; merge time lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da12c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animalpairs_datashapes = ['o','v','^','*']\n",
    "#animal1_fixedorders = ['eddie']\n",
    "#animal2_fixedorders = ['sparkle']\n",
    "#animalpairs_datashapes = ['o']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "pulltype_forplot = 'succpull' # 'succpull' or 'failedpull'\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(4,6)\n",
    "fig.set_figheight(8*4)\n",
    "fig.set_figwidth(8*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 8000)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 8000)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    \n",
    "    #\n",
    "    pull_pull_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "    pull_pull_toNodes_all = [[1,1,1],[0,0,0]]\n",
    "    #\n",
    "    gaze_gaze_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "    gaze_gaze_toNodes_all = [[3,3,3],[2,2,2]]\n",
    "    #\n",
    "    within_pullgaze_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "    within_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "    #\n",
    "    across_pullgaze_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "    across_pullgaze_toNodes_all = [[3,3,3],[2,2,2]]\n",
    "    #\n",
    "    within_gazepull_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "    within_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "    #\n",
    "    across_gazepull_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "    across_gazepull_toNodes_all = [[1,1,1],[0,0,0]]\n",
    "    \n",
    "    animalshortnames = ['A1','A2']\n",
    "\n",
    "    \n",
    "    for ianimal in np.arange(0,2,1):\n",
    "        \n",
    "        anishortname = animalshortnames[ianimal]\n",
    "        \n",
    "        \n",
    "        # plot coop self modulation\n",
    "\n",
    "        # pull-pull\n",
    "        a = MI_coop_self_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[2*ianimal+0,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_coop_self_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[2*ianimal+0,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_coop_self_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[2*ianimal+0,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_coop_self_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[2*ianimal+0,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_coop_self_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[2*ianimal+0,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_coop_self_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[2*ianimal+0,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        #\n",
    "        plottypes = ['from '+anishortname+' across animal pull<->pull','from '+anishortname+' across animal gaze<->gaze',\n",
    "                     'from '+anishortname+' within animal gaze->pull','from '+anishortname+' across animal gaze->pull',\n",
    "                     'from '+anishortname+' within animal pull->gaze','from '+anishortname+' across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[2*ianimal+0,iplot].set_xlim([-0.3,nanimalpairs-0.7])\n",
    "            axs[2*ianimal+0,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[2*ianimal+0,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "            axs[2*ianimal+0,iplot].set_xticklabels([])\n",
    "            axs[2*ianimal+0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            #\n",
    "            if iplot == 0:\n",
    "                axs[2*ianimal+0,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[2*ianimal+0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "            else:\n",
    "                axs[2*ianimal+0,iplot].set_yticklabels([])\n",
    "            axs[2*ianimal+0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[2*ianimal+0,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "\n",
    "        # plot novision coop modulation\n",
    "        # pull-pull\n",
    "        a = MI_nov_coop_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[2*ianimal+1,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[2*ianimal+1,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_nov_coop_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[2*ianimal+1,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_nov_coop_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[2*ianimal+1,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[2*ianimal+1,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[2*ianimal+1,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        plottypes = ['from '+anishortname+' across animal pull<->pull','from '+anishortname+' across animal gaze<->gaze',\n",
    "                     'from '+anishortname+' within animal gaze->pull','from '+anishortname+' across animal gaze->pull',\n",
    "                     'from '+anishortname+' within animal pull->gaze','from '+anishortname+' across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[2*ianimal+1,iplot].set_xlim([-0.3,nanimalpairs-0.7])\n",
    "            axs[2*ianimal+1,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[2*ianimal+1,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "            #axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "            axs[2*ianimal+1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA','DA/KA'],fontsize = 13)\n",
    "            #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "            axs[2*ianimal+1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            if iplot == 0:\n",
    "                axs[2*ianimal+1,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[2*ianimal+1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "            else:\n",
    "                axs[1,iplot].set_yticklabels([])\n",
    "            axs[2*ianimal+1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[2*ianimal+1,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "\n",
    "        #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "\n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_mergedLag_IndiAnimal_'+pulltype_forplot+'_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_mean95CI.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_mergedLag_IndiAnimal_'+pulltype_forplot+'_'+str(temp_resolu)+'_'+j_sampsize_name+'_mean95CI.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b2cdfe",
   "metadata": {},
   "source": [
    "### version 7: plot the key edges' modulation; only show the modulation among coop1s, self, no-vision; x axis shows the pairs. y axis showed the MI; separate animal 1 and 2; only for 1s time lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7466a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','ginger','dannon']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animalpairs_datashapes = ['o','v','^','*']\n",
    "#animal1_fixedorders = ['eddie']\n",
    "#animal2_fixedorders = ['sparkle']\n",
    "#animalpairs_datashapes = ['o']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "pulltype_forplot = 'succpull' # 'succpull' or 'failedpull'\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(4,6)\n",
    "fig.set_figheight(8*4)\n",
    "fig.set_figwidth(8*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 8000)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 8000)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    pull_pull_fromNodes_all = [8,9]\n",
    "    pull_pull_toNodes_all = [1,0]\n",
    "    #\n",
    "    gaze_gaze_fromNodes_all = [10,11]\n",
    "    gaze_gaze_toNodes_all = [3,2]\n",
    "    #\n",
    "    within_pullgaze_fromNodes_all = [8,9]\n",
    "    within_pullgaze_toNodes_all = [2,3]\n",
    "    #\n",
    "    across_pullgaze_fromNodes_all = [8,9]\n",
    "    across_pullgaze_toNodes_all = [3,2]\n",
    "    #\n",
    "    within_gazepull_fromNodes_all = [10,11]\n",
    "    within_gazepull_toNodes_all = [0,1]\n",
    "    #\n",
    "    across_gazepull_fromNodes_all = [10,11]\n",
    "    across_gazepull_toNodes_all = [1,0]\n",
    "\n",
    "    animalshortnames = ['A1','A2']\n",
    "    \n",
    "    for ianimal in np.arange(0,2,1):\n",
    "        \n",
    "        anishortname = animalshortnames[ianimal]\n",
    "        \n",
    "        # plot coop self modulation\n",
    "\n",
    "        # pull-pull\n",
    "        a = MI_coop_self_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[2*ianimal+0,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_coop_self_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[2*ianimal+0,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_coop_self_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[2*ianimal+0,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_coop_self_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[2*ianimal+0,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_coop_self_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[2*ianimal+0,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_coop_self_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+0,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[2*ianimal+0,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        #\n",
    "        plottypes = ['from '+anishortname+' across animal pull<->pull','from '+anishortname+' across animal gaze<->gaze',\n",
    "                     'from '+anishortname+' within animal gaze->pull','from '+anishortname+' across animal gaze->pull',\n",
    "                     'from '+anishortname+' within animal pull->gaze','from '+anishortname+' across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[2*ianimal+0,iplot].set_xlim([-0.3,nanimalpairs-0.7])\n",
    "            axs[2*ianimal+0,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[2*ianimal+0,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "            axs[2*ianimal+0,iplot].set_xticklabels([])\n",
    "            axs[2*ianimal+0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            #\n",
    "            if iplot == 0:\n",
    "                axs[2*ianimal+0,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[2*ianimal+0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=15)\n",
    "            else:\n",
    "                axs[2*ianimal+0,iplot].set_yticklabels([])\n",
    "            axs[2*ianimal+0,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[2*ianimal+0,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "\n",
    "        # plot novision coop modulation\n",
    "        # pull-pull\n",
    "        a = MI_nov_coop_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,0].errorbar(ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[2*ianimal+1,0].plot(ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,1].errorbar(ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[2*ianimal+1,1].plot(ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_nov_coop_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,2].errorbar(ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[2*ianimal+1,2].plot(ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_nov_coop_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,3].errorbar(ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[2*ianimal+1,3].plot(ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,4].errorbar(ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[2*ianimal+1,4].plot(ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[2*ianimal+1,5].errorbar(ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[2*ianimal+1,5].plot(ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        plottypes = ['from '+anishortname+' across animal pull<->pull','from '+anishortname+' across animal gaze<->gaze',\n",
    "                     'from '+anishortname+' within animal gaze->pull','from '+anishortname+' across animal gaze->pull',\n",
    "                     'from '+anishortname+' within animal pull->gaze','from '+anishortname+' across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[2*ianimal+1,iplot].set_xlim([-0.3,nanimalpairs-0.7])\n",
    "            axs[2*ianimal+1,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[2*ianimal+1,iplot].set_xticks(np.arange(0,nanimalpairs,1))\n",
    "            #axs[1,iplot].set_xticklabels(['t-3','t-2','t-1'],fontsize = 13)\n",
    "            axs[2*ianimal+1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA','DA/KA'],fontsize = 13)\n",
    "            #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "            axs[2*ianimal+1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            if iplot == 0:\n",
    "                axs[2*ianimal+1,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[2*ianimal+1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=15)\n",
    "            else:\n",
    "                axs[2*ianimal+1,iplot].set_yticklabels([])\n",
    "            axs[2*ianimal+1,iplot].set_title(plottypes[iplot],fontsize = 16)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[2*ianimal+1,iplot].plot([-1,nanimalpairs],[0,0],'k--')\n",
    "\n",
    "        #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "\n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_1secondLag_IndiAnimal_'+pulltype_forplot+'_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_mean95CI.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_1secondLag_IndiAnimal_'+pulltype_forplot+'_'+str(temp_resolu)+'_'+j_sampsize_name+'_mean95CI.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3371b3f",
   "metadata": {},
   "source": [
    "### version 7-2-2: \n",
    "#### plot the key edges' modulation; \n",
    "#### only show the modulation among coop1s, self, no-vision; \n",
    "#### separate animal 1 and 2, plot individual animal; \n",
    "#### put all animal in one plot - based on the \"to Node\"; for one time lag or merged all time lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ff85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','dannon','ginger']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga']\n",
    "animalpairs_datashapes = ['o','o','o','o']\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "\n",
    "timelag = 1 # 1 or 2 or 3 or 0(merged)\n",
    "timelagname = '1second' # '1/2/3second' or 'merged'\n",
    "# timelagname = 'merged'\n",
    "\n",
    "pulltype_forplot = 'succpull' # 'succpull' or 'failedpull'\n",
    "\n",
    "#\n",
    "fig, axs = plt.subplots(2,6)\n",
    "fig.set_figheight(8*2)\n",
    "fig.set_figwidth(8*6)\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    else:\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, 8000)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, 8000)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    if timelag == 1:\n",
    "        pull_pull_fromNodes_all = [9,8]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [11,10]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [8,9]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [9,8]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [10,11]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [11,10]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "    elif timelag == 2:\n",
    "        pull_pull_fromNodes_all = [5,4]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [7,6]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [4,5]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [5,4]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [6,7]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [7,6]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "    elif timelag == 3:\n",
    "        pull_pull_fromNodes_all = [1,0]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [3,2]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [0,1]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [1,0]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [2,3]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [3,2]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "    elif timelag == 0:\n",
    "        pull_pull_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "        pull_pull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "        gaze_gaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "        within_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "        across_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "        within_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "        across_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "    \n",
    "    \n",
    "    for ianimal in np.arange(0,2,1):\n",
    "                \n",
    "        # plot coop self modulation\n",
    "\n",
    "        # pull-pull\n",
    "        a = MI_coop_self_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,0].errorbar(ianimal*nanimalpairs+ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[0,0].plot(ianimal*nanimalpairs+ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_coop_self_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,1].errorbar(ianimal*nanimalpairs+ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[0,1].plot(ianimal*nanimalpairs+ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_coop_self_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,2].errorbar(ianimal*nanimalpairs+ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[0,2].plot(ianimal*nanimalpairs+ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_coop_self_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,3].errorbar(ianimal*nanimalpairs+ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[0,3].plot(ianimal*nanimalpairs+ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_coop_self_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,4].errorbar(ianimal*nanimalpairs+ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[0,4].plot(ianimal*nanimalpairs+ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_coop_self_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[0,5].errorbar(ianimal*nanimalpairs+ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[0,5].plot(ianimal*nanimalpairs+ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        #\n",
    "        plottypes = ['To Node; across animal pull<->pull','To Node; across animal gaze<->gaze',\n",
    "                     'To Node; within animal gaze->pull','To Node; across animal gaze->pull',\n",
    "                     'To Node; within animal pull->gaze','To Node; across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[0,iplot].set_xlim([-0.3,nanimalpairs*2-0.7])\n",
    "            axs[0,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[0,iplot].set_xticks(np.arange(0,nanimalpairs*2,1))\n",
    "            axs[0,iplot].set_xticklabels(['E','Do','Da','G','Sp','Sc','K','K'],fontsize = 20)\n",
    "            axs[0,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            #\n",
    "            if iplot == 0:\n",
    "                axs[0,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[0,iplot].set_ylabel('Cooperative - Self Reward\\nmodulation index',fontsize=22)\n",
    "            else:\n",
    "                axs[0,iplot].set_yticklabels([])\n",
    "            axs[0,iplot].set_title(plottypes[iplot],fontsize = 21)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[0,iplot].plot([-1,nanimalpairs*2],[0,0],'k--')\n",
    "\n",
    "        # plot novision coop modulation\n",
    "        # pull-pull\n",
    "        a = MI_nov_coop_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a)\n",
    "        err1 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,0].errorbar(ianimal*nanimalpairs+ianimalpair,xxx1,err1,color='k',capsize = 15)\n",
    "        line1 = axs[1,0].plot(ianimal*nanimalpairs+ianimalpair,xxx1,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # gaze-gaze\n",
    "        a = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a)\n",
    "        err2 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,1].errorbar(ianimal*nanimalpairs+ianimalpair,xxx2,err2,color='k',capsize = 15)\n",
    "        line2 = axs[1,1].plot(ianimal*nanimalpairs+ianimalpair,xxx2,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal gazepull\n",
    "        a = (MI_nov_coop_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a)\n",
    "        err3 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,2].errorbar(ianimal*nanimalpairs+ianimalpair,xxx3,err3,color='k',capsize = 15)\n",
    "        line3 = axs[1,2].plot(ianimal*nanimalpairs+ianimalpair,xxx3,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal gazepull\n",
    "        a = (MI_nov_coop_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a)\n",
    "        err4 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,3].errorbar(ianimal*nanimalpairs+ianimalpair,xxx4,err4,color='k',capsize = 15)\n",
    "        line4 = axs[1,3].plot(ianimal*nanimalpairs+ianimalpair,xxx4,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # within animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a)\n",
    "        err5 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,4].errorbar(ianimal*nanimalpairs+ianimalpair,xxx5,err5,color='k',capsize = 15)\n",
    "        line5 = axs[1,4].plot(ianimal*nanimalpairs+ianimalpair,xxx5,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "        # across animal pullgaze\n",
    "        a = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a)\n",
    "        err6 = (st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))-a.mean())[1]\n",
    "        axs[1,5].errorbar(ianimal*nanimalpairs+ianimalpair,xxx6,err6,color='k',capsize = 15)\n",
    "        line6 = axs[1,5].plot(ianimal*nanimalpairs+ianimalpair,xxx6,animalpairs_datashapes[ianimalpair],markersize = 13,color='k')\n",
    "\n",
    "        plottypes = ['To Node; across animal pull<->pull','To Node; across animal gaze<->gaze',\n",
    "                     'To Node; within animal gaze->pull','To Node; across animal gaze->pull',\n",
    "                     'To Node; within animal pull->gaze','To Node; across animal pull->gaze',\n",
    "                     ]\n",
    "        for iplot in np.arange(0,6,1):\n",
    "            axs[1,iplot].set_xlim([-0.3,nanimalpairs*2-0.7])\n",
    "            axs[1,iplot].set_ylim([-1.05,1.05])\n",
    "            axs[1,iplot].set_xticks(np.arange(0,nanimalpairs*2,1))\n",
    "            #axs[1,iplot].set_xticklabels(['ED/SP','DO/SC','GI/KA'],fontsize = 13)\n",
    "            axs[1,iplot].set_xticklabels(['E','Do','Da','G','Sp','Sc','K','K'],fontsize = 20)\n",
    "            #axs[1,iplot].set_xlabel('time lag',fontsize=15)\n",
    "            axs[1,iplot].set_yticks([-1,-0.5,0,0.5,1])\n",
    "            if iplot == 0:\n",
    "                axs[1,iplot].tick_params(axis='y', labelsize=13)\n",
    "                axs[1,iplot].set_ylabel('No Vision - Cooperative\\nmodulation index',fontsize=22)\n",
    "            else:\n",
    "                axs[1,iplot].set_yticklabels([])\n",
    "            axs[1,iplot].set_title(plottypes[iplot],fontsize = 21)\n",
    "            #\n",
    "            if ianimalpair == nanimalpairs-1:\n",
    "                axs[1,iplot].plot([-1,nanimalpairs*2],[0,0],'k--')\n",
    "\n",
    "        #axs[0,0].legend(['pair:'+animal1_fixedorders[0][0:2]+'/'+animal2_fixedorders[0][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[1][0:2]+'/'+animal2_fixedorders[1][0:2],\n",
    "        #                 'pair:'+animal1_fixedorders[2][0:2]+'/'+animal2_fixedorders[2][0:2]],fontsize=17)\n",
    "\n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_'+timelagname+'Lag_IndiAnimal_'+pulltype_forplot+'_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_mean95CI_version3.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_'+timelagname+'Lag_IndiAnimal_'+pulltype_forplot+'_'+str(temp_resolu)+'_'+j_sampsize_name+'_mean95CI_version3.pdf')\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0609",
   "metadata": {},
   "source": [
    "### version 7-2-3-2:\n",
    "#### plot the key edges' modulation; \n",
    "#### only show the modulation among coop1s, self, no-vision; \n",
    "#### separate animal 1 and 2, plot individual animal; \n",
    "#### pool 1) all the animals, 2) male and female, 3) subordinate and dominant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da044d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','dannon','ginger','koala']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga','vermelho']\n",
    "animal_pooled_list = ['E','SP','DO','SC','DA','KwDA','G','KwG','K','V']\n",
    "\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "nanimalpooled = np.shape(animal_pooled_list)[0]\n",
    "\n",
    "timelag = 12 # 1 or 2 or 3 or 0(merged - merge all three lags) or 12 (merged lag 1 and 2)\n",
    "# timelagname = '1second' # '1/2/3second' or 'merged' or '12merged'\n",
    "# timelagname = 'merged' # together with timelag = 0\n",
    "timelagname = '12merged' # together with timelag = 12\n",
    "\n",
    "pulltype_forplot = 'failedpull' # 'succpull' or 'failedpull'\n",
    "\n",
    "nMIbootstraps = 150\n",
    "\n",
    "# \n",
    "MI_coop_self_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps,6])\n",
    "MI_coop_self_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "MI_nov_coop_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps,6])\n",
    "MI_nov_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "ntimelags = 1\n",
    "if timelag == 0:\n",
    "    ntimelags = 3\n",
    "    MI_coop_self_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*3,6])\n",
    "    MI_coop_self_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "    MI_nov_coop_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*3,6])\n",
    "    MI_nov_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "if timelag == 12:\n",
    "    ntimelags = 2\n",
    "    MI_coop_self_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*2,6])\n",
    "    MI_coop_self_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "    MI_nov_coop_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*2,6])\n",
    "    MI_nov_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "#\n",
    "\n",
    "#\n",
    "#\n",
    "fig, axs = plt.subplots(1,3)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10*3)\n",
    "\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    weighted_graphs_self = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    weighted_graphs_sf_self = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    sig_edges_self = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['self']\n",
    "    #\n",
    "    weighted_graphs_coop = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    weighted_graphs_sf_coop = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    sig_edges_coop = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['coop(1s)']\n",
    "    #\n",
    "    weighted_graphs_nov = weighted_graphs_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov = weighted_graphs_shuffled_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov = sig_edges_diffTempRo_diffSampSize[(pulltype_forplot,str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    # organize the key edge data\n",
    "    weighted_graphs_self_mean = weighted_graphs_self.mean(axis=0)\n",
    "    weighted_graphs_coop_mean = weighted_graphs_coop.mean(axis=0)\n",
    "    weighted_graphs_nov_mean = weighted_graphs_nov.mean(axis=0)\n",
    "    # MI_coop_self = (weighted_graphs_coop_mean-weighted_graphs_self_mean)/(weighted_graphs_coop_mean+weighted_graphs_self_mean)\n",
    "    # MI_nov_coop = (weighted_graphs_nov_mean-weighted_graphs_coop_mean)/(weighted_graphs_nov_mean+weighted_graphs_coop_mean)\n",
    "    # MI_coop_self = ((weighted_graphs_coop-weighted_graphs_self)/(weighted_graphs_coop+weighted_graphs_self)).mean(axis=0)\n",
    "    # MI_nov_coop = ((weighted_graphs_nov-weighted_graphs_coop)/(weighted_graphs_nov+weighted_graphs_coop)).mean(axis=0)\n",
    "    #\n",
    "    if 0:\n",
    "        MI_coop_self_all = weighted_graphs_coop-weighted_graphs_self\n",
    "        MI_nov_coop_all = weighted_graphs_nov-weighted_graphs_coop  \n",
    "        MI_coop_self = (weighted_graphs_coop-weighted_graphs_self).mean(axis=0)\n",
    "        MI_nov_coop = (weighted_graphs_nov-weighted_graphs_coop).mean(axis=0)\n",
    "        #\n",
    "        sig_edges_coop_self = ((sig_edges_coop+sig_edges_self)>0)*1\n",
    "        sig_edges_nov_coop = ((sig_edges_coop+sig_edges_nov)>0)*1\n",
    "        #\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "        #\n",
    "        nMIbootstraps = 1\n",
    "    else:\n",
    "        nMIbootstraps = 150\n",
    "        #\n",
    "        MI_coop_self_all,sig_edges_coop_self = Modulation_Index(weighted_graphs_self, weighted_graphs_coop,\n",
    "                                          sig_edges_self, sig_edges_coop, nMIbootstraps)\n",
    "        MI_coop_self = MI_coop_self_all.mean(axis = 0)\n",
    "        MI_coop_self = MI_coop_self * sig_edges_coop_self\n",
    "        MI_nov_coop_all,sig_edges_nov_coop  = Modulation_Index(weighted_graphs_coop, weighted_graphs_nov,\n",
    "                                          sig_edges_coop, sig_edges_nov, nMIbootstraps)\n",
    "        MI_nov_coop = MI_nov_coop_all.mean(axis = 0)\n",
    "        MI_nov_coop = MI_nov_coop * sig_edges_nov_coop\n",
    "    \n",
    "    #\n",
    "    if timelag == 1:\n",
    "        pull_pull_fromNodes_all = [9,8]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [11,10]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [8,9]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [9,8]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [10,11]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [11,10]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        ntimelags = 1\n",
    "        #\n",
    "    elif timelag == 2:\n",
    "        pull_pull_fromNodes_all = [5,4]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [7,6]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [4,5]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [5,4]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [6,7]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [7,6]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        ntimelags = 1\n",
    "        #\n",
    "    elif timelag == 3:\n",
    "        pull_pull_fromNodes_all = [1,0]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [3,2]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [0,1]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [1,0]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [2,3]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [3,2]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        ntimelags = 1\n",
    "        #\n",
    "    elif timelag == 0:\n",
    "        pull_pull_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "        pull_pull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "        gaze_gaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "        within_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "        across_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "        within_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "        across_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        ntimelags = 3\n",
    "        #\n",
    "    elif timelag == 12:\n",
    "        pull_pull_fromNodes_all = [[5,9],[4,8]]\n",
    "        pull_pull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [[7,11],[6,10]]\n",
    "        gaze_gaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [[4,8],[5,9]]\n",
    "        within_pullgaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [[5,9],[4,8]]\n",
    "        across_pullgaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [[6,10],[7,11]]\n",
    "        within_gazepull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [[7,11],[6,10]]\n",
    "        across_gazepull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        ntimelags = 2\n",
    "        #\n",
    "    \n",
    "    \n",
    "    for ianimal in np.arange(0,2,1):\n",
    "                \n",
    "        # coop self modulation\n",
    "        # pull-pull\n",
    "        a1 = MI_coop_self_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a1)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,0] = a1\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,0] = xxx1\n",
    "        # gaze-gaze\n",
    "        a2 = (MI_coop_self_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a2)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,1] = a2\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,1] = xxx2\n",
    "        # within animal gazepull\n",
    "        a3 = (MI_coop_self_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a3)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,2] = a3\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,2] = xxx3\n",
    "        # across animal gazepull\n",
    "        a4 = (MI_coop_self_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a4)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,3] = a4\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,3] = xxx4\n",
    "        # within animal pullgaze\n",
    "        a5 = (MI_coop_self_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a5)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,4] = a5\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,4] = xxx5\n",
    "        # across animal pullgaze\n",
    "        a6 = (MI_coop_self_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a6)\n",
    "        MI_coop_self_all_IndiAni[2*ianimalpair+ianimal,:,5] = a6\n",
    "        MI_coop_self_mean_IndiAni[2*ianimalpair+ianimal,5] = xxx6\n",
    "        \n",
    "        \n",
    "        # novision coop modulation\n",
    "        # pull-pull\n",
    "        a1 = MI_nov_coop_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.mean(a1)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,0] = a1\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,0] = xxx1\n",
    "        # gaze-gaze\n",
    "        a2 = (MI_nov_coop_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.mean(a2)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,1] = a2\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,1] = xxx2\n",
    "        # within animal gazepull\n",
    "        a3 = (MI_nov_coop_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.mean(a3)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,2] = a3\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,2] = xxx3\n",
    "        # across animal gazepull\n",
    "        a4 = (MI_nov_coop_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.mean(a4)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,3] = a4\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,3] = xxx4\n",
    "        # within animal pullgaze\n",
    "        a5 = (MI_nov_coop_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.mean(a5)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,4] = a5\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,4] = xxx5\n",
    "        # across animal pullgaze\n",
    "        a6 = (MI_nov_coop_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.mean(a6)\n",
    "        MI_nov_coop_all_IndiAni[2*ianimalpair+ianimal,:,5] = a6\n",
    "        MI_nov_coop_mean_IndiAni[2*ianimalpair+ianimal,5] = xxx6\n",
    "        \n",
    "\n",
    "# prepare the data\n",
    "# average all animals for each dependency\n",
    "MI_coop_self_all_IndiAni_all = MI_coop_self_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)\n",
    "MI_nov_coop_all_IndiAni_all = MI_nov_coop_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)\n",
    "MI_coop_self_all_IndiAni_allmean = np.nanmean(MI_coop_self_all_IndiAni_all,axis=0)\n",
    "MI_nov_coop_all_IndiAni_allmean = np.nanmean(MI_nov_coop_all_IndiAni_all,axis=0) \n",
    "MI_coop_self_all_IndiAni_allse = np.nanstd(MI_coop_self_all_IndiAni_all,axis=0)/np.sqrt(8*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_allse = np.nanstd(MI_nov_coop_all_IndiAni_all,axis=0)/np.sqrt(8*nMIbootstraps*ntimelags) \n",
    "\n",
    "# average all males and females for each dependency\n",
    "MI_coop_self_all_IndiAni_male = MI_coop_self_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1),np.arange(9*nMIbootstraps*ntimelags,10*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_coop_all_IndiAni_male = MI_nov_coop_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1),np.arange(9*nMIbootstraps*ntimelags,10*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_self_all_IndiAni_malemean = np.nanmean(MI_coop_self_all_IndiAni_male,axis=0)\n",
    "MI_nov_coop_all_IndiAni_malemean = np.nanmean(MI_nov_coop_all_IndiAni_male,axis=0) \n",
    "MI_coop_self_all_IndiAni_malese = np.nanstd(MI_coop_self_all_IndiAni_male,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_malese = np.nanstd(MI_nov_coop_all_IndiAni_male,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "# average all males and females for each dependency\n",
    "MI_coop_self_all_IndiAni_female = MI_coop_self_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,9*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_coop_all_IndiAni_female = MI_nov_coop_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,9*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_self_all_IndiAni_femalemean = np.nanmean(MI_coop_self_all_IndiAni_female,axis=0)\n",
    "MI_nov_coop_all_IndiAni_femalemean = np.nanmean(MI_nov_coop_all_IndiAni_female,axis=0) \n",
    "MI_coop_self_all_IndiAni_femalese = np.nanstd(MI_coop_self_all_IndiAni_female,axis=0)/np.sqrt(6*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_femalese = np.nanstd(MI_nov_coop_all_IndiAni_female,axis=0)/np.sqrt(6*nMIbootstraps*ntimelags) \n",
    "\n",
    "# average all subordinate and dominant for each dependency\n",
    "MI_coop_self_all_IndiAni_sub = MI_coop_self_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1),np.arange(6*nMIbootstraps*ntimelags,7*nMIbootstraps*ntimelags,1),np.arange(8*nMIbootstraps*ntimelags,9*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_coop_all_IndiAni_sub = MI_nov_coop_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1),np.arange(6*nMIbootstraps*ntimelags,7*nMIbootstraps*ntimelags,1),np.arange(8*nMIbootstraps*ntimelags,9*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_self_all_IndiAni_submean = np.nanmean(MI_coop_self_all_IndiAni_sub,axis=0)\n",
    "MI_nov_coop_all_IndiAni_submean = np.nanmean(MI_nov_coop_all_IndiAni_sub,axis=0) \n",
    "MI_coop_self_all_IndiAni_subse = np.nanstd(MI_coop_self_all_IndiAni_sub,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_subse = np.nanstd(MI_nov_coop_all_IndiAni_sub,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "# average all subordinate and dominant for each dependency\n",
    "MI_coop_self_all_IndiAni_dom = MI_coop_self_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,6*nMIbootstraps*ntimelags,1),np.arange(7*nMIbootstraps*ntimelags,8*nMIbootstraps*ntimelags,1),np.arange(9*nMIbootstraps*ntimelags,10*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_coop_all_IndiAni_dom = MI_nov_coop_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,6*nMIbootstraps*ntimelags,1),np.arange(7*nMIbootstraps*ntimelags,8*nMIbootstraps*ntimelags,1),np.arange(9*nMIbootstraps*ntimelags,10*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_self_all_IndiAni_dommean = np.nanmean(MI_coop_self_all_IndiAni_dom,axis=0)\n",
    "MI_nov_coop_all_IndiAni_dommean = np.nanmean(MI_nov_coop_all_IndiAni_dom,axis=0) \n",
    "MI_coop_self_all_IndiAni_domse = np.nanstd(MI_coop_self_all_IndiAni_dom,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "MI_nov_coop_all_IndiAni_domse = np.nanstd(MI_nov_coop_all_IndiAni_dom,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "\n",
    "# pool everything together\n",
    "MI_coop_self_all_IndiAni_pooled = {'all':MI_coop_self_all_IndiAni_all,\n",
    "                                   'male':MI_coop_self_all_IndiAni_male,\n",
    "                                   'female':MI_coop_self_all_IndiAni_female,\n",
    "                                   'subordinate':MI_coop_self_all_IndiAni_sub,\n",
    "                                   'dominant':MI_coop_self_all_IndiAni_dom}\n",
    "MI_nov_coop_all_IndiAni_pooled =  {'all':MI_nov_coop_all_IndiAni_all,\n",
    "                                   'male':MI_nov_coop_all_IndiAni_male,\n",
    "                                   'female':MI_nov_coop_all_IndiAni_female,\n",
    "                                   'subordinate':MI_nov_coop_all_IndiAni_sub,\n",
    "                                   'dominant':MI_nov_coop_all_IndiAni_dom}\n",
    "MI_coop_self_mean_IndiAni_pooled ={'all':MI_coop_self_mean_IndiAni,\n",
    "                                   'male':MI_coop_self_mean_IndiAni[[0,2,4,9],:],\n",
    "                                   'female':MI_coop_self_mean_IndiAni[[1,3,5,6,7,8],:],\n",
    "                                   'subordinate':MI_coop_self_mean_IndiAni[[0,2,4,6,8],:],\n",
    "                                   'dominant':MI_coop_self_mean_IndiAni[[1,3,5,7,9],:]}\n",
    "MI_nov_coop_mean_IndiAni_pooled = {'all':MI_nov_coop_mean_IndiAni,\n",
    "                                   'male':MI_nov_coop_mean_IndiAni[[0,2,4,9],:],\n",
    "                                   'female':MI_nov_coop_mean_IndiAni[[1,3,5,6,7,8],:],\n",
    "                                   'subordinate':MI_nov_coop_mean_IndiAni[[0,2,4,6,8],:],\n",
    "                                   'dominant':MI_nov_coop_mean_IndiAni[[1,3,5,7,9],:]}\n",
    "\n",
    "# for plot\n",
    "dependencynames = ['pull-pull','gaze-gaze','within_gazepull','across_gazepull','within_pullgaze','across_pullgaze']\n",
    "dependencytargets = ['pull-pull','within_gazepull','across_pullgaze']\n",
    "# dependencytargets = dependencynames\n",
    "\n",
    "# plot 1\n",
    "# average all animals for each dependency\n",
    "# barplot\n",
    "MI_coop_self_all_IndiAni_all_df = pd.DataFrame(MI_coop_self_all_IndiAni_pooled['all'])\n",
    "MI_coop_self_all_IndiAni_all_df.columns = dependencynames\n",
    "MI_coop_self_all_IndiAni_all_df['MItype'] = 'coop-self'\n",
    "#\n",
    "MI_nov_coop_all_IndiAni_all_df = pd.DataFrame(MI_nov_coop_all_IndiAni_pooled['all'])\n",
    "MI_nov_coop_all_IndiAni_all_df.columns = dependencynames\n",
    "MI_nov_coop_all_IndiAni_all_df['MItype'] = 'nov-coop'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_self_all_IndiAni_all_df,MI_nov_coop_all_IndiAni_all_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on all bootstrap data point\n",
    "# seaborn.barplot(ax=ax1,data=df_long2,x='condition',y='value',hue='MItype',errorbar='ci',alpha=.5)\n",
    "#\n",
    "# swarmplot\n",
    "MI_coop_self_mean_IndiAni_df = pd.DataFrame(MI_coop_self_mean_IndiAni_pooled['all'])\n",
    "MI_coop_self_mean_IndiAni_df.columns = dependencynames\n",
    "MI_coop_self_mean_IndiAni_df['MItype'] = 'coop-self'\n",
    "#\n",
    "MI_nov_coop_mean_IndiAni_df = pd.DataFrame(MI_nov_coop_mean_IndiAni_pooled['all'])\n",
    "MI_nov_coop_mean_IndiAni_df.columns = dependencynames\n",
    "MI_nov_coop_mean_IndiAni_df['MItype'] = 'nov-coop'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_self_mean_IndiAni_df,MI_nov_coop_mean_IndiAni_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on mean value for each animal\n",
    "seaborn.barplot(ax=axs.ravel()[0],data=df_long2,x='condition',y='value',hue='MItype',errorbar='se',alpha=.5,capsize=0.1)\n",
    "seaborn.swarmplot(ax=axs.ravel()[0],data=df_long2,x='condition',y='value',hue='MItype',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs.ravel()[0].set_xlabel('')\n",
    "axs.ravel()[0].set_ylabel('Modulation Index',fontsize=20)\n",
    "axs.ravel()[0].set_title('all animals',fontsize=24)\n",
    "axs.ravel()[0].set_ylim([-1.35,1.35])\n",
    "\n",
    "# plot 2\n",
    "# average male and female animals for each dependency\n",
    "# barplot\n",
    "MI_coop_self_all_IndiAni_male_df = pd.DataFrame(MI_coop_self_all_IndiAni_pooled['male'])\n",
    "MI_coop_self_all_IndiAni_male_df.columns = dependencynames\n",
    "MI_coop_self_all_IndiAni_male_df['MItype'] = 'male coop-self'\n",
    "#\n",
    "MI_nov_coop_all_IndiAni_male_df = pd.DataFrame(MI_nov_coop_all_IndiAni_pooled['male'])\n",
    "MI_nov_coop_all_IndiAni_male_df.columns = dependencynames\n",
    "MI_nov_coop_all_IndiAni_male_df['MItype'] = 'male nov-coop'\n",
    "#\n",
    "MI_coop_self_all_IndiAni_female_df = pd.DataFrame(MI_coop_self_all_IndiAni_pooled['female'])\n",
    "MI_coop_self_all_IndiAni_female_df.columns = dependencynames\n",
    "MI_coop_self_all_IndiAni_female_df['MItype'] = 'female coop-self'\n",
    "#\n",
    "MI_nov_coop_all_IndiAni_female_df = pd.DataFrame(MI_nov_coop_all_IndiAni_pooled['female'])\n",
    "MI_nov_coop_all_IndiAni_female_df.columns = dependencynames\n",
    "MI_nov_coop_all_IndiAni_female_df['MItype'] = 'female nov-coop'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_self_all_IndiAni_male_df,MI_nov_coop_all_IndiAni_male_df,\n",
    "                   MI_coop_self_all_IndiAni_female_df,MI_nov_coop_all_IndiAni_female_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on all bootstrap data point\n",
    "# seaborn.barplot(ax=ax1,data=df_long2,x='condition',y='value',hue='MItype',errorbar='ci',alpha=.5)\n",
    "#\n",
    "# swarmplot\n",
    "MI_coop_self_mean_IndiAni_male_df = pd.DataFrame(MI_coop_self_mean_IndiAni_pooled['male'])\n",
    "MI_coop_self_mean_IndiAni_male_df.columns = dependencynames\n",
    "MI_coop_self_mean_IndiAni_male_df['MItype'] = 'male coop-self'\n",
    "#\n",
    "MI_nov_coop_mean_IndiAni_male_df = pd.DataFrame(MI_nov_coop_mean_IndiAni_pooled['male'])\n",
    "MI_nov_coop_mean_IndiAni_male_df.columns = dependencynames\n",
    "MI_nov_coop_mean_IndiAni_male_df['MItype'] = 'male nov-coop'\n",
    "#\n",
    "MI_coop_self_mean_IndiAni_female_df = pd.DataFrame(MI_coop_self_mean_IndiAni_pooled['female'])\n",
    "MI_coop_self_mean_IndiAni_female_df.columns = dependencynames\n",
    "MI_coop_self_mean_IndiAni_female_df['MItype'] = 'female coop-self'\n",
    "#\n",
    "MI_nov_coop_mean_IndiAni_female_df = pd.DataFrame(MI_nov_coop_mean_IndiAni_pooled['female'])\n",
    "MI_nov_coop_mean_IndiAni_female_df.columns = dependencynames\n",
    "MI_nov_coop_mean_IndiAni_female_df['MItype'] = 'female nov-coop'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_self_mean_IndiAni_male_df,MI_nov_coop_mean_IndiAni_male_df,\n",
    "                   MI_coop_self_mean_IndiAni_female_df,MI_nov_coop_mean_IndiAni_female_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on mean value for each animal\n",
    "seaborn.barplot(ax=axs.ravel()[1],data=df_long2,x='condition',y='value',hue='MItype',errorbar='se',alpha=.5,capsize=0.1)\n",
    "seaborn.swarmplot(ax=axs.ravel()[1],data=df_long2,x='condition',y='value',hue='MItype',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs.ravel()[1].set_xlabel('')\n",
    "axs.ravel()[1].set_ylabel('Modulation Index',fontsize=20)\n",
    "axs.ravel()[1].set_title('male vs female',fontsize=24)\n",
    "axs.ravel()[1].set_ylim([-1.35,1.35])\n",
    "\n",
    "# plot 3\n",
    "# average sub and dom animals for each dependency\n",
    "# barplot\n",
    "MI_coop_self_all_IndiAni_sub_df = pd.DataFrame(MI_coop_self_all_IndiAni_pooled['subordinate'])\n",
    "MI_coop_self_all_IndiAni_sub_df.columns = dependencynames\n",
    "MI_coop_self_all_IndiAni_sub_df['MItype'] = 'sub coop-self'\n",
    "#\n",
    "MI_nov_coop_all_IndiAni_sub_df = pd.DataFrame(MI_nov_coop_all_IndiAni_pooled['subordinate'])\n",
    "MI_nov_coop_all_IndiAni_sub_df.columns = dependencynames\n",
    "MI_nov_coop_all_IndiAni_sub_df['MItype'] = 'sub nov-coop'\n",
    "#\n",
    "MI_coop_self_all_IndiAni_dom_df = pd.DataFrame(MI_coop_self_all_IndiAni_pooled['dominant'])\n",
    "MI_coop_self_all_IndiAni_dom_df.columns = dependencynames\n",
    "MI_coop_self_all_IndiAni_dom_df['MItype'] = 'dom coop-self'\n",
    "#\n",
    "MI_nov_coop_all_IndiAni_dom_df = pd.DataFrame(MI_nov_coop_all_IndiAni_pooled['dominant'])\n",
    "MI_nov_coop_all_IndiAni_dom_df.columns = dependencynames\n",
    "MI_nov_coop_all_IndiAni_dom_df['MItype'] = 'dom nov-coop'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_self_all_IndiAni_sub_df,MI_nov_coop_all_IndiAni_sub_df,\n",
    "                   MI_coop_self_all_IndiAni_dom_df,MI_nov_coop_all_IndiAni_dom_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on all bootstrap data point\n",
    "# seaborn.barplot(ax=ax1,data=df_long2,x='condition',y='value',hue='MItype',errorbar='ci',alpha=.5)\n",
    "#\n",
    "# swarmplot\n",
    "MI_coop_self_mean_IndiAni_sub_df = pd.DataFrame(MI_coop_self_mean_IndiAni_pooled['subordinate'])\n",
    "MI_coop_self_mean_IndiAni_sub_df.columns = dependencynames\n",
    "MI_coop_self_mean_IndiAni_sub_df['MItype'] = 'sub coop-self'\n",
    "#\n",
    "MI_nov_coop_mean_IndiAni_sub_df = pd.DataFrame(MI_nov_coop_mean_IndiAni_pooled['subordinate'])\n",
    "MI_nov_coop_mean_IndiAni_sub_df.columns = dependencynames\n",
    "MI_nov_coop_mean_IndiAni_sub_df['MItype'] = 'sub nov-coop'\n",
    "#\n",
    "MI_coop_self_mean_IndiAni_dom_df = pd.DataFrame(MI_coop_self_mean_IndiAni_pooled['dominant'])\n",
    "MI_coop_self_mean_IndiAni_dom_df.columns = dependencynames\n",
    "MI_coop_self_mean_IndiAni_dom_df['MItype'] = 'dom coop-self'\n",
    "#\n",
    "MI_nov_coop_mean_IndiAni_dom_df = pd.DataFrame(MI_nov_coop_mean_IndiAni_pooled['dominant'])\n",
    "MI_nov_coop_mean_IndiAni_dom_df.columns = dependencynames\n",
    "MI_nov_coop_mean_IndiAni_dom_df['MItype'] = 'dom nov-coop'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_self_mean_IndiAni_sub_df,MI_nov_coop_mean_IndiAni_sub_df,\n",
    "                   MI_coop_self_mean_IndiAni_dom_df,MI_nov_coop_mean_IndiAni_dom_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on mean value for each animal\n",
    "seaborn.barplot(ax=axs.ravel()[2],data=df_long2,x='condition',y='value',hue='MItype',errorbar='se',alpha=.5,capsize=0.1)\n",
    "seaborn.swarmplot(ax=axs.ravel()[2],data=df_long2,x='condition',y='value',hue='MItype',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs.ravel()[2].set_xlabel('')\n",
    "axs.ravel()[2].set_ylabel('Modulation Index',fontsize=20)\n",
    "axs.ravel()[2].set_title('sub vs dom',fontsize=24)\n",
    "axs.ravel()[2].set_ylim([-1.35,1.35])\n",
    "\n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_'+timelagname+'Lag_IndiAnimal_summarized_'+pulltype_forplot+'_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_subset_version2.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_'+timelagname+'Lag_IndiAnimal_summarized_'+pulltype_forplot+'_'+str(temp_resolu)+'_'+j_sampsize_name+'_subset_version2.pdf')\n",
    "           \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deab886",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MI_coop_self_mean_IndiAni_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca897ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sts = scipy.stats.wilcoxon(MI_coop_self_mean_IndiAni_sub_df['pull-pull'])\n",
    "sts = scipy.stats.ttest_1samp(MI_coop_self_mean_IndiAni_sub_df['across_pullgaze'],0)\n",
    "pvalue = sts.pvalue\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e5c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sts = scipy.stats.wilcoxon(MI_nov_coop_mean_IndiAni_sub_df['within_gazepull'])\n",
    "sts = scipy.stats.ttest_1samp(MI_nov_coop_mean_IndiAni_sub_df['across_pullgaze'],0)\n",
    "pvalue = sts.pvalue\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e0639",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts = scipy.stats.ttest_ind(MI_coop_self_mean_IndiAni_sub_df['pull-pull'],MI_coop_self_mean_IndiAni_dom_df['pull-pull'])\n",
    "pvalue = sts.pvalue\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b697ba8",
   "metadata": {},
   "source": [
    "### version 7-2-3-3:\n",
    "#### plot the key edges' modulation; \n",
    "#### only show the modulation among coop1s, self, no-vision; \n",
    "#### separate animal 1 and 2, plot individual animal; \n",
    "#### pool 1) all the animals, 2) male and female, 3) subordinate and dominant\n",
    "#### compare successful vs failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT multiple pairs in one plot, so need to load data seperately\n",
    "moreSampSize = 0\n",
    "#\n",
    "animal1_fixedorders = ['eddie','dodson','dannon','ginger','koala']\n",
    "animal2_fixedorders = ['sparkle','scorch','kanga','kanga','vermelho']\n",
    "animal_pooled_list = ['E','SP','DO','SC','DA','KwDA','G','KwG','K','V']\n",
    "\n",
    "nanimalpairs = np.shape(animal1_fixedorders)[0]\n",
    "nanimalpooled = np.shape(animal_pooled_list)[0]\n",
    "\n",
    "timelag = 12 # 1 or 2 or 3 or 0(merged - merge all three lags) or 12 (merged lag 1 and 2)\n",
    "# timelagname = '1second' # '1/2/3second' or 'merged' or '12merged'\n",
    "# timelagname = 'merged' # together with timelag = 0\n",
    "timelagname = '12merged' # together with timelag = 12\n",
    "\n",
    "MI_cooptype = 'coop(1s)'  # 'coop(3s)','coop(2s)','coop(1.5s)','coop(1s)'\n",
    "\n",
    "nMIbootstraps = 150\n",
    "\n",
    "# \n",
    "MI_coop_coop_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps,6])\n",
    "MI_coop_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "MI_nov_nov_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps,6])\n",
    "MI_nov_nov_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "ntimelags = 1\n",
    "if timelag == 0:\n",
    "    ntimelags = 3\n",
    "    MI_coop_coop_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*3,6])\n",
    "    MI_coop_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "    MI_nov_nov_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*3,6])\n",
    "    MI_nov_nov_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "if timelag == 12:\n",
    "    ntimelags = 2\n",
    "    MI_coop_coop_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*2,6])\n",
    "    MI_coop_coop_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "    MI_nov_nov_all_IndiAni = np.zeros([nanimalpairs*2,nMIbootstraps*2,6])\n",
    "    MI_nov_nov_mean_IndiAni = np.zeros([nanimalpairs*2,6])\n",
    "#\n",
    "\n",
    "#\n",
    "#\n",
    "fig, axs = plt.subplots(1,3)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10*3)\n",
    "\n",
    "\n",
    "for ianimalpair in np.arange(0,nanimalpairs,1):\n",
    "    animal1_fixedorder = animal1_fixedorders[ianimalpair]\n",
    "    animal2_fixedorder = animal2_fixedorders[ianimalpair]\n",
    "    #\n",
    "    data_saved_subfolder = data_saved_folder+'data_saved_singlecam_wholebody_SuccAndFailedPull'+savefile_sufix+'_3lags/'+cameraID+'/'+animal1_fixedorder+animal2_fixedorder+'/'\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'_moreSampSize.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "    else:\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/weighted_graphs_shuffled_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            weighted_graphs_shuffled_diffTempRo_diffSampSize = pickle.load(f)\n",
    "        with open(data_saved_subfolder+'/sig_edges_diffTempRo_diffSampSize_'+animal1_fixedorder+animal2_fixedorder+'.pkl', 'rb') as f:\n",
    "            sig_edges_diffTempRo_diffSampSize = pickle.load(f)\n",
    "\n",
    "    # make sure these variables are the same as in the previous steps\n",
    "    # temp_resolus = [0.5,1,1.5,2] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    temp_resolus = [1] # temporal resolution in the DBN model, eg: 0.5 means 500ms\n",
    "    ntemp_reses = np.shape(temp_resolus)[0]\n",
    "    #\n",
    "    if moreSampSize:\n",
    "        # different data (down/re)sampling numbers\n",
    "        # samplingsizes = np.arange(1100,3000,100)\n",
    "        samplingsizes = [1100]\n",
    "        # samplingsizes = [100,500,1000,1500,2000,2500,3000]        \n",
    "        # samplingsizes = [100,500]\n",
    "        # samplingsizes_name = ['100','500','1000','1500','2000','2500','3000']\n",
    "        samplingsizes_name = list(map(str, samplingsizes))\n",
    "    else:\n",
    "        samplingsizes_name = ['min_row_number']   \n",
    "    nsamplings = np.shape(samplingsizes_name)[0]\n",
    "\n",
    "    #\n",
    "    temp_resolu = temp_resolus[0]\n",
    "    j_sampsize_name = samplingsizes_name[0]    \n",
    "\n",
    "    # load edge weight data    \n",
    "    # load successful pulls\n",
    "    weighted_graphs_coop_succ = weighted_graphs_diffTempRo_diffSampSize[('succpull',str(temp_resolu),j_sampsize_name)][MI_cooptype]\n",
    "    weighted_graphs_sf_coop_succ = weighted_graphs_shuffled_diffTempRo_diffSampSize[('succpull',str(temp_resolu),j_sampsize_name)][MI_cooptype]\n",
    "    sig_edges_coop_succ = sig_edges_diffTempRo_diffSampSize[('succpull',str(temp_resolu),j_sampsize_name)][MI_cooptype]\n",
    "    #\n",
    "    weighted_graphs_nov_succ = weighted_graphs_diffTempRo_diffSampSize[('succpull',str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov_succ = weighted_graphs_shuffled_diffTempRo_diffSampSize[('succpull',str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov_succ = sig_edges_diffTempRo_diffSampSize[('succpull',str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    #\n",
    "    # load failed pulls\n",
    "    weighted_graphs_coop_fail = weighted_graphs_diffTempRo_diffSampSize[('failedpull',str(temp_resolu),j_sampsize_name)][MI_cooptype]\n",
    "    weighted_graphs_sf_coop_fail = weighted_graphs_shuffled_diffTempRo_diffSampSize[('failedpull',str(temp_resolu),j_sampsize_name)][MI_cooptype]\n",
    "    sig_edges_coop_fail = sig_edges_diffTempRo_diffSampSize[('failedpull',str(temp_resolu),j_sampsize_name)][MI_cooptype]\n",
    "    #\n",
    "    weighted_graphs_nov_fail = weighted_graphs_diffTempRo_diffSampSize[('failedpull',str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    weighted_graphs_sf_nov_fail = weighted_graphs_shuffled_diffTempRo_diffSampSize[('failedpull',str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "    sig_edges_nov_fail = sig_edges_diffTempRo_diffSampSize[('failedpull',str(temp_resolu),j_sampsize_name)]['no-vision']\n",
    "\n",
    "    \n",
    "    # organize the key edge data\n",
    "    #\n",
    "    nMIbootstraps = 150\n",
    "    #\n",
    "    MI_coop_coop_all,sig_edges_coop_coop = Modulation_Index(weighted_graphs_coop_succ, weighted_graphs_coop_fail,\n",
    "                                      sig_edges_coop_succ, sig_edges_coop_fail, nMIbootstraps)\n",
    "    # MI_coop_coop_all = MI_coop_coop_all * sig_edges_coop_coop\n",
    "    MI_coop_coop_all[MI_coop_coop_all==0] = np.nan\n",
    "    MI_coop_coop = MI_coop_coop_all.mean(axis = 0)\n",
    "    # MI_coop_coop = MI_coop_coop * sig_edges_coop_coop\n",
    "    MI_nov_nov_all,sig_edges_nov_nov  = Modulation_Index(weighted_graphs_nov_succ, weighted_graphs_nov_fail,\n",
    "                                      sig_edges_nov_succ, sig_edges_nov_fail, nMIbootstraps)\n",
    "    # MI_nov_nov_all = MI_nov_nov_all * sig_edges_nov_nov\n",
    "    MI_nov_nov_all[MI_nov_nov_all==0] = np.nan\n",
    "    MI_nov_nov = MI_nov_nov_all.mean(axis = 0)\n",
    "    # MI_nov_nov = MI_nov_nov * sig_edges_nov_nov\n",
    "    \n",
    "    #\n",
    "    if timelag == 1:\n",
    "        pull_pull_fromNodes_all = [9,8]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [11,10]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [8,9]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [9,8]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [10,11]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [11,10]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        ntimelags = 1\n",
    "        #\n",
    "    elif timelag == 2:\n",
    "        pull_pull_fromNodes_all = [5,4]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [7,6]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [4,5]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [5,4]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [6,7]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [7,6]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        ntimelags = 1\n",
    "        #\n",
    "    elif timelag == 3:\n",
    "        pull_pull_fromNodes_all = [1,0]\n",
    "        pull_pull_toNodes_all = [0,1]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [3,2]\n",
    "        gaze_gaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [0,1]\n",
    "        within_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [1,0]\n",
    "        across_pullgaze_toNodes_all = [2,3]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [2,3]\n",
    "        within_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [3,2]\n",
    "        across_gazepull_toNodes_all = [0,1]\n",
    "        #\n",
    "        ntimelags = 1\n",
    "        #\n",
    "    elif timelag == 0:\n",
    "        pull_pull_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "        pull_pull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "        gaze_gaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [[0,4,8],[1,5,9]]\n",
    "        within_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [[1,5,9],[0,4,8]]\n",
    "        across_pullgaze_toNodes_all = [[2,2,2],[3,3,3]]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [[2,6,10],[3,7,11]]\n",
    "        within_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [[3,7,11],[2,6,10]]\n",
    "        across_gazepull_toNodes_all = [[0,0,0],[1,1,1]]\n",
    "        #\n",
    "        ntimelags = 3\n",
    "        #\n",
    "    elif timelag == 12:\n",
    "        pull_pull_fromNodes_all = [[5,9],[4,8]]\n",
    "        pull_pull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        gaze_gaze_fromNodes_all = [[7,11],[6,10]]\n",
    "        gaze_gaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        within_pullgaze_fromNodes_all = [[4,8],[5,9]]\n",
    "        within_pullgaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        across_pullgaze_fromNodes_all = [[5,9],[4,8]]\n",
    "        across_pullgaze_toNodes_all = [[2,2],[3,3]]\n",
    "        #\n",
    "        within_gazepull_fromNodes_all = [[6,10],[7,11]]\n",
    "        within_gazepull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        across_gazepull_fromNodes_all = [[7,11],[6,10]]\n",
    "        across_gazepull_toNodes_all = [[0,0],[1,1]]\n",
    "        #\n",
    "        ntimelags = 2\n",
    "        #\n",
    "    \n",
    "    \n",
    "    for ianimal in np.arange(0,2,1):\n",
    "                \n",
    "        # coop self modulation\n",
    "        # pull-pull\n",
    "        a1 = MI_coop_coop_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.nanmean(a1)\n",
    "        MI_coop_coop_all_IndiAni[2*ianimalpair+ianimal,:,0] = a1\n",
    "        MI_coop_coop_mean_IndiAni[2*ianimalpair+ianimal,0] = xxx1\n",
    "        # gaze-gaze\n",
    "        a2 = (MI_coop_coop_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.nanmean(a2)\n",
    "        MI_coop_coop_all_IndiAni[2*ianimalpair+ianimal,:,1] = a2\n",
    "        MI_coop_coop_mean_IndiAni[2*ianimalpair+ianimal,1] = xxx2\n",
    "        # within animal gazepull\n",
    "        a3 = (MI_coop_coop_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.nanmean(a3)\n",
    "        MI_coop_coop_all_IndiAni[2*ianimalpair+ianimal,:,2] = a3\n",
    "        MI_coop_coop_mean_IndiAni[2*ianimalpair+ianimal,2] = xxx3\n",
    "        # across animal gazepull\n",
    "        a4 = (MI_coop_coop_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.nanmean(a4)\n",
    "        MI_coop_coop_all_IndiAni[2*ianimalpair+ianimal,:,3] = a4\n",
    "        MI_coop_coop_mean_IndiAni[2*ianimalpair+ianimal,3] = xxx4\n",
    "        # within animal pullgaze\n",
    "        a5 = (MI_coop_coop_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.nanmean(a5)\n",
    "        MI_coop_coop_all_IndiAni[2*ianimalpair+ianimal,:,4] = a5\n",
    "        MI_coop_coop_mean_IndiAni[2*ianimalpair+ianimal,4] = xxx5\n",
    "        # across animal pullgaze\n",
    "        a6 = (MI_coop_coop_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.nanmean(a6)\n",
    "        MI_coop_coop_all_IndiAni[2*ianimalpair+ianimal,:,5] = a6\n",
    "        MI_coop_coop_mean_IndiAni[2*ianimalpair+ianimal,5] = xxx6\n",
    "        \n",
    "        \n",
    "        # novision coop modulation\n",
    "        # pull-pull\n",
    "        a1 = MI_nov_nov_all[:,pull_pull_fromNodes_all[ianimal],pull_pull_toNodes_all[ianimal]].flatten()\n",
    "        xxx1 = np.nanmean(a1)\n",
    "        MI_nov_nov_all_IndiAni[2*ianimalpair+ianimal,:,0] = a1\n",
    "        MI_nov_nov_mean_IndiAni[2*ianimalpair+ianimal,0] = xxx1\n",
    "        # gaze-gaze\n",
    "        a2 = (MI_nov_nov_all[:,gaze_gaze_fromNodes_all[ianimal],gaze_gaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx2 = np.nanmean(a2)\n",
    "        MI_nov_nov_all_IndiAni[2*ianimalpair+ianimal,:,1] = a2\n",
    "        MI_nov_nov_mean_IndiAni[2*ianimalpair+ianimal,1] = xxx2\n",
    "        # within animal gazepull\n",
    "        a3 = (MI_nov_nov_all[:,within_gazepull_fromNodes_all[ianimal],within_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx3 = np.nanmean(a3)\n",
    "        MI_nov_nov_all_IndiAni[2*ianimalpair+ianimal,:,2] = a3\n",
    "        MI_nov_nov_mean_IndiAni[2*ianimalpair+ianimal,2] = xxx3\n",
    "        # across animal gazepull\n",
    "        a4 = (MI_nov_nov_all[:,across_gazepull_fromNodes_all[ianimal],across_gazepull_toNodes_all[ianimal]]).flatten()\n",
    "        xxx4 = np.nanmean(a4)\n",
    "        MI_nov_nov_all_IndiAni[2*ianimalpair+ianimal,:,3] = a4\n",
    "        MI_nov_nov_mean_IndiAni[2*ianimalpair+ianimal,3] = xxx4\n",
    "        # within animal pullgaze\n",
    "        a5 = (MI_nov_nov_all[:,within_pullgaze_fromNodes_all[ianimal],within_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx5 = np.nanmean(a5)\n",
    "        MI_nov_nov_all_IndiAni[2*ianimalpair+ianimal,:,4] = a5\n",
    "        MI_nov_nov_mean_IndiAni[2*ianimalpair+ianimal,4] = xxx5\n",
    "        # across animal pullgaze\n",
    "        a6 = (MI_nov_nov_all[:,across_pullgaze_fromNodes_all[ianimal],across_pullgaze_toNodes_all[ianimal]]).flatten()\n",
    "        xxx6 = np.nanmean(a6)\n",
    "        MI_nov_nov_all_IndiAni[2*ianimalpair+ianimal,:,5] = a6\n",
    "        MI_nov_nov_mean_IndiAni[2*ianimalpair+ianimal,5] = xxx6\n",
    "        \n",
    "\n",
    "# prepare the data\n",
    "# average all animals for each dependency\n",
    "MI_coop_coop_all_IndiAni_all = MI_coop_coop_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)\n",
    "MI_nov_nov_all_IndiAni_all = MI_nov_nov_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)\n",
    "MI_coop_coop_all_IndiAni_allmean = np.nanmean(MI_coop_coop_all_IndiAni_all,axis=0)\n",
    "MI_nov_nov_all_IndiAni_allmean = np.nanmean(MI_nov_nov_all_IndiAni_all,axis=0) \n",
    "MI_coop_coop_all_IndiAni_allse = np.nanstd(MI_coop_coop_all_IndiAni_all,axis=0)/np.sqrt(8*nMIbootstraps*ntimelags) \n",
    "MI_nov_nov_all_IndiAni_allse = np.nanstd(MI_nov_nov_all_IndiAni_all,axis=0)/np.sqrt(8*nMIbootstraps*ntimelags) \n",
    "\n",
    "# average all males and females for each dependency\n",
    "MI_coop_coop_all_IndiAni_male = MI_coop_coop_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_nov_all_IndiAni_male = MI_nov_nov_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_coop_all_IndiAni_malemean = np.nanmean(MI_coop_coop_all_IndiAni_male,axis=0)\n",
    "MI_nov_nov_all_IndiAni_malemean = np.nanmean(MI_nov_nov_all_IndiAni_male,axis=0) \n",
    "MI_coop_coop_all_IndiAni_malese = np.nanstd(MI_coop_coop_all_IndiAni_male,axis=0)/np.sqrt(3*nMIbootstraps*ntimelags) \n",
    "MI_nov_nov_all_IndiAni_malese = np.nanstd(MI_nov_nov_all_IndiAni_male,axis=0)/np.sqrt(3*nMIbootstraps*ntimelags) \n",
    "# average all males and females for each dependency\n",
    "MI_coop_coop_all_IndiAni_female = MI_coop_coop_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,8*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_nov_all_IndiAni_female = MI_nov_nov_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,8*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_coop_all_IndiAni_femalemean = np.nanmean(MI_coop_coop_all_IndiAni_female,axis=0)\n",
    "MI_nov_nov_all_IndiAni_femalemean = np.nanmean(MI_nov_nov_all_IndiAni_female,axis=0) \n",
    "MI_coop_coop_all_IndiAni_femalese = np.nanstd(MI_coop_coop_all_IndiAni_female,axis=0)/np.sqrt(5*nMIbootstraps*ntimelags) \n",
    "MI_nov_nov_all_IndiAni_femalese = np.nanstd(MI_nov_nov_all_IndiAni_female,axis=0)/np.sqrt(5*nMIbootstraps*ntimelags) \n",
    "\n",
    "# average all subordinate and dominant for each dependency\n",
    "MI_coop_coop_all_IndiAni_sub = MI_coop_coop_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1),np.arange(6*nMIbootstraps*ntimelags,7*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_nov_all_IndiAni_sub = MI_nov_nov_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(0,nMIbootstraps*ntimelags,1),np.arange(2*nMIbootstraps*ntimelags,3*nMIbootstraps*ntimelags,1),np.arange(4*nMIbootstraps*ntimelags,5*nMIbootstraps*ntimelags,1),np.arange(6*nMIbootstraps*ntimelags,7*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_coop_all_IndiAni_submean = np.nanmean(MI_coop_coop_all_IndiAni_sub,axis=0)\n",
    "MI_nov_nov_all_IndiAni_submean = np.nanmean(MI_nov_nov_all_IndiAni_sub,axis=0) \n",
    "MI_coop_coop_all_IndiAni_subse = np.nanstd(MI_coop_coop_all_IndiAni_sub,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "MI_nov_nov_all_IndiAni_subse = np.nanstd(MI_nov_nov_all_IndiAni_sub,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "# average all subordinate and dominant for each dependency\n",
    "MI_coop_coop_all_IndiAni_dom = MI_coop_coop_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,6*nMIbootstraps*ntimelags,1),np.arange(7*nMIbootstraps*ntimelags,8*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_nov_nov_all_IndiAni_dom = MI_nov_nov_all_IndiAni.reshape(nanimalpairs*2*nMIbootstraps*ntimelags,6)[np.concatenate((np.arange(1*nMIbootstraps*ntimelags,2*nMIbootstraps*ntimelags,1),np.arange(3*nMIbootstraps*ntimelags,4*nMIbootstraps*ntimelags,1),np.arange(5*nMIbootstraps*ntimelags,6*nMIbootstraps*ntimelags,1),np.arange(7*nMIbootstraps*ntimelags,8*nMIbootstraps*ntimelags,1))),:]\n",
    "MI_coop_coop_all_IndiAni_dommean = np.nanmean(MI_coop_coop_all_IndiAni_dom,axis=0)\n",
    "MI_nov_nov_all_IndiAni_dommean = np.nanmean(MI_nov_nov_all_IndiAni_dom,axis=0) \n",
    "MI_coop_coop_all_IndiAni_domse = np.nanstd(MI_coop_coop_all_IndiAni_dom,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "MI_nov_nov_all_IndiAni_domse = np.nanstd(MI_nov_nov_all_IndiAni_dom,axis=0)/np.sqrt(4*nMIbootstraps*ntimelags) \n",
    "\n",
    "# pool everything together\n",
    "MI_coop_coop_all_IndiAni_pooled = {'all':MI_coop_coop_all_IndiAni_all,\n",
    "                                   'male':MI_coop_coop_all_IndiAni_male,\n",
    "                                   'female':MI_coop_coop_all_IndiAni_female,\n",
    "                                   'subordinate':MI_coop_coop_all_IndiAni_sub,\n",
    "                                   'dominant':MI_coop_coop_all_IndiAni_dom}\n",
    "MI_nov_nov_all_IndiAni_pooled =  {'all':MI_nov_nov_all_IndiAni_all,\n",
    "                                   'male':MI_nov_nov_all_IndiAni_male,\n",
    "                                   'female':MI_nov_nov_all_IndiAni_female,\n",
    "                                   'subordinate':MI_nov_nov_all_IndiAni_sub,\n",
    "                                   'dominant':MI_nov_nov_all_IndiAni_dom}\n",
    "MI_coop_coop_mean_IndiAni_pooled ={'all':MI_coop_coop_mean_IndiAni,\n",
    "                                   'male':MI_coop_coop_mean_IndiAni[[0,2,4],:],\n",
    "                                   'female':MI_coop_coop_mean_IndiAni[[1,3,5,6,7],:],\n",
    "                                   'subordinate':MI_coop_coop_mean_IndiAni[[0,2,4,6],:],\n",
    "                                   'dominant':MI_coop_coop_mean_IndiAni[[1,3,5,7],:]}\n",
    "MI_nov_nov_mean_IndiAni_pooled = {'all':MI_nov_nov_mean_IndiAni,\n",
    "                                   'male':MI_nov_nov_mean_IndiAni[[0,2,4],:],\n",
    "                                   'female':MI_nov_nov_mean_IndiAni[[1,3,5,6,7],:],\n",
    "                                   'subordinate':MI_nov_nov_mean_IndiAni[[0,2,4,6],:],\n",
    "                                   'dominant':MI_nov_nov_mean_IndiAni[[1,3,5,7],:]}\n",
    "\n",
    "# for plot\n",
    "dependencynames = ['pull-pull','gaze-gaze','within_gazepull','across_gazepull','within_pullgaze','across_pullgaze']\n",
    "dependencytargets = ['pull-pull','within_gazepull','across_pullgaze',]\n",
    "# dependencytargets = dependencynames\n",
    "\n",
    "# plot 1\n",
    "# average all animals for each dependency\n",
    "# barplot\n",
    "MI_coop_coop_all_IndiAni_all_df = pd.DataFrame(MI_coop_coop_all_IndiAni_pooled['all'])\n",
    "MI_coop_coop_all_IndiAni_all_df.columns = dependencynames\n",
    "MI_coop_coop_all_IndiAni_all_df['MItype'] = 'coop:fail-succ'\n",
    "#\n",
    "MI_nov_nov_all_IndiAni_all_df = pd.DataFrame(MI_nov_nov_all_IndiAni_pooled['all'])\n",
    "MI_nov_nov_all_IndiAni_all_df.columns = dependencynames\n",
    "MI_nov_nov_all_IndiAni_all_df['MItype'] = 'nov:fail-succ'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_coop_all_IndiAni_all_df,MI_nov_nov_all_IndiAni_all_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on all bootstrap data point\n",
    "# seaborn.barplot(ax=ax1,data=df_long2,x='condition',y='value',hue='MItype',errorbar='ci',alpha=.5)\n",
    "#\n",
    "# swarmplot\n",
    "MI_coop_coop_mean_IndiAni_df = pd.DataFrame(MI_coop_coop_mean_IndiAni_pooled['all'])\n",
    "MI_coop_coop_mean_IndiAni_df.columns = dependencynames\n",
    "MI_coop_coop_mean_IndiAni_df['MItype'] = 'coop:fail-succ'\n",
    "#\n",
    "MI_nov_nov_mean_IndiAni_df = pd.DataFrame(MI_nov_nov_mean_IndiAni_pooled['all'])\n",
    "MI_nov_nov_mean_IndiAni_df.columns = dependencynames\n",
    "MI_nov_nov_mean_IndiAni_df['MItype'] = 'nov:fail-succ'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_coop_mean_IndiAni_df,MI_nov_nov_mean_IndiAni_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on mean value for each animal\n",
    "seaborn.barplot(ax=axs.ravel()[0],data=df_long2,x='condition',y='value',hue='MItype',errorbar='se',alpha=.5,capsize=0.1)\n",
    "seaborn.swarmplot(ax=axs.ravel()[0],data=df_long2,x='condition',y='value',hue='MItype',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs.ravel()[0].set_xlabel('')\n",
    "axs.ravel()[0].set_ylabel('Modulation Index',fontsize=20)\n",
    "axs.ravel()[0].set_title('all animals',fontsize=24)\n",
    "axs.ravel()[0].set_ylim([-1.35,1.35])\n",
    "\n",
    "# plot 2\n",
    "# average male and female animals for each dependency\n",
    "# barplot\n",
    "MI_coop_coop_all_IndiAni_male_df = pd.DataFrame(MI_coop_coop_all_IndiAni_pooled['male'])\n",
    "MI_coop_coop_all_IndiAni_male_df.columns = dependencynames\n",
    "MI_coop_coop_all_IndiAni_male_df['MItype'] = 'male coop:fail-succ'\n",
    "#\n",
    "MI_nov_nov_all_IndiAni_male_df = pd.DataFrame(MI_nov_nov_all_IndiAni_pooled['male'])\n",
    "MI_nov_nov_all_IndiAni_male_df.columns = dependencynames\n",
    "MI_nov_nov_all_IndiAni_male_df['MItype'] = 'male nov:fail-succ'\n",
    "#\n",
    "MI_coop_coop_all_IndiAni_female_df = pd.DataFrame(MI_coop_coop_all_IndiAni_pooled['female'])\n",
    "MI_coop_coop_all_IndiAni_female_df.columns = dependencynames\n",
    "MI_coop_coop_all_IndiAni_female_df['MItype'] = 'female coop:fail-succ'\n",
    "#\n",
    "MI_nov_nov_all_IndiAni_female_df = pd.DataFrame(MI_nov_nov_all_IndiAni_pooled['female'])\n",
    "MI_nov_nov_all_IndiAni_female_df.columns = dependencynames\n",
    "MI_nov_nov_all_IndiAni_female_df['MItype'] = 'female nov:fail-succ'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_coop_all_IndiAni_male_df,MI_nov_nov_all_IndiAni_male_df,\n",
    "                   MI_coop_coop_all_IndiAni_female_df,MI_nov_nov_all_IndiAni_female_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on all bootstrap data point\n",
    "# seaborn.barplot(ax=ax1,data=df_long2,x='condition',y='value',hue='MItype',errorbar='ci',alpha=.5)\n",
    "#\n",
    "# swarmplot\n",
    "MI_coop_coop_mean_IndiAni_male_df = pd.DataFrame(MI_coop_coop_mean_IndiAni_pooled['male'])\n",
    "MI_coop_coop_mean_IndiAni_male_df.columns = dependencynames\n",
    "MI_coop_coop_mean_IndiAni_male_df['MItype'] = 'male coop:fail-succ'\n",
    "#\n",
    "MI_nov_nov_mean_IndiAni_male_df = pd.DataFrame(MI_nov_nov_mean_IndiAni_pooled['male'])\n",
    "MI_nov_nov_mean_IndiAni_male_df.columns = dependencynames\n",
    "MI_nov_nov_mean_IndiAni_male_df['MItype'] = 'male nov:fail-succ'\n",
    "#\n",
    "MI_coop_coop_mean_IndiAni_female_df = pd.DataFrame(MI_coop_coop_mean_IndiAni_pooled['female'])\n",
    "MI_coop_coop_mean_IndiAni_female_df.columns = dependencynames\n",
    "MI_coop_coop_mean_IndiAni_female_df['MItype'] = 'female coop:fail-succ'\n",
    "#\n",
    "MI_nov_nov_mean_IndiAni_female_df = pd.DataFrame(MI_nov_nov_mean_IndiAni_pooled['female'])\n",
    "MI_nov_nov_mean_IndiAni_female_df.columns = dependencynames\n",
    "MI_nov_nov_mean_IndiAni_female_df['MItype'] = 'female nov:fail-succ'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_coop_mean_IndiAni_male_df,MI_nov_nov_mean_IndiAni_male_df,\n",
    "                   MI_coop_coop_mean_IndiAni_female_df,MI_nov_nov_mean_IndiAni_female_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on mean value for each animal\n",
    "seaborn.barplot(ax=axs.ravel()[1],data=df_long2,x='condition',y='value',hue='MItype',errorbar='se',alpha=.5,capsize=0.1)\n",
    "seaborn.swarmplot(ax=axs.ravel()[1],data=df_long2,x='condition',y='value',hue='MItype',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs.ravel()[1].set_xlabel('')\n",
    "axs.ravel()[1].set_ylabel('Modulation Index',fontsize=20)\n",
    "axs.ravel()[1].set_title('male vs female',fontsize=24)\n",
    "axs.ravel()[1].set_ylim([-1.35,1.35])\n",
    "\n",
    "# plot 3\n",
    "# average sub and dom animals for each dependency\n",
    "# barplot\n",
    "MI_coop_coop_all_IndiAni_sub_df = pd.DataFrame(MI_coop_coop_all_IndiAni_pooled['subordinate'])\n",
    "MI_coop_coop_all_IndiAni_sub_df.columns = dependencynames\n",
    "MI_coop_coop_all_IndiAni_sub_df['MItype'] = 'sub coop-coop'\n",
    "#\n",
    "MI_nov_nov_all_IndiAni_sub_df = pd.DataFrame(MI_nov_nov_all_IndiAni_pooled['subordinate'])\n",
    "MI_nov_nov_all_IndiAni_sub_df.columns = dependencynames\n",
    "MI_nov_nov_all_IndiAni_sub_df['MItype'] = 'sub nov-nov'\n",
    "#\n",
    "MI_coop_coop_all_IndiAni_dom_df = pd.DataFrame(MI_coop_coop_all_IndiAni_pooled['dominant'])\n",
    "MI_coop_coop_all_IndiAni_dom_df.columns = dependencynames\n",
    "MI_coop_coop_all_IndiAni_dom_df['MItype'] = 'dom coop-coop'\n",
    "#\n",
    "MI_nov_nov_all_IndiAni_dom_df = pd.DataFrame(MI_nov_nov_all_IndiAni_pooled['dominant'])\n",
    "MI_nov_nov_all_IndiAni_dom_df.columns = dependencynames\n",
    "MI_nov_nov_all_IndiAni_dom_df['MItype'] = 'dom nov-nov'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_coop_all_IndiAni_sub_df,MI_nov_nov_all_IndiAni_sub_df,\n",
    "                   MI_coop_coop_all_IndiAni_dom_df,MI_nov_nov_all_IndiAni_dom_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on all bootstrap data point\n",
    "# seaborn.barplot(ax=ax1,data=df_long2,x='condition',y='value',hue='MItype',errorbar='ci',alpha=.5)\n",
    "#\n",
    "# swarmplot\n",
    "MI_coop_coop_mean_IndiAni_sub_df = pd.DataFrame(MI_coop_coop_mean_IndiAni_pooled['subordinate'])\n",
    "MI_coop_coop_mean_IndiAni_sub_df.columns = dependencynames\n",
    "MI_coop_coop_mean_IndiAni_sub_df['MItype'] = 'sub coop-coop'\n",
    "#\n",
    "MI_nov_nov_mean_IndiAni_sub_df = pd.DataFrame(MI_nov_nov_mean_IndiAni_pooled['subordinate'])\n",
    "MI_nov_nov_mean_IndiAni_sub_df.columns = dependencynames\n",
    "MI_nov_nov_mean_IndiAni_sub_df['MItype'] = 'sub nov-nov'\n",
    "#\n",
    "MI_coop_coop_mean_IndiAni_dom_df = pd.DataFrame(MI_coop_coop_mean_IndiAni_pooled['dominant'])\n",
    "MI_coop_coop_mean_IndiAni_dom_df.columns = dependencynames\n",
    "MI_coop_coop_mean_IndiAni_dom_df['MItype'] = 'dom coop-coop'\n",
    "#\n",
    "MI_nov_nov_mean_IndiAni_dom_df = pd.DataFrame(MI_nov_nov_mean_IndiAni_pooled['dominant'])\n",
    "MI_nov_nov_mean_IndiAni_dom_df.columns = dependencynames\n",
    "MI_nov_nov_mean_IndiAni_dom_df['MItype'] = 'dom nov-nov'\n",
    "#\n",
    "df_long=pd.concat([MI_coop_coop_mean_IndiAni_sub_df,MI_nov_nov_mean_IndiAni_sub_df,\n",
    "                   MI_coop_coop_mean_IndiAni_dom_df,MI_nov_nov_mean_IndiAni_dom_df])\n",
    "df_long2 = df_long.melt(id_vars=['MItype'], value_vars=dependencytargets,var_name='condition', value_name='value')\n",
    "#\n",
    "# barplot based on mean value for each animal\n",
    "seaborn.barplot(ax=axs.ravel()[2],data=df_long2,x='condition',y='value',hue='MItype',errorbar='se',alpha=.5,capsize=0.1)\n",
    "seaborn.swarmplot(ax=axs.ravel()[2],data=df_long2,x='condition',y='value',hue='MItype',alpha=.9,size= 9,dodge=True,legend=False)\n",
    "axs.ravel()[2].set_xlabel('')\n",
    "axs.ravel()[2].set_ylabel('Modulation Index',fontsize=20)\n",
    "axs.ravel()[2].set_title('sub vs dom',fontsize=24)\n",
    "axs.ravel()[2].set_ylim([-1.35,1.35])\n",
    "\n",
    "savefig = 1\n",
    "if savefig:\n",
    "    if moreSampSize:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_'+timelagname+'Lag_IndiAnimal_summarized_failedvssucc_'+str(temp_resolu)+'_'+str(j_sampsize_name)+'_rows_subset_version2.pdf')\n",
    "    else:\n",
    "        figsavefolder = data_saved_folder+'figs_for_3LagDBN_and_SuccAndFailedPull_singlecam_wholebodylabels_combinesessions_basicEvents/'+savefile_sufix+'/'+cameraID+'/'\n",
    "        if not os.path.exists(figsavefolder):\n",
    "            os.makedirs(figsavefolder)\n",
    "        plt.savefig(figsavefolder+'threeTimeLag_Edge_ModulationIndex_'+timelagname+'Lag_IndiAnimal_summarized_failedvssucc_'+str(temp_resolu)+'_'+j_sampsize_name+'_subset_version2.pdf')\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72257eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = np.array(MI_coop_coop_mean_IndiAni_df['across_pullgaze'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c617dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy = np.array(MI_nov_nov_mean_IndiAni_df['across_pullgaze'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d99571",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts = scipy.stats.ttest_1samp(yyy,0)\n",
    "pvalue = sts.pvalue\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ff61f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7dc0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56027a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e4b117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77991d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69fa4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e946637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
