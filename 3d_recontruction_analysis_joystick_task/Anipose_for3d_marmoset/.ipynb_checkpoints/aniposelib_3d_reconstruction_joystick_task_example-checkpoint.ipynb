{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import aniposelib\n",
    "import toml\n",
    "import pandas as pd\n",
    "from aniposelib.boards import CharucoBoard, Checkerboard\n",
    "from aniposelib.cameras import Camera, CameraGroup\n",
    "from aniposelib.utils import load_pose2d_fnames\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the cameras for 3d\n",
    "\n",
    "do_cali = 1\n",
    "\n",
    "vidnames = [['camera-1_old.mp4'],\n",
    "            ['camera-2_old.mp4']]\n",
    "\n",
    "cam_names = ['1', '2']\n",
    "\n",
    "n_cams = len(vidnames)\n",
    "\n",
    "#board = CharucoBoard(9, 7,\n",
    "#                      square_length=22.5, # here, in mm but any unit works\n",
    "#                      marker_length=16.5,\n",
    "#                      manually_verify=False)\n",
    "\n",
    "board = Checkerboard(8, 6,\n",
    "                      square_length=1, # here, in mm but any unit works\n",
    "                      manually_verify=False)\n",
    "\n",
    "# the videos provided are fisheye, so we need the fisheye option\n",
    "cgroup = CameraGroup.from_names(cam_names, fisheye=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if do_cali: \n",
    "    # this will take about 15 minutes (mostly due to detection)\n",
    "    # it will detect the charuco board in the videos,\n",
    "    # then calibrate the cameras based on the detections, using iterative bundle adjustment\n",
    "    cgroup.calibrate_videos(vidnames, board)\n",
    "\n",
    "    # if you need to save and load\n",
    "    # example saving and loading for later\n",
    "    cgroup.dump('calibration.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_cali:\n",
    "    ## example of loading calibration from a file\n",
    "    ## you can also load the provided file if you don't want to wait 15 minutes\n",
    "    cgroup = CameraGroup.load('calibration.toml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated for joystick task\n",
    "lever_locs_all = {'camera-1':{('dodson'):np.array([980, 530]),('scorch'):np.array([980, 530])},\n",
    "                  'camera-2':{('dodson'):np.array([910,560]),('scorch'):np.array([910, 560])}}\n",
    "\n",
    "tube_locs_all = {'camera-1':{('dodson'):np.array([750,315]),('scorch'):np.array([1200, 280])},\n",
    "                 'camera-2':{('dodson'):np.array([1210,700]),('scorch'):np.array([620, 700])}}\n",
    "\n",
    "boxCorner1_locs_all = {'camera-1':{('dodson'):np.array([360,  780]),('scorch'):np.array([1625, 737])},\n",
    "                       'camera-2':{('dodson'):np.array([1500, 565]),('scorch'):np.array([340,  580])}}\n",
    "\n",
    "boxCorner2_locs_all = {'camera-1':{('dodson'):np.array([360, 320]),('scorch'):np.array([1560, 275])},\n",
    "                       'camera-2':{('dodson'):np.array([1855,955]),('scorch'):np.array([   9,1010])}}\n",
    "\n",
    "boxCorner3_locs_all = {'camera-1':{('dodson'):np.array([840,  284]),('scorch'):np.array([1070, 300])},\n",
    "                       'camera-2':{('dodson'):np.array([1120,1010]),('scorch'):np.array([ 740, 1020])}}\n",
    "\n",
    "boxCorner4_locs_all = {'camera-1':{('dodson'):np.array([760,    9]),('scorch'):np.array([1140, 3])},\n",
    "                       'camera-2':{('dodson'):np.array([1155, 310]),('scorch'):np.array([615,320])}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example triangulation without filtering, should take < 15 seconds\n",
    "date_tgt = '20230801'\n",
    "animal1 = 'Koala'\n",
    "animal2 = 'Vermelho'\n",
    "\n",
    "singlecam_ana_type = \"DLC_dlcrnetms5_marmoset_tracking_with_top_cameraMay3shuffle1_150000\"\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "add_date_dir = current_dir+'/anipose_3d_h5_files/'+date_tgt+'_'+animal1+'_'+animal2\n",
    "bodyparts_3d_anipose_file = add_date_dir+'/'+date_tgt+'_'+animal1+'_'+animal2+'_anipose.h5'\n",
    "if os.path.exists(bodyparts_3d_anipose_file):\n",
    "    do_3dconstruct = 0\n",
    "else:\n",
    "    do_3dconstruct = 1\n",
    "# do_3dconstruct=1\n",
    "    \n",
    "if do_3dconstruct:   \n",
    "\n",
    "    twocamera_videos_cam12 = \"/gpfs/gibbs/pi/jadi/VideoTracker_SocialInter/test_video_joystick_task_3d/\"+date_tgt+\"_\"+animal1+\"_\"+animal2+\"_camera12/\"\n",
    "\n",
    "    bodyparts_cam1_cam12 = twocamera_videos_cam12+date_tgt+\"_\"+animal1+\"_\"+animal2+\"_camera-1\"+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "    bodyparts_cam2_cam12 = twocamera_videos_cam12+date_tgt+\"_\"+animal1+\"_\"+animal2+\"_camera-2\"+singlecam_ana_type+\"_el_filtered.h5\"\n",
    "\n",
    "    #bodyparts_3d_cam12_DLC = twocamera_videos_cam12+date_tgt+\"_\"+animal1+\"_\"+animal2+\"_weikang.h5\"\n",
    "\n",
    "\n",
    "    ## save the the h5 file separately for each animals and save them in the same folder for future purpose\n",
    "\n",
    "    # animal 1 - \"dodson\"\n",
    "\n",
    "    # dodson h5 files\n",
    "    bodyparts_cam1_cam12_dodson = twocamera_videos_cam12+date_tgt+\"_\"+animal1+\"_\"+animal2+\"_camera-1\"+singlecam_ana_type+\"_el_filtered_dodson.h5\"\n",
    "    bodyparts_cam2_cam12_dodson = twocamera_videos_cam12+date_tgt+\"_\"+animal1+\"_\"+animal2+\"_camera-2\"+singlecam_ana_type+\"_el_filtered_dodson.h5\"\n",
    "\n",
    "    # cam1 dodson\n",
    "    bodyparts_cam1_cam12_data = pd.read_hdf(bodyparts_cam1_cam12)\n",
    "    bodyparts_cam1_cam12_dodson_data = {}\n",
    "    bodyparts_cam1_cam12_dodson_data[singlecam_ana_type]=bodyparts_cam1_cam12_data.loc[:,(singlecam_ana_type,'dodson')]\n",
    "    bodyparts_cam1_cam12_dodson_data=pd.concat(bodyparts_cam1_cam12_dodson_data, axis=1)\n",
    "    # add lever\n",
    "    lever_x = np.ones((1,np.shape(bodyparts_cam1_cam12_dodson_data)[0]))*lever_locs_all['camera-1']['dodson'][0]\n",
    "    lever_y = np.ones((1,np.shape(bodyparts_cam1_cam12_dodson_data)[0]))*lever_locs_all['camera-1']['dodson'][1]\n",
    "    lever_likelihood = np.ones((1,np.shape(bodyparts_cam1_cam12_dodson_data)[0]))\n",
    "    bodyparts_cam1_cam12_dodson_data[(singlecam_ana_type,'lever','x')]=lever_x[0]\n",
    "    bodyparts_cam1_cam12_dodson_data[(singlecam_ana_type,'lever','y')]=lever_y[0]\n",
    "    bodyparts_cam1_cam12_dodson_data[(singlecam_ana_type,'lever','likelihood')]=lever_likelihood[0]\n",
    "    # add tube\n",
    "    tube_x = np.ones((1,np.shape(bodyparts_cam1_cam12_dodson_data)[0]))*tube_locs_all['camera-1']['dodson'][0]\n",
    "    tube_y = np.ones((1,np.shape(bodyparts_cam1_cam12_dodson_data)[0]))*tube_locs_all['camera-1']['dodson'][1]\n",
    "    tube_likelihood = np.ones((1,np.shape(bodyparts_cam1_cam12_dodson_data)[0]))\n",
    "    bodyparts_cam1_cam12_dodson_data[(singlecam_ana_type,'tube','x')]=tube_x[0]\n",
    "    bodyparts_cam1_cam12_dodson_data[(singlecam_ana_type,'tube','y')]=tube_y[0]\n",
    "    bodyparts_cam1_cam12_dodson_data[(singlecam_ana_type,'tube','likelihood')]=tube_likelihood[0]\n",
    "    #\n",
    "    bodyparts_cam1_cam12_dodson_data.to_hdf(bodyparts_cam1_cam12_dodson,key='tracks')\n",
    "\n",
    "    # cam2 dodson\n",
    "    bodyparts_cam2_cam12_data = pd.read_hdf(bodyparts_cam2_cam12)\n",
    "    bodyparts_cam2_cam12_dodson_data = {}\n",
    "    bodyparts_cam2_cam12_dodson_data[singlecam_ana_type]=bodyparts_cam2_cam12_data.loc[:,(singlecam_ana_type,'dodson')]\n",
    "    bodyparts_cam2_cam12_dodson_data=pd.concat(bodyparts_cam2_cam12_dodson_data, axis=1)\n",
    "    # add lever\n",
    "    lever_x = np.ones((1,np.shape(bodyparts_cam2_cam12_dodson_data)[0]))*lever_locs_all['camera-2']['dodson'][0]\n",
    "    lever_y = np.ones((1,np.shape(bodyparts_cam2_cam12_dodson_data)[0]))*lever_locs_all['camera-2']['dodson'][1]\n",
    "    lever_likelihood = np.ones((1,np.shape(bodyparts_cam2_cam12_dodson_data)[0]))\n",
    "    bodyparts_cam2_cam12_dodson_data[(singlecam_ana_type,'lever','x')]=lever_x[0]\n",
    "    bodyparts_cam2_cam12_dodson_data[(singlecam_ana_type,'lever','y')]=lever_y[0]\n",
    "    bodyparts_cam2_cam12_dodson_data[(singlecam_ana_type,'lever','likelihood')]=lever_likelihood[0]\n",
    "    # add tube\n",
    "    tube_x = np.ones((1,np.shape(bodyparts_cam2_cam12_dodson_data)[0]))*tube_locs_all['camera-2']['dodson'][0]\n",
    "    tube_y = np.ones((1,np.shape(bodyparts_cam2_cam12_dodson_data)[0]))*tube_locs_all['camera-2']['dodson'][1]\n",
    "    tube_likelihood = np.ones((1,np.shape(bodyparts_cam2_cam12_dodson_data)[0]))\n",
    "    bodyparts_cam2_cam12_dodson_data[(singlecam_ana_type,'tube','x')]=tube_x[0]\n",
    "    bodyparts_cam2_cam12_dodson_data[(singlecam_ana_type,'tube','y')]=tube_y[0]\n",
    "    bodyparts_cam2_cam12_dodson_data[(singlecam_ana_type,'tube','likelihood')]=tube_likelihood[0]\n",
    "    #\n",
    "    bodyparts_cam2_cam12_dodson_data.to_hdf(bodyparts_cam2_cam12_dodson,key='tracks')\n",
    "\n",
    "\n",
    "    # animal 2 - \"scorch\"\n",
    "\n",
    "    # scorch h5 files\n",
    "    bodyparts_cam1_cam12_scorch = twocamera_videos_cam12+date_tgt+\"_\"+animal1+\"_\"+animal2+\"_camera-1\"+singlecam_ana_type+\"_el_filtered_scorch.h5\"\n",
    "    bodyparts_cam2_cam12_scorch = twocamera_videos_cam12+date_tgt+\"_\"+animal1+\"_\"+animal2+\"_camera-2\"+singlecam_ana_type+\"_el_filtered_scorch.h5\"\n",
    "\n",
    "    # cam1 scorch\n",
    "    bodyparts_cam1_cam12_data = pd.read_hdf(bodyparts_cam1_cam12)\n",
    "    bodyparts_cam1_cam12_scorch_data = {}\n",
    "    bodyparts_cam1_cam12_scorch_data[singlecam_ana_type]=bodyparts_cam1_cam12_data.loc[:,(singlecam_ana_type,'scorch')]\n",
    "    bodyparts_cam1_cam12_scorch_data=pd.concat(bodyparts_cam1_cam12_scorch_data, axis=1)\n",
    "    # add lever\n",
    "    lever_x = np.ones((1,np.shape(bodyparts_cam1_cam12_scorch_data)[0]))*lever_locs_all['camera-1']['scorch'][0]\n",
    "    lever_y = np.ones((1,np.shape(bodyparts_cam1_cam12_scorch_data)[0]))*lever_locs_all['camera-1']['scorch'][1]\n",
    "    lever_likelihood = np.ones((1,np.shape(bodyparts_cam1_cam12_scorch_data)[0]))\n",
    "    bodyparts_cam1_cam12_scorch_data[(singlecam_ana_type,'lever','x')]=lever_x[0]\n",
    "    bodyparts_cam1_cam12_scorch_data[(singlecam_ana_type,'lever','y')]=lever_y[0]\n",
    "    bodyparts_cam1_cam12_scorch_data[(singlecam_ana_type,'lever','likelihood')]=lever_likelihood[0]\n",
    "    # add tube\n",
    "    tube_x = np.ones((1,np.shape(bodyparts_cam1_cam12_scorch_data)[0]))*tube_locs_all['camera-1']['scorch'][0]\n",
    "    tube_y = np.ones((1,np.shape(bodyparts_cam1_cam12_scorch_data)[0]))*tube_locs_all['camera-1']['scorch'][1]\n",
    "    tube_likelihood = np.ones((1,np.shape(bodyparts_cam1_cam12_scorch_data)[0]))\n",
    "    bodyparts_cam1_cam12_scorch_data[(singlecam_ana_type,'tube','x')]=tube_x[0]\n",
    "    bodyparts_cam1_cam12_scorch_data[(singlecam_ana_type,'tube','y')]=tube_y[0]\n",
    "    bodyparts_cam1_cam12_scorch_data[(singlecam_ana_type,'tube','likelihood')]=tube_likelihood[0]\n",
    "    #\n",
    "    bodyparts_cam1_cam12_scorch_data.to_hdf(bodyparts_cam1_cam12_scorch,key='tracks')\n",
    "\n",
    "    # cam2 scorch\n",
    "    bodyparts_cam2_cam12_data = pd.read_hdf(bodyparts_cam2_cam12)\n",
    "    bodyparts_cam2_cam12_scorch_data = {}\n",
    "    bodyparts_cam2_cam12_scorch_data[singlecam_ana_type]=bodyparts_cam2_cam12_data.loc[:,(singlecam_ana_type,'scorch')]\n",
    "    bodyparts_cam2_cam12_scorch_data=pd.concat(bodyparts_cam2_cam12_scorch_data, axis=1)\n",
    "    # add lever\n",
    "    lever_x = np.ones((1,np.shape(bodyparts_cam2_cam12_scorch_data)[0]))*lever_locs_all['camera-2']['scorch'][0]\n",
    "    lever_y = np.ones((1,np.shape(bodyparts_cam2_cam12_scorch_data)[0]))*lever_locs_all['camera-2']['scorch'][1]\n",
    "    lever_likelihood = np.ones((1,np.shape(bodyparts_cam2_cam12_scorch_data)[0]))\n",
    "    bodyparts_cam2_cam12_scorch_data[(singlecam_ana_type,'lever','x')]=lever_x[0]\n",
    "    bodyparts_cam2_cam12_scorch_data[(singlecam_ana_type,'lever','y')]=lever_y[0]\n",
    "    bodyparts_cam2_cam12_scorch_data[(singlecam_ana_type,'lever','likelihood')]=lever_likelihood[0]\n",
    "    # add tube\n",
    "    tube_x = np.ones((1,np.shape(bodyparts_cam2_cam12_scorch_data)[0]))*tube_locs_all['camera-2']['scorch'][0]\n",
    "    tube_y = np.ones((1,np.shape(bodyparts_cam2_cam12_scorch_data)[0]))*tube_locs_all['camera-2']['scorch'][1]\n",
    "    tube_likelihood = np.ones((1,np.shape(bodyparts_cam2_cam12_scorch_data)[0]))\n",
    "    bodyparts_cam2_cam12_scorch_data[(singlecam_ana_type,'tube','x')]=tube_x[0]\n",
    "    bodyparts_cam2_cam12_scorch_data[(singlecam_ana_type,'tube','y')]=tube_y[0]\n",
    "    bodyparts_cam2_cam12_scorch_data[(singlecam_ana_type,'tube','likelihood')]=tube_likelihood[0]\n",
    "    #\n",
    "    bodyparts_cam2_cam12_scorch_data.to_hdf(bodyparts_cam2_cam12_scorch,key='tracks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the 3d recontruction h5 file\n",
    "#if do_3dconstruct:\n",
    "#    bodyparts_3d_cam12_DLC_data = pd.read_hdf(bodyparts_3d_cam12_DLC)\n",
    "#    bodyparts_3d_cam12_DLC_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## triangulation without filtering, should take < 15 seconds\n",
    "if do_3dconstruct:\n",
    "    # for the animal 1 - dodson\n",
    "    fname_dict = {\n",
    "        '1': bodyparts_cam1_cam12_dodson,\n",
    "        '2': bodyparts_cam2_cam12_dodson,\n",
    "    }\n",
    "\n",
    "    d = load_pose2d_fnames(fname_dict, cam_names=cgroup.get_names())\n",
    "\n",
    "    score_threshold = 0.1\n",
    "\n",
    "    n_cams, n_points, n_joints, _ = d['points'].shape\n",
    "    points = d['points']\n",
    "    scores = d['scores']\n",
    "\n",
    "    bodyparts = d['bodyparts']\n",
    "\n",
    "    # remove points that are below threshold\n",
    "    points[scores < score_threshold] = np.nan\n",
    "\n",
    "    points_flat = points.reshape(n_cams, -1, 2)\n",
    "    scores_flat = scores.reshape(n_cams, -1)\n",
    "\n",
    "    p3ds_flat = cgroup.triangulate(points_flat, progress=True)\n",
    "    reprojerr_flat = cgroup.reprojection_error(p3ds_flat, points_flat, mean=True)\n",
    "\n",
    "    p3ds = p3ds_flat.reshape(n_points, n_joints, 3)\n",
    "    reprojerr = reprojerr_flat.reshape(n_points, n_joints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the new files - animal 1 dodson\n",
    "if do_3dconstruct:\n",
    "    bodyparts_3d_dodson_anipose = {}\n",
    "    nbodyparts = np.shape(bodyparts)[0]\n",
    "    for ibodypart in np.arange(0,nbodyparts,1):\n",
    "        # remove outlier\n",
    "        ind_outlier_x = (p3ds[:,ibodypart,0]<(np.nanmean(p3ds[:,ibodypart,0])-2*np.nanstd(p3ds[:,ibodypart,0])))|(p3ds[:,ibodypart,0]>(np.nanmean(p3ds[:,ibodypart,0])+2*np.nanstd(p3ds[:,ibodypart,0])))\n",
    "        p3ds[ind_outlier_x,ibodypart,0]=np.nan\n",
    "        ind_outlier_y = (p3ds[:,ibodypart,1]<(np.nanmean(p3ds[:,ibodypart,1])-2*np.nanstd(p3ds[:,ibodypart,1])))|(p3ds[:,ibodypart,1]>(np.nanmean(p3ds[:,ibodypart,1])+2*np.nanstd(p3ds[:,ibodypart,1])))\n",
    "        p3ds[ind_outlier_y,ibodypart,1]=np.nan\n",
    "        ind_outlier_z = (p3ds[:,ibodypart,2]<(np.nanmean(p3ds[:,ibodypart,2])-2*np.nanstd(p3ds[:,ibodypart,2])))|(p3ds[:,ibodypart,2]>(np.nanmean(p3ds[:,ibodypart,2])+2*np.nanstd(p3ds[:,ibodypart,2])))\n",
    "        p3ds[ind_outlier_z,ibodypart,2]=np.nan\n",
    "\n",
    "        bodyparts_3d_dodson_anipose[('weikang','dodson',bodyparts[ibodypart],'x')] = p3ds[:,ibodypart, 0]\n",
    "        bodyparts_3d_dodson_anipose[('weikang','dodson',bodyparts[ibodypart],'y')] = p3ds[:,ibodypart, 1]\n",
    "        bodyparts_3d_dodson_anipose[('weikang','dodson',bodyparts[ibodypart],'z')] = p3ds[:,ibodypart, 2]\n",
    "    bodyparts_3d_dodson_anipose = pd.DataFrame(bodyparts_3d_dodson_anipose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## triangulation without filtering, should take < 15 seconds\n",
    "if do_3dconstruct:\n",
    "    # for the animal 1 - scorch\n",
    "    fname_dict = {\n",
    "        '1': bodyparts_cam1_cam12_scorch,\n",
    "        '2': bodyparts_cam2_cam12_scorch,\n",
    "    }\n",
    "\n",
    "    d = load_pose2d_fnames(fname_dict, cam_names=cgroup.get_names())\n",
    "\n",
    "    score_threshold = 0.1\n",
    "\n",
    "    n_cams, n_points, n_joints, _ = d['points'].shape\n",
    "    points = d['points']\n",
    "    scores = d['scores']\n",
    "\n",
    "    bodyparts = d['bodyparts']\n",
    "\n",
    "    # remove points that are below threshold\n",
    "    points[scores < score_threshold] = np.nan\n",
    "\n",
    "    points_flat = points.reshape(n_cams, -1, 2)\n",
    "    scores_flat = scores.reshape(n_cams, -1)\n",
    "\n",
    "    p3ds_flat = cgroup.triangulate(points_flat, progress=True)\n",
    "    reprojerr_flat = cgroup.reprojection_error(p3ds_flat, points_flat, mean=True)\n",
    "\n",
    "    p3ds = p3ds_flat.reshape(n_points, n_joints, 3)\n",
    "    reprojerr = reprojerr_flat.reshape(n_points, n_joints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the new files - animal 2 scorch\n",
    "if do_3dconstruct:\n",
    "    bodyparts_3d_scorch_anipose = {}\n",
    "    nbodyparts = np.shape(bodyparts)[0]\n",
    "    for ibodypart in np.arange(0,nbodyparts,1):\n",
    "        # remove outlier\n",
    "        ind_outlier_x = (p3ds[:,ibodypart,0]<(np.nanmean(p3ds[:,ibodypart,0])-2*np.nanstd(p3ds[:,ibodypart,0])))|(p3ds[:,ibodypart,0]>(np.nanmean(p3ds[:,ibodypart,0])+2*np.nanstd(p3ds[:,ibodypart,0])))\n",
    "        p3ds[ind_outlier_x,ibodypart,0]=np.nan\n",
    "        ind_outlier_y = (p3ds[:,ibodypart,1]<(np.nanmean(p3ds[:,ibodypart,1])-2*np.nanstd(p3ds[:,ibodypart,1])))|(p3ds[:,ibodypart,1]>(np.nanmean(p3ds[:,ibodypart,1])+2*np.nanstd(p3ds[:,ibodypart,1])))\n",
    "        p3ds[ind_outlier_y,ibodypart,1]=np.nan\n",
    "        ind_outlier_z = (p3ds[:,ibodypart,2]<(np.nanmean(p3ds[:,ibodypart,2])-2*np.nanstd(p3ds[:,ibodypart,2])))|(p3ds[:,ibodypart,2]>(np.nanmean(p3ds[:,ibodypart,2])+2*np.nanstd(p3ds[:,ibodypart,2])))\n",
    "        p3ds[ind_outlier_z,ibodypart,2]=np.nan\n",
    "        \n",
    "        bodyparts_3d_scorch_anipose[('weikang','scorch',bodyparts[ibodypart],'x')] = p3ds[:,ibodypart, 0]\n",
    "        bodyparts_3d_scorch_anipose[('weikang','scorch',bodyparts[ibodypart],'y')] = p3ds[:,ibodypart, 1]\n",
    "        bodyparts_3d_scorch_anipose[('weikang','scorch',bodyparts[ibodypart],'z')] = p3ds[:,ibodypart, 2]\n",
    "    bodyparts_3d_scorch_anipose = pd.DataFrame(bodyparts_3d_scorch_anipose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine the two animals \n",
    "if do_3dconstruct:\n",
    "    bodyparts_3d_anipose = pd.concat([bodyparts_3d_dodson_anipose,bodyparts_3d_scorch_anipose],axis=1)\n",
    "\n",
    "    # save the combine the two animal 3d file\n",
    "    import os\n",
    "    current_dir = os.getcwd()\n",
    "    add_date_dir = current_dir+'/anipose_3d_h5_files/'+date_tgt+'_'+animal1+'_'+animal2\n",
    "    if not os.path.exists(add_date_dir):\n",
    "        os.makedirs(add_date_dir)\n",
    "    bodyparts_3d_anipose_file = add_date_dir+'/'+date_tgt+'_'+animal1+'_'+animal2+'_anipose.h5'\n",
    "    bodyparts_3d_anipose.to_hdf(bodyparts_3d_anipose_file,key='tracks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load saved 3d_anipose h5 file\n",
    "if not do_3dconstruct:\n",
    "    import os\n",
    "    current_dir = os.getcwd()\n",
    "    add_date_dir = current_dir+'/anipose_3d_h5_files/'+date_tgt+'_'+animal1+'_'+animal2\n",
    "    bodyparts_3d_anipose_file = add_date_dir+'/'+date_tgt+'_'+animal1+'_'+animal2+'_anipose.h5'\n",
    "    bodyparts_3d_anipose = pd.read_hdf(bodyparts_3d_anipose_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodyparts_3d_anipose.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the x, y, z coordinates of joint 1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "plt.figure(figsize=(9.4, 6))\n",
    "plt.plot(bodyparts_3d_anipose[('weikang','dodson','rightTuft','x')])\n",
    "plt.plot(bodyparts_3d_anipose[('weikang','dodson','rightTuft','y')])\n",
    "plt.plot(bodyparts_3d_anipose[('weikang','dodson','rightTuft','z')])\n",
    "plt.xlabel(\"Time (frames)\")\n",
    "plt.ylabel(\"Coordinate (mm)\")\n",
    "plt.title(\"x, y, z coordinates of {}\".format('rightTuft'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the example videos\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/ws523/marmoset_tracking_DLCv2/following_up_analysis/3d_recontruction_analysis_joystick_task/ana_functions')\n",
    "from tracking_video_3d_demo import tracking_video_3d_demo\n",
    "\n",
    "animalnames_videotrack = ['dodson','scorch']\n",
    "#bodypartnames_videotrack = ['rightTuft','whiteBlaze','leftTuft','rightEye','leftEye','mouth','lever','tube','boxCorner1','boxCorner2','boxCorner3','boxCorner4']\n",
    "bodypartnames_videotrack = ['rightTuft','whiteBlaze','leftTuft','rightEye','leftEye','mouth','lever','tube']\n",
    "animal1_filename = animal1\n",
    "animal2_filename = animal2\n",
    "session_start_time = 1.00\n",
    "fps = 30\n",
    "nframes = 2*fps\n",
    "\n",
    "withboxCorner = 0\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "add_date_dir = current_dir+'/anipose_3d_demo_videos/'+date_tgt+'_'+animal1_filename+'_'+animal2_filename\n",
    "if not os.path.exists(add_date_dir):\n",
    "    os.makedirs(add_date_dir)\n",
    "video_file = add_date_dir+'/'+date_tgt+'_'+animal1_filename+'_'+animal2_filename+'_anipose_3d_tracking_demo.mp4'\n",
    "\n",
    "tracking_video_3d_demo(bodyparts_3d_anipose['weikang'],animalnames_videotrack,bodypartnames_videotrack,date_tgt,animal1_filename,animal2_filename,session_start_time,fps,nframes,video_file,withboxCorner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
