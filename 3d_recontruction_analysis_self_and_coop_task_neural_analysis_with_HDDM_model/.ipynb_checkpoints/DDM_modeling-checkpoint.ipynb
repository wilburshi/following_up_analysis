{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb02d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd # Added import for Pandas\n",
    "\n",
    "# import hddm\n",
    "# import pymc as pm # Explicitly import pymc for summary function\n",
    "# import arviz as az # Explicitly import arviz for summary function\n",
    "\n",
    "# from lifelines import CoxPHFitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d80ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions._apply_gaussian_burst import _apply_gaussian_burst\n",
    "from functions.generate_marmoset_pull_data import generate_marmoset_pull_data\n",
    "from functions.compute_stats import compute_stats\n",
    "from functions.align_and_plot_data import align_and_plot_data\n",
    "from functions.get_aligned_segment import get_aligned_segment\n",
    "from functions.analyze_pull_aligned_data import analyze_pull_aligned_data\n",
    "from functions.analyze_pull_aligned_data_flexibleTW import analyze_pull_aligned_data_flexibleTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a83b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hddm_modeling(df_animal_data, animal_id, samples, burn, thin): # Modified signature\n",
    "    \"\"\"\n",
    "    Runs the Hierarchical Drift-Diffusion Model for a single animal using the provided dataframe.\n",
    "\n",
    "    Args:\n",
    "        df_animal_data (pd.DataFrame): DataFrame for a single animal's trials.\n",
    "        animal_id (str): Identifier for the animal (e.g., 'animal1').\n",
    "        samples (int): Number of MCMC samples to draw.\n",
    "        burn (int): Number of burn-in samples to discard.\n",
    "        thin (int): Thinning interval for MCMC samples.\n",
    "\n",
    "    Returns:\n",
    "        hddm.HDDM: The fitted HDDM model object.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Running HDDM Modeling for {animal_id} ---\")\n",
    "\n",
    "    df_combined = df_animal_data # Directly use the single animal's data\n",
    "    \n",
    "    # Debugging prints\n",
    "    print(f\"\\n--- DataFrame Info for {animal_id} before HDDM ---\")\n",
    "    print(\"Columns:\", df_combined.columns.tolist())\n",
    "    print(\"Head:\\n\", df_combined.head())\n",
    "    print(\"Tail:\\n\", df_combined.tail())\n",
    "    print(\"Shape:\", df_combined.shape)\n",
    "    print(\"Is empty:\", df_combined.empty)\n",
    "    print(\"NaN counts per column:\\n\", df_combined.isnull().sum())\n",
    "\n",
    "    # List of all covariates used in depends_on and regressors\n",
    "    covariates = [\n",
    "        'self_gaze_auc',\n",
    "        'partner_mean_speed',\n",
    "        'failed_pulls_before_reward',\n",
    "        'time_since_last_reward',\n",
    "        'prev_trial_outcome' \n",
    "    ]\n",
    "\n",
    "    # Ensure all covariates are numeric and drop rows with NaNs in these specific columns\n",
    "    for col in covariates:\n",
    "        if col in df_combined.columns:\n",
    "            df_combined[col] = pd.to_numeric(df_combined[col], errors='coerce')\n",
    "        else:\n",
    "            print(f\"Error: Covariate column '{col}' not found in DataFrame for {animal_id}. Please check data preparation.\")\n",
    "            return None # Exit if critical column is missing\n",
    "\n",
    "    # Drop rows where any of the specified covariates or RT are NaN\n",
    "    df_combined = df_combined.dropna(subset=['rt'] + covariates)\n",
    "\n",
    "    print(f\"\\n--- DataFrame Info for {animal_id} AFTER NaN-dropping for HDDM ---\")\n",
    "    print(\"Columns:\", df_combined.columns.tolist())\n",
    "    print(\"Head:\\n\", df_combined.head())\n",
    "    print(\"Tail:\\n\", df_combined.tail())\n",
    "    print(\"Shape:\", df_combined.shape)\n",
    "    print(\"Is empty:\", df_combined.empty)\n",
    "    print(\"NaN counts per column:\\n\", df_combined.isnull().sum())\n",
    "\n",
    "    if df_combined.empty:\n",
    "        print(f\"Error: DataFrame for {animal_id} is empty after dropping NaNs for covariates. Cannot run HDDM.\")\n",
    "        return None\n",
    "\n",
    "    # Crucial check: Ensure covariates have variance. HDDM (PyMC) needs variability for regression.\n",
    "    for col in covariates:\n",
    "        if df_combined[col].nunique() < 2:\n",
    "            print(f\"Warning: Covariate '{col}' has no variance (only one unique value) in {animal_id}'s data after filtering. HDDM may fail or estimate it poorly for this covariate.\")\n",
    "            # If a covariate has no variance, it essentially can't be used as a regressor.\n",
    "            # You might consider removing it from depends_on/regressors if this is a persistent issue.\n",
    "\n",
    "    # Define the HDDM model\n",
    "    print(f\"Defining HDDMRegressor model for {animal_id} with dependencies:\")\n",
    "    print(f\"  v (drift rate) depends on: self_gaze_auc, partner_mean_speed\")\n",
    "    print(f\"  a (boundary separation) depends on: failed_pulls_before_reward, time_since_last_reward\")\n",
    "    print(f\"  z (starting bias) depends on: prev_trial_outcome (categorical)\") \n",
    "\n",
    "    \n",
    "    # Run MCMC sampling\n",
    "    print(f\"Sampling HDDM with {samples} samples, {burn} burn-in...\")\n",
    "    # # simple HDDM model\n",
    "    # model = hddm.HDDM(df_combined,\n",
    "    #                   include=['v','a','z','t'], # Explicitly include all core DDM parameters\n",
    "    #                   # depends_on={'v': ['self_gaze_auc', 'partner_mean_speed'],\n",
    "    #                   #             'a': ['failed_pulls_before_reward', 'time_since_last_reward'],\n",
    "    #                   #             'z': 'prev_trial_outcome'}\n",
    "    #                  ) \n",
    "    \n",
    "    # # Using HDDMRegressor for linear regression with continuous covariates\n",
    "    model = hddm.HDDMRegressor(\n",
    "                                    df_combined,\n",
    "                                    [\n",
    "                                        'v ~ self_gaze_auc + partner_mean_speed',\n",
    "                                        'a ~ failed_pulls_before_reward + time_since_last_reward'\n",
    "                                    ],\n",
    "                                    include=['v', 'a', 'z', 't'],\n",
    "                                    depends_on={'z': 'prev_trial_outcome'}\n",
    "                                )\n",
    "    \n",
    "    # for hypothesis test \n",
    "    model_nogaze = hddm.HDDMRegressor(\n",
    "                                        df_combined,\n",
    "                                        [\n",
    "                                            # 'v ~ partner_mean_speed',\n",
    "                                            'v ~ partner_mean_speed + failed_pulls_before_reward + time_since_last_reward',\n",
    "                                            'a ~ failed_pulls_before_reward + time_since_last_reward'\n",
    "                                        ],\n",
    "                                        include=['v', 'a', 'z', 't'],\n",
    "                                        depends_on={'z': 'prev_trial_outcome'}\n",
    "                                    )\n",
    "    \n",
    "    \n",
    "    # Run MCMC sampling\n",
    "    print(f\"Sampling HDDM with {samples} samples, {burn} burn-in, {thin} thinning...\")\n",
    "    # Modified this line: Removed 'thin' and used proper args for hddm 0.8.0 / PyMC3 API\n",
    "    m = model.sample(samples, burn=burn, \n",
    "                     dbname=f'traces_{animal_id}.db', db='pickle') # Saves traces to a file per animal\n",
    "    m_nogaze = model_nogaze.sample(samples, burn=burn, \n",
    "                             dbname=f'traces_{animal_id}.db', db='pickle') # Saves traces to a file per animal\n",
    "    \n",
    "    print(f\"\\n--- HDDM Sampling Complete for {animal_id} ---\")\n",
    "    \n",
    "    # Print summary of parameters\n",
    "    print(f\"\\n--- HDDM Parameter Summary for {animal_id} ---\")\n",
    "    \n",
    "    # model.print_stats()\n",
    "\n",
    "    # Optional: Plot posteriors (can be slow for many parameters)\n",
    "    # model.plot_posteriors()\n",
    "    # plt.show()\n",
    "\n",
    "    return model,model_nogaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main execution ---\n",
    "\n",
    "# 1. Generate the simulated data using the function from the Canvas.\n",
    "duration_s=500\n",
    "resolution_s=1/30\n",
    "num_pulls_animal1=50\n",
    "num_pulls_animal2=80\n",
    "num_coop_pulls=40\n",
    "coop_window_s=1\n",
    "correlation_strength=0.7\n",
    "prob_self_gaze_pre_self_pull=0.8\n",
    "prob_self_gaze_post_partner_pull=0.6\n",
    "#\n",
    "pull1_data, pull2_data, gaze1_data, gaze2_data, speed1_data, speed2_data, \\\n",
    "simulation_summary = generate_marmoset_pull_data(duration_s, resolution_s,  num_pulls_animal1, num_pulls_animal2, \n",
    "                                                 num_coop_pulls, coop_window_s, correlation_strength, \n",
    "                                                 prob_self_gaze_pre_self_pull,  prob_self_gaze_post_partner_pull)\n",
    "\n",
    "# 2. Extract resolution for alignment and analysis\n",
    "resolution = simulation_summary[\"resolution_s\"]\n",
    "coop_window = simulation_summary[\"coop_window_s\"] # Pass coop_window_s to analysis\n",
    "\n",
    "# 3. Call the plotting function\n",
    "window_s_pre=4\n",
    "window_s_post=4\n",
    "#\n",
    "align_and_plot_data(pull1_data, pull2_data, gaze1_data, gaze2_data, speed1_data, speed2_data, \n",
    "                    resolution, window_s_pre, window_s_post)\n",
    "\n",
    "# 4. Do the correlation analysis\n",
    "time_window_start_s=-4\n",
    "time_window_end_s=0\n",
    "#\n",
    "analysis_results = analyze_pull_aligned_data(pull1_data, pull2_data, gaze1_data, gaze2_data, speed1_data, speed2_data, \n",
    "                                             resolution, time_window_start_s, time_window_end_s, coop_window)\n",
    "\n",
    "analysis_results_flexibleTW = analyze_pull_aligned_data_flexibleTW(pull1_data, pull2_data, gaze1_data, gaze2_data, speed1_data, speed2_data, \n",
    "                                                                   resolution, time_window_start_s, time_window_end_s, coop_window)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab894a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(pull1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb11cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Run the HDDM modeling\n",
    "samples=200 # 2000\n",
    "burn=50\n",
    "thin=2\n",
    "\n",
    "if 'hddm_data_animal1' in analysis_results and 'hddm_data_animal2' in analysis_results:\n",
    "    # # hddm_model_fitted_a1, hddm_model_fitted_nogaze_a1 = run_hddm_modeling(analysis_results['hddm_data_animal1'], 'animal1', samples, burn, thin)\n",
    "    # # hddm_model_fitted_a2, hddm_model_fitted_nogaze_a2 = run_hddm_modeling(analysis_results['hddm_data_animal2'], 'animal2', samples, burn, thin)\n",
    "    # hddm_model_fitted_a1, hddm_model_fitted_nogaze_a1 = run_hddm_modeling(analysis_results_flexibleTW['hddm_data_animal1'], 'animal1', samples, burn, thin)\n",
    "    hddm_model_fitted_a2, hddm_model_fitted_nogaze_a2 = run_hddm_modeling(analysis_results_flexibleTW['hddm_data_animal2'], 'animal2', samples, burn, thin)\n",
    "else:\n",
    "    print(\"HDDM DataFrames not found in analysis results. Cannot run HDDM modeling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c08bd-db98-410f-99a2-dfa4c80db96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = hddm_model_fitted_nogaze_a2\n",
    "my_model.get_traces().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520bfc2-108a-45fd-8154-6e1376c78a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results['hddm_data_animal2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f68c2-a65c-48fd-8426-d91551175e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the accumulation slope (v in the model) in the model without social gaze, and then correlate the social gaze accumulation level and the accumulation slope\n",
    "# \n",
    "\n",
    "my_model = hddm_model_fitted_nogaze_a2\n",
    "df_combined = analysis_results['hddm_data_animal2']\n",
    "\n",
    "# --- STEP 1: Get the mean posterior estimates for all 'v' coefficients ---\n",
    "traces = my_model.get_traces()\n",
    "\n",
    "# Get the mean value for the intercept\n",
    "v_intercept_mean = traces['v_Intercept'].mean()\n",
    "\n",
    "# Get the mean value for the coefficient of each predictor\n",
    "# v_gaze_coef_mean = traces['v_self_gaze_auc'].mean()\n",
    "v_speed_coef_mean = traces['v_partner_mean_speed'].mean()\n",
    "v_failed_pulls_before_reward_mean = traces['v_failed_pulls_before_reward'].mean()\n",
    "v_time_since_last_reward_mean = traces['v_time_since_last_reward'].mean()\n",
    "\n",
    "\n",
    "print(f\"Mean v_Intercept: {v_intercept_mean:.3f}\")\n",
    "# print(f\"Mean v_self_gaze_auc Coef: {v_gaze_coef_mean:.3f}\")\n",
    "print(f\"Mean v_partner_mean_speed Coef: {v_speed_coef_mean:.3f}\")\n",
    "print(f\"Mean v_failed_pulls_before_reward Coef: {v_failed_pulls_before_reward_mean:.3f}\")\n",
    "print(f\"Mean v_time_since_last_reward Coef: {v_time_since_last_reward_mean:.3f}\")\n",
    "\n",
    "\n",
    "# --- STEP 2: Apply the regression equation to your dataframe ---\n",
    "# This calculates the predicted 'v' for each trial based on its unique covariate values.\n",
    "df_with_v = df_combined.copy() # Work with a copy\n",
    "\n",
    "df_with_v['predicted_v'] = (v_intercept_mean +\n",
    "                              # (v_gaze_coef_mean * df_with_v['self_gaze_auc']) +\n",
    "                              (v_speed_coef_mean * df_with_v['partner_mean_speed'])+\n",
    "                              (v_failed_pulls_before_reward_mean * df_with_v['failed_pulls_before_reward'])+\n",
    "                              (v_time_since_last_reward_mean * df_with_v['time_since_last_reward']))\n",
    "\n",
    "# --- Plotting and Analysis ---\n",
    "\n",
    "# 1. Calculate the correlation coefficient (r) and the p-value\n",
    "r_value, p_value = pearsonr(df_with_v['self_gaze_auc'], df_with_v['predicted_v'])\n",
    "\n",
    "# 2. Create the scatter plot with a regression line using seaborn\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.regplot(x='self_gaze_auc', y='predicted_v', data=df_with_v,\n",
    "            line_kws={\"color\": \"red\", \"linewidth\": 2},\n",
    "            scatter_kws={\"alpha\": 0.6, \"s\": 50})\n",
    "\n",
    "# 3. Add titles and labels for clarity\n",
    "plt.title('Relationship Between Self-Gaze and Predicted Drift Rate (v)', fontsize=16)\n",
    "plt.xlabel('Self Gaze AUC', fontsize=12)\n",
    "plt.ylabel('Predicted Drift Rate (v) from HDDM Model', fontsize=12)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# 4. Annotate the plot with the statistics\n",
    "stats_text = f\"Pearson's r = {r_value:.4f}\\np-value = {p_value:.4f}\"\n",
    "plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes,\n",
    "         fontsize=12, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round,pad=0.5', fc='wheat', alpha=0.5))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print the statistics as well\n",
    "print(\"Regression Statistics:\")\n",
    "print(f\"Pearson's r: {r_value:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c6be5-74bd-49cf-ae6b-d099bc525f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = hddm_model_fitted_a2\n",
    "# my_model = hddm_model_fitted_nogaze_a2\n",
    "my_model.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16be5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a prediction model to predict the pull based on the hddm model fitting\n",
    "# --- Extract 'a' (new step) ---\n",
    "my_model = hddm_model_fitted_nogaze_a1\n",
    "df_combined = analysis_results['hddm_data_animal1']\n",
    "\n",
    "# --- STEP 1: Get the mean posterior estimates for all 'v' coefficients ---\n",
    "traces = my_model.get_traces()\n",
    "\n",
    "# Get the mean value for the intercept\n",
    "v_intercept_mean = traces['v_Intercept'].mean()\n",
    "\n",
    "# Get the mean value for the coefficient of each predictor\n",
    "# v_gaze_coef_mean = traces['v_self_gaze_auc'].mean()\n",
    "v_speed_coef_mean = traces['v_partner_mean_speed'].mean()\n",
    "v_failed_pulls_before_reward_mean = traces['v_failed_pulls_before_reward'].mean()\n",
    "v_time_since_last_reward_mean = traces['v_time_since_last_reward'].mean()\n",
    "\n",
    "# --- STEP 2: Apply the regression equation to your dataframe ---\n",
    "# This calculates the predicted 'v' for each trial based on its unique covariate values.\n",
    "df_lifelines = df_combined.copy() # Work with a copy\n",
    "\n",
    "df_lifelines['predicted_v']  = (v_intercept_mean +\n",
    "                              # (v_gaze_coef_mean * df_with_v['self_gaze_auc']) +\n",
    "                              (v_speed_coef_mean * df_with_v['partner_mean_speed'])+\n",
    "                              (v_failed_pulls_before_reward_mean * df_with_v['failed_pulls_before_reward'])+\n",
    "                              (v_time_since_last_reward_mean * df_with_v['time_since_last_reward']))\n",
    "\n",
    "\n",
    "\n",
    "a_intercept_mean = traces['a_Intercept'].mean()\n",
    "a_failed_pulls_coef = traces['a_failed_pulls_before_reward'].mean()\n",
    "# ... other a coefficients ...\n",
    "df_lifelines['predicted_a'] = (a_intercept_mean + (a_failed_pulls_coef * df_lifelines['failed_pulls_before_reward']))\n",
    "\n",
    "# --- Extract 'z' (new step) ---\n",
    "# Get the mean z values for each condition\n",
    "z_after_failure = traces['z_trans(0)'].mean()\n",
    "z_after_success = traces['z_trans(1)'].mean()\n",
    "# Create the predicted_z column based on the previous trial's outcome\n",
    "df_lifelines['predicted_z'] = np.where(df_lifelines['prev_trial_outcome'] == 0, z_after_failure, z_after_success)\n",
    "\n",
    "\n",
    "## --- Part 2: Fit the Cox Proportional Hazards Model ---\n",
    "print(\"\\n--- Step 2: Fitting the Cox Proportional Hazards Model ---\")\n",
    "\n",
    "df_for_fitting = df_lifelines[['rt', 'response', 'predicted_v', 'predicted_a', 'predicted_z']]\n",
    "# df_for_fitting = df_lifelines[['rt', 'response', 'predicted_v']]\n",
    "\n",
    "# cph = CoxPHFitter()\n",
    "cph = CoxPHFitter(penalizer=0.01)\n",
    "\n",
    "cph.fit(df_for_fitting, duration_col='rt', event_col='response')\n",
    "print(\"Model Fit Summary:\")\n",
    "cph.print_summary()\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- Part 3: Prepare Continuous Timeline for Prediction ---\n",
    "print(\"\\n--- Step 3: Preparing Continuous Timeline ---\")\n",
    "# Define the total length and resolution of your prediction timeline\n",
    "total_experiment_seconds = df_for_fitting['rt'].sum()\n",
    "prediction_timestep = 0.1 # Make a prediction every 100ms (10 Hz)\n",
    "# Create the continuous timeline dataframe\n",
    "timeline_df = pd.DataFrame({'time': np.arange(0, total_experiment_seconds, prediction_timestep)})\n",
    "# Get the absolute time when each pull (event) occurred\n",
    "event_times = df_for_fitting['rt'].cumsum().rename('time')\n",
    "\n",
    "# Create a dataframe of the covariate values at the time of each event\n",
    "covariates_at_events = df_for_fitting[['predicted_v', 'predicted_a', 'predicted_z']].set_index(event_times)\n",
    "# covariates_at_events = df_for_fitting[['predicted_v']].set_index(event_times)\n",
    "\n",
    "# Map the covariate values onto the continuous timeline\n",
    "timeline_with_covariates = pd.merge_asof(timeline_df, covariates_at_events, on='time')\n",
    "timeline_with_covariates = timeline_with_covariates.ffill().dropna()\n",
    "print(\"Timeline prepared for prediction.\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- Part 4: Run Stochastic Simulation to Predict Pulls ---\n",
    "# This part replaces the simple thresholding method.\n",
    "print(\"\\n--- Step 4: Running Stochastic Simulation ---\")\n",
    "# 4a: Predict the partial hazard (the step function based on covariates)\n",
    "partial_hazard = cph.predict_partial_hazard(timeline_with_covariates)\n",
    "timeline_with_covariates['partial_hazard'] = partial_hazard.values\n",
    "\n",
    "# 4b: Get the baseline hazard from the fitted model\n",
    "baseline_hazard_df = cph.baseline_hazard_\n",
    "\n",
    "# 4c: Map the baseline hazard onto our continuous timeline\n",
    "# MODIFICATION 3: Add .bfill() to fix the NaN issue at the beginning of the timeline.\n",
    "timeline_with_full_hazard = pd.merge(timeline_with_covariates, baseline_hazard_df,\n",
    "                                     left_on='time', right_index=True, how='left').ffill().bfill()\n",
    "\n",
    "# 4d: Calculate the full, time-varying hazard\n",
    "# Full Hazard h(t) = Baseline Hazard h₀(t) * Partial Hazard (from covariates)\n",
    "timeline_with_full_hazard['full_hazard'] = (timeline_with_full_hazard['baseline hazard'] *\n",
    "                                             timeline_with_full_hazard['partial_hazard'])\n",
    "\n",
    "# 4e: Run the simulation loop\n",
    "binary_prediction_list = []\n",
    "pulls_predicted_count = 0\n",
    "for index, row in timeline_with_full_hazard.iterrows():\n",
    "    # Calculate the probability of a pull in this specific time step\n",
    "    prob_of_pull = row['full_hazard'] * prediction_timestep\n",
    "    # Ensure probability is not > 1\n",
    "    prob_of_pull = min(prob_of_pull, 1.0)\n",
    "    # Simulate a \"coin flip\" weighted by this probability\n",
    "    if np.random.rand() < prob_of_pull:\n",
    "        binary_prediction_list.append(1)\n",
    "        pulls_predicted_count += 1\n",
    "    else:\n",
    "        binary_prediction_list.append(0)\n",
    "\n",
    "# Add the final prediction to our dataframe\n",
    "timeline_with_full_hazard['stochastic_prediction'] = binary_prediction_list\n",
    "print(f\"Simulation complete. Predicted {pulls_predicted_count} pulls.\")\n",
    "print(\"Sample of timeline with final predictions:\")\n",
    "print(timeline_with_full_hazard[['time', 'full_hazard', 'stochastic_prediction']].head(20))\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- Part 5: Visualize the Results of the Simulation ---\n",
    "print(\"\\n--- Step 5: Visualizing the Prediction ---\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(16, 7))\n",
    "\n",
    "# Plot the full predicted hazard over time\n",
    "ax.plot(timeline_with_full_hazard['time'], timeline_with_full_hazard['full_hazard'],\n",
    "        label='Full Predicted Hazard h(t)', color='mediumseagreen', alpha=0.9)\n",
    "\n",
    "# Mark the actual pull times from the data\n",
    "ax.vlines(event_times, ymin=0, ymax=ax.get_ylim()[1], color='black', linestyle='-',\n",
    "          alpha=0.7, label='Actual Pulls', linewidth=1.5)\n",
    "\n",
    "# Mark the predicted pull times from the stochastic simulation\n",
    "predicted_pull_df = timeline_with_full_hazard[timeline_with_full_hazard['stochastic_prediction'] == 1]\n",
    "ax.scatter(predicted_pull_df['time'], [ax.get_ylim()[1] * 0.95] * len(predicted_pull_df),\n",
    "           color='red', marker='v', s=80, label='Predicted Pulls (from Simulation)', zorder=5)\n",
    "\n",
    "ax.set_xlabel('Time (seconds)', fontsize=12)\n",
    "ax.set_ylabel('Full Predicted Hazard Rate', fontsize=12)\n",
    "ax.set_title('Stochastic Simulation of Pull Events Based on Predicted Hazard', fontsize=16)\n",
    "ax.legend()\n",
    "ax.set_xlim(0, 500) # Zoom in on the first 150 seconds for clarity\n",
    "ax.set_ylim(bottom=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67aec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prerequisite: You must have a fitted Cox model 'cph' ---\n",
    "# and your dataframe 'df_for_fitting' from the previous steps.\n",
    "\n",
    "print(\"\\n--- Evaluating Model with a Deterministic Method ---\")\n",
    "\n",
    "# --- Step 1: Predict the Median Survival Time for each Interval ---\n",
    "# This gives us the model's single best guess for the duration of each IPI.\n",
    "predicted_durations = cph.predict_median(df_for_fitting)\n",
    "df_for_fitting['predicted_rt'] = predicted_durations.values\n",
    "\n",
    "# --- Step 2: Calculate the Predicted Pull Times ---\n",
    "# We can see when the model predicted pulls would happen by taking the\n",
    "# cumulative sum of the predicted durations.\n",
    "actual_pull_times = df_for_fitting['rt'].cumsum()\n",
    "predicted_pull_times = df_for_fitting['predicted_rt'].cumsum()\n",
    "\n",
    "print(\"Comparison of first 10 actual vs. predicted pull times:\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Pull Time': actual_pull_times,\n",
    "    'Predicted Pull Time': predicted_pull_times\n",
    "})\n",
    "print(comparison_df.head(10))\n",
    "\n",
    "# --- Step 3: Visualize the Comparison ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot actual vs. predicted times in a scatter plot\n",
    "ax.scatter(actual_pull_times, predicted_pull_times, alpha=0.7, edgecolors='k')\n",
    "\n",
    "# Add a y=x line. Perfect predictions would fall on this line.\n",
    "perfect_line_max = max(actual_pull_times.max(), predicted_pull_times.max())\n",
    "ax.plot([0, perfect_line_max], [0, perfect_line_max], 'r--', label='Perfect Prediction (y=x)')\n",
    "\n",
    "ax.set_xlabel('Actual Pull Time (seconds)', fontsize=12)\n",
    "ax.set_ylabel('Predicted Pull Time (seconds)', fontsize=12)\n",
    "ax.set_title('Model Predictive Accuracy: Actual vs. Predicted Pull Times', fontsize=16)\n",
    "ax.legend()\n",
    "ax.axis('equal') # Ensure the plot is square for easy comparison\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8711c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c549e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60da7c27-3d1a-403c-9ff6-9c745ee118d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
